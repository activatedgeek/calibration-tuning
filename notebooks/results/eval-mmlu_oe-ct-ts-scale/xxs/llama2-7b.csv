N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.8181818127632141,0.25,0.2208840576085177,mmlu_offline:llama2-7b:abstract_algebra,validation,3.587974315043539
100,0.2199999988079071,0.7799999713897705,0.4831002331002331,0.19124611139297484,mmlu_offline:llama2-7b:abstract_algebra,test,4.392478338908404
14,0.2857142984867096,0.5714285969734192,0.25,0.10467244046075007,mmlu_offline:llama2-7b:anatomy,validation,0.77691302401945
135,0.4148148000240326,0.585185170173645,0.4967224231464737,0.05669267045127019,mmlu_offline:llama2-7b:anatomy,test,4.82159847766161
16,0.4375,0.5625,0.6507936507936508,0.04462525248527528,mmlu_offline:llama2-7b:astronomy,validation,0.9288903553970158
152,0.5065789222717285,0.5197368264198303,0.5553246753246753,0.10113442806821123,mmlu_offline:llama2-7b:astronomy,test,6.905427752062678
11,0.6363636255264282,0.6363636255264282,0.10714285714285714,0.43543597243048926,mmlu_offline:llama2-7b:business_ethics,validation,0.8242773148231208
100,0.30000001192092896,0.3199999928474426,0.4342857142857143,0.34717179417610167,mmlu_offline:llama2-7b:business_ethics,test,5.529323526658118
29,0.24137930572032928,0.7586206793785095,0.45779220779220775,0.19428581821507426,mmlu_offline:llama2-7b:clinical_knowledge,validation,1.332770791836083
265,0.35849055647850037,0.6188679337501526,0.5061300309597523,0.012124047189388632,mmlu_offline:llama2-7b:clinical_knowledge,test,10.3163418546319
16,0.3125,0.5,0.5818181818181818,0.08887080103158951,mmlu_offline:llama2-7b:college_biology,validation,0.899062030017376
144,0.2986111044883728,0.3680555522441864,0.5267096477089569,0.20417874223656124,mmlu_offline:llama2-7b:college_biology,test,6.871576642151922
8,0.125,0.375,0.6428571428571428,0.3373560607433319,mmlu_offline:llama2-7b:college_chemistry,validation,0.589326404966414
100,0.14000000059604645,0.2800000011920929,0.5897009966777409,0.3177652132511139,mmlu_offline:llama2-7b:college_chemistry,test,5.598166070878506
11,0.0,0.4545454680919647,,0.17179638147354123,mmlu_offline:llama2-7b:college_computer_science,validation,1.139532313682139
100,0.17000000178813934,0.5099999904632568,0.5212615166548548,0.07491710245609283,mmlu_offline:llama2-7b:college_computer_science,test,8.822606568224728
11,0.0,0.4545454680919647,,0.157167911529541,mmlu_offline:llama2-7b:college_mathematics,validation,0.9524826579727232
100,0.1599999964237213,0.5299999713897705,0.5825892857142856,0.053964631557464615,mmlu_offline:llama2-7b:college_mathematics,test,6.383672744035721
22,0.3636363744735718,0.6363636255264282,0.5982142857142857,0.07702089168808679,mmlu_offline:llama2-7b:college_medicine,validation,1.2669354840181768
173,0.36994218826293945,0.5028901696205139,0.5201404816513762,0.05022108485932982,mmlu_offline:llama2-7b:college_medicine,test,11.809883441776037
11,0.27272728085517883,0.5454545617103577,0.625,0.044013213027607315,mmlu_offline:llama2-7b:college_physics,validation,0.8959292382933199
102,0.14705882966518402,0.38235294818878174,0.5279693486590038,0.17512551826589248,mmlu_offline:llama2-7b:college_physics,test,5.996081801131368
11,0.7272727489471436,0.9090909361839294,0.9791666666666667,0.3196150443770669,mmlu_offline:llama2-7b:computer_security,validation,0.750569743104279
100,0.4300000071525574,0.46000000834465027,0.5856793145654834,0.13942830085754396,mmlu_offline:llama2-7b:computer_security,test,4.33639579731971
26,0.3076923191547394,0.6153846383094788,0.7430555555555556,0.08198393995945269,mmlu_offline:llama2-7b:conceptual_physics,validation,1.16002352302894
235,0.4127659499645233,0.45957446098327637,0.46481398476019725,0.07607263529554324,mmlu_offline:llama2-7b:conceptual_physics,test,8.548519966192544
12,0.0833333358168602,0.3333333432674408,0.7272727272727273,0.42690374453862506,mmlu_offline:llama2-7b:econometrics,validation,0.9810547181405127
114,0.14912280440330505,0.5263158082962036,0.43905397210430563,0.15193388859430948,mmlu_offline:llama2-7b:econometrics,test,7.475036760326475
16,0.125,0.875,0.25,0.2510361149907112,mmlu_offline:llama2-7b:electrical_engineering,validation,0.9235433177091181
145,0.1862068921327591,0.8068965673446655,0.496390458254865,0.18866046584885693,mmlu_offline:llama2-7b:electrical_engineering,test,7.053217240143567
41,0.26829269528388977,0.6341463327407837,0.5924242424242424,0.08645689487457274,mmlu_offline:llama2-7b:elementary_mathematics,validation,2.257607747800648
378,0.32275131344795227,0.523809552192688,0.5174660604508197,0.03340257302163143,mmlu_offline:llama2-7b:elementary_mathematics,test,19.036531019955873
14,0.5,0.6428571343421936,0.693877551020408,0.17357067550931657,mmlu_offline:llama2-7b:formal_logic,validation,0.9917569481767714
126,0.30158731341362,0.5634920597076416,0.4373504784688995,0.019522514608171226,mmlu_offline:llama2-7b:formal_logic,test,7.22975295688957
10,0.30000001192092896,0.5,0.33333333333333337,0.08118304610252383,mmlu_offline:llama2-7b:global_facts,validation,0.6730749998241663
100,0.17000000178813934,0.3199999928474426,0.5981573352232459,0.23274673223495485,mmlu_offline:llama2-7b:global_facts,test,4.546237679198384
32,0.15625,0.34375,0.6888888888888889,0.24963785894215107,mmlu_offline:llama2-7b:high_school_biology,validation,1.6294861808419228
310,0.41290321946144104,0.42258065938949585,0.5052798763736264,0.18373758369876494,mmlu_offline:llama2-7b:high_school_biology,test,14.586034920997918
22,0.13636364042758942,0.13636364042758942,0.456140350877193,0.5068200772458857,mmlu_offline:llama2-7b:high_school_chemistry,validation,1.3655123771168292
203,0.16748768091201782,0.19211822748184204,0.46562826313957534,0.44942904399533573,mmlu_offline:llama2-7b:high_school_chemistry,test,10.883767965249717
9,0.2222222238779068,0.8888888955116272,0.8571428571428572,0.31884767611821485,mmlu_offline:llama2-7b:high_school_computer_science,validation,0.8935182150453329
100,0.3700000047683716,0.5699999928474426,0.5540540540540541,0.06082317233085637,mmlu_offline:llama2-7b:high_school_computer_science,test,7.8901574849151075
18,0.7222222089767456,0.5,0.14615384615384616,0.06531319353315565,mmlu_offline:llama2-7b:high_school_european_history,validation,5.636462328955531
165,0.6727272868156433,0.5575757622718811,0.5103436770103437,0.0467882109410835,mmlu_offline:llama2-7b:high_school_european_history,test,50.858610874041915
22,0.4545454680919647,0.4545454680919647,0.575,0.1220022114840421,mmlu_offline:llama2-7b:high_school_geography,validation,0.9804196138866246
198,0.3636363744735718,0.4595959484577179,0.6342592592592592,0.09366853791053847,mmlu_offline:llama2-7b:high_school_geography,test,7.99276294792071
21,0.4285714328289032,0.5714285969734192,0.4444444444444444,0.1459567490078154,mmlu_offline:llama2-7b:high_school_government_and_politics,validation,1.084243851248175
193,0.48704662919044495,0.5181347131729126,0.5870943477326457,0.0885296179840602,mmlu_offline:llama2-7b:high_school_government_and_politics,test,7.913009464740753
43,0.41860464215278625,0.4883720874786377,0.5333333333333333,0.10415732028872464,mmlu_offline:llama2-7b:high_school_macroeconomics,validation,1.802602319046855
390,0.34358975291252136,0.4692307710647583,0.4948985541044776,0.08837530643512038,mmlu_offline:llama2-7b:high_school_macroeconomics,test,15.043825450818986
29,0.03448275849223137,0.6206896305084229,0.375,0.06797218528287167,mmlu_offline:llama2-7b:high_school_mathematics,validation,1.9497316591441631
270,0.08148147910833359,0.5592592358589172,0.5561766862170089,0.014331443662996612,mmlu_offline:llama2-7b:high_school_mathematics,test,15.685558665078133
26,0.3076923191547394,0.4615384638309479,0.47222222222222227,0.09552158759190485,mmlu_offline:llama2-7b:high_school_microeconomics,validation,1.1904420512728393
238,0.32773110270500183,0.4957983195781708,0.5242788461538461,0.053382876039553114,mmlu_offline:llama2-7b:high_school_microeconomics,test,9.07570742117241
17,0.23529411852359772,0.1764705926179886,0.6057692307692308,0.4835050246294807,mmlu_offline:llama2-7b:high_school_physics,validation,1.194145877379924
151,0.17880794405937195,0.21192052960395813,0.5595878136200717,0.42498293144023974,mmlu_offline:llama2-7b:high_school_physics,test,8.591803587973118
60,0.5,0.5333333611488342,0.683888888888889,0.05508294502894086,mmlu_offline:llama2-7b:high_school_psychology,validation,3.052925072144717
545,0.5064220428466797,0.5119265913963318,0.528096546522278,0.07357953010349098,mmlu_offline:llama2-7b:high_school_psychology,test,26.137641042936593
23,0.1304347813129425,0.21739129722118378,0.5083333333333333,0.42926461541134375,mmlu_offline:llama2-7b:high_school_statistics,validation,1.8423428609967232
216,0.24074074625968933,0.2638888955116272,0.4427767354596623,0.3808203314741453,mmlu_offline:llama2-7b:high_school_statistics,test,15.36873754998669
22,0.5909090638160706,0.5454545617103577,0.6452991452991453,0.03465425697239964,mmlu_offline:llama2-7b:high_school_us_history,validation,5.390390025917441
204,0.5980392098426819,0.4166666567325592,0.5390843662534986,0.17295258068570904,mmlu_offline:llama2-7b:high_school_us_history,test,48.898772805929184
26,0.5384615659713745,0.5384615659713745,0.4464285714285714,0.07136097321143522,mmlu_offline:llama2-7b:high_school_world_history,validation,4.7842686315998435
237,0.4345991611480713,0.4514767825603485,0.5197797420663672,0.14472325366257618,mmlu_offline:llama2-7b:high_school_world_history,test,38.34859683783725
23,0.21739129722118378,0.21739129722118378,0.4277777777777778,0.4031746698462445,mmlu_offline:llama2-7b:human_aging,validation,1.0121714873239398
223,0.340807169675827,0.35426008701324463,0.4835750089509488,0.2674554514243464,mmlu_offline:llama2-7b:human_aging,test,8.24520902801305
12,0.4166666567325592,0.3333333432674408,0.24285714285714288,0.2138843387365341,mmlu_offline:llama2-7b:human_sexuality,validation,0.6584426811896265
131,0.47328245639801025,0.4885496199131012,0.5017531556802244,0.05598408438777198,mmlu_offline:llama2-7b:human_sexuality,test,5.262066794093698
13,0.23076923191547394,0.6153846383094788,0.5833333333333333,0.06291466951370236,mmlu_offline:llama2-7b:international_law,validation,0.8642360423691571
121,0.4876033067703247,0.5619834661483765,0.5528977583378895,0.013928625209272377,mmlu_offline:llama2-7b:international_law,test,5.951261830050498
11,0.4545454680919647,0.5454545617103577,0.7166666666666667,0.07588770172812723,mmlu_offline:llama2-7b:jurisprudence,validation,0.6835414473898709
108,0.37037035822868347,0.6018518805503845,0.468014705882353,0.06656516481328896,mmlu_offline:llama2-7b:jurisprudence,test,4.491695191711187
18,0.4444444477558136,0.4444444477558136,0.5375,0.09267589781019425,mmlu_offline:llama2-7b:logical_fallacies,validation,1.036066039931029
163,0.42944785952568054,0.46625766158103943,0.4744239631336405,0.07764684020375913,mmlu_offline:llama2-7b:logical_fallacies,test,7.336057400330901
11,0.27272728085517883,0.7272727489471436,0.75,0.1396720897067677,mmlu_offline:llama2-7b:machine_learning,validation,0.9005031171254814
112,0.2857142984867096,0.7142857313156128,0.5025390625,0.12674457473414286,mmlu_offline:llama2-7b:machine_learning,test,6.80063087400049
11,0.4545454680919647,0.5454545617103577,0.7833333333333333,0.14633561806245288,mmlu_offline:llama2-7b:management,validation,0.6068379748612642
103,0.4563106894493103,0.553398072719574,0.49183130699088146,0.06253928871988096,mmlu_offline:llama2-7b:management,test,3.5523972930386662
25,0.2800000011920929,0.6399999856948853,0.4880952380952381,0.15482008457183835,mmlu_offline:llama2-7b:marketing,validation,1.3461063150316477
234,0.4572649598121643,0.504273533821106,0.5084259327397159,0.04283121865019841,mmlu_offline:llama2-7b:marketing,test,9.562677496112883
11,0.7272727489471436,0.4545454680919647,0.5416666666666667,0.10249795155091719,mmlu_offline:llama2-7b:medical_genetics,validation,0.628323417622596
100,0.4699999988079071,0.550000011920929,0.6071858691288639,0.02875718832015993,mmlu_offline:llama2-7b:medical_genetics,test,3.6292364047840238
86,0.5465116500854492,0.5930232405662537,0.5062738679759957,0.09425300567649136,mmlu_offline:llama2-7b:miscellaneous,validation,3.4622156070545316
783,0.5874840617179871,0.5989782810211182,0.5262585812356979,0.028030467063835565,mmlu_offline:llama2-7b:miscellaneous,test,28.277622462250292
38,0.42105263471603394,0.4736842215061188,0.32528409090909094,0.07767664131365326,mmlu_offline:llama2-7b:moral_disputes,validation,1.896175286732614
346,0.41040462255477905,0.5404624342918396,0.5103044739022369,0.005573212928165549,mmlu_offline:llama2-7b:moral_disputes,test,15.460153088904917
100,0.3499999940395355,0.6299999952316284,0.525934065934066,0.10511643171310425,mmlu_offline:llama2-7b:moral_scenarios,validation,6.921061598230153
895,0.3173184394836426,0.632402241230011,0.5044835296558401,0.11226198773144339,mmlu_offline:llama2-7b:moral_scenarios,test,60.31954276608303
33,0.3636363744735718,0.39393940567970276,0.4523809523809524,0.1670151912804806,mmlu_offline:llama2-7b:nutrition,validation,1.832067629788071
306,0.38235294818878174,0.5359477400779724,0.5703884592773483,0.01196680972778722,mmlu_offline:llama2-7b:nutrition,test,15.173601310700178
34,0.29411765933036804,0.47058823704719543,0.6958333333333334,0.1448514303740333,mmlu_offline:llama2-7b:philosophy,validation,1.5181987541727722
311,0.3247588276863098,0.3954983949661255,0.4671145685997171,0.15696137031941554,mmlu_offline:llama2-7b:philosophy,test,11.685265602078289
35,0.3142857253551483,0.6857143044471741,0.5738636363636364,0.08554316929408484,mmlu_offline:llama2-7b:prehistory,validation,1.7702946849167347
324,0.4166666567325592,0.5586419701576233,0.43758573388203015,0.05297098501964855,mmlu_offline:llama2-7b:prehistory,test,14.134428356774151
31,0.12903225421905518,0.8064516186714172,0.2962962962962963,0.22022237700800745,mmlu_offline:llama2-7b:professional_accounting,validation,2.454256873112172
282,0.152482271194458,0.804964542388916,0.4824851610392138,0.22098892314214233,mmlu_offline:llama2-7b:professional_accounting,test,21.105109001044184
170,0.3117647171020508,0.6529411673545837,0.5095952265763586,0.08031243191045871,mmlu_offline:llama2-7b:professional_law,validation,26.137497046031058
1534,0.2777053415775299,0.6877444386482239,0.4935054066880223,0.10206835020474382,mmlu_offline:llama2-7b:professional_law,test,239.03395852120593
31,0.4193548262119293,0.6129032373428345,0.7307692307692308,0.058041097656373025,mmlu_offline:llama2-7b:professional_medicine,validation,3.924428927246481
272,0.27941176295280457,0.3602941036224365,0.4616004296455424,0.2035058881430065,mmlu_offline:llama2-7b:professional_medicine,test,34.05894194776192
69,0.3913043439388275,0.49275362491607666,0.5066137566137566,0.06756729146708615,mmlu_offline:llama2-7b:professional_psychology,validation,3.776324790902436
612,0.30882352590560913,0.5506535768508911,0.5122956458653859,0.01729120177770756,mmlu_offline:llama2-7b:professional_psychology,test,30.029904930852354
12,0.4166666567325592,0.5833333134651184,0.45714285714285713,0.13701214392979938,mmlu_offline:llama2-7b:public_relations,validation,0.7543426090851426
110,0.3181818127632141,0.6090909242630005,0.504952380952381,0.04784863862124359,mmlu_offline:llama2-7b:public_relations,test,4.674043661914766
27,0.5925925970077515,0.4444444477558136,0.5909090909090908,0.14046410057279798,mmlu_offline:llama2-7b:security_studies,validation,1.7666728519834578
245,0.5306122303009033,0.5061224699020386,0.5051170568561872,0.06586490942507374,mmlu_offline:llama2-7b:security_studies,test,14.306345579214394
22,0.3181818127632141,0.6818181872367859,0.7380952380952381,0.09612964500080456,mmlu_offline:llama2-7b:sociology,validation,1.0414993148297071
201,0.3781094551086426,0.5970149040222168,0.5629473684210526,0.028866077536967242,mmlu_offline:llama2-7b:sociology,test,7.96139468671754
11,0.6363636255264282,0.3636363744735718,0.5714285714285714,0.360464404929768,mmlu_offline:llama2-7b:us_foreign_policy,validation,0.6614582501351833
100,0.5799999833106995,0.41999998688697815,0.5578817733990148,0.30146497786045073,mmlu_offline:llama2-7b:us_foreign_policy,test,4.080695699900389
18,0.5,0.5555555820465088,0.45679012345679015,0.1905593938297696,mmlu_offline:llama2-7b:virology,validation,1.0559934577904642
166,0.3313252925872803,0.5722891688346863,0.4439803439803439,0.02607236784624766,mmlu_offline:llama2-7b:virology,test,6.613151555880904
19,0.7368420958518982,0.6315789222717285,0.7214285714285715,0.09640541202143615,mmlu_offline:llama2-7b:world_religions,validation,0.8798514232039452
171,0.5847952961921692,0.5380116701126099,0.49823943661971837,0.008852856898168344,mmlu_offline:llama2-7b:world_religions,test,5.892888858914375
