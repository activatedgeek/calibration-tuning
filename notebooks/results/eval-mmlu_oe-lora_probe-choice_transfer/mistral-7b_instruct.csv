N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.27272728085517883,0.4545454680919647,0.3333333333333333,0.24283356016332455,mmlu:abstract_algebra,validation,36.96396070346236
100,0.28999999165534973,0.5699999928474426,0.4385624089363769,0.19007322192192078,mmlu:abstract_algebra,test,273.301231469959
14,0.4285714626312256,0.6428571939468384,0.7291666666666666,0.25976710234369554,mmlu:anatomy,validation,33.959970366209745
135,0.5407407283782959,0.5333333015441895,0.5341361025187804,0.24165092441770764,mmlu:anatomy,test,349.5865967236459
16,0.5625,0.625,0.5873015873015873,0.26943906769156456,mmlu:astronomy,validation,39.677582666277885
152,0.6710526347160339,0.6381579041481018,0.6954901960784314,0.12327376949159724,mmlu:astronomy,test,349.54156831279397
11,0.5454545617103577,0.7272727489471436,0.7666666666666666,0.2668274911967191,mmlu:business_ethics,validation,24.28034085407853
100,0.4399999976158142,0.5600000023841858,0.5923295454545455,0.1881763952970505,mmlu:business_ethics,test,223.7291247881949
29,0.37931033968925476,0.517241358757019,0.4949494949494949,0.3178747008586752,mmlu:clinical_knowledge,validation,78.06994364410639
265,0.46415096521377563,0.5396226644515991,0.5970743158135807,0.20183894971631608,mmlu:clinical_knowledge,test,859.4664934873581
16,0.25,0.375,0.4166666666666667,0.39887119084596634,mmlu:college_biology,validation,42.43611875921488
144,0.4652777910232544,0.6041666865348816,0.6777476255088196,0.15617599876390562,mmlu:college_biology,test,349.3018154427409
8,0.125,0.5,0.8571428571428572,0.426339752972126,mmlu:college_chemistry,validation,21.316451888531446
100,0.19999998807907104,0.4099999964237213,0.6434375000000001,0.37013587713241575,mmlu:college_chemistry,test,253.17356780916452
11,0.1818181872367859,0.7272727489471436,0.7222222222222223,0.3220030448653481,mmlu:college_computer_science,validation,30.44254705682397
100,0.2800000011920929,0.5600000023841858,0.6651785714285714,0.18668518126010894,mmlu:college_computer_science,test,278.53323159366846
11,0.1818181872367859,0.3636363744735718,0.2777777777777778,0.4025336503982544,mmlu:college_mathematics,validation,28.910873346030712
100,0.1899999976158142,0.5699999928474426,0.49090318388564,0.16847628593444824,mmlu:college_mathematics,test,280.0115098692477
22,0.5454545617103577,0.5909091234207153,0.6791666666666667,0.15684828974983908,mmlu:college_medicine,validation,62.947915729135275
173,0.4393063485622406,0.589595377445221,0.64575420510038,0.18980212535472274,mmlu:college_medicine,test,458.93085965514183
11,0.1818181872367859,0.5454545617103577,0.8888888888888888,0.2311213720928539,mmlu:college_physics,validation,34.05591154098511
102,0.1568627506494522,0.38235294818878174,0.5134447674418604,0.34382462559961813,mmlu:college_physics,test,289.3888251706958
11,0.7272727489471436,0.3636363744735718,0.4166666666666667,0.34410473433407873,mmlu:computer_security,validation,24.530578453093767
100,0.6599999666213989,0.5600000023841858,0.6024955436720143,0.17379375219345095,mmlu:computer_security,test,257.2003509476781
26,0.42307692766189575,0.5384615659713745,0.5212121212121212,0.28605287120892453,mmlu:conceptual_physics,validation,71.79691157862544
235,0.44680848717689514,0.6085106134414673,0.6587545787545788,0.12448808360607064,mmlu:conceptual_physics,test,655.0339271724224
12,0.5,0.5,0.4722222222222222,0.34245859086513525,mmlu:econometrics,validation,34.594190914183855
114,0.3070175349712372,0.5087719559669495,0.5687160940325497,0.21999538676780572,mmlu:econometrics,test,318.62992553785443
16,0.375,0.75,0.65,0.32526708766818047,mmlu:electrical_engineering,validation,40.97559650614858
145,0.40689656138420105,0.5034482479095459,0.5938115884903429,0.23492467444518517,mmlu:electrical_engineering,test,363.6848584860563
41,0.46341460943222046,0.5121951103210449,0.6842105263157894,0.29368711826277943,mmlu:elementary_mathematics,validation,95.81032181158662
378,0.4656084477901459,0.5449735522270203,0.6568266201620162,0.2513481157797354,mmlu:elementary_mathematics,test,846.4122970923781
14,0.4285714626312256,0.5714285969734192,0.5625,0.23009780475071498,mmlu:formal_logic,validation,29.09808197617531
126,0.3730158805847168,0.4285714626312256,0.6085375706975491,0.3939712761886536,mmlu:formal_logic,test,276.7150470763445
10,0.4000000059604645,0.4000000059604645,0.4166666666666667,0.5499906539916993,mmlu:global_facts,validation,21.10803984105587
100,0.25999999046325684,0.4099999964237213,0.5062370062370063,0.2736840999126434,mmlu:global_facts,test,254.85422413423657
32,0.375,0.5625,0.6125,0.2713505383580923,mmlu:high_school_biology,validation,87.67606136202812
310,0.5645161271095276,0.5999999642372131,0.6681481481481482,0.1652528653221746,mmlu:high_school_biology,test,774.891742490232
22,0.27272728085517883,0.3636363744735718,0.53125,0.45724377307024866,mmlu:high_school_chemistry,validation,59.06328101828694
203,0.2610837519168854,0.41871920228004456,0.611006289308176,0.34093378623718107,mmlu:high_school_chemistry,test,518.1328499317169
9,0.4444444477558136,0.6666666865348816,0.85,0.1535578237639533,mmlu:high_school_computer_science,validation,21.270877566188574
100,0.5099999904632568,0.5399999618530273,0.5388155262104842,0.26938836455345155,mmlu:high_school_computer_science,test,232.01036592945457
22,0.5,0.5909091234207153,0.7520661157024794,0.2342963381247087,mmlu:high_school_geography,validation,51.522802006453276
198,0.46464645862579346,0.5050504803657532,0.6080291222313372,0.26808079083760583,mmlu:high_school_geography,test,487.8900729380548
21,0.8095238208770752,0.9047619104385376,0.9705882352941176,0.21377690916969663,mmlu:high_school_government_and_politics,validation,46.40968015789986
193,0.6113989353179932,0.6165803074836731,0.5829378531073447,0.14880868159427546,mmlu:high_school_government_and_politics,test,450.8093254864216
43,0.4883720874786377,0.41860464215278625,0.46969696969696967,0.33835680124371553,mmlu:high_school_macroeconomics,validation,117.47024490684271
390,0.49230772256851196,0.5410256385803223,0.5621580387205387,0.21682225236525904,mmlu:high_school_macroeconomics,test,1029.1259856075048
29,0.17241379618644714,0.5517241358757019,0.65,0.18025423534985247,mmlu:high_school_mathematics,validation,83.31222315505147
270,0.14814814925193787,0.42222222685813904,0.6040760869565216,0.2869698292679257,mmlu:high_school_mathematics,test,803.8285627141595
26,0.3461538553237915,0.42307692766189575,0.45098039215686275,0.35341688761344325,mmlu:high_school_microeconomics,validation,73.97984272614121
238,0.42016810178756714,0.47478994727134705,0.5766666666666667,0.28075096987876574,mmlu:high_school_microeconomics,test,641.3032229468226
17,0.23529411852359772,0.5882353186607361,0.7115384615384616,0.22549321020350738,mmlu:high_school_physics,validation,42.222127098590136
151,0.2847682237625122,0.4701986610889435,0.5954995693367786,0.285296843541379,mmlu:high_school_physics,test,376.54196950793266
60,0.6333333849906921,0.6833333969116211,0.722488038277512,0.13405776321887974,mmlu:high_school_psychology,validation,42.26956066861749
545,0.6018348932266235,0.6366972327232361,0.6409815106215577,0.13571495966080133,mmlu:high_school_psychology,test,291.2599284965545
23,0.30434784293174744,0.43478262424468994,0.625,0.32397763625435205,mmlu:high_school_statistics,validation,14.913916556164622
216,0.3888888955116272,0.46759259700775146,0.5706168831168832,0.28592700842354035,mmlu:high_school_statistics,test,131.79401889070868
22,0.7272727489471436,0.6818181872367859,0.6354166666666667,0.1377541856332259,mmlu:high_school_us_history,validation,27.862400069832802
204,0.7205882668495178,0.7303921580314636,0.7339181286549707,0.09167862639707679,mmlu:high_school_us_history,test,254.06566231511533
23,0.3913043439388275,0.5652173757553101,0.5238095238095238,0.2944211778433427,mmlu:human_aging,validation,10.951058564707637
223,0.46188342571258545,0.5336323380470276,0.5573624595469255,0.18057398731933047,mmlu:human_aging,test,114.26647675223649
12,0.4166666865348816,0.4166666865348816,0.5142857142857142,0.26117076476414997,mmlu:human_sexuality,validation,8.146951962262392
131,0.5877862572669983,0.6412214040756226,0.6495911495911496,0.15642380577917314,mmlu:human_sexuality,test,67.08297064714134
13,0.692307710647583,0.8461538553237915,1.0,0.2557841906180749,mmlu:international_law,validation,8.709441171959043
121,0.8016528487205505,0.6694214344024658,0.6166237113402062,0.11973911622339044,mmlu:international_law,test,61.171596731990576
11,0.9090909361839294,0.7272727489471436,0.0,0.17261449857191608,mmlu:jurisprudence,validation,7.814809560775757
108,0.6574074029922485,0.5833333134651184,0.5323562999619338,0.20040871534082622,mmlu:jurisprudence,test,56.31457357481122
18,0.7222222089767456,0.5,0.676923076923077,0.2904515167077383,mmlu:logical_fallacies,validation,12.095791693776846
163,0.5398772954940796,0.5766870975494385,0.5970454545454544,0.1522064029804768,mmlu:logical_fallacies,test,87.571060821414
11,0.4545454680919647,0.7272727489471436,0.6333333333333333,0.2602381110191345,mmlu:machine_learning,validation,8.998467838391662
112,0.455357164144516,0.6160714626312256,0.5533590485374478,0.1833135187625885,mmlu:machine_learning,test,61.341322699561715
11,0.8181818723678589,0.7272727489471436,0.8333333333333333,0.11773302880200477,mmlu:management,validation,7.483745004981756
103,0.5145630836486816,0.5145630836486816,0.6005660377358492,0.21793835660786307,mmlu:management,test,50.91609812527895
25,0.3199999928474426,0.3999999761581421,0.7058823529411764,0.3417087244987488,mmlu:marketing,validation,15.126705894246697
234,0.47435900568962097,0.5982906222343445,0.7429136453526698,0.17217404414445928,mmlu:marketing,test,246.98310009017587
11,0.6363636255264282,0.7272727489471436,0.6428571428571428,0.26645357500423084,mmlu:medical_genetics,validation,8.427398076280951
100,0.5600000023841858,0.5399999618530273,0.5693993506493507,0.1881666672229767,mmlu:medical_genetics,test,53.707458110526204
38,0.6052631735801697,0.5526315569877625,0.5333333333333333,0.2324559625826384,mmlu:moral_disputes,validation,20.70188975520432
346,0.5722543001174927,0.5838150382041931,0.5678064428064429,0.14921764710735036,mmlu:moral_disputes,test,176.1878878325224
33,0.6060606241226196,0.5151515007019043,0.55,0.2658990820248922,mmlu:nutrition,validation,19.369561169296503
306,0.5751634240150452,0.584967315196991,0.5699956293706294,0.15485166276202486,mmlu:nutrition,test,159.66644277982414
34,0.5,0.6176470518112183,0.6262975778546712,0.10794291952077081,mmlu:philosophy,validation,17.86741795949638
311,0.4115755558013916,0.5144694447517395,0.5784024931693988,0.21275996299418606,mmlu:philosophy,test,151.6541240848601
35,0.5142857432365417,0.6285714507102966,0.7091503267973855,0.13162918090820314,mmlu:prehistory,validation,19.035971635952592
324,0.5432099103927612,0.5679012537002563,0.5794302825552825,0.1744338421174038,mmlu:prehistory,test,167.45554106496274
69,0.47826087474823,0.5797101259231567,0.712121212121212,0.19021188694497815,mmlu:professional_psychology,validation,39.32160904072225
612,0.4297385811805725,0.529411792755127,0.6387996121455108,0.24167251421345604,mmlu:professional_psychology,test,318.80887574888766
12,0.3333333432674408,0.4166666865348816,0.65625,0.40788282950719196,mmlu:public_relations,validation,6.986002778634429
110,0.33636361360549927,0.5272727012634277,0.6625323954091078,0.23432107947089456,mmlu:public_relations,test,57.72023027203977
27,0.7777777910232544,0.7037037014961243,0.6825396825396826,0.14491580592261422,mmlu:security_studies,validation,17.40339688770473
245,0.7551019787788391,0.6163265109062195,0.6206756756756757,0.17764310131267624,mmlu:security_studies,test,139.58579792827368
22,0.7272727489471436,0.7727273106575012,0.5572916666666666,0.18414963104508142,mmlu:sociology,validation,14.487932715564966
201,0.5721392631530762,0.5721392631530762,0.5441354903943376,0.16977777350601264,mmlu:sociology,test,103.67994160205126
11,0.9090909361839294,0.4545454680919647,0.3,0.4142155647277832,mmlu:us_foreign_policy,validation,8.598917968571186
100,0.7999999523162842,0.5999999642372131,0.540625,0.1726655912399292,mmlu:us_foreign_policy,test,72.93329491652548
18,0.6666666865348816,0.4444444477558136,0.41666666666666663,0.28201354543368023,mmlu:virology,validation,12.422465780749917
166,0.668674647808075,0.5361445546150208,0.5177723177723177,0.19448723814573632,mmlu:virology,test,84.45936472900212
19,0.7368420958518982,0.6842105388641357,0.7,0.2170603651749461,mmlu:world_religions,validation,12.94600902684033
171,0.6783626079559326,0.6959064602851868,0.7353448275862069,0.0737393958526745,mmlu:world_religions,test,85.93132250383496
