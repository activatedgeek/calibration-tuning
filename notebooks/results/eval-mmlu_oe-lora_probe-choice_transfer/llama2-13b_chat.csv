N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
69,0.2753623127937317,0.6231884360313416,0.603157894736842,0.13340978950693985,mmlu:professional_psychology,validation,56.4274819009006
612,0.3284313678741455,0.6503267884254456,0.5555616080183026,0.02086951500839659,mmlu:professional_psychology,test,609.2831246070564
12,0.3333333432674408,0.1666666716337204,0.25,0.5014850745598476,mmlu:public_relations,validation,3.9099445044994354
110,0.3181818127632141,0.4363636374473572,0.5474285714285715,0.2313422138040716,mmlu:public_relations,test,35.67362779378891
27,0.5925925970077515,0.48148149251937866,0.5681818181818182,0.16057284010781184,mmlu:security_studies,validation,15.760388281196356
245,0.636734664440155,0.5877550840377808,0.5894194756554307,0.05023929634872748,mmlu:security_studies,test,160.98258623294532
22,0.6818181872367859,0.6363636255264282,0.4095238095238095,0.08827678181908347,mmlu:sociology,validation,7.709525039419532
201,0.46766167879104614,0.5721392631530762,0.6148836746868165,0.06029973101260061,mmlu:sociology,test,66.76353393867612
11,0.6363636255264282,0.5454545617103577,0.6428571428571428,0.1515194231813604,mmlu:us_foreign_policy,validation,5.219167500734329
100,0.6299999952316284,0.6299999952316284,0.58987558987559,0.06770849585533141,mmlu:us_foreign_policy,test,43.724247405305505
18,0.4444444477558136,0.5,0.3375,0.36690599057409495,mmlu:virology,validation,11.04691968858242
166,0.3132529854774475,0.48795178532600403,0.5883940620782727,0.10771215321069744,mmlu:virology,test,78.19254476763308
19,0.6315789222717285,0.6842105388641357,0.7023809523809523,0.061402860440705954,mmlu:world_religions,validation,6.475992443040013
171,0.5497075915336609,0.6257309913635254,0.6615777839182095,0.061626503690641515,mmlu:world_religions,test,156.18592449650168
11,0.0,0.8181818723678589,,0.21053415536880496,mmlu:abstract_algebra,validation,30.80989668518305
100,0.3100000023841858,0.5,0.37400654511453946,0.11781127631664277,mmlu:abstract_algebra,test,431.1835062354803
14,0.2142857313156128,0.4285714626312256,0.5151515151515151,0.15910886015210834,mmlu:anatomy,validation,12.300775062292814
135,0.4296296238899231,0.4444444477558136,0.49081952530228395,0.1494740190329375,mmlu:anatomy,test,116.14751167222857
16,0.5625,0.625,0.33333333333333337,0.14580562710762024,mmlu:astronomy,validation,19.28104066848755
152,0.5328947305679321,0.5723684430122375,0.49165362545644237,0.14391594772276128,mmlu:astronomy,test,175.19210769236088
11,0.5454545617103577,0.4545454680919647,0.39999999999999997,0.1308840892531655,mmlu:business_ethics,validation,11.476548552513123
100,0.32999998331069946,0.4399999976158142,0.5522388059701493,0.16163247883319856,mmlu:business_ethics,test,111.52954530715942
29,0.20689654350280762,0.6896551847457886,0.4130434782608695,0.13935293205853166,mmlu:clinical_knowledge,validation,35.86289765685797
265,0.3094339668750763,0.6566038131713867,0.630581100892976,0.07864870485269797,mmlu:clinical_knowledge,test,428.80663400515914
16,0.375,0.5625,0.65,0.13414141908288002,mmlu:college_biology,validation,25.657326754182577
144,0.375,0.5277777910232544,0.6166666666666667,0.06725266699989638,mmlu:college_biology,test,171.6863881573081
8,0.0,0.25,,0.3889516741037369,mmlu:college_chemistry,validation,9.669395476579666
100,0.19999998807907104,0.3199999928474426,0.6003125,0.31052224814891816,mmlu:college_chemistry,test,124.62197243049741
11,0.3636363744735718,0.5454545617103577,0.625,0.23559564352035522,mmlu:college_computer_science,validation,16.628091920167208
100,0.25,0.3799999952316284,0.5536000000000001,0.26323670327663423,mmlu:college_computer_science,test,143.8146688528359
11,0.0,0.1818181872367859,,0.3707837083122947,mmlu:college_mathematics,validation,30.076548781245947
100,0.09999999403953552,0.29999998211860657,0.5655555555555556,0.3079164153337478,mmlu:college_mathematics,test,197.3544358164072
22,0.3181818127632141,0.6363636255264282,0.5333333333333333,0.18769272078167307,mmlu:college_medicine,validation,24.91235426440835
173,0.41040462255477905,0.5664739608764648,0.5628279480806407,0.02718007116648504,mmlu:college_medicine,test,208.61964824795723
11,0.27272728085517883,0.5454545617103577,0.6666666666666666,0.1731052236123518,mmlu:college_physics,validation,10.193059973418713
102,0.14705882966518402,0.4705882668495178,0.5777777777777777,0.1403191370122573,mmlu:college_physics,test,132.97164153680205
11,0.6363636255264282,0.6363636255264282,0.6428571428571428,0.18592933091250333,mmlu:computer_security,validation,10.038509372621775
100,0.5299999713897705,0.6100000143051147,0.6085909273384184,0.12484073221683499,mmlu:computer_security,test,325.17911080271006
26,0.3461538553237915,0.5,0.4117647058823529,0.08829226860633263,mmlu:conceptual_physics,validation,28.234069015830755
235,0.44680848717689514,0.5446808338165283,0.5797435897435897,0.08131504033474213,mmlu:conceptual_physics,test,213.0917680412531
12,0.4166666865348816,0.5833333730697632,0.48571428571428577,0.09290541211764018,mmlu:econometrics,validation,15.255159817636013
114,0.2017543911933899,0.6140350699424744,0.5590062111801243,0.04444632561583271,mmlu:econometrics,test,218.39740370959044
16,0.3125,0.6875,0.4909090909090909,0.1861995980143547,mmlu:electrical_engineering,validation,29.597002379596233
145,0.24827586114406586,0.6068965196609497,0.4839449541284404,0.06545916425770723,mmlu:electrical_engineering,test,364.3502822294831
41,0.24390242993831635,0.3414633870124817,0.45483870967741935,0.31369778731974163,mmlu:elementary_mathematics,validation,50.40519041568041
378,0.3253968060016632,0.4100528955459595,0.5858122110632871,0.23056217539247384,mmlu:elementary_mathematics,test,597.6589062735438
14,0.2142857313156128,0.2142857313156128,0.3333333333333333,0.39979857632092064,mmlu:formal_logic,validation,18.913063161075115
126,0.2539682686328888,0.3095238208770752,0.425531914893617,0.3098901245329116,mmlu:formal_logic,test,207.45042334124446
10,0.20000000298023224,0.5,0.625,0.14103671908378604,mmlu:global_facts,validation,12.435644965618849
100,0.1599999964237213,0.5199999809265137,0.49255952380952384,0.09845583915710446,mmlu:global_facts,test,112.80365128442645
32,0.25,0.5,0.49479166666666663,0.11832178756594658,mmlu:high_school_biology,validation,40.949587408453226
310,0.42903226613998413,0.5129032135009766,0.5472579754470923,0.08547946541540083,mmlu:high_school_biology,test,371.1838050186634
22,0.13636364042758942,0.3636363744735718,0.7368421052631579,0.3055874326012351,mmlu:high_school_chemistry,validation,30.211097866296768
203,0.1822660118341446,0.32019704580307007,0.48884728101595576,0.3147797026657706,mmlu:high_school_chemistry,test,252.77072155475616
9,0.6666666865348816,0.4444444477558136,0.5555555555555556,0.2761445575290256,mmlu:high_school_computer_science,validation,13.161760751157999
100,0.41999998688697815,0.5,0.49815270935960587,0.09320354700088504,mmlu:high_school_computer_science,test,200.24497151747346
22,0.3636363744735718,0.5909091234207153,0.5982142857142857,0.17359482700174506,mmlu:high_school_geography,validation,23.393485456705093
198,0.38383838534355164,0.5505050420761108,0.6109253666954271,0.026416534426236416,mmlu:high_school_geography,test,240.76281195506454
21,0.523809552192688,0.6666666865348816,0.5545454545454546,0.19105305274327597,mmlu:high_school_government_and_politics,validation,19.844341598451138
193,0.5803108811378479,0.6373056769371033,0.6300154320987653,0.05658202066322681,mmlu:high_school_government_and_politics,test,192.52375657856464
43,0.44186046719551086,0.4883720874786377,0.4353070175438597,0.08643569502719614,mmlu:high_school_macroeconomics,validation,59.00967639312148
390,0.3512820601463318,0.49230772256851196,0.5159978073338911,0.08949282199908525,mmlu:high_school_macroeconomics,test,546.367348421365
29,0.03448275849223137,0.17241379618644714,0.9285714285714286,0.47225329588199483,mmlu:high_school_mathematics,validation,29.983683120459318
270,0.10000000149011612,0.17777776718139648,0.539247065996037,0.4751899288760292,mmlu:high_school_mathematics,test,301.0223410576582
26,0.26923078298568726,0.6153846383094788,0.7067669172932332,0.11989323450968814,mmlu:high_school_microeconomics,validation,35.113856982439756
238,0.4159664213657379,0.5,0.5377152823195989,0.08717007221294051,mmlu:high_school_microeconomics,test,340.4363678842783
17,0.23529411852359772,0.529411792755127,0.5769230769230769,0.35385043130201455,mmlu:high_school_physics,validation,27.878105502575636
151,0.16556291282176971,0.33774834871292114,0.4288888888888889,0.2660126318994737,mmlu:high_school_physics,test,212.5104932822287
60,0.6000000238418579,0.6333333849906921,0.5509259259259259,0.08510874013106029,mmlu:high_school_psychology,validation,62.105584520846605
545,0.5064220428466797,0.5834862589836121,0.6253704003017079,0.032193529715231844,mmlu:high_school_psychology,test,819.0191051624715
23,0.17391304671764374,0.3913043439388275,0.39473684210526316,0.1994694678679757,mmlu:high_school_statistics,validation,62.60004138201475
216,0.26851850748062134,0.4861111044883728,0.552597119161938,0.11865034313113601,mmlu:high_school_statistics,test,615.0947807468474
22,0.8181818723678589,0.7727273106575012,0.5416666666666667,0.18788171627304773,mmlu:high_school_us_history,validation,43.6538523696363
204,0.6764706373214722,0.6421568989753723,0.5561045234958278,0.059578922449373725,mmlu:high_school_us_history,test,430.66773429885507
23,0.47826087474823,0.6086956858634949,0.856060606060606,0.1302033014919447,mmlu:human_aging,validation,21.273633014410734
223,0.4035874605178833,0.4708520472049713,0.5259398496240602,0.15179957162104377,mmlu:human_aging,test,244.0122952312231
12,0.3333333432674408,0.6666666865348816,0.59375,0.05826158821582792,mmlu:human_sexuality,validation,18.345918461680412
131,0.4885496199131012,0.5496183037757874,0.5753264925373135,0.049923634711112705,mmlu:human_sexuality,test,162.87148166820407
13,0.38461539149284363,0.46153849363327026,0.425,0.19494864115348232,mmlu:international_law,validation,21.784545369446278
121,0.6280991435050964,0.586776852607727,0.5711988304093568,0.045989402069533176,mmlu:international_law,test,194.43563152104616
11,0.27272728085517883,0.1818181872367859,0.3333333333333333,0.49574186585166236,mmlu:jurisprudence,validation,10.621985565871
108,0.40740740299224854,0.4166666567325592,0.5390624999999999,0.18814961115519208,mmlu:jurisprudence,test,110.96868904307485
18,0.6666666865348816,0.7222222089767456,0.6111111111111112,0.11684176325798036,mmlu:logical_fallacies,validation,17.995338395237923
163,0.46625766158103943,0.5030674934387207,0.5396249243799154,0.11664875226518129,mmlu:logical_fallacies,test,186.54546384885907
11,0.27272728085517883,0.4545454680919647,0.5,0.18492380055514246,mmlu:machine_learning,validation,12.068215072154999
112,0.25,0.3750000298023224,0.49022108843537415,0.23641963303089142,mmlu:machine_learning,test,112.40440507605672
11,0.6363636255264282,0.5454545617103577,0.5,0.04097419977188111,mmlu:management,validation,9.299852050840855
103,0.3980582654476166,0.5145630836486816,0.6142800944138473,0.07888326540734003,mmlu:management,test,89.55447285622358
25,0.19999998807907104,0.35999998450279236,0.46,0.21753121376037599,mmlu:marketing,validation,52.95410418882966
234,0.4316239655017853,0.504273533821106,0.5461177696717041,0.06823870157584164,mmlu:marketing,test,439.7392289713025
11,0.6363636255264282,0.3636363744735718,0.21428571428571427,0.22064770351756702,mmlu:medical_genetics,validation,21.621515661478043
100,0.47999998927116394,0.6299999952316284,0.6342147435897435,0.07296105504035949,mmlu:medical_genetics,test,157.47283707931638
38,0.42105263471603394,0.5,0.7102272727272727,0.132634195842241,mmlu:moral_disputes,validation,39.230118196457624
346,0.43352600932121277,0.4566473960876465,0.5799149659863946,0.16867813485206207,mmlu:moral_disputes,test,349.77019138261676
33,0.3030303120613098,0.4848484992980957,0.6043478260869566,0.1235704060756799,mmlu:nutrition,validation,40.51422403007746
306,0.43790850043296814,0.5653594732284546,0.6203358208955223,0.03907970548455232,mmlu:nutrition,test,390.73385163396597
34,0.3235294222831726,0.38235294818878174,0.5098814229249012,0.19931146677802594,mmlu:philosophy,validation,26.066462241113186
311,0.35691317915916443,0.49196141958236694,0.5663063063063063,0.07670396068088497,mmlu:philosophy,test,265.1790854409337
35,0.4000000059604645,0.4571428596973419,0.6258503401360545,0.18344509771892004,mmlu:prehistory,validation,41.80354104563594
324,0.43518519401550293,0.472222238779068,0.5398209510522032,0.1647308533206398,mmlu:prehistory,test,345.26458893716335
