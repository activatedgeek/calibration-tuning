N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.19600508429787375,0.1818181872367859,0.8181818127632141,0.7222222222222222,0.27947444265539,mmlu:abstract_algebra,validation,2.575953929917887
100,0.10345885753631592,0.3400000035762787,0.6600000262260437,0.45187165775401067,0.12816408634185794,mmlu:abstract_algebra,test,6.628945298027247
14,0.27451826844896593,0.6428571343421936,0.3571428656578064,0.38888888888888884,0.17968750851494925,mmlu:anatomy,validation,1.1201927089132369
135,0.06617017697404932,0.48148149251937866,0.5185185074806213,0.4767032967032967,0.02019678442566486,mmlu:anatomy,test,9.053997235139832
16,0.10867198556661603,0.4375,0.5625,0.5,0.05859375,mmlu:astronomy,validation,1.6578388360794634
152,0.07267576789385394,0.42105263471603394,0.5789473652839661,0.5,0.07504111842105265,mmlu:astronomy,test,14.015239710919559
11,0.2740178975191983,0.6363636255264282,0.3636363744735718,0.5,0.15980113636363635,mmlu:business_ethics,validation,1.2239798931404948
100,0.0867828518152237,0.47999998927116394,0.5199999809265137,0.5,0.0034374999999999822,mmlu:business_ethics,test,8.99400470405817
29,0.1713621636916851,0.4137931168079376,0.5862069129943848,0.6225490196078431,0.04983834768163742,mmlu:clinical_knowledge,validation,2.2453898298554122
265,0.0635473775413801,0.49056604504585266,0.5094339847564697,0.562108262108262,0.026695154747872984,mmlu:clinical_knowledge,test,18.800009872065857
16,0.14043159037828445,0.3125,0.625,0.5999999999999999,0.116455078125,mmlu:college_biology,validation,1.4181643961928785
144,0.09594800944129625,0.4375,0.5694444179534912,0.5339016264942191,0.06187608506944442,mmlu:college_biology,test,11.674784112954512
8,0.2831239774823189,0.5,0.5,0.40625,0.03076171875,mmlu:college_chemistry,validation,0.8802506870124489
100,0.022121665477752676,0.3499999940395355,0.6499999761581421,0.6334065934065933,0.1200390696525574,mmlu:college_chemistry,test,8.643458670936525
11,0.27322495254603296,0.6363636255264282,0.3636363744735718,0.5,0.15198863636363635,mmlu:college_computer_science,validation,1.451964925043285
100,0.13088626027107236,0.36000001430511475,0.6399999856948853,0.5,0.12437500000000001,mmlu:college_computer_science,test,11.38308423012495
11,0.1655176877975464,0.3636363744735718,0.6363636255264282,0.5,0.11683238636363635,mmlu:college_mathematics,validation,1.2040571940597147
100,0.056095322370529194,0.3499999940395355,0.6499999761581421,0.5,0.13046875000000002,mmlu:college_mathematics,test,8.662432689918205
22,0.11802463910796426,0.40909090638160706,0.6363636255264282,0.5854700854700855,0.12144888531077991,mmlu:college_medicine,validation,2.0846823069732636
173,0.1069928762540652,0.38728323578834534,0.6127167344093323,0.5725147845677274,0.0976562785964481,mmlu:college_medicine,test,17.71058878302574
11,0.17821372909979386,0.4545454680919647,0.5454545617103577,0.7833333333333333,0.02627841992811719,mmlu:college_physics,validation,1.1248224980663508
102,0.1996084521798526,0.21568627655506134,0.7843137383460999,0.4173295454545454,0.259038018245323,mmlu:college_physics,test,7.962579682935029
11,0.12465705925768072,0.5454545617103577,0.3636363744735718,0.41666666666666663,0.1448863853107799,mmlu:computer_security,validation,1.109446755843237
100,0.09803613364696503,0.5699999928474426,0.4099999964237213,0.43839249286005705,0.0991015696525574,mmlu:computer_security,test,7.076830095145851
26,0.15487189017809355,0.38461539149284363,0.6153846383094788,0.815625,0.08969352337030267,mmlu:conceptual_physics,validation,1.805882670916617
235,0.07419210482150952,0.42553192377090454,0.5744680762290955,0.5753333333333333,0.04734040194369382,mmlu:conceptual_physics,test,13.483159425901249
12,0.22426709284385046,0.1666666716337204,0.1666666716337204,0.5,0.34114583333333337,mmlu:econometrics,validation,1.3211102781351656
114,0.15179891910469323,0.28947368264198303,0.28947368264198303,0.5,0.21833881578947367,mmlu:econometrics,test,10.569694381207228
16,0.20547708123922345,0.5625,0.4375,0.33333333333333337,0.109619140625,mmlu:electrical_engineering,validation,1.3145612520165741
145,0.08971572210048809,0.4275861978530884,0.5724138021469116,0.5866692576758648,0.0296875147983946,mmlu:electrical_engineering,test,10.443331261863932
41,0.13848892653860695,0.24390244483947754,0.7560975551605225,0.3274193548387097,0.19883764371639345,mmlu:elementary_mathematics,validation,3.7203860150184482
378,0.08314153386486901,0.230158731341362,0.7698412537574768,0.4873800213295414,0.21160920082576695,mmlu:elementary_mathematics,test,31.003183896886185
14,0.13452591427734922,0.2142857164144516,0.7857142686843872,0.5,0.2583705357142857,mmlu:formal_logic,validation,1.4599436197895557
126,0.04521348386529893,0.3730158805847168,0.6269841194152832,0.5,0.09964037698412698,mmlu:formal_logic,test,11.707719684112817
10,0.3186369210481644,0.0,1.0,,0.47929686307907104,mmlu:global_facts,validation,2.6874702458735555
100,0.08433903574943544,0.30000001192092896,0.699999988079071,0.47714285714285715,0.17921872138977046,mmlu:global_facts,test,7.161570803029463
32,0.17761011514812708,0.34375,0.65625,0.4696969696969697,0.1453857421875,mmlu:high_school_biology,validation,2.8215063381940126
310,0.05050483990100123,0.48064514994621277,0.5161290168762207,0.48989120013339443,0.00642640936759209,mmlu:high_school_biology,test,25.654805822996423
22,0.06607326187870721,0.3636363744735718,0.6363636255264282,0.6741071428571428,0.11754263531077991,mmlu:high_school_chemistry,validation,1.9824112229980528
203,0.0466676843283799,0.3694581389427185,0.6256157755851746,0.5197916666666667,0.10791258800205927,mmlu:high_school_chemistry,test,16.508611146127805
9,0.2883785665035247,0.5555555820465088,0.4444444477558136,0.5,0.07118055555555558,mmlu:high_school_computer_science,validation,1.4096103359479457
100,0.09103344589471818,0.3799999952316284,0.6200000047683716,0.5,0.104375,mmlu:high_school_computer_science,test,12.516606042161584
18,0.3306613730059729,0.6111111044883728,0.3888888955116272,0.5,0.1345486111111111,mmlu:high_school_european_history,validation,6.84577521099709
165,0.14075853662057358,0.6121212244033813,0.38787877559661865,0.5,0.13555871212121212,mmlu:high_school_european_history,test,60.76952108484693
22,0.12117820300839165,0.6818181872367859,0.3181818127632141,0.561904761904762,0.20987218076532538,mmlu:high_school_geography,validation,1.7285095120314509
198,0.10586895846357249,0.4898989796638489,0.5101010203361511,0.5054098193324488,0.017321656448672562,mmlu:high_school_geography,test,13.744747895980254
21,0.1786493942851112,0.6666666865348816,0.3333333432674408,0.6122448979591837,0.20684526364008587,mmlu:high_school_government_and_politics,validation,1.8731610770337284
193,0.09154047419370147,0.6891191601753235,0.3108808398246765,0.5162907268170426,0.22925437577647867,mmlu:high_school_government_and_politics,test,15.047494439873844
43,0.14036800764327825,0.3255814015865326,0.6744186282157898,0.4482758620689655,0.14689317969388738,mmlu:high_school_macroeconomics,validation,3.2272842929232866
390,0.029747987175599115,0.4384615421295166,0.5615384578704834,0.4884643114635905,0.034545246454385614,mmlu:high_school_macroeconomics,test,26.81797446194105
29,0.0965060406717761,0.4137931168079376,0.5862069129943848,0.5784313725490197,0.014547391184445035,mmlu:high_school_mathematics,validation,2.5502586809452623
270,0.05462032037752647,0.25925925374031067,0.7407407164573669,0.45428571428571435,0.1698784474973325,mmlu:high_school_mathematics,test,21.718496148008853
26,0.3137267323640676,0.26923078298568726,0.7307692170143127,0.36466165413533835,0.22235579674060524,mmlu:high_school_microeconomics,validation,2.0418053190223873
238,0.08233299976637382,0.4495798349380493,0.5420168042182922,0.5214382535492617,0.03353137028317488,mmlu:high_school_microeconomics,test,16.69544141390361
17,0.135624300031101,0.4117647111415863,0.5882353186607361,0.4642857142857143,0.08226100136252013,mmlu:high_school_physics,validation,1.7857911670580506
151,0.10170582963141386,0.2847682237625122,0.7152317762374878,0.5462962962962963,0.2095922946140466,mmlu:high_school_physics,test,13.082676865160465
60,0.167490786810716,0.6833333373069763,0.3166666626930237,0.5853658536585366,0.20722657044728598,mmlu:high_school_psychology,validation,5.0669852388091385
545,0.07126192281005582,0.6293578147888184,0.37064221501350403,0.4805227607308836,0.15370558030014736,mmlu:high_school_psychology,test,44.870557913091034
23,0.1275557771972988,0.3478260934352875,0.6521739363670349,0.5,0.15217391304347827,mmlu:high_school_statistics,validation,2.7222167160362005
216,0.1062640449791043,0.25925925374031067,0.7407407164573669,0.5,0.2407407407407407,mmlu:high_school_statistics,test,24.431605411926284
22,0.2552962045777928,0.6818181872367859,0.3181818127632141,0.5,0.19744318181818182,mmlu:high_school_us_history,validation,6.483024926157668
204,0.09984620470626682,0.5686274766921997,0.4313725531101227,0.5,0.08425245098039214,mmlu:high_school_us_history,test,58.56878421199508
26,0.15238313491527855,0.5769230723381042,0.42307692766189575,0.5,0.09254807692307693,mmlu:high_school_world_history,validation,5.674462198046967
237,0.1755296935009051,0.6455696225166321,0.3544303774833679,0.5,0.16119462025316456,mmlu:high_school_world_history,test,47.15330756106414
23,0.2850923564123071,0.6521739363670349,0.3478260934352875,0.49166666666666664,0.1824049120363982,mmlu:human_aging,validation,1.5335442079231143
223,0.07290999691582581,0.5650224089622498,0.43497759103775024,0.5358779250531828,0.09506375853790833,mmlu:human_aging,test,13.297466239891946
12,0.2745535920063654,0.5833333134651184,0.4166666567325592,0.6,0.11067708333333331,mmlu:human_sexuality,validation,1.0264907490927726
131,0.08630409222522764,0.5419847369194031,0.4580152630805969,0.528169014084507,0.07186305113421143,mmlu:human_sexuality,test,8.891758939018473
13,0.2099853983292213,0.8461538553237915,0.1538461595773697,0.5,0.36177884615384615,mmlu:international_law,validation,1.5136817551683635
121,0.09245428492215052,0.6198347210884094,0.3801652789115906,0.5,0.13545971074380164,mmlu:international_law,test,11.584768663858995
11,0.16036485000090164,0.5454545617103577,0.4545454680919647,0.23333333333333334,0.06605110927061603,mmlu:jurisprudence,validation,1.0476310951635242
108,0.11777489604773345,0.5092592835426331,0.49074074625968933,0.5497427101200686,0.028501128708874723,mmlu:jurisprudence,test,7.861214776989073
18,0.24433038135369617,0.7222222089767456,0.2777777910232544,0.7076923076923078,0.23914928568734062,mmlu:logical_fallacies,validation,1.6214899059850723
163,0.07949475166987788,0.5398772954940796,0.4601227045059204,0.611439393939394,0.057491367214296485,mmlu:logical_fallacies,test,12.331799656152725
11,0.16532550074837424,0.1818181872367859,0.8181818127632141,0.5,0.31818181818181823,mmlu:machine_learning,validation,1.2894880149979144
112,0.053231227610792416,0.4017857015132904,0.5982142686843872,0.5,0.0982142857142857,mmlu:machine_learning,test,10.693301990861073
11,0.30823718959634955,0.27272728085517883,0.7272727489471436,0.25,0.1743607900359414,mmlu:management,validation,0.8777435370720923
103,0.11671582066897052,0.6019417643547058,0.3980582654476166,0.5019669551534225,0.15029583683291686,mmlu:management,test,5.779361503897235
25,0.2095997428894043,0.800000011920929,0.20000000298023224,0.54,0.3157812237739563,mmlu:marketing,validation,2.0907089218962938
234,0.07044184717357667,0.6666666865348816,0.3333333432674408,0.5084237343852729,0.1812566916147868,mmlu:marketing,test,16.661204871954396
11,0.17338090051304209,0.8181818127632141,0.7272727489471436,0.5555555555555556,0.2173295400359414,mmlu:medical_genetics,validation,1.0216834919992834
100,0.13484414756298066,0.4699999988079071,0.550000011920929,0.5943396226415094,0.040078151226043746,mmlu:medical_genetics,test,6.626926437020302
86,0.13362047041571418,0.604651153087616,0.39534884691238403,0.5610859728506786,0.168968026028123,mmlu:miscellaneous,validation,5.176977357128635
783,0.0690558131779443,0.64112389087677,0.35887610912323,0.5243403609760248,0.1974776778489085,mmlu:miscellaneous,test,46.688727419124916
38,0.20729207600417893,0.3684210479259491,0.6315789222717285,0.49404761904761907,0.11615952378825134,mmlu:moral_disputes,validation,3.169343398883939
346,0.07984148026201766,0.49421966075897217,0.5057803392410278,0.44994152046783625,0.009268872310660425,mmlu:moral_disputes,test,27.138652216875926
100,0.08912282347679136,0.25,0.75,0.5,0.23046875,mmlu:moral_scenarios,validation,9.506755849113688
895,0.11698284418889265,0.22234636545181274,0.7776536345481873,0.5,0.25812238128491616,mmlu:moral_scenarios,test,82.54928909102455
33,0.12149139335661226,0.6666666865348816,0.6666666865348816,0.5,0.16666666666666663,mmlu:nutrition,validation,3.258461558027193
306,0.06356700436741698,0.5032680034637451,0.5032680034637451,0.5,0.0032679738562091387,mmlu:nutrition,test,28.05211493303068
34,0.25986306456958547,0.4117647111415863,0.5882353186607361,0.49107142857142855,0.06744024683447447,mmlu:philosophy,validation,2.4585969038307667
311,0.05007771175007345,0.5691318511962891,0.4308681786060333,0.4751454591449532,0.08955488749255702,mmlu:philosophy,test,19.851723104016855
35,0.18676100288118636,0.4000000059604645,0.6000000238418579,0.4642857142857143,0.08604911565780637,mmlu:prehistory,validation,3.261882863007486
324,0.08562614612373304,0.5061728358268738,0.4938271641731262,0.5029725609756097,0.018988732202553482,mmlu:prehistory,test,27.64616571785882
31,0.2381780435962062,0.25806450843811035,0.7419354915618896,0.5,0.21849798387096775,mmlu:professional_accounting,validation,3.397760739782825
282,0.06284227924989469,0.3617021143436432,0.6382978558540344,0.5,0.11486037234042556,mmlu:professional_accounting,test,29.197679562028497
170,0.08942360790336834,0.3529411852359772,0.6470588445663452,0.5,0.1275275735294118,mmlu:professional_law,validation,37.84397709695622
1534,0.028630297684451897,0.3422425091266632,0.6577575206756592,0.5,0.13822624674054762,mmlu:professional_law,test,342.3736693300307
31,0.10904836462390041,0.4516128897666931,0.5483871102333069,0.5,0.044480846774193505,mmlu:professional_medicine,validation,4.934529582969844
272,0.13875008264885233,0.5110294222831726,0.4889705777168274,0.5,0.014935661764705899,mmlu:professional_medicine,test,42.87861212505959
69,0.12799802120181097,0.37681159377098083,0.6231883764266968,0.5,0.07631340579710144,mmlu:professional_psychology,validation,6.450299676973373
612,0.04183238024025961,0.4215686321258545,0.5784313678741455,0.5,0.03155637254901966,mmlu:professional_psychology,test,53.96148932306096
12,0.22806940476099655,0.4166666567325592,0.5833333134651184,0.6142857142857143,0.04166664679845178,mmlu:public_relations,validation,1.1950442700181156
110,0.08100855242122304,0.5363636612892151,0.4636363685131073,0.6370887337986041,0.07674006115306509,mmlu:public_relations,test,8.122039658948779
27,0.07586135687651457,0.4444444477558136,0.5555555820465088,0.5,0.03993055555555558,mmlu:security_studies,validation,4.7309734700247645
245,0.058859858220937325,0.4612244963645935,0.5387755036354065,0.5,0.023150510204081653,mmlu:security_studies,test,40.591316376114264
22,0.12477527152408253,0.6818181872367859,0.3181818127632141,0.3666666666666667,0.22070311958139593,mmlu:sociology,validation,1.786326884990558
201,0.08385253100845944,0.6318408250808716,0.3681592047214508,0.5732602681421579,0.17150577976929016,mmlu:sociology,test,15.137741140089929
11,0.21938796747814523,0.4545454680919647,0.5454545617103577,0.55,0.020241482691331303,mmlu:us_foreign_policy,validation,1.094325803918764
100,0.06875552415847777,0.6499999761581421,0.3499999940395355,0.5336263736263737,0.17226561307907107,mmlu:us_foreign_policy,test,7.566414610948414
18,0.28559624486499363,0.3333333432674408,0.5555555820465088,0.4930555555555556,0.041449639532301186,mmlu:virology,validation,1.7004609359428287
166,0.1447548810617033,0.40361446142196655,0.5481927990913391,0.37645107794361526,0.03534451306584374,mmlu:virology,test,11.089996347902343
19,0.2317042586050536,0.7894737124443054,0.21052631735801697,0.6333333333333333,0.3268914536425942,mmlu:world_religions,validation,1.3220017079729587
171,0.14489754790451093,0.707602322101593,0.2923976480960846,0.5708264462809918,0.24435766259132075,mmlu:world_religions,test,9.565917226020247
