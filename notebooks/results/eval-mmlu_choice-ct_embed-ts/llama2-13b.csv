N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.0696131939237768,0.1818181872367859,0.1818181872367859,0.75,0.32244319265538995,mmlu:abstract_algebra,validation,3.9436950078234076
100,0.062481691688299174,0.33000001311302185,0.3400000035762787,0.42220714608774307,0.16390624999999998,mmlu:abstract_algebra,test,9.363326105987653
14,0.12325577012130193,0.5,0.4285714328289032,0.5306122448979592,0.07393971511295866,mmlu:anatomy,validation,1.5663442169316113
135,0.1060570167170631,0.5185185074806213,0.5037037134170532,0.4791208791208791,0.0011284850261829016,mmlu:anatomy,test,13.15097702597268
16,0.232487965375185,0.625,0.625,0.5,0.1171875,mmlu:astronomy,validation,2.3937002059537917
152,0.11130888250313306,0.4934210479259491,0.4934210479259491,0.5,0.014391447368421073,mmlu:astronomy,test,21.321837642928585
11,0.24546931277621875,0.3636363744735718,0.6363636255264282,0.5,0.12855113636363635,mmlu:business_ethics,validation,1.7944228709675372
100,0.10062643349170684,0.5199999809265137,0.47999998927116394,0.5,0.027812500000000018,mmlu:business_ethics,test,13.873508524149656
29,0.17387458990360125,0.5862069129943848,0.5517241358757019,0.5539215686274509,0.04754847493664971,mmlu:clinical_knowledge,validation,3.2918490688316524
265,0.058063485487452084,0.5962263941764832,0.6075471639633179,0.5740565479711346,0.10303652871329827,mmlu:clinical_knowledge,test,28.64401309308596
16,0.22307050228118896,0.5625,0.625,0.5555555555555556,0.1171875,mmlu:college_biology,validation,2.106972954934463
144,0.05422817170619965,0.5486111044883728,0.5416666865348816,0.5178188899707886,0.03371850649515784,mmlu:college_biology,test,17.88482010597363
8,0.2814292460680008,0.5,0.5,0.25,0.0048828125,mmlu:college_chemistry,validation,1.2875623318832368
100,0.07826841533184052,0.4399999976158142,0.46000000834465027,0.5393668831168831,0.04539064407348631,mmlu:college_chemistry,test,13.359223975101486
11,0.23915172706950794,0.5454545617103577,0.5454545617103577,0.5,0.041548295454545414,mmlu:college_computer_science,validation,2.1936114579439163
100,0.11487072974443437,0.4399999976158142,0.4399999976158142,0.5,0.06390625,mmlu:college_computer_science,test,17.764538686024025
11,0.17525375431234186,0.1818181872367859,0.1818181872367859,0.5,0.3299005681818182,mmlu:college_mathematics,validation,1.7481339590158314
100,0.06233548492193221,0.3100000023841858,0.3100000023841858,0.5,0.20171875,mmlu:college_mathematics,test,13.451733252964914
22,0.15730334141037683,0.5454545617103577,0.5454545617103577,0.5291666666666667,0.03480110927061597,mmlu:college_medicine,validation,2.982232721056789
173,0.07321169403936133,0.5491329431533813,0.5491329431533813,0.5767206477732794,0.03696263318806026,mmlu:college_medicine,test,27.801795365987346
11,0.12884083119305698,0.5454545617103577,0.4545454680919647,0.7666666666666667,0.054687483744187804,mmlu:college_physics,validation,1.5494801378808916
102,0.18728521553909075,0.23529411852359772,0.7450980544090271,0.7307692307692307,0.23330269724714991,mmlu:college_physics,test,12.116410024929792
11,0.31622943011197174,0.8181818127632141,0.27272728085517883,0.8888888888888888,0.23473010279915552,mmlu:computer_security,validation,1.5578695619478822
100,0.05812181204557419,0.699999988079071,0.30000001192092896,0.4388095238095238,0.20761717557907106,mmlu:computer_security,test,10.611030715052038
26,0.1564652782220107,0.42307692766189575,0.5769230723381042,0.496969696969697,0.06445312958497262,mmlu:conceptual_physics,validation,2.4854911740403622
235,0.1324305961740778,0.3787234127521515,0.6212766170501709,0.5839618285362475,0.10872671857793281,mmlu:conceptual_physics,test,19.894201372982934
12,0.16740141312281293,0.25,0.25,0.5,0.29296875,mmlu:econometrics,validation,1.9773744370322675
114,0.1380235351491393,0.2719298303127289,0.2719298303127289,0.5,0.2710389254385965,mmlu:econometrics,test,16.458363472949713
16,0.22651579603552818,0.3125,0.6875,0.6000000000000001,0.162353515625,mmlu:electrical_engineering,validation,1.9360061660408974
145,0.07684717507197941,0.4482758641242981,0.5517241358757019,0.5774038461538462,0.025862040190861135,mmlu:electrical_engineering,test,15.834217268973589
41,0.11319765666636025,0.3658536672592163,0.6341463327407837,0.5346153846153846,0.11356706299432895,mmlu:elementary_mathematics,validation,5.525291161146015
378,0.0972330496897773,0.32275131344795227,0.6772486567497253,0.49414062499999994,0.15585728549452682,mmlu:elementary_mathematics,test,47.714589128037915
14,0.12619798524039133,0.2857142984867096,0.7142857313156128,0.5,0.2103794642857143,mmlu:formal_logic,validation,2.183155824895948
126,0.03215286679684172,0.3571428656578064,0.6428571343421936,0.5,0.1389508928571429,mmlu:formal_logic,test,18.268467708025128
10,0.16201186776161192,0.5,0.5,0.66,0.00234377384185791,mmlu:global_facts,validation,1.5789241141173989
100,0.10517410397529603,0.3499999940395355,0.6800000071525574,0.4762637362637362,0.17808591604232793,mmlu:global_facts,test,10.927889651851729
32,0.12172777019441128,0.53125,0.5,0.17647058823529416,0.009765625,mmlu:high_school_biology,validation,4.261025984073058
310,0.08067745210662966,0.6580645442008972,0.6516128778457642,0.4810164631890493,0.14096524869242022,mmlu:high_school_biology,test,39.55157753895037
22,0.12493294883858076,0.3636363744735718,0.4545454680919647,0.5892857142857143,0.051846607164903136,mmlu:high_school_chemistry,validation,2.989282364025712
203,0.05575069344689694,0.47783252596855164,0.467980295419693,0.5178467224275431,0.038716107460078364,mmlu:high_school_chemistry,test,25.309181466000155
9,0.26322924759652877,0.6666666865348816,0.3333333432674408,0.5,0.16666666666666669,mmlu:high_school_computer_science,validation,2.0254442300647497
100,0.12126098752021791,0.550000011920929,0.44999998807907104,0.5,0.04999999999999999,mmlu:high_school_computer_science,test,19.825492676813155
18,0.21657157772117192,0.6666666865348816,0.3333333432674408,0.5,0.16666666666666669,mmlu:high_school_european_history,validation,11.035192373208702
165,0.07021790941556295,0.6484848260879517,0.35151514410972595,0.5,0.1484848484848485,mmlu:high_school_european_history,test,99.37599143083207
22,0.1206256137652831,0.7272727489471436,0.6363636255264282,0.515625,0.13299007307399402,mmlu:high_school_geography,validation,2.397323968121782
198,0.07263806537546293,0.7222222089767456,0.7020202279090881,0.5157660521296884,0.19842961821893246,mmlu:high_school_geography,test,19.881849030032754
21,0.1852072931471325,0.7142857313156128,0.5714285969734192,0.5833333333333333,0.07031247445515221,mmlu:high_school_government_and_politics,validation,2.672506985021755
193,0.07061314428408529,0.8341968655586243,0.2849740982055664,0.4754464285714285,0.2165236522496673,mmlu:high_school_government_and_politics,test,22.503623785916716
43,0.12308676021043644,0.4883720874786377,0.4651162922382355,0.4978354978354978,0.038608295972957174,mmlu:high_school_macroeconomics,validation,4.61151527101174
390,0.08908910621435215,0.5435897707939148,0.5435897707939148,0.5308061267754929,0.03940305373607533,mmlu:high_school_macroeconomics,test,40.431965159019455
29,0.11224446214478592,0.24137930572032928,0.7586206793785095,0.7045454545454546,0.24003232553087428,mmlu:high_school_mathematics,validation,3.792881601024419
270,0.0799310932556788,0.24444444477558136,0.7555555701255798,0.5357620320855615,0.23679105970594616,mmlu:high_school_mathematics,test,33.01980059710331
26,0.1624302909924434,0.6538461446762085,0.6538461446762085,0.3856209150326797,0.1482872458604666,mmlu:high_school_microeconomics,validation,2.887737304205075
238,0.0833617255968206,0.5840336084365845,0.5840336084365845,0.5478526269893176,0.07827270531854713,mmlu:high_school_microeconomics,test,24.9092171380762
17,0.1716516771737267,0.23529411852359772,0.7647058963775635,0.423076923076923,0.25873158959781417,mmlu:high_school_physics,validation,2.6032054049428552
151,0.06615366327841553,0.41059601306915283,0.5827814340591431,0.3959768031895614,0.0767798056665635,mmlu:high_school_physics,test,20.15509784920141
60,0.11583499262730279,0.800000011920929,0.5,0.4782986111111111,0.0015624761581420898,mmlu:high_school_psychology,validation,7.691555505851284
545,0.056013657849863036,0.763302743434906,0.4275229275226593,0.5494931425163982,0.07385321625875768,mmlu:high_school_psychology,test,68.9954390199855
23,0.10543480645055357,0.3913043439388275,0.6086956262588501,0.5,0.10869565217391308,mmlu:high_school_statistics,validation,4.12043710402213
216,0.04311546021037632,0.4583333432674408,0.5416666865348816,0.5,0.04166666666666663,mmlu:high_school_statistics,test,38.5182407440152
22,0.1829272142865441,0.7727272510528564,0.7727272510528564,0.5,0.2649147727272727,mmlu:high_school_us_history,validation,10.43492371100001
204,0.06136218823638616,0.75,0.75,0.5,0.2421875,mmlu:high_school_us_history,test,95.41010068100877
26,0.1794874771283223,0.5384615659713745,0.5384615659713745,0.5,0.030649038461538436,mmlu:high_school_world_history,validation,9.119437964167446
237,0.051091996426320785,0.7257384061813354,0.7257384061813354,0.5,0.2179258966244726,mmlu:high_school_world_history,test,76.15886228205636
23,0.3181648306224657,0.5652173757553101,0.3913043439388275,0.4423076923076924,0.11107334105864813,mmlu:human_aging,validation,2.1683739200234413
223,0.07719957734971838,0.605381190776825,0.4573991000652313,0.5102693602693603,0.04510578205767235,mmlu:human_aging,test,19.415512318024412
12,0.23632426559925082,0.4166666567325592,0.5,0.4714285714285715,0.002604186534881592,mmlu:human_sexuality,validation,1.3972509070299566
131,0.09733276467286903,0.6106870174407959,0.5343511700630188,0.6328431372549019,0.031130706080953585,mmlu:human_sexuality,test,13.003380590118468
13,0.1827215964977558,0.7692307829856873,0.7692307829856873,0.5,0.2653245192307693,mmlu:international_law,validation,2.1706117300782353
121,0.08156253237369632,0.7190082669258118,0.7190082669258118,0.5,0.21510201446280997,mmlu:international_law,test,17.76722645200789
11,0.2184979725967754,0.4545454680919647,0.4545454680919647,0.13333333333333336,0.054687483744187804,mmlu:jurisprudence,validation,1.41384074697271
108,0.12156277619026327,0.7222222089767456,0.7222222089767456,0.5053418803418804,0.21068431271447075,mmlu:jurisprudence,test,11.564136517001316
18,0.1765345086654027,0.7777777910232544,0.2777777910232544,0.4732142857142857,0.22526039017571342,mmlu:logical_fallacies,validation,2.353685745038092
163,0.07610305193011746,0.6441717743873596,0.3987730145454407,0.5381773399014778,0.10527701026822894,mmlu:logical_fallacies,test,18.51599665102549
11,0.18800130757418546,0.4545454680919647,0.4545454680919647,0.5,0.04936079545454547,mmlu:machine_learning,validation,1.8369563568849117
112,0.18364768049546648,0.2232142835855484,0.2232142835855484,0.5,0.2806919642857143,mmlu:machine_learning,test,16.64536242792383
11,0.13454832001165912,0.7272727489471436,0.8181818127632141,0.6666666666666667,0.31463069265539,mmlu:management,validation,1.1851596250198781
103,0.08853922220109736,0.7572815418243408,0.6504854559898376,0.48461538461538456,0.14752731797764607,mmlu:management,test,8.433661841088906
25,0.24610543847084046,0.8399999737739563,0.7200000286102295,0.6904761904761905,0.21765622615814206,mmlu:marketing,validation,2.980602389900014
234,0.0726083690284664,0.7991452813148499,0.6282051205635071,0.5398793946979178,0.12600160409242678,mmlu:marketing,test,24.955195249058306
11,0.17787489565936004,0.8181818127632141,0.8181818127632141,0.7777777777777778,0.3018465692346747,mmlu:medical_genetics,validation,1.3983750778716058
100,0.13138089478015902,0.5799999833106995,0.5699999928474426,0.5463875205254516,0.05460936546325679,mmlu:medical_genetics,test,9.753675983054563
86,0.08592159768869709,0.6627907156944275,0.6860465407371521,0.7065940713853599,0.18273076484369677,mmlu:miscellaneous,validation,7.516477226978168
783,0.056328266021696834,0.7586206793785095,0.7139208316802979,0.5611716815420519,0.21050845145570207,mmlu:miscellaneous,test,68.71115163015202
38,0.1724564589952168,0.5,0.5,0.3213296398891967,0.006476163864135742,mmlu:moral_disputes,validation,4.590238858014345
346,0.05548769166703859,0.6040462255477905,0.39306357502937317,0.5341738553417386,0.11304416373975013,mmlu:moral_disputes,test,40.753739771200344
100,0.08906677156686785,0.33000001311302185,0.33000001311302185,0.5,0.17390624999999998,mmlu:moral_scenarios,validation,14.685312646906823
895,0.07549112196075183,0.35754188895225525,0.35754188895225525,0.5,0.1463643505586592,mmlu:moral_scenarios,test,128.54573591519147
33,0.1590046322706974,0.7575757503509521,0.7575757503509521,0.5,0.24976325757575757,mmlu:nutrition,validation,4.907242929097265
306,0.09267530517250881,0.6307189464569092,0.6307189464569092,0.5,0.12290645424836599,mmlu:nutrition,test,43.686138017103076
34,0.20768010265686931,0.6470588445663452,0.529411792755127,0.42045454545454547,0.025160821045146275,mmlu:philosophy,validation,3.481983741046861
311,0.09510084574628873,0.6495176553726196,0.5594855546951294,0.4989099827413933,0.056445932081657935,mmlu:philosophy,test,29.063711795024574
35,0.14031588009425572,0.6571428775787354,0.6000000238418579,0.4384057971014492,0.09676340818405149,mmlu:prehistory,validation,4.854608319001272
324,0.05882724328541461,0.6358024477958679,0.5987654328346252,0.48669162415665623,0.09514856264914995,mmlu:prehistory,test,42.02857998502441
31,0.14624394428345464,0.29032257199287415,0.7096773982048035,0.5,0.20577116935483875,mmlu:professional_accounting,validation,5.221559504047036
282,0.03571194600551686,0.41489362716674805,0.585106372833252,0.5,0.08120013297872342,mmlu:professional_accounting,test,46.02194710588083
170,0.12842015641577104,0.38235294818878174,0.38235294818878174,0.5,0.12155330882352944,mmlu:professional_law,validation,61.12063717190176
1534,0.09026802297210446,0.40612778067588806,0.40612778067588806,0.5,0.09777847946544982,mmlu:professional_law,test,554.4807921389583
31,0.19196684706595632,0.4516128897666931,0.4516128897666931,0.5,0.05229334677419356,mmlu:professional_medicine,validation,7.895672528073192
272,0.09498748511952512,0.5404411554336548,0.5404411554336548,0.5,0.0365349264705882,mmlu:professional_medicine,test,68.71238566515967
69,0.15919146891953287,0.5652173757553101,0.5652173757553101,0.5,0.06521739130434778,mmlu:professional_psychology,validation,9.909172900952399
612,0.0768520909976336,0.5539215803146362,0.5539215803146362,0.5,0.05392156862745101,mmlu:professional_psychology,test,83.9174642751459
12,0.4198806956410408,0.5,0.4166666567325592,0.4305555555555556,0.08723958333333331,mmlu:public_relations,validation,1.6327361499425024
110,0.08595223860307172,0.6454545259475708,0.4636363685131073,0.4972914409534127,0.038707410205494286,mmlu:public_relations,test,12.176422907039523
27,0.22061538365152147,0.6296296119689941,0.6296296119689941,0.5,0.11400462962962965,mmlu:security_studies,validation,7.292177102062851
245,0.05831849891312268,0.6204081773757935,0.6204081773757935,0.5,0.10478316326530612,mmlu:security_studies,test,64.63554367399774
22,0.20658719404177228,0.8181818127632141,0.1818181872367859,0.16666666666666669,0.31924713199788873,mmlu:sociology,validation,2.6357693849131465
201,0.0791623977879387,0.7761194109916687,0.31840795278549194,0.5686609686609687,0.18310790512692277,mmlu:sociology,test,22.81145265698433
11,0.13104425235228107,0.9090909361839294,0.9090909361839294,0.35,0.4023437229069796,mmlu:us_foreign_policy,validation,1.44758750195615
100,0.08155262723565102,0.8399999737739563,0.8399999737739563,0.5171130952380952,0.33406248331069943,mmlu:us_foreign_policy,test,10.89779106900096
18,0.2801609834035238,0.4444444477558136,0.6666666865348816,0.76875,0.16080729166666663,mmlu:virology,validation,2.4047751240432262
166,0.1782420268618917,0.4397590458393097,0.5060241222381592,0.5472087199882162,0.0019530991473829529,mmlu:virology,test,16.24430607818067
19,0.09875376914676866,0.7894737124443054,0.2631579041481018,0.4,0.24259866225092036,mmlu:world_religions,validation,1.7127132748719305
171,0.05092698492501912,0.7602339386940002,0.28654971718788147,0.5508442776735459,0.21836165552250825,mmlu:world_religions,test,13.234774806071073
