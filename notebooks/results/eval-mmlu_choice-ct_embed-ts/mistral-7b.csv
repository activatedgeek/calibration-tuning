N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.17018335515802555,0.4545454680919647,0.5454545617103577,0.43333333333333335,0.035511358217759526,mmlu:abstract_algebra,validation,4.343665197957307
100,0.043980423361063,0.33000001311302185,0.6700000166893005,0.5330167345092718,0.16261718988418583,mmlu:abstract_algebra,test,6.2976225931197405
14,0.12516065154756817,0.6428571343421936,0.6428571343421936,0.5777777777777777,0.1169084991727557,mmlu:anatomy,validation,1.113584578037262
135,0.07553706279507391,0.5777778029441833,0.5777778029441833,0.4408457040035988,0.05361691580878358,mmlu:anatomy,test,8.698928815079853
16,0.12928905338048935,0.625,0.625,0.5,0.046875,mmlu:astronomy,validation,1.6209031350445002
152,0.07584191113710403,0.6578947305679321,0.6578947305679321,0.5,0.07976973684210531,mmlu:astronomy,test,12.953566733980551
11,0.36880690401250665,0.4545454680919647,0.4545454680919647,0.5,0.06107954545454547,mmlu:business_ethics,validation,1.2312227571383119
100,0.09758620858192443,0.5899999737739563,0.5899999737739563,0.5,0.07437499999999997,mmlu:business_ethics,test,8.369864618172869
29,0.24320986969717617,0.6206896305084229,0.6206896305084229,0.4747474747474747,0.09523167692381762,mmlu:clinical_knowledge,validation,2.1701982370577753
265,0.09750527672047885,0.6754717230796814,0.6754717230796814,0.5084123684552423,0.14995578414988964,mmlu:clinical_knowledge,test,18.150389432907104
16,0.1347656361758709,0.625,0.625,0.5,0.066162109375,mmlu:college_biology,validation,1.4346578728873283
144,0.04710646718740463,0.7152777910232544,0.7152777910232544,0.4950272318257163,0.15443249998821157,mmlu:college_biology,test,11.066580190090463
8,0.3223490081727505,0.25,0.25,0.5,0.2744140625,mmlu:college_chemistry,validation,0.9585152601357549
100,0.0631174963712692,0.47999998927116394,0.4699999988079071,0.5693108974358975,0.057890622615814236,mmlu:college_chemistry,test,8.494838541839272
11,0.06236901066519998,0.4545454680919647,0.5454545617103577,0.5,0.022017045454545414,mmlu:college_computer_science,validation,1.5192691490519792
100,0.1660211804509163,0.5400000214576721,0.46000000834465027,0.5,0.06343749999999998,mmlu:college_computer_science,test,11.065737078897655
11,0.0985872122374448,0.27272728085517883,0.27272728085517883,0.5,0.2468039772727273,mmlu:college_mathematics,validation,1.258136433083564
100,0.09338311880826951,0.3499999940395355,0.3499999940395355,0.5,0.16953125000000002,mmlu:college_mathematics,test,8.432513728970662
22,0.20120580629868942,0.5454545617103577,0.5454545617103577,0.5708333333333333,0.02024145559831103,mmlu:college_medicine,validation,1.9583751889877021
173,0.0414742293385412,0.6300578117370605,0.6300578117370605,0.4778526376146789,0.06331287987659429,mmlu:college_medicine,test,16.776510915951803
11,0.27771310914646496,0.3636363744735718,0.3636363744735718,0.8571428571428571,0.2034801353107799,mmlu:college_physics,validation,1.2786256361287087
102,0.0993184745311737,0.4215686321258545,0.4215686321258545,0.6363815530153725,0.13610601892658308,mmlu:college_physics,test,7.722086638910696
11,0.3703038475730202,0.8181818127632141,0.8181818127632141,0.7777777777777778,0.30042613094503234,mmlu:computer_security,validation,1.1338807961437851
100,0.05424466729164127,0.7699999809265137,0.7599999904632568,0.6369282891022021,0.24070311546325684,mmlu:computer_security,test,6.803049877984449
26,0.2384749192457933,0.42307692766189575,0.42307692766189575,0.6424242424242423,0.10997593861359817,mmlu:conceptual_physics,validation,1.7158991429023445
235,0.06336895924933414,0.6042553186416626,0.6042553186416626,0.5963198546115402,0.07360374978248108,mmlu:conceptual_physics,test,12.958322112914175
12,0.22919477025667825,0.6666666865348816,0.6666666865348816,0.5,0.07682291666666663,mmlu:econometrics,validation,1.364954519784078
114,0.061843172761431905,0.5,0.5,0.5,0.08984375,mmlu:econometrics,test,10.213059685891494
16,0.26017797738313675,0.625,0.625,0.7166666666666667,0.11376953125,mmlu:electrical_engineering,validation,1.3330603858921677
145,0.04798555004185644,0.565517246723175,0.4965517222881317,0.590495547812621,0.009806005297036013,mmlu:electrical_engineering,test,10.045547340996563
41,0.1277144900182398,0.4146341383457184,0.5853658318519592,0.5575980392156863,0.039538882127622244,mmlu:elementary_mathematics,validation,3.538127664010972
378,0.07350501418113708,0.4021163880825043,0.5978835821151733,0.4985299254774104,0.05204202321471363,mmlu:elementary_mathematics,test,29.85382105782628
14,0.2780844122171402,0.2142857164144516,0.7857142686843872,0.5,0.2818080357142857,mmlu:formal_logic,validation,1.5249831131659448
126,0.08739520301894535,0.3968254029750824,0.60317462682724,0.5,0.09926835317460314,mmlu:formal_logic,test,11.453030995093286
10,0.18303847908973697,0.6000000238418579,0.6000000238418579,0.6666666666666666,0.08906248807907102,mmlu:global_facts,validation,0.9824694502167404
100,0.06439917892217638,0.3199999928474426,0.3199999928474426,0.5080422794117647,0.18980466604232787,mmlu:global_facts,test,6.895333274034783
32,0.109920903109014,0.6875,0.6875,0.5136363636363637,0.1346435546875,mmlu:high_school_biology,validation,2.6932795678731054
310,0.04330083997018876,0.7612903118133545,0.7612903118133545,0.5322377462207971,0.20490170601875546,mmlu:high_school_biology,test,24.64004957792349
22,0.336632411588322,0.3636363744735718,0.5,0.4821428571428572,0.022904813289642334,mmlu:high_school_chemistry,validation,2.003897041082382
203,0.032795608337289596,0.5123152732849121,0.5517241358757019,0.5695415695415695,0.029056312709019094,mmlu:high_school_chemistry,test,15.871286849025637
9,0.29575566781891716,0.6666666865348816,0.6666666865348816,0.5,0.09635416666666663,mmlu:high_school_computer_science,validation,1.3883977679070085
100,0.14218660235404967,0.7300000190734863,0.7300000190734863,0.5,0.15968749999999998,mmlu:high_school_computer_science,test,12.312555528013036
18,0.30340122514300877,0.7222222089767456,0.7222222089767456,0.5,0.1831597222222222,mmlu:high_school_european_history,validation,6.489211163949221
165,0.06843155821164448,0.7636363506317139,0.7636363506317139,0.5,0.22457386363636367,mmlu:high_school_european_history,test,57.76735884905793
22,0.18262522328983655,0.8181818127632141,0.8181818127632141,0.45833333333333337,0.2837358171289618,mmlu:high_school_geography,validation,1.6475452890153974
198,0.035832466501178176,0.808080792427063,0.808080792427063,0.4961348684210526,0.27016253844656124,mmlu:high_school_geography,test,12.711235369788483
21,0.2009876540728978,0.8571428656578064,0.8571428656578064,0.537037037037037,0.3232886706079755,mmlu:high_school_government_and_politics,validation,1.7268057588953525
193,0.07055158056125738,0.8860103487968445,0.8756476640701294,0.4876395534290271,0.34508580401771427,mmlu:high_school_government_and_politics,test,13.971476047998294
43,0.08322383359421132,0.6511628031730652,0.6511628031730652,0.5666666666666667,0.12291060630665274,mmlu:high_school_macroeconomics,validation,2.999336733017117
390,0.07889645802669039,0.6538461446762085,0.6487179398536682,0.5674800290486565,0.11967147283065016,mmlu:high_school_macroeconomics,test,25.01305023697205
29,0.09204062511181012,0.2068965584039688,0.7931034564971924,0.6594202898550724,0.24097519290858305,mmlu:high_school_mathematics,validation,2.48953869799152
270,0.049816260845572856,0.3185185194015503,0.6814814805984497,0.4643263397371082,0.1298032411822566,mmlu:high_school_mathematics,test,20.846279561985284
26,0.14385099823658284,0.7307692170143127,0.7307692170143127,0.5639097744360901,0.1781851190787095,mmlu:high_school_microeconomics,validation,1.969714456005022
238,0.05148605952242845,0.6722689270973206,0.6722689270973206,0.557852564102564,0.11930475665741613,mmlu:high_school_microeconomics,test,16.085501129971817
17,0.1623183383661158,0.23529411852359772,0.23529411852359772,0.4903846153846154,0.3991268382352941,mmlu:high_school_physics,validation,1.8395572579465806
151,0.06380645486692718,0.34437087178230286,0.34437087178230286,0.3624708624708624,0.24384312756014184,mmlu:high_school_physics,test,12.618240460054949
60,0.06861836363871893,0.8833333253860474,0.8833333253860474,0.5795148247978437,0.3354817708333333,mmlu:high_school_psychology,validation,4.791894357185811
545,0.024298798108319603,0.8165137767791748,0.8165137767791748,0.5005617977528091,0.2683701362084905,mmlu:high_school_psychology,test,41.63048499380238
23,0.13325972142426865,0.52173912525177,0.52173912525177,0.5,0.021229619565217406,mmlu:high_school_statistics,validation,2.7285435791127384
216,0.08938277112665001,0.5787037014961243,0.5787037014961243,0.5,0.03573495370370372,mmlu:high_school_statistics,test,23.78383298800327
22,0.16132216968319635,0.7727272510528564,0.7727272510528564,0.5,0.2063210227272727,mmlu:high_school_us_history,validation,6.243107930058613
204,0.039715321332800625,0.7745097875595093,0.7745097875595093,0.5,0.20810355392156865,mmlu:high_school_us_history,test,55.908621387090534
26,0.17852042730037984,0.7307692170143127,0.7307692170143127,0.5,0.19951923076923073,mmlu:high_school_world_history,validation,5.486185890855268
237,0.057549775652744564,0.75527423620224,0.75527423620224,0.5,0.22402426160337552,mmlu:high_school_world_history,test,44.64960363693535
23,0.18107274174690252,0.739130437374115,0.739130437374115,0.1715686274509804,0.20414399841557374,mmlu:human_aging,validation,1.5508087419439107
223,0.07521940333426268,0.6995515823364258,0.6995515823364258,0.5728568694986605,0.16499088911732218,mmlu:human_aging,test,12.624379915883765
12,0.2105246310432752,0.5833333134651184,0.5833333134651184,0.7142857142857143,0.05371095736821496,mmlu:human_sexuality,validation,1.0476891789585352
131,0.10232193733899647,0.8015267252922058,0.8015267252922058,0.5499999999999999,0.27647899807864473,mmlu:human_sexuality,test,8.443037012824789
13,0.10194548735251793,0.9230769276618958,0.9230769276618958,0.5,0.38401442307692313,mmlu:international_law,validation,1.4790077849756926
121,0.05805432205357827,0.7933884263038635,0.7933884263038635,0.5,0.25432592975206614,mmlu:international_law,test,10.95446244510822
11,0.2690740092234178,0.6363636255264282,0.6363636255264282,0.3928571428571428,0.09836645017970691,mmlu:jurisprudence,validation,1.0783471381291747
108,0.12221521966987187,0.8148148059844971,0.8148148059844971,0.4795454545454545,0.2695312588303177,mmlu:jurisprudence,test,7.416861334815621
18,0.20434738198916116,0.7222222089767456,0.7222222089767456,0.46153846153846156,0.1699218882454766,mmlu:logical_fallacies,validation,1.584886313881725
163,0.09247886220370331,0.803680956363678,0.803680956363678,0.537094465648855,0.2536426438875725,mmlu:logical_fallacies,test,11.713646874995902
11,0.2018365128473802,0.27272728085517883,0.27272728085517883,0.5,0.2819602272727273,mmlu:machine_learning,validation,1.3392826849594712
112,0.12399928271770477,0.375,0.375,0.5,0.1796875,mmlu:machine_learning,test,10.460061793914065
11,0.16547433625568045,0.9090909361839294,0.9090909361839294,0.30000000000000004,0.3924005952748385,mmlu:management,validation,0.8779033760074526
103,0.042513576526086304,0.7961165308952332,0.7572815418243408,0.5740418118466899,0.23994995320884926,mmlu:management,test,5.582587273791432
25,0.11829211235046386,0.8799999952316284,0.8799999952316284,0.49242424242424243,0.35062498331069947,mmlu:marketing,validation,1.9935261660721153
234,0.04439549428275506,0.867521345615387,0.867521345615387,0.4802955665024631,0.3374899844838004,mmlu:marketing,test,15.710729708895087
11,0.13500616767189721,1.0,1.0,,0.46555399894714355,mmlu:medical_genetics,validation,1.1381290389690548
100,0.11493014007806779,0.7300000190734863,0.7300000190734863,0.6385083713850837,0.1967578339576721,mmlu:medical_genetics,test,6.363955084932968
86,0.08882987568544788,0.7674418687820435,0.7674418687820435,0.7106060606060607,0.2503179228583048,mmlu:miscellaneous,validation,4.99822705402039
783,0.04395729360452559,0.8173691034317017,0.7445721626281738,0.5691542832167832,0.2258440809536102,mmlu:miscellaneous,test,44.758616250008345
38,0.1661682050479086,0.6315789222717285,0.6315789222717285,0.32738095238095233,0.10649671680048889,mmlu:moral_disputes,validation,3.1235829358920455
346,0.0584012302704629,0.7052023410797119,0.7052023410797119,0.5384924461587913,0.18037620272939603,mmlu:moral_disputes,test,25.72966208914295
100,0.13669809579849243,0.4099999964237213,0.4099999964237213,0.5,0.12125000000000002,mmlu:moral_scenarios,validation,9.173597259214148
895,0.06356477018175177,0.37318435311317444,0.37318435311317444,0.5,0.15806564245810056,mmlu:moral_scenarios,test,77.95313874213025
33,0.1369313398996989,0.7272727489471436,0.7272727489471436,0.5,0.1608664772727273,mmlu:nutrition,validation,3.1945849910844117
306,0.09520230291326062,0.741830050945282,0.741830050945282,0.5,0.17542381535947715,mmlu:nutrition,test,26.651595008093864
34,0.22579511123545035,0.7352941036224365,0.7352941036224365,0.35111111111111115,0.21036304445827714,mmlu:philosophy,validation,2.4923945430200547
311,0.03980188086101864,0.7202572226524353,0.6945337653160095,0.44963567323481113,0.17129724892006049,mmlu:philosophy,test,19.144347836030647
35,0.16099082486970084,0.5714285969734192,0.5714285969734192,0.5366666666666667,0.0035714251654488383,mmlu:prehistory,validation,3.1194203151389956
324,0.022805552699683616,0.7407407164573669,0.7407407164573669,0.5967757936507937,0.17133244044250912,mmlu:prehistory,test,25.84597365418449
31,0.1648519971678334,0.4516128897666931,0.5483871102333069,0.5,0.032762096774193505,mmlu:professional_accounting,validation,3.357177433092147
282,0.0664195701585594,0.5106382966041565,0.4893617033958435,0.5,0.02626329787234044,mmlu:professional_accounting,test,27.80351648805663
170,0.07522207375834968,0.4529411792755127,0.4529411792755127,0.5,0.07049632352941176,mmlu:professional_law,validation,35.38485887600109
1534,0.03781230397998431,0.4537157714366913,0.4537157714366913,0.5,0.06972172425032597,mmlu:professional_law,test,320.90209707198665
31,0.2296288888300619,0.5483871102333069,0.5483871102333069,0.5,0.0023941532258064946,mmlu:professional_medicine,validation,4.7908437580335885
272,0.09225848952637,0.6764705777168274,0.6764705777168274,0.5,0.12568933823529416,mmlu:professional_medicine,test,40.148382385028526
69,0.10513200967208197,0.7101449370384216,0.7101449370384216,0.5,0.17108242753623193,mmlu:professional_psychology,validation,6.279284761054441
612,0.05439026449240889,0.6813725233078003,0.6813725233078003,0.5,0.14231004901960786,mmlu:professional_psychology,test,51.3230070900172
12,0.2725921496748924,0.5,0.5833333134651184,0.6944444444444444,0.07031251986821496,mmlu:public_relations,validation,1.2346370848827064
110,0.07899739335883746,0.6636363863945007,0.5181818008422852,0.5438726397630507,0.00759943073446101,mmlu:public_relations,test,7.675321466987953
27,0.140475841584029,0.7037037014961243,0.7037037014961243,0.5,0.12167245370370372,mmlu:security_studies,validation,4.450434967176989
245,0.0749469412832844,0.7469387650489807,0.7469387650489807,0.5,0.16490752551020404,mmlu:security_studies,test,37.416959546972066
22,0.12233782898296008,0.8636363744735718,0.8636363744735718,0.7017543859649122,0.3485440503467213,mmlu:sociology,validation,1.8235834038350731
201,0.03701394321906625,0.8358209133148193,0.8407959938049316,0.5767496392496392,0.32861086355513003,mmlu:sociology,test,14.082661901134998
11,0.18971927057613028,0.9090909361839294,0.9090909361839294,0.15000000000000002,0.3746449080380526,mmlu:us_foreign_policy,validation,1.1357605569064617
100,0.08733016997575761,0.8799999952316284,0.8799999952316284,0.5833333333333334,0.3434374976158142,mmlu:us_foreign_policy,test,7.02482372103259
18,0.3344945990377003,0.6666666865348816,0.6666666865348816,0.47916666666666663,0.13411460320154822,mmlu:virology,validation,1.7082133588846773
166,0.21905659570033292,0.5301204919815063,0.5301204919815063,0.5560897435897436,0.0020472507878958046,mmlu:virology,test,10.580915457801893
19,0.20538539008090367,0.8947368264198303,0.3684210479259491,0.8676470588235294,0.134662832084455,mmlu:world_religions,validation,1.3126318510621786
171,0.04527864260980259,0.8187134265899658,0.28654971718788147,0.4601382488479263,0.2170824206363388,mmlu:world_religions,test,8.99613999389112
