N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1974574490026994,0.3636363744735718,0.5454545617103577,0.17857142857142858,0.02627841992811719,mmlu:abstract_algebra,validation,4.560512974858284
100,0.15133172899484634,0.30000001192092896,0.5600000023841858,0.44595238095238093,0.045390603542327934,mmlu:abstract_algebra,test,10.815938915824518
14,0.28083460032939916,0.5714285969734192,0.2857142984867096,0.34375,0.2290736862591335,mmlu:anatomy,validation,1.7472291339654475
135,0.18391638354018883,0.5185185074806213,0.4592592716217041,0.4321978021978022,0.05228586241051003,mmlu:anatomy,test,15.056297984905541
16,0.11572423949837685,0.625,0.625,0.5,0.07421875,mmlu:astronomy,validation,2.6511057030875236
152,0.2484234453816163,0.5526315569877625,0.5526315569877625,0.5,0.0018503289473684736,mmlu:astronomy,test,23.622367656091228
11,0.22676623409444638,0.5454545617103577,0.5454545617103577,0.5,0.029829545454545414,mmlu:business_ethics,validation,1.9964390699751675
100,0.23358124196529387,0.5400000214576721,0.5400000214576721,0.5,0.024375000000000036,mmlu:business_ethics,test,15.409163539065048
29,0.29384357764803126,0.517241358757019,0.4137931168079376,0.3047619047619048,0.0984644129358489,mmlu:clinical_knowledge,validation,3.795535843120888
265,0.21524647384319667,0.5660377144813538,0.49056604504585266,0.5597391304347825,0.023186899581045473,mmlu:clinical_knowledge,test,32.765669986838475
16,0.2030270304530859,0.5625,0.625,0.6111111111111112,0.081298828125,mmlu:college_biology,validation,2.3627650050912052
144,0.2009299904521969,0.5763888955116272,0.5763888955116272,0.5434524985186648,0.04017471604877043,mmlu:college_biology,test,22.737290716031566
8,0.5081976652145386,0.125,0.875,1.0,0.359375,mmlu:college_chemistry,validation,1.4518316469620913
100,0.2300338837504387,0.3700000047683716,0.6000000238418579,0.5965250965250967,0.08812502622604368,mmlu:college_chemistry,test,14.739723751088604
11,0.3500310236757452,0.5454545617103577,0.4545454680919647,0.5,0.07670454545454547,mmlu:college_computer_science,validation,2.427757655037567
100,0.13046191811561583,0.5299999713897705,0.4699999988079071,0.5,0.06125000000000003,mmlu:college_computer_science,test,19.393981419038028
11,0.25505628910931677,0.27272728085517883,0.7272727489471436,0.5,0.2077414772727273,mmlu:college_mathematics,validation,1.9603412610013038
100,0.2144278207421303,0.3499999940395355,0.6499999761581421,0.5,0.13046875000000002,mmlu:college_mathematics,test,14.978339582914487
22,0.45070950416001404,0.3636363744735718,0.3636363744735718,0.7857142857142857,0.18554688583720813,mmlu:college_medicine,validation,3.3953519598580897
173,0.28988235878806584,0.4624277353286743,0.4624277353286743,0.572983870967742,0.08589236894783947,mmlu:college_medicine,test,30.414783326908946
11,0.35103211348707025,0.5454545617103577,0.5454545617103577,0.6666666666666666,0.02237216992811719,mmlu:college_physics,validation,1.783006127923727
102,0.37260022467257936,0.2450980395078659,0.7352941036224365,0.6672727272727272,0.2032781979616951,mmlu:college_physics,test,13.704921087948605
11,0.45593208887360315,0.6363636255264282,0.3636363744735718,0.2857142857142857,0.1473721374164928,mmlu:computer_security,validation,1.7291618208400905
100,0.2413292744755745,0.6399999856948853,0.4000000059604645,0.5403645833333334,0.11359373331069944,mmlu:computer_security,test,11.99227955006063
26,0.3352957837856733,0.4615384638309479,0.6153846383094788,0.7708333333333334,0.10862377973703241,mmlu:conceptual_physics,validation,2.965833812020719
235,0.32360163495895716,0.40851062536239624,0.5957446694374084,0.6078012589928058,0.08633644530113704,mmlu:conceptual_physics,test,23.373167483136058
12,0.4949806133906046,0.3333333432674408,0.3333333432674408,0.5,0.2877604166666667,mmlu:econometrics,validation,2.1823466748464853
114,0.30560289924604855,0.31578946113586426,0.31578946113586426,0.5,0.3053042763157895,mmlu:econometrics,test,18.242809917079285
16,0.45588679052889347,0.5,0.5,0.40625,0.02392578125,mmlu:electrical_engineering,validation,2.228188833920285
145,0.23437489312270593,0.48965516686439514,0.5517241358757019,0.5849828701941377,0.035506488948032766,mmlu:electrical_engineering,test,18.21189318993129
41,0.2608854894231005,0.4146341383457184,0.5853658318519592,0.6433823529411764,0.01772105984571508,mmlu:elementary_mathematics,validation,6.297133212909102
378,0.30925155088068945,0.33068782091140747,0.6693121790885925,0.4726166007905138,0.08542082580939804,mmlu:elementary_mathematics,test,53.394893035059795
14,0.5275802676166808,0.0714285746216774,0.0714285746216774,0.5,0.4402901785714286,mmlu:formal_logic,validation,2.4393222369253635
126,0.3190843548093523,0.2936508059501648,0.2936508059501648,0.5,0.21806795634920634,mmlu:formal_logic,test,20.067224197089672
10,0.4928306341171265,0.30000001192092896,0.30000001192092896,0.6190476190476191,0.23007811307907106,mmlu:global_facts,validation,1.6031825630925596
100,0.3210132357478142,0.30000001192092896,0.3100000023841858,0.46166666666666667,0.2241796875,mmlu:global_facts,test,12.354491604026407
32,0.2951065404340625,0.5625,0.5625,0.5892857142857143,0.01123046875,mmlu:high_school_biology,validation,4.786911173025146
310,0.1685357293775005,0.6741935610771179,0.6741935610771179,0.5326401061158748,0.12055193108897055,mmlu:high_school_biology,test,44.433523091021925
22,0.3267563784664328,0.40909090638160706,0.5909090638160706,0.6923076923076924,0.05735084143551916,mmlu:high_school_chemistry,validation,3.2832802748307586
203,0.23822169732577697,0.4088670015335083,0.5960590839385986,0.5842369477911648,0.0628655846483015,mmlu:high_school_chemistry,test,28.370765724917874
9,0.22142142719692648,0.6666666865348816,0.3333333432674408,0.5,0.16666666666666669,mmlu:high_school_computer_science,validation,2.336557583184913
100,0.1494222471117973,0.6000000238418579,0.4000000059604645,0.5,0.09999999999999998,mmlu:high_school_computer_science,test,21.506158638047054
18,0.1720835847987069,0.8333333134651184,0.8333333134651184,0.5,0.27864583333333337,mmlu:high_school_european_history,validation,11.533135244855657
165,0.21913791316928286,0.6848484873771667,0.6848484873771667,0.5,0.13016098484848482,mmlu:high_school_european_history,test,102.02098697191104
22,0.15659447962587528,0.7272727489471436,0.6818181872367859,0.49479166666666663,0.14719461852853943,mmlu:high_school_geography,validation,2.765408596023917
198,0.1713440926990124,0.7121211886405945,0.6969696879386902,0.5487122060470324,0.16011680075616552,mmlu:high_school_geography,test,22.893650555983186
21,0.23234996483439488,0.7142857313156128,0.7142857313156128,0.5,0.1882440277508327,mmlu:high_school_government_and_politics,validation,2.999173884978518
193,0.1403555290995484,0.7927461266517639,0.7927461266517639,0.4770424836601307,0.2678513400295238,mmlu:high_school_government_and_politics,test,25.279383952030912
43,0.3187217435171438,0.4651162922382355,0.4883720874786377,0.4945652173913043,0.06231831949810651,mmlu:high_school_macroeconomics,validation,5.298470824025571
390,0.23806955034916216,0.5307692289352417,0.5333333611488342,0.5183469285393733,0.017277626196543383,mmlu:high_school_macroeconomics,test,45.8348013330251
29,0.2368637878319313,0.27586206793785095,0.7241379022598267,0.6071428571428572,0.12271012931034478,mmlu:high_school_mathematics,validation,4.278433554805815
270,0.23808817863464354,0.28148147463798523,0.7185184955596924,0.4713781877373847,0.11780961133815623,mmlu:high_school_mathematics,test,37.338364666095
26,0.2125687048985408,0.6153846383094788,0.6153846383094788,0.43124999999999997,0.060396648370302675,mmlu:high_school_microeconomics,validation,3.2788204678799957
238,0.21300476626688697,0.5798319578170776,0.5798319578170776,0.5846739130434784,0.02550551771115861,mmlu:high_school_microeconomics,test,28.53673579194583
17,0.4743419324650484,0.29411765933036804,0.3529411852359772,0.6666666666666666,0.1537224440013661,mmlu:high_school_physics,validation,2.9645658559165895
151,0.3228851777828292,0.34437087178230286,0.3973509967327118,0.43230380730380724,0.11258277632542796,mmlu:high_school_physics,test,22.45982529898174
60,0.12056558529535932,0.800000011920929,0.44999998807907104,0.4904513888888889,0.05651043653488158,mmlu:high_school_psychology,validation,8.74974477197975
545,0.1326619252152399,0.7486238479614258,0.44954127073287964,0.5283920137398025,0.057525799908769215,mmlu:high_school_psychology,test,78.51979208597913
23,0.31458042497220257,0.3478260934352875,0.3478260934352875,0.5,0.19123641304347827,mmlu:high_school_statistics,validation,4.656449069036171
216,0.24465402105340253,0.3611111044883728,0.3611111044883728,0.5,0.1779513888888889,mmlu:high_school_statistics,test,42.54842653195374
22,0.23554935374043207,0.7272727489471436,0.7272727489471436,0.5,0.1608664772727273,mmlu:high_school_us_history,validation,10.968010063981637
204,0.13857290660049398,0.7401960492134094,0.7401960492134094,0.5,0.17378982843137258,mmlu:high_school_us_history,test,98.39868691493757
26,0.2755839412028973,0.6153846383094788,0.6153846383094788,0.5,0.08413461538461542,mmlu:high_school_world_history,validation,9.796939346008003
237,0.14447074443227628,0.7383966445922852,0.7383966445922852,0.5,0.20714662447257381,mmlu:high_school_world_history,test,79.79546037013642
23,0.23390976242397143,0.695652186870575,0.3478260934352875,0.4464285714285714,0.16644022516582324,mmlu:human_aging,validation,2.484278296120465
223,0.18573621262883927,0.6322869658470154,0.48430493474006653,0.5291904514789829,0.030461760379808356,mmlu:human_aging,test,22.35928573505953
12,0.2759020452698072,0.4166666567325592,0.6666666865348816,0.7285714285714286,0.15755210320154822,mmlu:human_sexuality,validation,1.6115639109630138
131,0.20084000771282284,0.6183205842971802,0.572519063949585,0.7145679012345678,0.058444639198652615,mmlu:human_sexuality,test,14.786252144025639
13,0.09948286184897794,0.8461538553237915,0.1538461595773697,0.5,0.35787259615384615,mmlu:international_law,validation,2.4111956029664725
121,0.15452220912807246,0.7438016533851624,0.25619834661483765,0.5,0.255520402892562,mmlu:international_law,test,19.713454538956285
11,0.28702737526460126,0.4545454680919647,0.3636363744735718,0.24999999999999997,0.1764914501797069,mmlu:jurisprudence,validation,1.675115582998842
108,0.07802043137726959,0.75,0.7407407164573669,0.47050754458161864,0.19661458774849216,mmlu:jurisprudence,test,13.004651977913454
18,0.24995947215292189,0.7222222089767456,0.7222222089767456,0.6,0.1812065972222222,mmlu:logical_fallacies,validation,2.5636734168510884
163,0.19532882527339684,0.6809815764427185,0.6809815764427185,0.5614171864171864,0.14141585307618587,mmlu:logical_fallacies,test,20.51868172502145
11,0.3918234353715723,0.27272728085517883,0.27272728085517883,0.5,0.2858664772727273,mmlu:machine_learning,validation,2.113937160000205
112,0.4253287336656026,0.2946428656578064,0.2946428656578064,0.5,0.26395089285714285,mmlu:machine_learning,test,18.215095384977758
11,0.19583951343189585,0.8181818127632141,0.7272727489471436,0.5277777777777778,0.2038352272727273,mmlu:management,validation,1.3894584018271416
103,0.12938599621207972,0.7281553149223328,0.7184466123580933,0.5152380952380953,0.18992720992819778,mmlu:management,test,9.702830655965954
25,0.16847306013107297,0.800000011920929,0.800000011920929,0.675,0.2676562547683716,mmlu:marketing,validation,3.414356760913506
234,0.06053689911834193,0.811965823173523,0.811965823173523,0.5597488038277512,0.27829526734148335,mmlu:marketing,test,27.81251266412437
11,0.19213878566568549,0.7272727489471436,0.7272727489471436,0.7083333333333333,0.15838068181818177,mmlu:medical_genetics,validation,1.6472787540405989
100,0.23054085969924926,0.5600000023841858,0.5699999928474426,0.5533685064935064,0.012656269073486293,mmlu:medical_genetics,test,11.131870995042846
86,0.1663382084563721,0.6627907156944275,0.4651162922382355,0.6361161524500908,0.050508720930232565,mmlu:miscellaneous,validation,8.686295181978494
783,0.12437413927848005,0.7407407164573669,0.3550446927547455,0.5811406488873789,0.15811582688018583,mmlu:miscellaneous,test,78.68200190598145
38,0.2750846571043918,0.4736842215061188,0.4736842215061188,0.5513888888888889,0.04142681862178604,mmlu:moral_disputes,validation,5.167906104121357
346,0.21023098978004012,0.6011560559272766,0.6011560559272766,0.509423773690078,0.0858584776779131,mmlu:moral_disputes,test,45.83862641896121
100,0.40612256377935413,0.25,0.25,0.5,0.28515625,mmlu:moral_scenarios,validation,16.008148903027177
895,0.41758067374788854,0.22234636545181274,0.22234636545181274,0.5,0.3128098812849162,mmlu:moral_scenarios,test,140.9575779698789
33,0.12732311089833578,0.6969696879386902,0.6969696879386902,0.5,0.11493844696969702,mmlu:nutrition,validation,5.499240062898025
306,0.198469851336448,0.6045751571655273,0.6045751571655273,0.5,0.022543913398692772,mmlu:nutrition,test,48.03323460393585
34,0.35916966813452106,0.5588235259056091,0.5882353186607361,0.45438596491228067,0.052734350456910994,mmlu:philosophy,validation,3.975899315904826
311,0.26256365187681757,0.6141479015350342,0.610932469367981,0.4563699825479931,0.07637912686614745,mmlu:philosophy,test,33.14530457695946
35,0.21211651563644407,0.6285714507102966,0.6285714507102966,0.5052447552447553,0.09352675846644809,mmlu:prehistory,validation,5.413336133118719
324,0.24364728066656324,0.5987654328346252,0.5987654328346252,0.5125297383029341,0.0637659423145247,mmlu:prehistory,test,46.757590148830786
31,0.3145434991005928,0.4516128897666931,0.5483871102333069,0.5,0.024949596774193505,mmlu:professional_accounting,validation,5.701114517170936
282,0.18436649832742436,0.40425533056259155,0.5957446694374084,0.5,0.0723071808510638,mmlu:professional_accounting,test,50.10453110514209
170,0.3331159968586529,0.38235294818878174,0.38235294818878174,0.5,0.14889705882352944,mmlu:professional_law,validation,63.424991687061265
1534,0.3078311076375621,0.4002607464790344,0.4002607464790344,0.5,0.1309892438070404,mmlu:professional_law,test,575.4097526648548
31,0.26948743289516824,0.4838709533214569,0.4838709533214569,0.5,0.0356602822580645,mmlu:professional_medicine,validation,8.38882159604691
272,0.12061821483075617,0.529411792755127,0.529411792755127,0.5,0.00988051470588236,mmlu:professional_medicine,test,72.53169043688104
69,0.24589078409084375,0.5942028760910034,0.5942028760910034,0.5,0.07467164855072461,mmlu:professional_psychology,validation,11.028799629071727
612,0.23834817914986142,0.5539215803146362,0.5539215803146362,0.5,0.03439031862745101,mmlu:professional_psychology,test,92.97899265796877
12,0.4489505539337794,0.5,0.4166666567325592,0.41666666666666663,0.11295570929845172,mmlu:public_relations,validation,1.8255765791982412
110,0.15075297572396018,0.6454545259475708,0.6545454263687134,0.5854098952690502,0.12919035391374067,mmlu:public_relations,test,13.591391314053908
27,0.33861775309951214,0.5555555820465088,0.5555555820465088,0.5,0.01258680555555558,mmlu:security_studies,validation,7.755847425200045
245,0.25127739298100377,0.6448979377746582,0.6448979377746582,0.5,0.10192920918367343,mmlu:security_studies,test,67.96873925905675
22,0.11302886496890674,0.8181818127632141,0.8181818127632141,0.4236111111111111,0.2821377569978888,mmlu:sociology,validation,2.927936377003789
201,0.1635524873709797,0.7611940503120422,0.7611940503120422,0.5557598039215687,0.22765080074765787,mmlu:sociology,test,24.895545401843265
11,0.07452987540851938,0.9090909361839294,0.9090909361839294,0.25,0.36434659632769495,mmlu:us_foreign_policy,validation,1.628614503890276
100,0.12262817621231081,0.7900000214576721,0.7799999713897705,0.5256178420735382,0.2370702910423279,mmlu:us_foreign_policy,test,12.057123339967802
18,0.453576640950309,0.4444444477558136,0.6111111044883728,0.65,0.08506942457622957,mmlu:virology,validation,2.6250734839122742
166,0.3417032912194011,0.47590360045433044,0.6144578456878662,0.614215044376546,0.09615020507789518,mmlu:virology,test,18.065825854893774
19,0.14529098021356684,0.7894737124443054,0.3684210479259491,0.7666666666666667,0.14165296680048894,mmlu:world_religions,validation,2.0285491179674864
171,0.07563390247305932,0.7836257219314575,0.35672515630722046,0.472367890278338,0.15360016641561053,mmlu:world_religions,test,15.368497539078817
