"N","acc","unc_acc","unc_auroc","unc_ece","split","seed","model_name","prompt_style","mode","log_dir","int8","dataset","ts"
"38","0.5526315569877625","0.3947368562221527","0.4327731092436975","0.19874281318564163","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-02-01T00-45-19","false","mmlu:moral_disputes","344.6752900471911"
"346","0.4595375657081604","0.5664739608764648","0.5003195103084115","0.05266824468022823","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-02-01T00-45-19","false","mmlu:moral_disputes","344.6752900471911"
"25","0.19999998807907104","0.3199999928474426","0.835","0.2937610125541687","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-02-01T00-45-01","false","mmlu:marketing","412.75241031777114"
"234","0.4529914855957031","0.6025641560554504","0.5423054245283019","0.028776938079768798","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-02-01T00-45-01","false","mmlu:marketing","412.75241031777114"
"11","0.6363636255264282","0.3636363744735718","0.25","0.26186323165893555","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-02-01T00-44-20","false","mmlu:management","201.20110867265612"
"103","0.3980582654476166","0.6893203854560852","0.4862313139260425","0.10066284485233644","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-02-01T00-44-20","false","mmlu:management","201.20110867265612"
"11","0.27272728085517883","0.4545454680919647","0.6041666666666666","0.15553646196018567","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-02-01T00-40-15","false","mmlu:jurisprudence","119.78629373945296"
"108","0.4166666567325592","0.472222238779068","0.5049382716049383","0.11626520201011939","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-02-01T00-40-15","false","mmlu:jurisprudence","119.78629373945296"
"11","0.27272728085517883","0.1818181872367859","0.4375","0.5908792127262462","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-02-01T00-40-12","false","mmlu:machine_learning","128.36464251298457"
"112","0.3214285969734192","0.3125","0.5712719298245613","0.47720751698528013","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-02-01T00-40-12","false","mmlu:machine_learning","128.36464251298457"
"12","0.3333333432674408","0.6666666865348816","0.546875","0.1896199484666189","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-02-01T00-06-19","false","mmlu:human_sexuality","139.2691602371633"
"131","0.5267175436019897","0.5038167834281921","0.4680925666199159","0.22788820876419996","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-02-01T00-06-19","false","mmlu:human_sexuality","139.2691602371633"
"23","0.21739131212234497","0.21739131212234497","0.5277777777777777","0.67517410153928","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-59-11","false","mmlu:high_school_statistics","317.36498348694295"
"216","0.2777777910232544","0.2777777910232544","0.5631944444444444","0.603507743941413","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-59-11","false","mmlu:high_school_statistics","317.36498348694295"
"60","0.5333333611488342","0.5833333730697632","0.6869419642857142","0.18830961485703784","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-58-42","false","mmlu:high_school_psychology","411.1101903449744"
"545","0.5174311995506287","0.5321100950241089","0.6481945905131732","0.17577976480536509","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-58-42","false","mmlu:high_school_psychology","411.1101903449744"
"17","0.29411765933036804","0.29411765933036804","0.43333333333333335","0.39300374073140765","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-56-33","false","mmlu:high_school_physics","318.65087233670056"
"151","0.17218543589115143","0.17880794405937195","0.46738461538461534","0.5136375036460675","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-56-33","false","mmlu:high_school_physics","318.65087233670056"
"26","0.3461538553237915","0.46153849363327026","0.7189542483660131","0.10824306882344761","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-53-14","false","mmlu:high_school_microeconomics","260.30578415095806"
"238","0.3529411852359772","0.4873949885368347","0.6014996907854052","0.10188610638890946","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-53-14","false","mmlu:high_school_microeconomics","260.30578415095806"
"29","0.13793103396892548","0.13793103396892548","0.45999999999999996","0.6170531408540134","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-51-14","false","mmlu:high_school_mathematics","359.8928211638704"
"270","0.0962962955236435","0.0962962955236435","0.5257723833543505","0.651263599925571","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-51-14","false","mmlu:high_school_mathematics","359.8928211638704"
"43","0.4883720874786377","0.44186046719551086","0.5952380952380951","0.1342349177183107","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-50-12","false","mmlu:high_school_macroeconomics","400.18353395722806"
"390","0.33589744567871094","0.5897436141967773","0.49547584662088473","0.023564333029282413","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-50-12","false","mmlu:high_school_macroeconomics","400.18353395722806"
"21","0.523809552192688","0.6190476417541504","0.7590909090909091","0.10871924956639606","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-49-31","false","mmlu:high_school_government_and_politics","114.085105557926"
"193","0.5958548784255981","0.6165803074836731","0.6593088071348939","0.05998565032692153","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-49-31","false","mmlu:high_school_government_and_politics","114.085105557926"
"22","0.04545454680919647","0.1818181872367859","0.9047619047619048","0.4476700967008417","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-46-43","false","mmlu:high_school_chemistry","158.39459485001862"
"203","0.19211822748184204","0.3103448152542114","0.6322701688555347","0.3338312189567265","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-46-43","false","mmlu:high_school_chemistry","158.39459485001862"
"10","0.20000000298023224","0.20000000298023224","0.59375","0.35247623920440674","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-45-59","false","mmlu:global_facts","99.40978150628507"
"100","0.12999999523162842","0.3400000035762787","0.5075154730327145","0.2480423140525818","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-45-59","false","mmlu:global_facts","99.40978150628507"
"41","0.3414633870124817","0.3414633870124817","0.4973544973544973","0.38710216923457824","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-44-35","false","mmlu:elementary_mathematics","604.0091640846804"
"378","0.32804232835769653","0.3650793433189392","0.6109664719329438","0.3412099468014228","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-44-35","false","mmlu:elementary_mathematics","604.0091640846804"
"16","0.3125","0.5","0.5545454545454546","0.14374981448054314","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-42-56","false","mmlu:electrical_engineering","176.9126382227987"
"145","0.24827586114406586","0.4689655303955078","0.5560652395514781","0.14363143978447754","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-42-56","false","mmlu:electrical_engineering","176.9126382227987"
"12","0.4166666865348816","0.4166666865348816","0.6857142857142857","0.4499327490727108","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-42-07","false","mmlu:econometrics","166.00628320500255"
"114","0.17543859779834747","0.17543859779834747","0.5550531914893616","0.6334689369327143","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-42-07","false","mmlu:econometrics","166.00628320500255"
"26","0.3461538553237915","0.5769230723381042","0.522875816993464","0.07929973189647382","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-41-52","false","mmlu:conceptual_physics","137.77209032233804"
"235","0.44680848717689514","0.5829787254333496","0.4591208791208791","0.06926704974884682","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-41-52","false","mmlu:conceptual_physics","137.77209032233804"
"11","0.4545454680919647","0.7272727489471436","0.5166666666666667","0.20055626197294757","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-39-10","false","mmlu:computer_security","113.61073944345117"
"100","0.4899999797344208","0.44999998807907104","0.4893957583033213","0.1729771637916565","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-39-10","false","mmlu:computer_security","113.61073944345117"
"11","0.3636363744735718","0.3636363744735718","0.6785714285714285","0.300860730084506","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-38-12","false","mmlu:college_physics","107.66988984495401"
"102","0.1568627506494522","0.1568627506494522","0.543968023255814","0.512012661672106","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-38-12","false","mmlu:college_physics","107.66988984495401"
"22","0.5","0.4545454680919647","0.36363636363636365","0.16841695525429462","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-37-40","false","mmlu:college_medicine","160.24586059246212"
"173","0.4046242833137512","0.5375722646713257","0.4907073509015256","0.06874231210333763","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-37-40","false","mmlu:college_medicine","160.24586059246212"
"11","0.09090909361839294","0.09090909361839294","0.5","0.7241128032857721","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-36-19","false","mmlu:college_mathematics","376.84021584130824"
"100","0.10999999940395355","0.10999999940395355","0.650153217568948","0.7299618011713029","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-36-19","false","mmlu:college_mathematics","376.84021584130824"
"11","0.27272728085517883","0.27272728085517883","0.9375","0.6105593226172707","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-35-23","false","mmlu:college_computer_science","116.23924064170569"
"100","0.19999998807907104","0.19999998807907104","0.5690625","0.6735144108533859","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-35-23","false","mmlu:college_computer_science","116.23924064170569"
"8","0","0","null","0.709744043648243","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-34-33","false","mmlu:college_chemistry","76.82668185047805"
"100","0.14999999105930328","0.1599999964237213","0.743529411764706","0.5799246799945832","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-34-33","false","mmlu:college_chemistry","76.82668185047805"
"16","0.25","0.375","0.5","0.2149156853556633","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-34-14","false","mmlu:college_biology","125.05167314317077"
"144","0.3819444477558136","0.6597222089767456","0.49458631256384056","0.11108185433679157","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-34-14","false","mmlu:college_biology","125.05167314317077"
"11","0.5454545617103577","0.6363636255264282","0.8","0.07221010598269376","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-32-01","false","mmlu:business_ethics","86.36390917003155"
"100","0.32999998331069946","0.5","0.4615558570782452","0.10822520673274996","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-32-01","false","mmlu:business_ethics","86.36390917003155"
"16","0.5625","0.5625","0.6825396825396826","0.12636108323931694","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-30-22","false","mmlu:astronomy","120.59426526259631"
"152","0.5131579041481018","0.5789473652839661","0.4232501732501733","0.03399537425292168","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-30-22","false","mmlu:astronomy","120.59426526259631"
"11","0.09090909361839294","0.5454545617103577","1","0.02806621789932253","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-30-08","false","mmlu:abstract_algebra","150.92842278443277"
"100","0.3100000023841858","0.4699999988079071","0.4791958859280037","0.10876395285129548","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-30-08","false","mmlu:abstract_algebra","150.92842278443277"
"9","0.5555555820465088","0.5555555820465088","0.45","0.32049746645821464","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-29-22","false","mmlu:high_school_computer_science","308.57122072950006"
"100","0.429999977350235","0.429999977350235","0.45124439004487965","0.33694668829441066","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-29-22","false","mmlu:high_school_computer_science","308.57122072950006"
"22","0.40909093618392944","0.5454545617103577","0.4102564102564102","0.20712398128076032","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-26-06","false","mmlu:high_school_geography","181.5968337021768"
"198","0.38383838534355164","0.5202020406723022","0.6697044866264021","0.08820517737456043","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-26-06","false","mmlu:high_school_geography","181.5968337021768"
"11","0.6363636255264282","0.6363636255264282","0.6428571428571428","0.20922592011365024","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-26-02","false","mmlu:medical_genetics","136.5794413406402"
"100","0.47999998927116394","0.5299999713897705","0.49379006410256404","0.10223453640937807","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-26-02","false","mmlu:medical_genetics","136.5794413406402"
"29","0.17241379618644714","0.7931034564971924","0.47500000000000003","0.22082159025915737","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-25-16","false","mmlu:clinical_knowledge","196.5177752012387"
"265","0.28679245710372925","0.6830188632011414","0.36086744639376217","0.08020354374399724","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-25-16","false","mmlu:clinical_knowledge","196.5177752012387"
"14","0.2142857313156128","0.785714328289032","0.06060606060606061","0.284159562417439","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-25-00","false","mmlu:anatomy","149.24734142329544"
"135","0.4740740656852722","0.5333333015441895","0.40647007042253525","0.16357264297979845","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-25-00","false","mmlu:anatomy","149.24734142329544"
"18","0.7222222089767456","0.7222222089767456","0.7076923076923077","0.15566955672370067","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-22-00","false","mmlu:logical_fallacies","135.4417871683836"
"163","0.46625766158103943","0.46625766158103943","0.5740320629159105","0.1921278424789569","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-22-00","false","mmlu:logical_fallacies","135.4417871683836"
"23","0.43478262424468994","0.43478262424468994","0.5615384615384615","0.1455637242483056","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-21-07","false","mmlu:human_aging","188.2326470706612"
"223","0.3946188688278198","0.5067265033721924","0.4829545454545454","0.09367832661744191","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-21-07","false","mmlu:human_aging","188.2326470706612"
"14","0.3571428656578064","0.2857142984867096","0.45555555555555555","0.4038985243865422","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-20-59","false","mmlu:formal_logic","144.16267566755414"
"126","0.3492063581943512","0.341269850730896","0.3981430155210643","0.36936928355504595","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-20-59","false","mmlu:formal_logic","144.16267566755414"
"32","0.3125","0.59375","0.5068181818181818","0.07592072151601315","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-14-42","false","mmlu:high_school_biology","500.32351078186184"
"310","0.43870967626571655","0.5354838371276855","0.5359617985125085","0.05177741531402833","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-14-42","false","mmlu:high_school_biology","500.32351078186184"
"13","0.6153846383094788","0.6153846383094788","0.37499999999999994","0.30633147863241345","validation","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-10-21","false","mmlu:international_law","270.1756741357967"
"121","0.6611570119857788","0.5950412750244141","0.5599085365853659","0.029676456096743773","test","137","llama2_13b_chat","oe","oe_fuzzy_gpt-3.5-turbo-1106","/workspace/logs/deeplearn/llm-calibration/2024-01-31T23-10-21","false","mmlu:international_law","270.1756741357967"