N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.6363636255264282,0.6666666666666667,0.20872754942287097,mmlu:abstract_algebra,validation,10.600439600646496
100,0.22999998927116394,0.47999998927116394,0.6420101637492942,0.266277204155922,mmlu:abstract_algebra,test,76.57270409166813
14,0.2142857313156128,0.6428571939468384,0.8787878787878788,0.24276060717446465,mmlu:anatomy,validation,15.658818535506725
135,0.39259257912635803,0.4962962865829468,0.5521168890934193,0.18377147692221188,mmlu:anatomy,test,137.29057204909623
16,0.375,0.625,0.6666666666666666,0.09723207727074623,mmlu:astronomy,validation,25.89436500892043
152,0.4802631735801697,0.5592105388641357,0.5417894919368823,0.16381330788135529,mmlu:astronomy,test,192.97580331750214
11,0.3636363744735718,0.5454545617103577,0.6071428571428572,0.3108223568309437,mmlu:business_ethics,validation,10.18174472823739
100,0.3700000047683716,0.47999998927116394,0.6100386100386102,0.2535262525081635,mmlu:business_ethics,test,115.65415379032493
29,0.13793103396892548,0.3448275923728943,0.6599999999999999,0.3601575206066,mmlu:clinical_knowledge,validation,31.480338398367167
265,0.2943396270275116,0.3962264060974121,0.5482654600301659,0.3314608378230401,mmlu:clinical_knowledge,test,311.4525368567556
16,0.4375,0.375,0.39682539682539686,0.3444130904972553,mmlu:college_biology,validation,17.272316006943583
144,0.3541666567325592,0.3888888955116272,0.500843348091925,0.30705124305354214,mmlu:college_biology,test,161.7474508471787
8,0.0,0.375,,0.48746296763420105,mmlu:college_chemistry,validation,9.301797643303871
100,0.14999999105930328,0.47999998927116394,0.7094117647058824,0.23904035925865172,mmlu:college_chemistry,test,98.24676192179322
11,0.1818181872367859,0.4545454680919647,0.3333333333333333,0.43040650541132147,mmlu:college_computer_science,validation,12.16667127981782
100,0.17999999225139618,0.4699999988079071,0.5948509485094851,0.24980582296848297,mmlu:college_computer_science,test,104.5773321967572
11,0.0,0.8181818723678589,,0.21199410070072525,mmlu:college_mathematics,validation,9.85707188397646
100,0.1899999976158142,0.5199999809265137,0.5071474983755686,0.17033106386661534,mmlu:college_mathematics,test,80.45691136457026
22,0.4545454680919647,0.4545454680919647,0.5583333333333333,0.28319580175659875,mmlu:college_medicine,validation,23.76149956882
173,0.30635836720466614,0.41040462255477905,0.5022012578616352,0.3085650619054805,mmlu:college_medicine,test,196.5055143367499
11,0.09090909361839294,0.5454545617103577,0.19999999999999996,0.3093230019916188,mmlu:college_physics,validation,12.23181488737464
102,0.0882352963089943,0.5392156839370728,0.35961768219832735,0.17552850117870405,mmlu:college_physics,test,112.72553712315857
11,0.6363636255264282,0.6363636255264282,0.6428571428571428,0.267477349801497,mmlu:computer_security,validation,14.737479619681835
100,0.44999998807907104,0.429999977350235,0.42787878787878786,0.2855389702320099,mmlu:computer_security,test,127.60549304261804
26,0.3461538553237915,0.42307692766189575,0.32679738562091504,0.22426138703639692,mmlu:conceptual_physics,validation,48.50402619689703
235,0.3829787075519562,0.46808508038520813,0.5487739463601533,0.18634547020526646,mmlu:conceptual_physics,test,473.62195521965623
12,0.25,0.1666666716337204,0.4814814814814815,0.49955611924330395,mmlu:econometrics,validation,13.50502727739513
114,0.11403508484363556,0.28947368264198303,0.43183549124143183,0.39221022108144926,mmlu:econometrics,test,181.46149192750454
16,0.25,0.625,0.7499999999999999,0.25133511051535606,mmlu:electrical_engineering,validation,16.168644715100527
145,0.22068965435028076,0.565517246723175,0.49958517699115046,0.1276142827395735,mmlu:electrical_engineering,test,148.7307025771588
41,0.31707316637039185,0.5365853309631348,0.5851648351648351,0.13991912254473057,mmlu:elementary_mathematics,validation,31.806522447615862
378,0.29629629850387573,0.5714285373687744,0.5728719119226638,0.10157606147584462,mmlu:elementary_mathematics,test,376.9458397459239
14,0.4285714626312256,0.4285714626312256,0.7083333333333334,0.2924106674534934,mmlu:formal_logic,validation,22.216716216877103
126,0.2301587462425232,0.4126984477043152,0.5975826519729827,0.27852769125075566,mmlu:formal_logic,test,157.36826542764902
10,0.20000000298023224,0.5,1.0,0.3412883043289185,mmlu:global_facts,validation,12.925375679507852
100,0.08999999612569809,0.32999998331069946,0.7557997557997558,0.426469749212265,mmlu:global_facts,test,130.91463316977024
32,0.28125,0.5,0.642512077294686,0.22862665355205536,mmlu:high_school_biology,validation,38.242104979231954
310,0.4258064329624176,0.47741934657096863,0.5113849165815458,0.25285508036613463,mmlu:high_school_biology,test,420.23232615739107
22,0.09090909361839294,0.3636363744735718,0.85,0.3410596332766793,mmlu:high_school_chemistry,validation,24.461316345259547
203,0.14778324961662292,0.5270935893058777,0.7432562620423891,0.16577622162297442,mmlu:high_school_chemistry,test,216.1794805675745
9,0.4444444477558136,0.8888888955116272,0.8,0.43142972389856976,mmlu:high_school_computer_science,validation,13.457299657166004
100,0.3999999761581421,0.44999998807907104,0.49916666666666665,0.23119939386844637,mmlu:high_school_computer_science,test,186.28225432895124
22,0.40909093618392944,0.5,0.3846153846153846,0.3908314488150857,mmlu:high_school_geography,validation,31.86792386509478
198,0.3737373650074005,0.42424243688583374,0.48365300784655624,0.29526567760140005,mmlu:high_school_geography,test,249.2902030888945
21,0.4761904776096344,0.523809552192688,0.4818181818181818,0.23234826610201886,mmlu:high_school_government_and_politics,validation,46.602480908855796
193,0.5181347131729126,0.5854921936988831,0.631505376344086,0.18641115439370504,mmlu:high_school_government_and_politics,test,419.9627888649702
43,0.3720930218696594,0.302325576543808,0.46412037037037035,0.3776510080625845,mmlu:high_school_macroeconomics,validation,72.85902602784336
390,0.30000001192092896,0.41025641560554504,0.5757646911493065,0.26897430450488363,mmlu:high_school_macroeconomics,test,696.12459060736
29,0.0,0.48275861144065857,,0.23280610298288282,mmlu:high_school_mathematics,validation,18.933395301923156
270,0.0555555559694767,0.4740740656852722,0.5977777777777779,0.1931338206485466,mmlu:high_school_mathematics,test,184.0961704608053
26,0.3076923191547394,0.5384615659713745,0.7291666666666667,0.27526388718531686,mmlu:high_school_microeconomics,validation,30.995915427803993
238,0.3739495873451233,0.4327731430530548,0.5450192293190559,0.2883725819968376,mmlu:high_school_microeconomics,test,317.1360397450626
17,0.05882352963089943,0.3529411852359772,0.8125,0.37031196846681486,mmlu:high_school_physics,validation,18.004459174349904
151,0.16556291282176971,0.430463582277298,0.5495238095238095,0.2604804386366282,mmlu:high_school_physics,test,167.41334598511457
60,0.5166667103767395,0.5,0.4961067853170189,0.20900752246379847,mmlu:high_school_psychology,validation,64.48597755841911
545,0.4990825653076172,0.5247706174850464,0.5502450980392157,0.18380786191432846,mmlu:high_school_psychology,test,666.8452582228929
23,0.21739131212234497,0.52173912525177,0.6777777777777778,0.20771870146627014,mmlu:high_school_statistics,validation,25.976340083405375
216,0.20370370149612427,0.4861111044883728,0.5819899577167019,0.18403812801396408,mmlu:high_school_statistics,test,254.25108643434942
22,0.7272727489471436,0.7272727489471436,0.8802083333333333,0.17816009575670422,mmlu:high_school_us_history,validation,31.07960188575089
204,0.6127451062202454,0.5392156839370728,0.433873417721519,0.1604243364988589,mmlu:high_school_us_history,test,304.7675384245813
23,0.30434784293174744,0.47826087474823,0.6964285714285714,0.22633237164953474,mmlu:human_aging,validation,22.779153732582927
223,0.354260116815567,0.452914834022522,0.5500615330520394,0.28052302753978786,mmlu:human_aging,test,304.7864207532257
12,0.25,0.3333333432674408,0.37037037037037035,0.37902635832627607,mmlu:human_sexuality,validation,19.55640966258943
131,0.38167938590049744,0.4580152630805969,0.45037037037037037,0.25312432624001535,mmlu:human_sexuality,test,202.1883386000991
13,0.46153849363327026,0.46153849363327026,0.35714285714285715,0.2785514318026029,mmlu:international_law,validation,18.350223027169704
121,0.5537189841270447,0.5289255976676941,0.44472084024322833,0.2046497001135645,mmlu:international_law,test,169.64113700389862
11,0.4545454680919647,0.3636363744735718,0.5333333333333333,0.42278551513498486,mmlu:jurisprudence,validation,17.94690472446382
108,0.5462962985038757,0.5555555820465088,0.5077827741265998,0.26930241893838947,mmlu:jurisprudence,test,148.5918895713985
18,0.4444444477558136,0.5,0.5625,0.20155449708302814,mmlu:logical_fallacies,validation,25.298353023827076
163,0.44785276055336,0.4969325065612793,0.5824200913242009,0.21679118586464163,mmlu:logical_fallacies,test,196.15732103958726
11,0.3636363744735718,0.5454545617103577,0.5714285714285714,0.30960169705477625,mmlu:machine_learning,validation,14.661489840596914
112,0.2142857313156128,0.5,0.5021306818181819,0.22215826490095683,mmlu:machine_learning,test,132.0992163643241
11,0.3636363744735718,0.5454545617103577,0.4642857142857143,0.3854196992787448,mmlu:management,validation,22.32895042747259
103,0.3203883469104767,0.33980584144592285,0.445021645021645,0.40136175074623626,mmlu:management,test,158.47476995177567
25,0.1599999964237213,0.23999999463558197,0.36904761904761907,0.4111547660827638,mmlu:marketing,validation,28.104950986802578
234,0.4059829115867615,0.46581199765205383,0.5228701249526695,0.22832137575516337,mmlu:marketing,test,268.9807136692107
11,0.8181818723678589,0.7272727489471436,0.7222222222222222,0.05340882323004986,mmlu:medical_genetics,validation,27.71906174533069
100,0.3999999761581421,0.4899999797344208,0.53625,0.20783168911933897,mmlu:medical_genetics,test,229.46235616505146
38,0.44736841320991516,0.44736841320991516,0.57703081232493,0.40032848715782166,mmlu:moral_disputes,validation,62.943607764318585
346,0.43063583970069885,0.42485547065734863,0.47758321125608966,0.3758704092116715,mmlu:moral_disputes,test,545.3079019282013
33,0.3030303120613098,0.4848484992980957,0.7043478260869566,0.22962982004339044,mmlu:nutrition,validation,44.27791138924658
306,0.40522876381874084,0.46405228972435,0.48582063098192124,0.22608980497503592,mmlu:nutrition,test,387.0227398108691
34,0.4117647111415863,0.44117647409439087,0.5142857142857142,0.3752182441599229,mmlu:philosophy,validation,48.624828627333045
311,0.34405145049095154,0.3536977469921112,0.5401777533443284,0.4550323754644854,mmlu:philosophy,test,482.3438979052007
35,0.34285715222358704,0.6285714507102966,0.6684782608695653,0.17064213241849627,mmlu:prehistory,validation,75.63207652978599
324,0.3888888955116272,0.5339506268501282,0.5846761263427931,0.11932681500911714,mmlu:prehistory,test,690.457632381469
69,0.36231884360313416,0.4057971239089966,0.4036363636363637,0.261079320009204,mmlu:professional_psychology,validation,89.46375466883183
612,0.32679739594459534,0.4166666567325592,0.43753033980582523,0.25626358087935475,mmlu:professional_psychology,test,756.4865172151476
12,0.4166666865348816,0.6666666865348816,0.5428571428571429,0.45369227727254235,mmlu:public_relations,validation,12.53780160471797
110,0.37272727489471436,0.4999999701976776,0.587310003534818,0.22010663368485192,mmlu:public_relations,test,92.89476249180734
27,0.7777777910232544,0.8148148059844971,0.5079365079365079,0.21043380322279756,mmlu:security_studies,validation,45.566064139828086
245,0.6897959113121033,0.6775509715080261,0.5353083151666148,0.1528700166819047,mmlu:security_studies,test,414.39329582452774
22,0.5454545617103577,0.3636363744735718,0.4083333333333333,0.3505544256080281,mmlu:sociology,validation,43.118263171985745
201,0.4427860677242279,0.5422885417938232,0.6145666131621187,0.17012686604884134,mmlu:sociology,test,390.85214729979634
11,0.6363636255264282,0.6363636255264282,0.5714285714285714,0.3760237422856418,mmlu:us_foreign_policy,validation,12.293314296752214
100,0.5399999618530273,0.5899999737739563,0.4875201288244766,0.24562238276004789,mmlu:us_foreign_policy,test,102.7354931961745
18,0.3333333432674408,0.7222222089767456,0.6944444444444444,0.11124323805173239,mmlu:virology,validation,22.146275732666254
166,0.3313252925872803,0.5602409243583679,0.5684684684684684,0.15839291265211913,mmlu:virology,test,257.71456776559353
19,0.5789473652839661,0.6842105388641357,0.7159090909090908,0.23182535171508786,mmlu:world_religions,validation,14.076308766379952
171,0.5438596606254578,0.5438596606254578,0.5348083815825752,0.26035267358634906,mmlu:world_religions,test,138.99328014813364
