N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.0,0.9090909361839294,,0.2528898445042697,mmlu:abstract_algebra,validation,27.24169955216348
100,0.3100000023841858,0.6299999952316284,0.5656848994857411,0.12212664723396296,mmlu:abstract_algebra,test,204.54467456042767
14,0.2142857313156128,0.8571429252624512,0.7272727272727272,0.283473653452737,mmlu:anatomy,validation,10.144695937633514
135,0.4296296238899231,0.614814817905426,0.6267353336318853,0.05937570686693545,mmlu:anatomy,test,94.04365134611726
16,0.4375,0.6875,0.746031746031746,0.09553907811641693,mmlu:astronomy,validation,17.598801726475358
152,0.5065789222717285,0.6184210777282715,0.6471861471861472,0.07110411791425,mmlu:astronomy,test,153.15610799007118
11,0.4545454680919647,0.5454545617103577,0.5,0.2711161808534102,mmlu:business_ethics,validation,8.182334091514349
100,0.3100000023841858,0.5,0.5208041140719963,0.15522282838821408,mmlu:business_ethics,test,99.31884009949863
29,0.13793103396892548,0.37931033968925476,0.8800000000000001,0.2432995890748912,mmlu:clinical_knowledge,validation,30.317909056320786
265,0.31698113679885864,0.5584905743598938,0.5929689555380163,0.09412271279209065,mmlu:clinical_knowledge,test,248.36718002334237
16,0.25,0.6875,0.6666666666666667,0.1404405981302261,mmlu:college_biology,validation,23.47886254452169
144,0.347222238779068,0.5208333134651184,0.5285106382978724,0.11846400383445954,mmlu:college_biology,test,155.36602677963674
8,0.0,0.75,,0.15832972526550293,mmlu:college_chemistry,validation,9.36839866451919
100,0.19999998807907104,0.6299999952316284,0.6153125,0.09437773644924163,mmlu:college_chemistry,test,106.25799968652427
11,0.27272728085517883,0.4545454680919647,0.3333333333333333,0.3336734988472679,mmlu:college_computer_science,validation,14.844578681513667
100,0.23999999463558197,0.5799999833106995,0.5424890350877193,0.10093284726142883,mmlu:college_computer_science,test,126.44794157147408
11,0.0,1.0,,0.2737821069630709,mmlu:college_mathematics,validation,27.96524823643267
100,0.10999999940395355,0.7999999523162842,0.3278855975485189,0.10599038004875184,mmlu:college_mathematics,test,178.32032852992415
22,0.40909093618392944,0.7727273106575012,0.7948717948717948,0.166955213655125,mmlu:college_medicine,validation,22.91155448742211
173,0.42774564027786255,0.5838150382041931,0.6216216216216216,0.0633530647768451,mmlu:college_medicine,test,177.52848067320883
11,0.27272728085517883,0.6363636255264282,0.75,0.23339518091895367,mmlu:college_physics,validation,9.113043094053864
102,0.14705882966518402,0.6960784792900085,0.5141762452107279,0.04824419290411706,mmlu:college_physics,test,114.707394214347
11,0.7272727489471436,0.3636363744735718,0.5416666666666666,0.2910785187374462,mmlu:computer_security,validation,7.806274153292179
100,0.5299999713897705,0.5099999904632568,0.49056603773584906,0.13455655097961425,mmlu:computer_security,test,93.96411135978997
26,0.42307692766189575,0.6538462042808533,0.5878787878787879,0.14543501918132487,mmlu:conceptual_physics,validation,23.040486147627234
235,0.46808508038520813,0.5531914830207825,0.5710181818181819,0.1046320861958443,mmlu:conceptual_physics,test,165.24073927477002
12,0.3333333432674408,0.3333333432674408,0.46875,0.33218400677045185,mmlu:econometrics,validation,12.531036311760545
114,0.14912280440330505,0.48245614767074585,0.5833838690115222,0.2080873611726259,mmlu:econometrics,test,195.05771797522902
16,0.4375,0.375,0.33333333333333337,0.27081143110990524,mmlu:electrical_engineering,validation,27.19304492138326
145,0.2344827651977539,0.7034482955932617,0.6524907260201378,0.045394765919652476,mmlu:electrical_engineering,test,198.7024136055261
41,0.24390242993831635,0.6341463327407837,0.5758064516129032,0.0707706852657039,mmlu:elementary_mathematics,validation,42.680791579186916
378,0.31481480598449707,0.5925925970077515,0.4675870348139256,0.09444898524612347,mmlu:elementary_mathematics,test,379.9677940234542
14,0.1428571492433548,0.6428571939468384,0.7083333333333333,0.1400066912174225,mmlu:formal_logic,validation,17.972977248951793
126,0.3174603283405304,0.547619104385376,0.5015988372093023,0.09775837073250421,mmlu:formal_logic,test,192.7185317929834
10,0.20000000298023224,0.6000000238418579,0.5625,0.17014124989509585,mmlu:global_facts,validation,10.990666227415204
100,0.14999999105930328,0.7099999785423279,0.6188235294117647,0.1168953710794449,mmlu:global_facts,test,98.83727638423443
32,0.34375,0.65625,0.645021645021645,0.08778581395745277,mmlu:high_school_biology,validation,32.297448271885514
310,0.4258064329624176,0.5258064270019531,0.5295795028941096,0.10058610381618621,mmlu:high_school_biology,test,329.7885118275881
22,0.27272728085517883,0.7272727489471436,0.71875,0.10597815296866676,mmlu:high_school_chemistry,validation,28.791950019076467
203,0.2019704431295395,0.6699507236480713,0.5328967178560675,0.027123764230699912,mmlu:high_school_chemistry,test,217.49290133081377
9,0.4444444477558136,0.4444444477558136,0.49999999999999994,0.21511340803570217,mmlu:high_school_computer_science,validation,12.836714830249548
100,0.3999999761581421,0.5799999833106995,0.573125,0.07634446501731874,mmlu:high_school_computer_science,test,143.40297632850707
22,0.40909093618392944,0.5909091234207153,0.7521367521367521,0.21742942387407477,mmlu:high_school_geography,validation,20.768606102094054
198,0.40909090638160706,0.5909090638160706,0.6211353803946397,0.05471211129968818,mmlu:high_school_geography,test,210.03280799649656
21,0.523809552192688,0.523809552192688,0.5181818181818182,0.11774378731137232,mmlu:high_school_government_and_politics,validation,16.857336627319455
193,0.5958548784255981,0.4922279715538025,0.6031772575250836,0.17708894625846586,mmlu:high_school_government_and_politics,test,159.17680758424103
43,0.41860464215278625,0.5581395626068115,0.5355555555555556,0.16814728531726572,mmlu:high_school_macroeconomics,validation,53.806296177208424
390,0.33076924085617065,0.6743590235710144,0.5860435415367252,0.06167756426028717,mmlu:high_school_macroeconomics,test,481.47569852136075
29,0.06896551698446274,0.7586206793785095,0.03703703703703709,0.10925956841172843,mmlu:high_school_mathematics,validation,26.75335888005793
270,0.0962962955236435,0.7666666507720947,0.6448612862547289,0.0847372061676449,mmlu:high_school_mathematics,test,268.1500843912363
26,0.3076923191547394,0.692307710647583,0.5347222222222223,0.12160150362895085,mmlu:high_school_microeconomics,validation,33.312982430681586
238,0.38235294818878174,0.6386554837226868,0.5898931000971819,0.10509486909673998,mmlu:high_school_microeconomics,test,305.5691609568894
17,0.29411765933036804,0.7647058963775635,0.6666666666666666,0.1633119548068327,mmlu:high_school_physics,validation,25.16497990489006
151,0.1986754983663559,0.5629138946533203,0.5073002754820937,0.08797283559445514,mmlu:high_school_physics,test,174.33225393481553
60,0.5833333730697632,0.5,0.5805714285714285,0.13384050329526267,mmlu:high_school_psychology,validation,50.94766775518656
545,0.4935779869556427,0.5688073635101318,0.5937718872905554,0.0590653493863727,mmlu:high_school_psychology,test,752.5805239696056
23,0.260869562625885,0.6086956858634949,0.8137254901960784,0.18731481614320175,mmlu:high_school_statistics,validation,59.21299897134304
216,0.25925925374031067,0.4861111044883728,0.5078125,0.17688889249607367,mmlu:high_school_statistics,test,569.0234650038183
22,0.8181818723678589,0.5909091234207153,0.2638888888888889,0.09609109976074914,mmlu:high_school_us_history,validation,40.52177731692791
204,0.7058823704719543,0.6617647409439087,0.6223958333333333,0.04842147377191802,mmlu:high_school_us_history,test,399.26295194402337
23,0.3913043439388275,0.47826087474823,0.5555555555555556,0.23106900246247003,mmlu:human_aging,validation,20.427368203178048
223,0.3946188688278198,0.5919283032417297,0.5609848484848485,0.0805224920602123,mmlu:human_aging,test,217.1754174605012
12,0.4166666865348816,0.5,0.5428571428571429,0.17754668990770975,mmlu:human_sexuality,validation,16.576354816555977
131,0.5038167834281921,0.572519063949585,0.6006993006993008,0.06788133164398542,mmlu:human_sexuality,test,141.8483209963888
13,0.5384615659713745,0.5384615659713745,0.42857142857142855,0.2197387539423429,mmlu:international_law,validation,19.843616522848606
121,0.6446280479431152,0.5123966932296753,0.4364937388193202,0.1417716618411797,mmlu:international_law,test,173.5733854304999
11,0.09090909361839294,0.6363636255264282,0.5,0.13739079236984253,mmlu:jurisprudence,validation,9.138753844425082
108,0.40740740299224854,0.472222238779068,0.4753196022727273,0.17358174864892603,mmlu:jurisprudence,test,99.22009364888072
18,0.6666666865348816,0.6666666865348816,0.3611111111111111,0.1916017499234941,mmlu:logical_fallacies,validation,16.0928697809577
163,0.43558281660079956,0.48466256260871887,0.5589406001224739,0.21240791769846817,mmlu:logical_fallacies,test,154.16565590910614
11,0.27272728085517883,0.7272727489471436,0.7916666666666666,0.09845850142565643,mmlu:machine_learning,validation,12.582061992958188
112,0.2857142984867096,0.5267857313156128,0.5453125,0.12592676281929016,mmlu:machine_learning,test,93.73186946846545
11,0.5454545617103577,0.6363636255264282,0.7,0.06413290717385033,mmlu:management,validation,7.488390741869807
103,0.40776699781417847,0.6019417643547058,0.6725214676034348,0.07759005004919851,mmlu:management,test,78.66429093666375
25,0.19999998807907104,0.3199999928474426,0.72,0.32295123338699344,mmlu:marketing,validation,48.801648158580065
234,0.4572649896144867,0.5427350401878357,0.5916182206196188,0.10559065270627668,mmlu:marketing,test,403.50942816771567
11,0.6363636255264282,0.9090909361839294,0.8214285714285714,0.26158220117742365,mmlu:medical_genetics,validation,19.174703508615494
100,0.47999998927116394,0.5299999713897705,0.5416666666666666,0.09789290904998779,mmlu:medical_genetics,test,143.2501815687865
38,0.5263158082962036,0.5789473652839661,0.5666666666666667,0.13605545853313647,mmlu:moral_disputes,validation,36.143212862312794
346,0.44508668780326843,0.5289016962051392,0.5583739177489178,0.09655503971728287,mmlu:moral_disputes,test,299.1305814664811
33,0.3030303120613098,0.6060606241226196,0.6521739130434783,0.13347810326200543,mmlu:nutrition,validation,36.17512717470527
306,0.4313725531101227,0.584967315196991,0.5844000348310693,0.06489221878301087,mmlu:nutrition,test,354.8089401163161
34,0.3529411852359772,0.529411792755127,0.5871212121212122,0.0864820427754346,mmlu:philosophy,validation,21.461059011518955
311,0.379421204328537,0.6045016050338745,0.5930666549574076,0.0412911646235794,mmlu:philosophy,test,219.40807559341192
35,0.4000000059604645,0.48571428656578064,0.6190476190476191,0.1422032015664237,mmlu:prehistory,validation,37.76888380199671
324,0.4135802388191223,0.5771604776382446,0.6435781618224666,0.05912479850245108,mmlu:prehistory,test,297.4512541759759
69,0.37681159377098083,0.49275362491607666,0.5746869409660108,0.1325356312420057,mmlu:professional_psychology,validation,145.9259810820222
612,0.34477123618125916,0.5098039507865906,0.5713973360437768,0.13261200546049604,mmlu:professional_psychology,test,1245.6628806442022
12,0.25,0.4166666865348816,0.18518518518518517,0.2753814061482747,mmlu:public_relations,validation,8.445532830432057
110,0.3181818127632141,0.5090909004211426,0.586095238095238,0.14091570919210258,mmlu:public_relations,test,77.7670440711081
27,0.6666666865348816,0.37037038803100586,0.37962962962962965,0.3197051264621593,mmlu:security_studies,validation,39.330199629068375
245,0.6244897842407227,0.514285683631897,0.5801364023870417,0.15611488113597946,mmlu:security_studies,test,402.061151150614
22,0.4545454680919647,0.5454545617103577,0.525,0.04282000389966099,mmlu:sociology,validation,19.2369483448565
201,0.42288556694984436,0.5671641826629639,0.6068965517241379,0.07731191139316083,mmlu:sociology,test,181.70811141096056
11,0.6363636255264282,0.4545454680919647,0.6071428571428571,0.21269380504434762,mmlu:us_foreign_policy,validation,12.373573487624526
100,0.6200000047683716,0.5099999904632568,0.5700339558573855,0.13399284482002258,mmlu:us_foreign_policy,test,95.50901658460498
18,0.4444444477558136,0.5555555820465088,0.7125,0.33950757980346674,mmlu:virology,validation,17.553119834512472
166,0.33734938502311707,0.6024096012115479,0.5391233766233766,0.07061486430915007,mmlu:virology,test,173.14921359345317
19,0.6315789222717285,0.6842105388641357,0.7857142857142856,0.09910911949057327,mmlu:world_religions,validation,13.733581701293588
171,0.584795355796814,0.6783626079559326,0.6733098591549296,0.08203790898908646,mmlu:world_religions,test,117.31434595398605
