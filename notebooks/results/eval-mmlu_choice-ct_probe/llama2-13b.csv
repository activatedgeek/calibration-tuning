N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.06961113756353204,0.1818181872367859,0.8181818723678589,0.7777777777777778,0.23046874458139593,mmlu:abstract_algebra,validation,6.714249402284622
100,0.062483969628810886,0.32999998331069946,0.6200000047683716,0.5137946630483944,0.2717578011751175,mmlu:abstract_algebra,test,15.73385252058506
14,0.12325840762683324,0.5,0.5714285969734192,0.510204081632653,0.38560268708637785,mmlu:anatomy,validation,2.3303756676614285
135,0.1060579664177365,0.5185185074806213,0.6518518328666687,0.6747252747252748,0.20801505468509818,mmlu:anatomy,test,22.259486809372902
16,0.2022381741553545,0.625,0.625,0.8250000000000001,0.1994628943502903,mmlu:astronomy,validation,3.9913769029080868
152,0.10121979701675868,0.5065789222717285,0.5592105388641357,0.7536796536796537,0.33724814104406453,mmlu:astronomy,test,37.20675881952047
11,0.24853395602919842,0.3636363744735718,0.5454545617103577,0.7142857142857143,0.24112214825370093,mmlu:business_ethics,validation,2.8020348325371742
100,0.08915986150503158,0.5299999713897705,0.6800000071525574,0.798073063026897,0.1424999976158142,mmlu:business_ethics,test,24.289872266352177
29,0.1738769925873855,0.5862069129943848,0.48275861144065857,0.5661764705882353,0.31586744661988886,mmlu:clinical_knowledge,validation,5.442877497524023
265,0.05797947262817958,0.5962264537811279,0.6792452931404114,0.7837158405299893,0.177579620874153,mmlu:clinical_knowledge,test,49.42206480354071
16,0.22307293117046356,0.5625,0.8125,0.9047619047619047,0.1984863318502903,mmlu:college_biology,validation,3.4701005183160305
144,0.045583076154192305,0.5555555820465088,0.7152777910232544,0.77177734375,0.1330023825996452,mmlu:college_biology,test,31.171540170907974
8,0.41109248623251915,0.625,0.25,0.13333333333333336,0.70556640625,mmlu:college_chemistry,validation,2.1020121425390244
100,0.12592173516750338,0.44999998807907104,0.6399999856948853,0.6404040404040404,0.1630859375,mmlu:college_chemistry,test,23.25074354559183
11,0.24364772980863397,0.5454545617103577,0.7272727489471436,0.7333333333333333,0.24218750541860404,mmlu:college_computer_science,validation,3.646230824291706
100,0.06135625153779985,0.41999998688697815,0.6499999761581421,0.6619458128078818,0.16101561665534972,mmlu:college_computer_science,test,32.046019196510315
11,0.11771725795485757,0.1818181872367859,0.7272727489471436,0.6666666666666666,0.20703126083720813,mmlu:college_mathematics,validation,2.781733240932226
100,0.04548154473304749,0.3199999928474426,0.5199999809265137,0.5151654411764706,0.21828124642372132,mmlu:college_mathematics,test,23.38765025883913
22,0.11778001216324896,0.5454545617103577,0.7272727489471436,0.8666666666666667,0.14133523269133133,mmlu:college_medicine,validation,5.040699765086174
173,0.06503648978437303,0.5491329431533813,0.6127167344093323,0.6731443994601889,0.20289920554684765,mmlu:college_medicine,test,49.970416478812695
11,0.12884132157672534,0.5454545617103577,0.7272727489471436,0.7333333333333334,0.2322443181818182,mmlu:college_physics,validation,2.381914682686329
102,0.18728324391093906,0.2352941334247589,0.6470588445663452,0.6209935897435898,0.11312804385727528,mmlu:college_physics,test,21.034660454839468
11,0.31623197143728077,0.8181818723678589,0.8181818723678589,0.5833333333333333,0.20845169912685046,mmlu:computer_security,validation,2.34309758618474
100,0.05812336832284927,0.699999988079071,0.7299999594688416,0.7407142857142857,0.17820314049720762,mmlu:computer_security,test,18.06638104096055
26,0.15646312213861027,0.42307692766189575,0.6538462042808533,0.7636363636363637,0.24308894918515134,mmlu:conceptual_physics,validation,3.807292252779007
235,0.13242765297280984,0.3787233829498291,0.6765957474708557,0.6867400338617824,0.16363033081622835,mmlu:conceptual_physics,test,33.01128447055817
12,0.176067811747392,0.25,0.5,0.5925925925925926,0.41992187996705377,mmlu:econometrics,validation,3.1458234190940857
114,0.1726585276294173,0.2368421107530594,0.44736841320991516,0.6168582375478927,0.3393297807166451,mmlu:econometrics,test,28.79196759313345
16,0.22651450335979462,0.3125,0.6875,0.7636363636363637,0.207275390625,mmlu:electrical_engineering,validation,3.088626816868782
145,0.07690157273720052,0.4482758641242981,0.6137930750846863,0.7125961538461538,0.1610183152659186,mmlu:electrical_engineering,test,26.976803425699472
41,0.10450614879770978,0.3414633870124817,0.707317054271698,0.58994708994709,0.17578124709245635,mmlu:elementary_mathematics,validation,9.412455640733242
378,0.09799692452584624,0.3253968060016632,0.6243386268615723,0.5419097720388968,0.1524470755978236,mmlu:elementary_mathematics,test,83.82133895158768
14,0.11395825871399468,0.3571428656578064,0.5714285969734192,0.5222222222222223,0.20452008502823968,mmlu:formal_logic,validation,3.588396295905113
126,0.05262105758228001,0.3730158805847168,0.6349206566810608,0.5593859412873687,0.16325644510132922,mmlu:formal_logic,test,32.09901975467801
10,0.16201133131980894,0.5,0.4000000059604645,0.48,0.3515625,mmlu:global_facts,validation,2.040223252028227
100,0.10517343789339069,0.3499999940395355,0.550000011920929,0.5595604395604395,0.22335938096046445,mmlu:global_facts,test,18.67014630511403
32,0.14254247955977917,0.53125,0.59375,0.6509803921568627,0.3395996019244194,mmlu:high_school_biology,validation,7.19032035395503
310,0.0758247837904961,0.6645160913467407,0.7193548083305359,0.7632794996265869,0.16246218546744318,mmlu:high_school_biology,test,69.478192538023
22,0.155993636358868,0.3181818127632141,0.7272727489471436,0.6190476190476191,0.15997869860042227,mmlu:high_school_chemistry,validation,4.954716328531504
203,0.06557942229538716,0.47783249616622925,0.5812807679176331,0.5574304609998055,0.26408558702233975,mmlu:high_school_chemistry,test,44.13147173449397
9,0.17929370535744557,0.6666666865348816,0.7777777910232544,0.888888888888889,0.1657986044883728,mmlu:high_school_computer_science,validation,3.321726217865944
100,0.0882824456691742,0.5399999618530273,0.7099999785423279,0.7900563607085346,0.10562499463558198,mmlu:high_school_computer_science,test,36.18285442516208
22,0.12062895027073949,0.7272727489471436,0.7727273106575012,0.8958333333333334,0.14914773810993542,mmlu:high_school_geography,validation,3.7534316666424274
198,0.0726383120724649,0.7222222089767456,0.7222222089767456,0.7295613477431659,0.15617107622551196,mmlu:high_school_geography,test,33.86282122135162
21,0.18521009598459517,0.7142857313156128,0.761904776096344,0.9555555555555556,0.16592259917940416,mmlu:high_school_government_and_politics,validation,4.298138909041882
193,0.07063052027336673,0.8341968655586243,0.8290154933929443,0.8212344720496895,0.08484456236498347,mmlu:high_school_government_and_politics,test,38.660639192909
43,0.12308457909628401,0.4883720874786377,0.5581395626068115,0.7196969696969697,0.3541061018788537,mmlu:high_school_macroeconomics,validation,7.546261478215456
390,0.08908771299398863,0.5435897707939148,0.6051282286643982,0.7017171931312275,0.2741886864870023,mmlu:high_school_macroeconomics,test,68.96547159180045
29,0.1122421365359734,0.24137930572032928,0.7586206793785095,0.7142857142857142,0.13146551313071414,mmlu:high_school_mathematics,validation,6.3514208272099495
270,0.07992847749480496,0.24444444477558136,0.6777777671813965,0.5712269756387403,0.08505498766899108,mmlu:high_school_mathematics,test,57.89683957025409
26,0.1624323794474969,0.6538462042808533,0.6538462042808533,0.6274509803921569,0.23452523350715637,mmlu:high_school_microeconomics,validation,4.549326755106449
238,0.08336376192189064,0.5840336680412292,0.6596639156341553,0.7392994695152969,0.20614495372571867,mmlu:high_school_microeconomics,test,42.845365799963474
17,0.17164016997112946,0.23529411852359772,0.47058823704719543,0.42307692307692313,0.32490808823529416,mmlu:high_school_physics,validation,4.154628250747919
151,0.048587049672145714,0.4039735198020935,0.5496688485145569,0.46830601092896174,0.2843543113462183,mmlu:high_school_physics,test,35.14448966085911
60,0.1154120499889056,0.8000000715255737,0.8833333849906921,0.8923611111111112,0.08391925295193994,mmlu:high_school_psychology,validation,13.161736741662025
545,0.054627282685096125,0.763302743434906,0.8055046200752258,0.8112701252236136,0.11280819626029479,mmlu:high_school_psychology,test,120.78464378044009
23,0.15028261101764182,0.3478260934352875,0.6086956858634949,0.7250000000000001,0.1722146661385246,mmlu:high_school_statistics,validation,7.2846833392977715
216,0.04774715765206901,0.46296295523643494,0.6111111044883728,0.665603448275862,0.18415436590159384,mmlu:high_school_statistics,test,69.63300307095051
22,0.1912571273066781,0.7727273106575012,0.7727273106575012,0.8235294117647058,0.14772727543657474,mmlu:high_school_us_history,validation,19.84092566370964
204,0.0663730903875594,0.7549020051956177,0.8039215803146362,0.8022727272727272,0.0925436478619482,mmlu:high_school_us_history,test,182.20923608914018
23,0.318163170762684,0.5652173757553101,0.6086956858634949,0.803846153846154,0.2899117003316465,mmlu:human_aging,validation,3.401493951678276
223,0.07719885848562816,0.605381190776825,0.695067286491394,0.7699494949494949,0.1708239953079566,mmlu:human_aging,test,32.28472425416112
12,0.2363257755835851,0.4166666865348816,0.5833333730697632,0.6857142857142857,0.37597656746705377,mmlu:human_sexuality,validation,2.029423613101244
131,0.09733255264413265,0.6106870174407959,0.6717557311058044,0.7291666666666667,0.20455631090484502,mmlu:human_sexuality,test,21.754617299884558
13,0.18251251028134272,0.7692307829856873,0.9230769872665405,0.9166666666666667,0.05558896064758304,mmlu:international_law,validation,3.5751017592847347
121,0.0831900497605978,0.719008207321167,0.7851239442825317,0.7961460446247465,0.11915678229213744,mmlu:international_law,test,31.185122575610876
11,0.21849849820137024,0.4545454680919647,0.8181818723678589,0.9666666666666667,0.20596591450951315,mmlu:jurisprudence,validation,2.075666431337595
108,0.12156721121735044,0.7222222089767456,0.7407407760620117,0.7429487179487181,0.11461950452239428,mmlu:jurisprudence,test,19.42655671387911
18,0.17653857668240866,0.7777777910232544,0.7777777910232544,0.7232142857142857,0.16102428237597144,mmlu:logical_fallacies,validation,3.626117218285799
163,0.07610399481709018,0.6441717743873596,0.699386477470398,0.7749589490968801,0.19902703915636966,mmlu:logical_fallacies,test,31.74225203692913
11,0.18980318307876587,0.4545454680919647,0.4545454680919647,0.5666666666666667,0.3600852272727273,mmlu:machine_learning,validation,2.9645571261644363
112,0.1718911344983748,0.2321428656578064,0.5714285969734192,0.6739713774597496,0.1561104862817696,mmlu:machine_learning,test,29.29481879621744
11,0.1345507963137193,0.7272727489471436,0.6363636255264282,0.75,0.19105113636363635,mmlu:management,validation,1.5861867927014828
103,0.08853916693659661,0.7572815418243408,0.6990291476249695,0.7412820512820513,0.1895858801684333,mmlu:management,test,13.64118393138051
25,0.24609284043312074,0.8399999737739563,0.8799999952316284,0.7559523809523809,0.11421874046325683,mmlu:marketing,validation,4.741771083325148
234,0.07261072697802488,0.7991453409194946,0.8076923489570618,0.8591989987484355,0.08989381408080074,mmlu:marketing,test,42.38103658333421
11,0.177878891879862,0.8181818723678589,0.8181818723678589,0.8888888888888888,0.18430399352853954,mmlu:medical_genetics,validation,2.020908586680889
100,0.13137866437435153,0.5799999833106995,0.6499999761581421,0.7321428571428571,0.2235546791553497,mmlu:medical_genetics,test,16.321405295282602
38,0.17245584334197797,0.5,0.6052631735801697,0.6842105263157895,0.26932565475765025,mmlu:moral_disputes,validation,7.724806498736143
346,0.05548757004600041,0.6040462255477905,0.6705201864242554,0.7159047253169419,0.14794075075601565,mmlu:moral_disputes,test,70.69863990321755
33,0.16067132985953128,0.7575757503509521,0.8181818723678589,0.76,0.10688920093305185,mmlu:nutrition,validation,8.296478290110826
306,0.07396646106944366,0.6241829991340637,0.6405228972434998,0.6656271340769406,0.19190411746891498,mmlu:nutrition,test,76.64527893811464
34,0.2076805461855496,0.6470588445663452,0.7352941036224365,0.8882575757575758,0.1968060854603263,mmlu:philosophy,validation,5.461843274533749
311,0.09509623798143442,0.6495176553726196,0.6881029009819031,0.7222726859841948,0.20822448784132097,mmlu:philosophy,test,49.00829207152128
35,0.1406967146056039,0.6285714507102966,0.5714285969734192,0.7080419580419581,0.23872767175946913,mmlu:prehistory,validation,8.216958440840244
324,0.0693502246781632,0.6419752836227417,0.709876537322998,0.782659151193634,0.1265432236739147,mmlu:prehistory,test,73.41735190153122
69,0.16101905919503479,0.5652173757553101,0.6811594367027283,0.7632478632478633,0.21524003882339035,mmlu:professional_psychology,validation,17.217398777604103
612,0.07285571979736191,0.5588235259056091,0.6307189464569092,0.7013970110461338,0.21880745147567948,mmlu:professional_psychology,test,146.87647047266364
12,0.4197406445940336,0.5,0.75,0.7500000000000001,0.24446614583333331,mmlu:public_relations,validation,2.553499713540077
110,0.08595207414843818,0.6454545259475708,0.7363635897636414,0.8158179848320694,0.11953125866976651,mmlu:public_relations,test,20.8727539293468
27,0.2921704429167289,0.5925925970077515,0.7407407760620117,0.7556818181818181,0.18373842371834648,mmlu:security_studies,validation,13.249371111392975
245,0.06731781655428362,0.6326530575752258,0.7061223983764648,0.7288172043010753,0.12775828035510314,mmlu:security_studies,test,120.16342863440514
22,0.2065855657512491,0.8181818723678589,0.7727273106575012,0.8055555555555556,0.1757812337441878,mmlu:sociology,validation,4.277554489672184
201,0.07930083787856414,0.7761194109916687,0.7363184094429016,0.7938746438746439,0.1510999567473113,mmlu:sociology,test,38.93617094308138
11,0.13104990395632657,0.9090909361839294,0.9090909361839294,0.9,0.14098013531077994,mmlu:us_foreign_policy,validation,2.1924183666706085
100,0.08155728235840798,0.8399999737739563,0.8100000023841858,0.7220982142857142,0.10953123927116393,mmlu:us_foreign_policy,test,18.49697171896696
18,0.2801588558488422,0.4444444477558136,0.5,0.50625,0.3793402810891469,mmlu:virology,validation,3.795757468789816
166,0.17840684968304923,0.4397590160369873,0.5602409243583679,0.6020768890852851,0.2623070521527026,mmlu:virology,test,27.577152341604233
19,0.09875564826162236,0.7894737124443054,0.8421052694320679,0.8,0.09827301690452975,mmlu:world_religions,validation,2.486763495951891
171,0.05092319253592464,0.7602339386940002,0.8070175647735596,0.8380863039399625,0.12287554406283194,mmlu:world_religions,test,21.34136164933443
18,0.21657157772117192,0.6666666865348816,0.8888888955116272,0.9583333333333335,0.08897567788759864,mmlu:high_school_european_history,validation,27.814678146038204
165,0.07021790941556295,0.6484848260879517,0.7515151500701904,0.8323396712858523,0.1335700728676536,mmlu:high_school_european_history,test,198.21189614594914
26,0.1794874771283223,0.5384615659713745,0.7692307829856873,0.9553571428571428,0.18013820739892814,mmlu:high_school_world_history,validation,17.398271254030988
237,0.051091996426320785,0.7257384061813354,0.746835470199585,0.8114937388193202,0.09338739426327151,mmlu:high_school_world_history,test,147.72646378609352
86,0.08592159768869709,0.6627907156944275,0.6860465407371521,0.8163944343617664,0.23387536614440207,mmlu:miscellaneous,validation,12.586824700934812
783,0.056328266021696834,0.7586206793785095,0.8173691034317017,0.8531612420501309,0.10717491171825888,mmlu:miscellaneous,test,118.44478504895233
100,0.08906677156686785,0.33000001311302185,0.6700000166893005,0.5685210312075983,0.22492188811302186,mmlu:moral_scenarios,validation,26.448784581851214
895,0.07549112196075183,0.35754188895225525,0.6424580812454224,0.4155163043478261,0.25267544112391976,mmlu:moral_scenarios,test,233.72631287015975
31,0.14624394428345464,0.29032257199287415,0.6129032373428345,0.654040404040404,0.1979586808912216,mmlu:professional_accounting,validation,9.424312094924971
282,0.03571194600551686,0.41489362716674805,0.6063829660415649,0.6721056721056721,0.16198471399909217,mmlu:professional_accounting,test,84.39506438793615
170,0.12842015641577104,0.38235294818878174,0.5470588207244873,0.6134065934065934,0.21511949546196887,mmlu:professional_law,validation,118.805671507027
1534,0.09026802297210446,0.40612778067588806,0.5788787603378296,0.6395323432349049,0.184202359078605,mmlu:professional_law,test,1084.4036036881153
31,0.19196684706595632,0.4516128897666931,0.6451612710952759,0.75,0.15234374999999997,mmlu:professional_medicine,validation,14.901328573934734
272,0.09498748511952512,0.5404411554336548,0.658088207244873,0.7254149659863947,0.14061064053984249,mmlu:professional_medicine,test,130.91965288296342
