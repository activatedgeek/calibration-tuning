N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
22,0.20957888527349997,0.7727273106575012,0.3181818127632141,0.5882352941176471,0.5315580395135012,mmlu:high_school_us_history,validation,12.62039972934872
204,0.17298911102846554,0.7647058963775635,0.44607844948768616,0.41700053418803423,0.37140772068033034,mmlu:high_school_us_history,test,103.17771343514323
9,0.29965168568823075,0.6666666865348816,0.3333333432674408,0.33333333333333337,0.6084511876106262,mmlu:high_school_computer_science,validation,6.470712825655937
100,0.25068582922220234,0.6299999952316284,0.4399999976158142,0.5546975546975546,0.4712589997053146,mmlu:high_school_computer_science,test,60.437355395406485
86,0.18002967848334206,0.7325581312179565,0.3255814015865326,0.4855072463768116,0.5954200569973435,mmlu:miscellaneous,validation,22.268405467271805
783,0.15140201627142433,0.7777777314186096,0.320561945438385,0.4228290206292584,0.602604507790976,mmlu:miscellaneous,test,200.02994588389993
41,0.5727009380736002,0.31707316637039185,0.6585365533828735,0.5412087912087913,0.26513432584157803,mmlu:elementary_mathematics,validation,16.338240168988705
378,0.42320468596049715,0.38359788060188293,0.634920597076416,0.5133639188989196,0.26091056005664603,mmlu:elementary_mathematics,test,133.8197496905923
38,0.40822118834445353,0.5,0.5526315569877625,0.5983379501385042,0.35851519986202846,mmlu:moral_disputes,validation,14.562038611620665
346,0.20758274232031979,0.6965317726135254,0.35260114073753357,0.5458209839952578,0.5403451053048833,mmlu:moral_disputes,test,120.56229463592172
100,0.4591043141484261,0.3700000047683716,0.5899999737739563,0.5963105963105964,0.3334567040205002,mmlu:moral_scenarios,validation,41.76169475913048
895,0.5181126988133905,0.31843575835227966,0.6804469227790833,0.5359591601955709,0.241071451309673,mmlu:moral_scenarios,test,362.17716393619776
11,0.3877894092689861,0.5454545617103577,0.4545454680919647,0.2666666666666666,0.43882474032315344,mmlu:college_computer_science,validation,7.176345307379961
100,0.24030961245298385,0.5199999809265137,0.5099999904632568,0.3629807692307692,0.35808752417564393,mmlu:college_computer_science,test,50.567095313221216
26,0.3512281259665122,0.5,0.5384615659713745,0.34911242603550297,0.39951073894133937,mmlu:conceptual_physics,validation,7.292334668338299
235,0.3372520951514549,0.5021276473999023,0.612765908241272,0.44248877299724754,0.28740756131233053,mmlu:conceptual_physics,test,55.4762662909925
23,0.28427459364352026,0.739130437374115,0.30434784293174744,0.7500000000000001,0.550568894199703,mmlu:human_aging,validation,3.5105323309544474
223,0.27087081908645116,0.6457399129867554,0.4304932951927185,0.5076037271448663,0.48065469003044436,mmlu:human_aging,test,19.996297186007723
18,0.22757794128523934,0.7222222089767456,0.3333333432674408,0.5923076923076923,0.6516204310788047,mmlu:logical_fallacies,validation,3.526184779126197
163,0.20550321636755775,0.6932514905929565,0.3251533806324005,0.3112389380530974,0.6319956073731733,mmlu:logical_fallacies,test,18.502438995987177
11,0.32416897741231054,0.6363636255264282,0.4545454680919647,0.14285714285714285,0.4529394832524386,mmlu:computer_security,validation,4.89925467222929
100,0.1908364862203598,0.7199999690055847,0.41999998688697815,0.421875,0.471486799120903,mmlu:computer_security,test,29.47702226229012
21,0.19357890458334065,0.761904776096344,0.3333333432674408,0.5125,0.6745596840268089,mmlu:high_school_government_and_politics,validation,8.414513356983662
193,0.11865964825289238,0.8341968655586243,0.26424869894981384,0.4559394409937888,0.6766894978562786,mmlu:high_school_government_and_politics,test,63.96883149445057
10,0.644013872742653,0.20000000298023224,0.9000000357627869,0.4375,0.08487215042114259,mmlu:global_facts,validation,4.4287134334445
100,0.4887322998046876,0.3499999940395355,0.6399999856948853,0.3919270833333333,0.2339599937200546,mmlu:global_facts,test,29.268598336726427
33,0.20537934881268127,0.7272727489471436,0.39393940567970276,0.3148148148148148,0.48402011755741003,mmlu:nutrition,validation,6.2880451588425785
306,0.20991167776724873,0.6797385811805725,0.4313725531101227,0.46077806122448983,0.4568053337873197,mmlu:nutrition,test,44.46085141506046
18,0.3027564552095201,0.6111111044883728,0.3888888955116272,0.35064935064935066,0.5281557275189294,mmlu:virology,validation,6.80527014285326
166,0.4095375338591726,0.48795178532600403,0.518072247505188,0.47604529616724733,0.3612737397113478,mmlu:virology,test,44.2973314113915
34,0.2455204549957724,0.7058823704719543,0.529411792755127,0.30416666666666664,0.4175957073183621,mmlu:philosophy,validation,10.23536540940404
311,0.22823822785803746,0.6913183331489563,0.4244372844696045,0.4649709302325582,0.47282348530085516,mmlu:philosophy,test,82.32511076703668
11,0.493845674124631,0.4545454680919647,0.6363636255264282,0.4166666666666667,0.3982792821797458,mmlu:college_physics,validation,5.123910408467054
102,0.4071022833094878,0.4117647111415863,0.6274510025978088,0.4035714285714286,0.3391559778475294,mmlu:college_physics,test,36.016609005630016
22,0.34913744303313166,0.5454545617103577,0.3636363744735718,0.27499999999999997,0.5915453081781215,mmlu:high_school_chemistry,validation,4.257672984851524
203,0.3363187564124028,0.5024630427360535,0.5665024518966675,0.5066491943311978,0.29080977228474736,mmlu:high_school_chemistry,test,26.376007430953905
69,0.25022709067317017,0.695652186870575,0.37681159377098083,0.3680555555555556,0.566252641055895,mmlu:professional_psychology,validation,30.186491567641497
612,0.2649987743181341,0.6372548937797546,0.41830065846443176,0.4712883776371064,0.49871081376776977,mmlu:professional_psychology,test,254.67162469401956
11,0.04649685187773271,0.9090909361839294,0.4545454680919647,0.9,0.5910185033624822,mmlu:medical_genetics,validation,4.579842079430819
100,0.2633916762471199,0.6599999666213989,0.3799999952316284,0.5608288770053476,0.522676019668579,mmlu:medical_genetics,test,26.22195317223668
19,0.1606659983333788,0.8421052694320679,0.2631579041481018,0.45833333333333337,0.6224906820999948,mmlu:world_religions,validation,3.158299176953733
171,0.1364303168497588,0.8304093480110168,0.31578946113586426,0.3936376881981545,0.5896075347013641,mmlu:world_religions,test,13.776385605335236
23,0.3252764616323554,0.52173912525177,0.5652173757553101,0.5227272727272727,0.3947438675424327,mmlu:high_school_statistics,validation,13.436963938176632
216,0.3690704256296158,0.45370370149612427,0.5787037014961243,0.48309408509166374,0.3280901966823472,mmlu:high_school_statistics,test,119.82367784902453
17,0.575691151268342,0.1764705926179886,0.7647058963775635,0.42857142857142855,0.1337521742371952,mmlu:high_school_physics,validation,7.983160447329283
151,0.4651692444520281,0.33112582564353943,0.6556291580200195,0.508019801980198,0.24998218965846183,mmlu:high_school_physics,test,59.069267362356186
31,0.3662339891156843,0.6129032373428345,0.4516128897666931,0.506578947368421,0.5143196428975751,mmlu:professional_medicine,validation,9.35614626808092
272,0.3212055785252767,0.591911792755127,0.4485294222831726,0.4905433383694253,0.4771319888532162,mmlu:professional_medicine,test,71.25250163092278
11,0.7643224542791193,0.09090909361839294,0.27272728085517883,0.7,0.6604159257628701,mmlu:abstract_algebra,validation,4.271275632083416
100,0.4031590214371681,0.29999998211860657,0.6200000047683716,0.49809523809523804,0.28113077640533446,mmlu:abstract_algebra,test,26.565746376290917
11,0.08234056559475988,0.9090909361839294,0.1818181872367859,0.6,0.7921340519731694,mmlu:management,validation,3.798708036541939
103,0.20205990897798995,0.7475728392601013,0.3980582654476166,0.45829170829170834,0.4991158304862605,mmlu:management,test,23.311067178845406
12,0.23787748813629153,0.6666666865348816,0.4166666865348816,0.53125,0.5132388273874919,mmlu:econometrics,validation,3.133601310197264
114,0.44167632021402053,0.4035087823867798,0.4385964870452881,0.45268542199488493,0.4673745904052467,mmlu:econometrics,test,17.211005927994847
170,0.3847176639472737,0.47647058963775635,0.5352941155433655,0.47627965043695386,0.4418357018162222,mmlu:professional_law,validation,196.8949762955308
1534,0.41742439630211875,0.42829203605651855,0.5723598599433899,0.48082226491654645,0.4000740447597678,mmlu:professional_law,test,1791.549409020692
12,0.4036060348153115,0.5,0.5833333730697632,0.16666666666666666,0.36774495740731555,mmlu:human_sexuality,validation,4.76480396091938
131,0.19538163911295303,0.6870229244232178,0.4122137427330017,0.4269647696476965,0.4846746411942343,mmlu:human_sexuality,test,33.32775989547372
29,0.28908198455284384,0.6206896305084229,0.37931033968925476,0.5126262626262627,0.5907562477835294,mmlu:clinical_knowledge,validation,5.056870334781706
265,0.20924715669649951,0.6943396329879761,0.31698113679885864,0.5352254428341385,0.6515679550620744,mmlu:clinical_knowledge,test,29.00534553732723
16,0.27259473502635956,0.6875,0.5625,0.4363636363636364,0.4818699434399605,mmlu:college_biology,validation,6.811633791774511
144,0.2272974890139368,0.7291666865348816,0.5,0.40402930402930404,0.40059894985622835,mmlu:college_biology,test,51.5210775192827
35,0.2834143774850028,0.6285714507102966,0.4000000059604645,0.38636363636363635,0.5123044984681266,mmlu:prehistory,validation,14.804829627275467
324,0.2162013934166343,0.694444477558136,0.4104938209056854,0.449023569023569,0.4756904146921488,mmlu:prehistory,test,124.8554426021874
32,0.2306552482768893,0.71875,0.34375,0.7101449275362319,0.5831936895847321,mmlu:high_school_biology,validation,7.081088765989989
310,0.1958934453225905,0.7322580814361572,0.3774193525314331,0.5266174831484528,0.5213934986822066,mmlu:high_school_biology,test,41.638023257022724
22,0.09853547676043077,0.8636363744735718,0.09090909361839294,0.7543859649122808,0.8321847834370353,mmlu:high_school_geography,validation,7.658299569040537
198,0.16608701420552807,0.7575757503509521,0.28282827138900757,0.45868055555555554,0.6533526769190123,mmlu:high_school_geography,test,54.60541680082679
18,0.11844011478953893,0.8888888955116272,0.3333333432674408,0.4375,0.4903931717077891,mmlu:high_school_european_history,validation,35.02389683946967
165,0.25320393641789757,0.7090908885002136,0.5757575631141663,0.5272435897435898,0.26696810252738723,mmlu:high_school_european_history,test,309.17801989614964
11,0.0979376055977561,0.9090909361839294,0.1818181872367859,0.3,0.7462287761948325,mmlu:us_foreign_policy,validation,4.776698239147663
100,0.1474481576681137,0.8399999737739563,0.23999999463558197,0.44270833333333337,0.6586882376670837,mmlu:us_foreign_policy,test,31.100740250200033
27,0.3264375351093433,0.6296296119689941,0.48148149251937866,0.4852941176470588,0.4614604247940911,mmlu:security_studies,validation,8.425369026139379
245,0.2150687349085905,0.7061223983764648,0.4734693765640259,0.48053147077713554,0.39995627768185676,mmlu:security_studies,test,66.44407788477838
43,0.2296308119629705,0.6511628031730652,0.44186046719551086,0.21071428571428574,0.5109312686809274,mmlu:high_school_macroeconomics,validation,13.110686354339123
390,0.3068390015608225,0.5794872045516968,0.45897436141967773,0.411248111374919,0.47045239485227147,mmlu:high_school_macroeconomics,test,110.5595160163939
16,0.20895074307918549,0.6875,0.375,0.5545454545454545,0.5446988008916378,mmlu:electrical_engineering,validation,3.105056911939755
145,0.2817974072078179,0.565517246723175,0.517241358757019,0.4211188540456834,0.3720983225723793,mmlu:electrical_engineering,test,16.496020377846435
11,0.46565471725030383,0.27272728085517883,0.5454545617103577,0.3333333333333333,0.3202235915444114,mmlu:machine_learning,validation,6.197148364037275
112,0.4036267655236381,0.4285714626312256,0.5803571939468384,0.4871419270833333,0.3149388059973717,mmlu:machine_learning,test,52.20007439702749
31,0.3555353168518312,0.4838709533214569,0.5483870506286621,0.4666666666666666,0.4415515103647786,mmlu:professional_accounting,validation,16.1118176728487
282,0.40098563639830187,0.44680848717689514,0.5496453642845154,0.45288970288970287,0.4099317231076829,mmlu:professional_accounting,test,136.81219987943769
16,0.34564853459596634,0.5625,0.5,0.42063492063492064,0.4691197909414768,mmlu:astronomy,validation,8.030839558690786
152,0.23982455189290802,0.6513158082962036,0.5526315569877625,0.4552125023823137,0.2958007835243877,mmlu:astronomy,test,62.86449350789189
22,0.2926851267164404,0.6363636255264282,0.3636363744735718,0.33035714285714285,0.6036903099580245,mmlu:college_medicine,validation,4.161320340819657
173,0.34965311395639626,0.5664739608764648,0.42774564027786255,0.42673469387755103,0.5257946604249105,mmlu:college_medicine,test,25.773048329167068
11,0.21520352363586426,0.7272727489471436,0.3636363744735718,0.3333333333333333,0.5847371437332848,mmlu:business_ethics,validation,5.5824578776955605
100,0.30391647219657897,0.5600000023841858,0.5299999713897705,0.5657467532467533,0.39103628695011133,mmlu:business_ethics,test,39.98526982963085
8,0.4576853886246681,0.5,0.5,0.75,0.42161357402801514,mmlu:college_chemistry,validation,5.098534047603607
100,0.3473054426908493,0.44999998807907104,0.6399999856948853,0.5134863123993558,0.2792172288894653,mmlu:college_chemistry,test,37.20987072587013
29,0.36512368506398696,0.3448275923728943,0.6551724076271057,0.45263157894736844,0.30549779637106533,mmlu:high_school_mathematics,validation,11.26067440584302
270,0.35188147558106314,0.31481480598449707,0.7074074149131775,0.42823529411764705,0.2615145208658995,mmlu:high_school_mathematics,test,91.27130641043186
26,0.2985493861711942,0.6538462042808533,0.5,0.4869281045751634,0.4757230740327102,mmlu:high_school_microeconomics,validation,8.265600968152285
238,0.24070155432745194,0.6680672764778137,0.44117650389671326,0.4206273385876921,0.4851795845672864,mmlu:high_school_microeconomics,test,65.35215832665563
26,0.27441956446721,0.7307692766189575,0.5384615659713745,0.7142857142857143,0.35095371191318225,mmlu:high_school_world_history,validation,28.50013978779316
237,0.21655371646840865,0.7426159977912903,0.49367085099220276,0.41868479880774967,0.3490955935248846,mmlu:high_school_world_history,test,239.54427908360958
22,0.09810863841663708,0.9090909361839294,0.13636364042758942,0.1625,0.8109333244237033,mmlu:sociology,validation,3.939859102945775
201,0.14230316921846192,0.8208954930305481,0.20398008823394775,0.44856902356902356,0.7514907984591244,mmlu:sociology,test,22.36423931294121
11,0.5015530450777574,0.5454545617103577,0.3636363744735718,0.2666666666666666,0.5809814713217996,mmlu:college_mathematics,validation,6.263957414776087
100,0.3651839891076088,0.3100000023841858,0.6899999976158142,0.48620850864890136,0.253669638633728,mmlu:college_mathematics,test,40.73789022490382
14,0.4105997639042991,0.5714285969734192,0.5,0.34374999999999994,0.4786461804594312,mmlu:anatomy,validation,4.875439287163317
135,0.3086984787826184,0.5999999642372131,0.4000000059604645,0.6049382716049383,0.572883794925831,mmlu:anatomy,test,13.342239835299551
11,0.4062383635477586,0.5454545617103577,0.6363636255264282,0.09999999999999999,0.3689056255600669,mmlu:jurisprudence,validation,4.517672557383776
108,0.12951665620009106,0.7777777910232544,0.31481480598449707,0.4799107142857143,0.6466661090100254,mmlu:jurisprudence,test,32.45234593003988
13,0.046483397483825684,1.0,0.23076924681663513,,0.7215559161626375,mmlu:international_law,validation,6.784349218010902
121,0.18757747655565085,0.7438015937805176,0.29752063751220703,0.5530465949820789,0.632566047108863,mmlu:international_law,test,52.39428021013737
12,0.26917629688978195,0.5833333730697632,0.5,0.34285714285714286,0.5239542176326115,mmlu:public_relations,validation,5.063288886100054
110,0.21890750933777198,0.699999988079071,0.40909090638160706,0.3890200708382527,0.5242901986295527,mmlu:public_relations,test,33.21369689702988
14,0.5318877186094011,0.3571428656578064,0.6428571939468384,0.5222222222222223,0.3693450135844094,mmlu:formal_logic,validation,3.4074603801127523
126,0.43135314635814187,0.3888889253139496,0.6746032238006592,0.385237211767824,0.22669750262820532,mmlu:formal_logic,test,19.692718997132033
60,0.14361121356487278,0.8666667342185974,0.30000001192092896,0.18990384615384615,0.6048463294903438,mmlu:high_school_psychology,validation,8.833158300025389
545,0.15350774162953057,0.7981651425361633,0.31926605105400085,0.4588296760710554,0.5888172896630174,mmlu:high_school_psychology,test,69.42072863387875
25,0.10132803440093999,0.8399999737739563,0.3199999928474426,0.4642857142857143,0.558103039264679,mmlu:marketing,validation,8.781659327447414
234,0.09073696482894764,0.8717949390411377,0.3461538553237915,0.5042483660130719,0.5348190061556988,mmlu:marketing,test,69.57613591849804
