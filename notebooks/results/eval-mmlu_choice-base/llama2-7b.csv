N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.19600178707729685,0.1818181872367859,0.1818181872367859,0.36111111111111116,0.4418815862048756,mmlu:abstract_algebra,validation,4.8286595940589905
100,0.10345929622650146,0.3400000035762787,0.3700000047683716,0.6147504456327986,0.2502369648218155,mmlu:abstract_algebra,test,9.530469562858343
14,0.2745207079819271,0.6428571939468384,0.6428571939468384,0.3222222222222222,0.1356738678046635,mmlu:anatomy,validation,1.4412841461598873
135,0.06617062445040103,0.4814814627170563,0.4814814627170563,0.5283516483516484,0.24593061782695627,mmlu:anatomy,test,13.335837572813034
16,0.21181475743651387,0.4375,0.4375,0.626984126984127,0.3260355778038502,mmlu:astronomy,validation,2.407146319746971
152,0.06972781058989072,0.43421053886413574,0.43421053886413574,0.5347075405214939,0.2990921876932445,mmlu:astronomy,test,21.81048795953393
11,0.1848977885463021,0.5454545617103577,0.5454545617103577,0.6666666666666666,0.2095680670304732,mmlu:business_ethics,validation,1.7053764797747135
100,0.06806178212165834,0.47999998927116394,0.47999998927116394,0.45933493589743585,0.19581442654132844,mmlu:business_ethics,test,14.144003700464964
29,0.17136164369254275,0.41379308700561523,0.4482758641242981,0.1911764705882353,0.38458863003500576,mmlu:clinical_knowledge,validation,3.216649007052183
265,0.06352440062558876,0.49056604504585266,0.49433964490890503,0.4732763532763533,0.1183648080196021,mmlu:clinical_knowledge,test,28.49096293374896
16,0.14042930863797665,0.3125,0.3125,0.5909090909090909,0.3052928186953068,mmlu:college_biology,validation,2.0670842565596104
144,0.09512731060385704,0.4375,0.4305555522441864,0.5146972369194591,0.18253463630874955,mmlu:college_biology,test,18.348304890096188
8,0.2852059379220009,0.5,0.5,0.3125,0.28666040301322937,mmlu:college_chemistry,validation,1.30516716837883
100,0.02657668381929397,0.35999998450279236,0.35999998450279236,0.5262586805555556,0.3087800097465515,mmlu:college_chemistry,test,13.68974256515503
11,0.27593808011575177,0.6363636255264282,0.6363636255264282,0.2142857142857143,0.18935598026622424,mmlu:college_computer_science,validation,2.173090048134327
100,0.1143285819888115,0.3700000047683716,0.3700000047683716,0.4834834834834835,0.28490533709526067,mmlu:college_computer_science,test,18.721224673092365
11,0.07282546433535489,0.27272728085517883,0.3636363744735718,0.4583333333333333,0.2255466092716564,mmlu:college_mathematics,validation,1.6743683591485023
100,0.045478269457817064,0.3400000035762787,0.4399999976158142,0.49754901960784315,0.12571060657501223,mmlu:college_mathematics,test,13.684256758540869
22,0.1310065632516688,0.40909093618392944,0.40909093618392944,0.5299145299145299,0.23511226610703903,mmlu:college_medicine,validation,3.041729912161827
173,0.09979745022134284,0.39306357502937317,0.39306357502937317,0.517577030812325,0.2651127318426364,mmlu:college_medicine,test,29.343144197016954
11,0.17821613225069913,0.4545454680919647,0.4545454680919647,0.8333333333333334,0.1562873125076294,mmlu:college_physics,validation,1.4862174540758133
102,0.19960654804519576,0.21568627655506134,0.22549019753932953,0.5994318181818181,0.40767306615324583,mmlu:college_physics,test,12.28672395274043
11,0.12466021559455176,0.5454545617103577,0.5454545617103577,0.31666666666666665,0.2276700030673634,mmlu:computer_security,validation,1.4394467137753963
100,0.09803608745336534,0.5699999928474426,0.5699999928474426,0.5815993472052223,0.12790939450263974,mmlu:computer_security,test,10.60031320527196
26,0.1548698808138187,0.38461539149284363,0.38461539149284363,0.640625,0.3024055315898015,mmlu:conceptual_physics,validation,2.3371373265981674
235,0.07418854287330144,0.42553189396858215,0.42553189396858215,0.503,0.2540966655345673,mmlu:conceptual_physics,test,19.559930097311735
12,0.1461530551314354,0.25,0.4166666865348816,0.35185185185185186,0.4083477258682251,mmlu:econometrics,validation,1.9237855039536953
114,0.1777252818931613,0.2982456088066101,0.5087719559669495,0.6011029411764706,0.24415907316040572,mmlu:econometrics,test,16.89810809865594
16,0.20548003911972043,0.5625,0.5625,0.4365079365079365,0.137826818972826,mmlu:electrical_engineering,validation,1.8639823906123638
145,0.08971816835732298,0.4275861978530884,0.46206897497177124,0.5418771861640109,0.10568589917544663,mmlu:electrical_engineering,test,15.818343922495842
41,0.1618965587964872,0.2195121943950653,0.2195121943950653,0.390625,0.5096835610343189,mmlu:elementary_mathematics,validation,5.58145547658205
378,0.07699811931640385,0.23544973134994507,0.23544973134994507,0.5596788616305743,0.45443196287230836,mmlu:elementary_mathematics,test,49.53158442676067
14,0.13051569674696242,0.2142857313156128,0.2142857313156128,0.5606060606060606,0.3561685936791556,mmlu:formal_logic,validation,2.158609990030527
126,0.06072341355066451,0.3809524178504944,0.3888889253139496,0.41947115384615385,0.18811971327615162,mmlu:formal_logic,test,18.729526080191135
10,0.3186344265937805,0.0,0.0,,0.6245536446571349,mmlu:global_facts,validation,1.5306910835206509
100,0.08433636128902436,0.29999998211860657,0.29999998211860657,0.4335714285714286,0.32411975979804997,mmlu:global_facts,test,10.763929169625044
32,0.15764552727341652,0.34375,0.34375,0.6298701298701299,0.32399058155715466,mmlu:high_school_biology,validation,4.269194889813662
310,0.06778160891225259,0.4741935431957245,0.4741935431957245,0.47137014314928427,0.19368004183615412,mmlu:high_school_biology,test,40.54614546149969
22,0.0664168664000251,0.3636363744735718,0.3636363744735718,0.44642857142857145,0.3473830385641618,mmlu:high_school_chemistry,validation,3.003511056303978
203,0.033929474101278,0.37438422441482544,0.37438422441482544,0.4744094488188976,0.339096305992803,mmlu:high_school_chemistry,test,25.919677510857582
9,0.3543669912550184,0.5555555820465088,0.6666666865348816,0.8500000000000001,0.15712577104568481,mmlu:high_school_computer_science,validation,1.99049611389637
100,0.10661277830600738,0.3700000047683716,0.4099999964237213,0.46761046761046765,0.17836083412170411,mmlu:high_school_computer_science,test,20.926846235990524
22,0.12118071317672728,0.6818181872367859,0.6818181872367859,0.4,0.14114133065397086,mmlu:high_school_geography,validation,2.287088133394718
198,0.10586718778417568,0.4898989796638489,0.4747474789619446,0.40941104419720326,0.09691943875466935,mmlu:high_school_geography,test,20.276595029979944
21,0.17865190477598278,0.6666666865348816,0.6666666865348816,0.5255102040816326,0.029409263815198594,mmlu:high_school_government_and_politics,validation,2.5962732657790184
193,0.09149920878632699,0.6891191601753235,0.6839377880096436,0.4454260651629072,0.07687343803712124,mmlu:high_school_government_and_politics,test,23.066320702433586
43,0.14036576484524926,0.3255814015865326,0.41860464215278625,0.6995073891625616,0.15324890197709548,mmlu:high_school_macroeconomics,validation,4.535687252879143
390,0.029747932538008073,0.4384615421295166,0.4564102590084076,0.49546049293706107,0.11288162637979557,mmlu:high_school_macroeconomics,test,40.556086748838425
29,0.09650889450106129,0.41379308700561523,0.41379308700561523,0.5049019607843137,0.2719797348154002,mmlu:high_school_mathematics,validation,3.803484696894884
270,0.04743213896398192,0.2666666507720947,0.2666666507720947,0.5963453984287318,0.4230780923808063,mmlu:high_school_mathematics,test,33.932128481566906
26,0.31372461869166446,0.26923078298568726,0.3076923191547394,0.40225563909774437,0.293660193681717,mmlu:high_school_microeconomics,validation,2.797305040061474
238,0.08233287930488584,0.4495798647403717,0.47478994727134705,0.49532710280373826,0.10905225512360324,mmlu:high_school_microeconomics,test,25.280451882630587
17,0.13780631738550522,0.4117647111415863,0.4117647111415863,0.5357142857142857,0.21996092445710128,mmlu:high_school_physics,validation,2.5017282888293266
151,0.07364640804316033,0.2781457006931305,0.2781457006931305,0.5346221057230232,0.36260171283949294,mmlu:high_school_physics,test,20.811108320951462
60,0.16761498898267746,0.6833333969116211,0.6666666865348816,0.5025673940949936,0.07200761636098225,mmlu:high_school_psychology,validation,7.778197392821312
545,0.07928151635948673,0.6293578147888184,0.6183486580848694,0.45895274658661206,0.05678427427186876,mmlu:high_school_psychology,test,70.77159875258803
23,0.12523381347241608,0.43478262424468994,0.43478262424468994,0.7307692307692308,0.25851436801578687,mmlu:high_school_statistics,validation,4.313196886330843
216,0.11009164168326943,0.25462964177131653,0.25462964177131653,0.36086956521739133,0.40766640366227536,mmlu:high_school_statistics,test,47.69698779657483
22,0.30077560110525653,0.6818181872367859,0.6818181872367859,0.5666666666666667,0.11466746709563516,mmlu:high_school_us_history,validation,11.495052427053452
204,0.10001707427641923,0.5784313678741455,0.5784313678741455,0.4699448167126528,0.18833541461065703,mmlu:high_school_us_history,test,105.16277872398496
23,0.2850950878599416,0.6521739363670349,0.6521739363670349,0.38333333333333336,0.06768459081649782,mmlu:human_aging,validation,2.080620665103197
223,0.07291243669698057,0.5650224685668945,0.5560538172721863,0.5261004745540829,0.029754734360049155,mmlu:human_aging,test,19.291529953479767
12,0.27455595632394153,0.5833333730697632,0.5833333730697632,0.44285714285714284,0.22908799846967065,mmlu:human_sexuality,validation,1.2960634976625443
131,0.08630535211271911,0.5419847369194031,0.5419847369194031,0.43462441314553996,0.17667940918725866,mmlu:human_sexuality,test,13.066518481820822
13,0.27090010505456197,0.8461538553237915,0.8461538553237915,0.3863636363636364,0.15094978075761067,mmlu:international_law,validation,2.162782911211252
121,0.06861441194518537,0.6280991435050964,0.6280991435050964,0.5318713450292397,0.08032049324886856,mmlu:international_law,test,18.373278327286243
11,0.16036775708198547,0.5454545617103577,0.5454545617103577,0.5333333333333332,0.06882303411310367,mmlu:jurisprudence,validation,1.300838392227888
108,0.11777681691779031,0.5092592835426331,0.5185185074806213,0.5089193825042881,0.0925489537141941,mmlu:jurisprudence,test,11.449046101421118
18,0.24433257513576082,0.7222222089767456,0.7777777910232544,0.6615384615384616,0.19739663600921636,mmlu:logical_fallacies,validation,2.1321411542594433
163,0.07949630193915104,0.5398772954940796,0.5030674934387207,0.4467424242424243,0.07069347204606224,mmlu:logical_fallacies,test,18.79083876684308
11,0.19437930800698017,0.1818181872367859,0.1818181872367859,0.5555555555555556,0.5073114091699773,mmlu:machine_learning,validation,1.8486994616687298
112,0.05080046850655761,0.4017857313156128,0.4017857313156128,0.5081260364842455,0.23374828110848156,mmlu:machine_learning,test,17.14563123509288
11,0.3082366639917547,0.27272728085517883,0.27272728085517883,0.5,0.32237599654631177,mmlu:management,validation,1.0056748799979687
103,0.1167176114124002,0.6019417643547058,0.5922330021858215,0.5743509047993706,0.046711136415166714,mmlu:management,test,8.263239696621895
25,0.20999683380126954,0.7999999523162842,0.6800000071525574,0.5800000000000001,0.13524168014526372,mmlu:marketing,validation,2.7737266942858696
234,0.07044396543095253,0.6666666865348816,0.5598291158676147,0.4792899408284023,0.01934457309225681,mmlu:marketing,test,24.780189376324415
11,0.17338241772218185,0.8181818723678589,0.8181818723678589,0.16666666666666666,0.24410828677090732,mmlu:medical_genetics,validation,1.2460557594895363
100,0.13484239101409912,0.4699999988079071,0.4699999988079071,0.6310718586912887,0.20834235668182371,mmlu:medical_genetics,test,9.74319901689887
38,0.20729178503939982,0.3684210479259491,0.34210526943206787,0.6235119047619049,0.3184823017371328,mmlu:moral_disputes,validation,4.631254263222218
346,0.07984121669234569,0.4942196309566498,0.49132946133613586,0.5064160401002507,0.18812099633189291,mmlu:moral_disputes,test,41.58855251967907
33,0.12400645107933973,0.6363636255264282,0.575757622718811,0.31150793650793646,0.08051703734831378,mmlu:nutrition,validation,4.889022201299667
306,0.05371734227230345,0.5032680034637451,0.4673202633857727,0.4642216336295284,0.12823036001398672,mmlu:nutrition,test,44.93469840660691
34,0.2598603814840317,0.4117647111415863,0.4117647111415863,0.6035714285714286,0.26001402911017923,mmlu:philosophy,validation,3.3613055050373077
311,0.05007908534007058,0.5691318511962891,0.5691318511962891,0.5200691457964415,0.11213998108431458,mmlu:philosophy,test,29.245602283626795
35,0.20663451637540542,0.4000000059604645,0.4000000059604645,0.49659863945578225,0.2537567121641977,mmlu:prehistory,validation,4.882320683449507
324,0.08355181498659983,0.5061728358268738,0.5061728358268738,0.47486661585365847,0.14868600372179053,mmlu:prehistory,test,43.31140740215778
69,0.11826330121012701,0.3913043439388275,0.3913043439388275,0.4470899470899471,0.3053005311800086,mmlu:professional_psychology,validation,10.146041981875896
612,0.047442037977424314,0.4248366057872772,0.4248366057872772,0.5111997377622377,0.2821776716927298,mmlu:professional_psychology,test,85.45491928234696
12,0.2658598124980927,0.4166666865348816,0.3333333432674408,0.28571428571428575,0.22931390007336933,mmlu:public_relations,validation,1.513832964003086
110,0.08100817745382137,0.5363636016845703,0.5181818008422852,0.4469923562645397,0.027973463318564668,mmlu:public_relations,test,12.20630831643939
27,0.07412915318100541,0.4444444477558136,0.48148149251937866,0.5555555555555556,0.12439246751643995,mmlu:security_studies,validation,7.736179769039154
245,0.06830503794611717,0.4653061032295227,0.45714282989501953,0.47827105932770864,0.13413668311372096,mmlu:security_studies,test,69.53299820795655
22,0.12477473372762851,0.6818181872367859,0.6818181872367859,0.5238095238095237,0.10996003042567865,mmlu:sociology,validation,2.5885679461061954
201,0.0839439366587359,0.6318407654762268,0.6318407654762268,0.4774952117471803,0.06198473801067218,mmlu:sociology,test,23.046091347932816
11,0.2193876721642234,0.4545454680919647,0.4545454680919647,0.6000000000000001,0.1620099436153065,mmlu:us_foreign_policy,validation,1.3278160467743874
100,0.0687565591931343,0.6499999761581421,0.6599999666213989,0.47208791208791206,0.09884588420391081,mmlu:us_foreign_policy,test,10.692655049264431
18,0.2855966008371777,0.3333333432674408,0.3888888955116272,0.7222222222222222,0.22276725371678668,mmlu:virology,validation,2.2299260422587395
166,0.1434897751693266,0.40963852405548096,0.40963852405548096,0.4459033613445378,0.2249289912631713,mmlu:virology,test,16.50486570596695
19,0.23170600439372815,0.7894737124443054,0.7894737124443054,0.65,0.11652788049296324,mmlu:world_religions,validation,1.5305270701646805
171,0.1449006686085149,0.707602322101593,0.707602322101593,0.4756198347107437,0.047398807012546826,mmlu:world_religions,test,13.02062413841486
18,0.3306613730059729,0.6111111044883728,0.6111111044883728,0.6818181818181819,0.13805394702487522,mmlu:high_school_european_history,validation,16.734582690987736
165,0.14075853662057358,0.6121212244033813,0.6121212244033813,0.5377475247524752,0.13361473480860397,mmlu:high_school_european_history,test,115.73976772208698
26,0.15238313491527855,0.5769230723381042,0.5769230723381042,0.3939393939393939,0.1929017397073599,mmlu:high_school_world_history,validation,10.136252401047386
237,0.1755296935009051,0.6455696225166321,0.6455696225166321,0.4549097416744475,0.13987059683739383,mmlu:high_school_world_history,test,86.41241188207641
86,0.13362047041571418,0.604651153087616,0.604651153087616,0.6281108597285068,0.07135618841925334,mmlu:miscellaneous,validation,7.598518806975335
783,0.0690558131779443,0.64112389087677,0.64112389087677,0.5655243793509237,0.03680502302649684,mmlu:miscellaneous,test,70.63827831600793
100,0.08912282347679136,0.25,0.25,0.4597333333333333,0.3784449362754822,mmlu:moral_scenarios,validation,15.734783821972087
895,0.11698284418889265,0.22234636545181274,0.22122904658317566,0.48388855195517816,0.4033829965404958,mmlu:moral_scenarios,test,138.53292457701173
31,0.2381780435962062,0.25806450843811035,0.4193548262119293,0.3804347826086956,0.11674054207340362,mmlu:professional_accounting,validation,5.575037295930088
282,0.06284227924989469,0.3617021143436432,0.5283687710762024,0.5786220043572984,0.009299445236828277,mmlu:professional_accounting,test,49.63353229302447
170,0.08942360790336834,0.3529411852359772,0.6294117569923401,0.48159090909090907,0.06624637386378122,mmlu:professional_law,validation,69.44930983195081
1534,0.028630297684451897,0.3422425091266632,0.6453715562820435,0.4820104771343621,0.059974077200174634,mmlu:professional_law,test,633.5216354629956
31,0.10904836462390041,0.4516128897666931,0.4516128897666931,0.5441176470588236,0.21015502175977152,mmlu:professional_medicine,validation,8.702122616930865
272,0.13875008264885233,0.5110294222831726,0.5110294222831726,0.5052469302753286,0.1646575349218705,mmlu:professional_medicine,test,76.74708507803734
