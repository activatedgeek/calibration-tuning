N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
35,0.2644531607627869,0.6571428775787354,0.6571428775787354,0.657608695652174,0.14820329802376886,mmlu:prehistory,validation,11.773736327886581
324,0.2409034050357194,0.6018518805503845,0.6018518805503845,0.5266746173722917,0.20640994865953186,mmlu:prehistory,test,95.67521568993106
14,0.21229801646300728,0.5714285969734192,0.5714285969734192,0.7291666666666666,0.107409873179027,mmlu:anatomy,validation,5.726283602416515
135,0.19077150026957193,0.5111110806465149,0.5185185074806213,0.39635485287659206,0.16028831932279802,mmlu:anatomy,test,30.782941728830338
41,0.23956186524251613,0.4146341383457184,0.4146341383457184,0.7316176470588235,0.24548203189198564,mmlu:elementary_mathematics,validation,13.679700646549463
378,0.3091333003113509,0.33068782091140747,0.32804232835769653,0.5389565217391304,0.34496404758836857,mmlu:elementary_mathematics,test,111.77076742611825
18,0.24711839689148796,0.7222222089767456,0.7222222089767456,0.8769230769230769,0.1588084035449558,mmlu:logical_fallacies,validation,5.870206671766937
163,0.1738014663655334,0.6809815764427185,0.6809815764427185,0.5798683298683298,0.05004122359621009,mmlu:logical_fallacies,test,40.235678458586335
16,0.11451517790555954,0.625,0.625,0.24166666666666664,0.19604392722249034,mmlu:astronomy,validation,7.066856140270829
152,0.2452580393537095,0.5657894611358643,0.5592105388641357,0.537262156448203,0.19222425159655115,mmlu:astronomy,test,48.936152623966336
11,0.19265199791301382,0.7272727489471436,0.7272727489471436,1.0,0.15575709126212378,mmlu:medical_genetics,validation,4.850561831146479
100,0.2191424548625946,0.5699999928474426,0.550000011920929,0.5556915544675644,0.08192657470703125,mmlu:medical_genetics,test,22.789402041584253
11,0.2265852987766266,0.5454545617103577,0.5454545617103577,0.75,0.23112403804605658,mmlu:college_computer_science,validation,6.142959743738174
100,0.17021598696708679,0.5399999618530273,0.5399999618530273,0.6018518518518519,0.18540453791618353,mmlu:college_computer_science,test,36.03056411072612
16,0.2665847837924957,0.5625,0.6875,0.7619047619047619,0.11279615759849546,mmlu:college_biology,validation,5.843087527900934
144,0.20155534520745277,0.5763888955116272,0.5416666865348816,0.43896899071696627,0.04807062281502621,mmlu:college_biology,test,39.61198223941028
10,0.47131555378437046,0.20000000298023224,0.20000000298023224,0.6875,0.5647107660770416,mmlu:global_facts,validation,4.415616124868393
100,0.3192180448770523,0.29999998211860657,0.29999998211860657,0.5033333333333333,0.463368713259697,mmlu:global_facts,test,24.163992427289486
13,0.1019190962498005,0.8461538553237915,0.8461538553237915,0.7727272727272727,0.21293039505298317,mmlu:international_law,validation,5.656267765909433
121,0.15326742569277113,0.7520660758018494,0.7603305578231812,0.6269230769230769,0.038430893224132956,mmlu:international_law,test,39.84080536197871
33,0.1475859121842818,0.696969747543335,0.696969747543335,0.6130434782608696,0.035417471871231516,mmlu:nutrition,validation,12.939737927168608
306,0.20150976681631375,0.5980392098426819,0.6045751571655273,0.6325247678706296,0.06343732141201794,mmlu:nutrition,test,100.97422985732555
29,0.27030036881052216,0.24137930572032928,0.24137930572032928,0.6103896103896104,0.4429684178582553,mmlu:high_school_mathematics,validation,10.681240662932396
270,0.23570811527746693,0.28148147463798523,0.28518518805503845,0.5158369506239826,0.3928860918239311,mmlu:high_school_mathematics,test,77.83846503123641
11,0.38241077282212,0.4545454680919647,0.4545454680919647,0.9500000000000001,0.35281563888896594,mmlu:college_physics,validation,5.1124390829354525
102,0.38198426950211617,0.2352941334247589,0.2352941334247589,0.6231303418803419,0.41638068299667513,mmlu:college_physics,test,28.15866440348327
22,0.35463312945582653,0.40909093618392944,0.4545454680919647,0.6025641025641026,0.1448437977920879,mmlu:high_school_chemistry,validation,8.53493807464838
203,0.23890778906826904,0.403940886259079,0.43349751830101013,0.5294799435597662,0.15643721261047966,mmlu:high_school_chemistry,test,57.18036999180913
18,0.45080843567848206,0.4444444477558136,0.5,0.26875000000000004,0.23918796910179982,mmlu:virology,validation,5.404524490237236
166,0.3379125191145632,0.46987950801849365,0.46987950801849365,0.48907342657342656,0.093786416283573,mmlu:virology,test,36.102833210490644
11,0.4523282159458507,0.6363636255264282,0.5454545617103577,0.5357142857142857,0.18593583323738794,mmlu:computer_security,validation,3.911745900288224
100,0.22826966643333435,0.6399999856948853,0.6399999856948853,0.6293402777777778,0.06237970173358917,mmlu:computer_security,test,22.649956423789263
19,0.1464866587990209,0.7894737124443054,0.7894737124443054,0.7083333333333334,0.04765241397054572,mmlu:world_religions,validation,6.37849273532629
171,0.08514788851403356,0.7836257219314575,0.7719298601150513,0.6066962484872932,0.026936013099045777,mmlu:world_religions,test,35.38567630201578
43,0.2917576972828355,0.4651162624359131,0.44186046719551086,0.5010869565217391,0.19002582167470178,mmlu:high_school_macroeconomics,validation,12.309693410992622
390,0.2419572834021006,0.5307692289352417,0.5256410241127014,0.5403500435574562,0.08745666513076193,mmlu:high_school_macroeconomics,test,92.9703941270709
11,0.2831841653043573,0.4545454680919647,0.4545454680919647,0.6833333333333333,0.29056658528067847,mmlu:jurisprudence,validation,4.917153276503086
108,0.08379791428645453,0.75,0.75,0.5505258344764518,0.046742648990065944,mmlu:jurisprudence,test,25.27995254471898
11,0.39722792126915674,0.27272728085517883,0.27272728085517883,0.625,0.5176232782277195,mmlu:machine_learning,validation,5.972443420439959
112,0.43705505877733225,0.2857142984867096,0.2946428656578064,0.5201171874999999,0.48724687578422676,mmlu:machine_learning,test,37.8358517177403
22,0.44476605409925635,0.3636363744735718,0.3636363744735718,0.3482142857142857,0.3912508514794436,mmlu:college_medicine,validation,8.830123540014029
173,0.2831535918175141,0.46820807456970215,0.46820807456970215,0.5432769726247988,0.2388277053833008,mmlu:college_medicine,test,51.91389713063836
16,0.46082551777362823,0.5,0.5625,0.546875,0.10460467636585236,mmlu:electrical_engineering,validation,5.095955638214946
145,0.22342124005843855,0.5034482479095459,0.5241379141807556,0.5725837138508372,0.1191609830691897,mmlu:electrical_engineering,test,34.350510702468455
32,0.3195789000019431,0.59375,0.53125,0.5182186234817814,0.1027633436024189,mmlu:high_school_biology,validation,11.823337383568287
310,0.17259021468700902,0.6709677577018738,0.6612902879714966,0.5102752639517345,0.05343729795948148,mmlu:high_school_biology,test,90.98123642802238
21,0.22653476397196454,0.7142857313156128,0.7142857313156128,0.6833333333333332,0.07093684446244011,mmlu:high_school_government_and_politics,validation,6.719715777784586
193,0.1327874672845237,0.7927460670471191,0.787564754486084,0.5173202614379085,0.04080454240808835,mmlu:high_school_government_and_politics,test,49.60285491589457
12,0.44714824855327606,0.5,0.6666666865348816,0.6944444444444445,0.2084388037522634,mmlu:public_relations,validation,5.081407405436039
110,0.1626250435005535,0.6272727251052856,0.6181818246841431,0.6115235065394133,0.13063676411455333,mmlu:public_relations,test,26.186707723885775
22,0.11265508424152026,0.8181818723678589,0.7727273106575012,0.5208333333333334,0.18262122436003247,mmlu:sociology,validation,7.746975213289261
201,0.16373492547528665,0.7661691308021545,0.7512437701225281,0.5461453440176844,0.11573498077060455,mmlu:sociology,test,48.97934416308999
11,0.10703215273943814,0.8181818723678589,0.8181818723678589,0.3055555555555555,0.18925745920701464,mmlu:management,validation,3.690156564116478
103,0.1312992786898196,0.7281553745269775,0.6990291476249695,0.461904761904762,0.09228811449217567,mmlu:management,test,20.857585163787007
22,0.20017560097304254,0.7272727489471436,0.7272727489471436,0.38020833333333337,0.11118255420164631,mmlu:high_school_geography,validation,6.532386761158705
198,0.17760831268146784,0.7070707082748413,0.6818181872367859,0.5797413793103448,0.06927436800918196,mmlu:high_school_geography,test,46.4678492564708
27,0.34244441103052203,0.5555555820465088,0.5925925970077515,0.4,0.29385083251529265,mmlu:security_studies,validation,14.924850684124976
245,0.23526021266470148,0.6408162713050842,0.636734664440155,0.43543717429067746,0.16256622951857894,mmlu:security_studies,test,123.70745184319094
9,0.2205338610543145,0.6666666865348816,0.6666666865348816,0.5277777777777778,0.1598070926136441,mmlu:high_school_computer_science,validation,4.852082662284374
100,0.16224209606647488,0.5999999642372131,0.6100000143051147,0.6104166666666667,0.10229669988155367,mmlu:high_school_computer_science,test,38.46637720335275
11,0.26193174448880285,0.27272728085517883,0.27272728085517883,0.22916666666666666,0.386299653486772,mmlu:college_mathematics,validation,5.681738754734397
100,0.22207549244165425,0.3499999940395355,0.35999998450279236,0.4378021978021978,0.31502978980541235,mmlu:college_mathematics,test,30.707367345690727
17,0.521738374934477,0.23529411852359772,0.4117647111415863,0.7596153846153846,0.1807273766573738,mmlu:high_school_physics,validation,6.518966245464981
151,0.3349980257994292,0.33112582564353943,0.4039735198020935,0.4382178217821782,0.18561691835226604,mmlu:high_school_physics,test,45.587929248809814
11,0.07595292546532369,0.9090909361839294,0.9090909361839294,1.0,0.19663478569550946,mmlu:us_foreign_policy,validation,4.610383812338114
100,0.13912511348724363,0.7699999809265137,0.7699999809265137,0.48108413325804633,0.05950814366340641,mmlu:us_foreign_policy,test,24.417289707809687
26,0.20957786074051493,0.6153846383094788,0.6153846383094788,0.47187500000000004,0.18946271905532253,mmlu:high_school_microeconomics,validation,8.40951224975288
238,0.19670617442671992,0.5882353186607361,0.5672269463539124,0.5871355685131194,0.05077123216220313,mmlu:high_school_microeconomics,test,55.45369555428624
14,0.5245533159800939,0.0714285746216774,0.0714285746216774,0.4230769230769231,0.5645091959408352,mmlu:formal_logic,validation,5.880379419773817
126,0.33890555160386227,0.2777777910232544,0.2857142984867096,0.5240188383045526,0.3270796017041282,mmlu:formal_logic,test,39.930396041832864
25,0.1628538346290588,0.7999999523162842,0.7999999523162842,0.615,0.03568651199340823,mmlu:marketing,validation,8.335380837321281
234,0.06541628677111408,0.8162393569946289,0.8162393569946289,0.6013028126141483,0.02802643281781774,mmlu:marketing,test,54.64748886227608
23,0.2071259449357572,0.695652186870575,0.6086956858634949,0.2544642857142857,0.15216665941735974,mmlu:human_aging,validation,6.057339212857187
223,0.17858105336604096,0.6412556171417236,0.6457399129867554,0.5492569930069929,0.08932254827610578,mmlu:human_aging,test,45.219765175133944
11,0.22761628302660852,0.5454545617103577,0.5454545617103577,0.75,0.15941420468417083,mmlu:business_ethics,validation,5.750045355409384
100,0.2266611909866333,0.5399999618530273,0.550000011920929,0.5684380032206119,0.17020785689353948,mmlu:business_ethics,test,32.6708144582808
60,0.11629870285590493,0.8000000715255737,0.8000000715255737,0.5850694444444444,0.034858711560567246,mmlu:high_school_psychology,validation,20.09267831966281
545,0.1344845986147539,0.7486238479614258,0.7467889785766602,0.5205381422642049,0.02229926367418486,mmlu:high_school_psychology,test,161.13850801065564
11,0.2852583202448758,0.4545454680919647,0.4545454680919647,0.6,0.21872906793247573,mmlu:abstract_algebra,validation,3.870315322652459
100,0.16309133648872376,0.28999999165534973,0.29999998211860657,0.5711510441962118,0.3436523485183717,mmlu:abstract_algebra,test,21.475196721032262
12,0.2582124645511309,0.4166666865348816,0.5833333730697632,0.7714285714285715,0.185725395878156,mmlu:human_sexuality,validation,4.050861826166511
131,0.20436140621891458,0.6106870174407959,0.5954198241233826,0.550735294117647,0.052094412668970726,mmlu:human_sexuality,test,28.613796465098858
34,0.3621428082971012,0.5588235259056091,0.5882353186607361,0.6491228070175438,0.1823360849829281,mmlu:philosophy,validation,8.320113183930516
311,0.26314713976007564,0.6141479015350342,0.6141479015350342,0.4596640488656195,0.12877012659882428,mmlu:philosophy,test,63.74730249494314
23,0.31505882221719494,0.3478260934352875,0.43478262424468994,0.6833333333333333,0.18846144106077115,mmlu:high_school_statistics,validation,10.538587437942624
216,0.24621717742195837,0.3611111044883728,0.39814814925193787,0.4500650315867707,0.23120157806961628,mmlu:high_school_statistics,test,78.34491050057113
12,0.4958619525035222,0.3333333432674408,0.0833333358168602,0.28125,0.5173819065093994,mmlu:econometrics,validation,5.114349701907486
114,0.32211975701022566,0.31578946113586426,0.41228070855140686,0.5502136752136753,0.2146785489299841,mmlu:econometrics,test,35.851892607752234
8,0.4231206551194191,0.25,0.375,0.25,0.1695871353149414,mmlu:college_chemistry,validation,3.7285201204940677
100,0.25189707785844806,0.3499999940395355,0.41999998688697815,0.6202197802197801,0.16429792165756227,mmlu:college_chemistry,test,30.12296276539564
38,0.3022773210939608,0.44736841320991516,0.44736841320991516,0.4943977591036415,0.2741032415314725,mmlu:moral_disputes,validation,11.650149682536721
346,0.20743531005920018,0.6040462255477905,0.5953757166862488,0.5228058533859532,0.12642722977379156,mmlu:moral_disputes,test,92.27419264707714
29,0.32334206844198293,0.517241358757019,0.5517241358757019,0.7880952380952381,0.1434572770677764,mmlu:clinical_knowledge,validation,9.437420783564448
265,0.2131977405188219,0.5698113441467285,0.5547170042991638,0.5139711862437552,0.06883066802654628,mmlu:clinical_knowledge,test,62.67878123931587
22,0.21577529880133545,0.7272727489471436,0.7272727489471436,0.609375,0.04913893342018132,mmlu:high_school_us_history,validation,18.912954694591463
204,0.14957182956676854,0.7549020051956177,0.7549020051956177,0.5081168831168832,0.045614225899471936,mmlu:high_school_us_history,test,164.80838652700186
26,0.31178321288182187,0.46153849363327026,0.5384615659713745,0.5476190476190476,0.18728181490531334,mmlu:conceptual_physics,validation,6.780234191566706
235,0.3176226870810733,0.4170212745666504,0.4382978677749634,0.5828243706241621,0.20664861506604132,mmlu:conceptual_physics,test,46.803049109876156
