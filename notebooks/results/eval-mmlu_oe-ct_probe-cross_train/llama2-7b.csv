N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.1818181872367859,0.5,0.4119318181818182,mmlu:abstract_algebra,validation,2.5933378969784826
100,0.2199999988079071,0.2199999988079071,0.5,0.37375,mmlu:abstract_algebra,test,3.3118567389901727
14,0.2857142984867096,0.2857142984867096,0.5,0.3080357142857143,mmlu:anatomy,validation,0.6547770041506737
135,0.4148148000240326,0.4148148000240326,0.5,0.1789351851851852,mmlu:anatomy,test,3.75681890710257
16,0.4375,0.4375,0.5,0.15625,mmlu:astronomy,validation,0.7866275939159095
152,0.5065789222717285,0.5065789222717285,0.49333333333333335,0.08979235197368417,mmlu:astronomy,test,5.471729611046612
11,0.6363636255264282,0.6363636255264282,0.5714285714285714,0.04012784090909089,mmlu:business_ethics,validation,0.7353967989329249
100,0.30000001192092896,0.30000001192092896,0.4928571428571429,0.29624999999999996,mmlu:business_ethics,test,4.720286525087431
29,0.24137930572032928,0.24137930572032928,0.5,0.3523706896551724,mmlu:clinical_knowledge,validation,1.130052651045844
265,0.35849055647850037,0.35849055647850037,0.5052631578947369,0.2368514150943396,mmlu:clinical_knowledge,test,8.169537694891915
16,0.3125,0.3125,0.5,0.28125,mmlu:college_biology,validation,0.7666543319355696
144,0.2986111044883728,0.2986111044883728,0.5,0.2951388888888889,mmlu:college_biology,test,5.643450593110174
8,0.125,0.125,0.5,0.46875,mmlu:college_chemistry,validation,0.49055735510773957
100,0.14000000059604645,0.14000000059604645,0.5,0.45375,mmlu:college_chemistry,test,4.712396127870306
11,0.0,0.0,,0.59375,mmlu:college_computer_science,validation,1.0673153230454773
100,0.17000000178813934,0.17000000178813934,0.5,0.42374999999999996,mmlu:college_computer_science,test,8.05695872893557
11,0.0,0.0,,0.59375,mmlu:college_mathematics,validation,0.7983539521228522
100,0.1599999964237213,0.1599999964237213,0.5,0.43374999999999997,mmlu:college_mathematics,test,5.683280884986743
22,0.3636363744735718,0.3636363744735718,0.5,0.23011363636363635,mmlu:college_medicine,validation,1.051970219006762
173,0.36994218826293945,0.36994218826293945,0.5,0.2238078034682081,mmlu:college_medicine,test,10.368352417135611
11,0.27272728085517883,0.27272728085517883,0.5,0.3210227272727273,mmlu:college_physics,validation,0.7928550788201392
102,0.14705882966518402,0.14705882966518402,0.5,0.4466911764705882,mmlu:college_physics,test,5.212336970027536
11,0.7272727489471436,0.7272727489471436,0.5,0.1335227272727273,mmlu:computer_security,validation,0.6538169600535184
100,0.4300000071525574,0.4300000071525574,0.49122807017543857,0.16773437499999996,mmlu:computer_security,test,3.399536458775401
26,0.3076923191547394,0.3076923191547394,0.5,0.2860576923076923,mmlu:conceptual_physics,validation,0.9357384510803968
235,0.4127659499645233,0.4127659499645233,0.5,0.1809840425531915,mmlu:conceptual_physics,test,6.8141667898744345
12,0.0833333358168602,0.0833333358168602,0.5,0.5104166666666666,mmlu:econometrics,validation,0.8931403681635857
114,0.14912280440330505,0.15789473056793213,0.5051546391752577,0.4354783233843352,mmlu:econometrics,test,6.597800272051245
16,0.125,0.125,0.4642857142857143,0.487060546875,mmlu:electrical_engineering,validation,0.7330048689618707
145,0.1862068921327591,0.1862068921327591,0.4957627118644068,0.40910560344827585,mmlu:electrical_engineering,test,5.916590726934373
41,0.26829269528388977,0.26829269528388977,0.5,0.3254573170731707,mmlu:elementary_mathematics,validation,1.917238128837198
378,0.32275131344795227,0.32275131344795227,0.5,0.27099867724867727,mmlu:elementary_mathematics,test,15.87503949785605
14,0.5,0.5,0.4285714285714286,0.1010044642857143,mmlu:formal_logic,validation,0.8572949490044266
126,0.30158731341362,0.30158731341362,0.4943181818181818,0.2950458602299766,mmlu:formal_logic,test,6.157389017986134
10,0.30000001192092896,0.30000001192092896,0.5,0.29375,mmlu:global_facts,validation,0.6304959780536592
100,0.17000000178813934,0.17000000178813934,0.5,0.42374999999999996,mmlu:global_facts,test,3.6617328780703247
32,0.15625,0.15625,0.5,0.4375,mmlu:high_school_biology,validation,1.3541385098360479
310,0.41290321946144104,0.41290321946144104,0.5,0.1808467741935484,mmlu:high_school_biology,test,12.10248782695271
22,0.13636364042758942,0.13636364042758942,0.5,0.45738636363636365,mmlu:high_school_chemistry,validation,1.112253966042772
203,0.16748768091201782,0.16748768091201782,0.5,0.42626231527093594,mmlu:high_school_chemistry,test,9.099768467945978
9,0.2222222238779068,0.2222222238779068,0.5,0.3715277777777778,mmlu:high_school_computer_science,validation,0.8550457470119
100,0.3700000047683716,0.3700000047683716,0.5135135135135135,0.2302734375,mmlu:high_school_computer_science,test,7.184028981951997
18,0.7222222089767456,0.7222222089767456,0.5,0.1284722222222222,mmlu:high_school_european_history,validation,5.772283121943474
165,0.6727272868156433,0.6727272868156433,0.5,0.07897727272727273,mmlu:high_school_european_history,test,52.3326853280887
22,0.4545454680919647,0.4545454680919647,0.5,0.13920454545454547,mmlu:high_school_geography,validation,0.8633979251608253
198,0.3636363744735718,0.3636363744735718,0.5,0.23011363636363635,mmlu:high_school_geography,test,5.855920302215964
21,0.4285714328289032,0.4285714328289032,0.5,0.16517857142857145,mmlu:high_school_government_and_politics,validation,0.9860464001540095
193,0.48704662919044495,0.48704662919044495,0.5,0.10670336787564766,mmlu:high_school_government_and_politics,test,6.455507060978562
43,0.41860464215278625,0.41860464215278625,0.5,0.17514534883720928,mmlu:high_school_macroeconomics,validation,1.5651140979025513
390,0.34358975291252136,0.34358975291252136,0.5,0.2501602564102564,mmlu:high_school_macroeconomics,test,11.739622115856037
29,0.03448275849223137,0.03448275849223137,0.48214285714285715,0.5598060344827587,mmlu:high_school_mathematics,validation,1.677505262894556
270,0.08148147910833359,0.08148147910833359,0.5,0.5122685185185185,mmlu:high_school_mathematics,test,13.426224167924374
26,0.3076923191547394,0.3076923191547394,0.5,0.2860576923076923,mmlu:high_school_microeconomics,validation,1.065345152048394
238,0.32773110270500183,0.32773110270500183,0.5,0.2660189075630252,mmlu:high_school_microeconomics,test,7.163564646849409
17,0.23529411852359772,0.23529411852359772,0.5,0.3584558823529412,mmlu:high_school_physics,validation,1.0744476080872118
151,0.17880794405937195,0.17880794405937195,0.5,0.4149420529801324,mmlu:high_school_physics,test,7.304800674086437
60,0.5,0.5,0.5,0.09375,mmlu:high_school_psychology,validation,2.555111608002335
545,0.5064220428466797,0.5064220428466797,0.5,0.08732798165137612,mmlu:high_school_psychology,test,21.914173817029223
23,0.1304347813129425,0.1304347813129425,0.5,0.4633152173913043,mmlu:high_school_statistics,validation,1.6204804859589785
216,0.24074074625968933,0.24074074625968933,0.5,0.3530092592592593,mmlu:high_school_statistics,test,13.836377616971731
22,0.5909090638160706,0.5909090638160706,0.5,0.0028409090909090606,mmlu:high_school_us_history,validation,5.512322809081525
204,0.5980392098426819,0.5980392098426819,0.5,0.0042892156862744946,mmlu:high_school_us_history,test,49.679062962997705
26,0.5384615659713745,0.5384615659713745,0.5,0.055288461538461564,mmlu:high_school_world_history,validation,4.578741853125393
237,0.4345991611480713,0.4345991611480713,0.5097087378640777,0.16346914556962022,mmlu:high_school_world_history,test,37.86780827003531
23,0.21739129722118378,0.21739129722118378,0.5,0.37635869565217395,mmlu:human_aging,validation,0.8675884548574686
223,0.340807169675827,0.340807169675827,0.4965986394557823,0.25425658632286996,mmlu:human_aging,test,6.471626335056499
12,0.4166666567325592,0.4166666567325592,0.5,0.17708333333333331,mmlu:human_sexuality,validation,0.6168750680517405
131,0.47328245639801025,0.47328245639801025,0.5,0.12046755725190839,mmlu:human_sexuality,test,4.086235950002447
13,0.23076923191547394,0.23076923191547394,0.5,0.3629807692307692,mmlu:international_law,validation,0.6940466568339616
121,0.4876033067703247,0.4876033067703247,0.5,0.10614669421487605,mmlu:international_law,test,4.918185805901885
11,0.4545454680919647,0.4545454680919647,0.5,0.13920454545454547,mmlu:jurisprudence,validation,0.5787219698540866
108,0.37037035822868347,0.37037035822868347,0.5,0.22337962962962965,mmlu:jurisprudence,test,3.5760865171905607
18,0.4444444477558136,0.4444444477558136,0.45,0.1625434027777778,mmlu:logical_fallacies,validation,0.8881971191149205
163,0.42944785952568054,0.42944785952568054,0.5,0.16430214723926378,mmlu:logical_fallacies,test,5.792150050168857
11,0.27272728085517883,0.27272728085517883,0.5,0.3210227272727273,mmlu:machine_learning,validation,0.7517898089718074
112,0.2857142984867096,0.2857142984867096,0.5,0.3080357142857143,mmlu:machine_learning,test,5.8815991340670735
11,0.4545454680919647,0.4545454680919647,0.5,0.13920454545454547,mmlu:management,validation,0.5803492551203817
103,0.4563106894493103,0.4563106894493103,0.5,0.1374393203883495,mmlu:management,test,2.823278430150822
25,0.2800000011920929,0.2800000011920929,0.5,0.31375,mmlu:marketing,validation,1.1437074751593173
234,0.4572649598121643,0.4572649598121643,0.5,0.13648504273504275,mmlu:marketing,test,7.69249230902642
11,0.7272727489471436,0.7272727489471436,0.5,0.1335227272727273,mmlu:medical_genetics,validation,0.5066091238986701
100,0.4699999988079071,0.4699999988079071,0.5,0.12375000000000003,mmlu:medical_genetics,test,2.812856680015102
86,0.5465116500854492,0.5465116500854492,0.5106382978723404,0.05359738372093027,mmlu:miscellaneous,validation,2.591530483914539
783,0.5874840617179871,0.5874840617179871,0.49488154529546374,0.008715477330779054,mmlu:miscellaneous,test,21.79274576692842
38,0.42105263471603394,0.42105263471603394,0.5,0.17269736842105265,mmlu:moral_disputes,validation,1.5194235448725522
346,0.41040462255477905,0.41040462255477905,0.5,0.18334537572254334,mmlu:moral_disputes,test,12.201401350088418
100,0.3499999940395355,0.3499999940395355,0.5,0.24375000000000002,mmlu:moral_scenarios,validation,6.07515907404013
895,0.3173184394836426,0.3173184394836426,0.5,0.27643156424581006,mmlu:moral_scenarios,test,53.37620501220226
33,0.3636363744735718,0.3636363744735718,0.5,0.23011363636363635,mmlu:nutrition,validation,1.5791839330922812
306,0.38235294818878174,0.38235294818878174,0.5,0.21139705882352944,mmlu:nutrition,test,12.61650709505193
34,0.29411765933036804,0.29411765933036804,0.5,0.29963235294117646,mmlu:philosophy,validation,1.3060294929891825
311,0.3247588276863098,0.3247588276863098,0.504950495049505,0.27053607315112543,mmlu:philosophy,test,9.221458045067266
35,0.3142857253551483,0.3142857253551483,0.5,0.2794642857142857,mmlu:prehistory,validation,1.4942223590333015
324,0.4166666567325592,0.4166666567325592,0.5,0.17708333333333331,mmlu:prehistory,test,10.961214323993772
31,0.12903225421905518,0.12903225421905518,0.5,0.4647177419354839,mmlu:professional_accounting,validation,2.25172303407453
282,0.152482271194458,0.152482271194458,0.5,0.4412677304964539,mmlu:professional_accounting,test,19.23103274498135
170,0.3117647171020508,0.3117647171020508,0.5,0.28198529411764706,mmlu:professional_law,validation,25.833355257986113
1534,0.2777053415775299,0.2777053415775299,0.5,0.3160446544980443,mmlu:professional_law,test,236.85286195902154
31,0.4193548262119293,0.4193548262119293,0.5,0.17439516129032256,mmlu:professional_medicine,validation,3.7936825409997255
272,0.27941176295280457,0.27941176295280457,0.5,0.31433823529411764,mmlu:professional_medicine,test,33.167136353906244
69,0.3913043439388275,0.3913043439388275,0.5,0.20244565217391303,mmlu:professional_psychology,validation,3.2076238750014454
612,0.30882352590560913,0.30882352590560913,0.5,0.2849264705882353,mmlu:professional_psychology,test,25.04254149692133
12,0.4166666567325592,0.4166666567325592,0.5,0.17708333333333331,mmlu:public_relations,validation,0.6282351540867239
110,0.3181818127632141,0.3181818127632141,0.49333333333333335,0.27649147727272727,mmlu:public_relations,test,3.8032659341115505
27,0.5925925970077515,0.5925925970077515,0.5,0.0011574074074074403,mmlu:security_studies,validation,1.5943964128382504
245,0.5306122303009033,0.5306122303009033,0.5,0.06313775510204078,mmlu:security_studies,test,12.350808994146064
22,0.3181818127632141,0.3181818127632141,0.5,0.2755681818181818,mmlu:sociology,validation,0.8380311499349773
201,0.3781094551086426,0.3781094551086426,0.5,0.2156405472636816,mmlu:sociology,test,6.252935397904366
11,0.6363636255264282,0.6363636255264282,0.5,0.042613636363636354,mmlu:us_foreign_policy,validation,0.6086732640396804
100,0.5799999833106995,0.5799999833106995,0.5,0.01375000000000004,mmlu:us_foreign_policy,test,3.2738408860750496
18,0.5,0.5,0.5,0.09375,mmlu:virology,validation,0.9018713990226388
166,0.3313252925872803,0.33734938502311707,0.5045045045045045,0.25891848644578314,mmlu:virology,test,5.178855578880757
19,0.7368420958518982,0.7368420958518982,0.5,0.14309210526315785,mmlu:world_religions,validation,0.7859385958872736
171,0.5847952961921692,0.5847952961921692,0.5,0.008954678362573132,mmlu:world_religions,test,4.6018021770287305
