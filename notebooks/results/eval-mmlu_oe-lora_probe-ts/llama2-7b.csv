N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.4545454680919647,0.33333333333333337,0.4442708763209256,mmlu:abstract_algebra,validation,37.16797466389835
100,0.22999998927116394,0.41999998688697815,0.5530773574251835,0.23901651203632354,mmlu:abstract_algebra,test,275.4854170177132
14,0.2142857313156128,0.2857142984867096,0.8181818181818182,0.31892629180635723,mmlu:anatomy,validation,39.26095974445343
135,0.4296296238899231,0.5333333015441895,0.6480071652485446,0.060624043146769176,mmlu:anatomy,test,366.8296761419624
16,0.4375,0.5,0.3015873015873016,0.19030668213963509,mmlu:astronomy,validation,44.615337340161204
152,0.4868420958518982,0.5394737124443054,0.5854989604989604,0.11891748599315945,mmlu:astronomy,test,419.3638787623495
11,0.6363636255264282,0.5454545617103577,0.5357142857142857,0.3031561049548062,mmlu:business_ethics,validation,36.46595862880349
100,0.28999999165534973,0.3700000047683716,0.6597863040310831,0.36903069317340853,mmlu:business_ethics,test,276.22248653136194
29,0.24137930572032928,0.6896551847457886,0.6558441558441559,0.1130080901343247,mmlu:clinical_knowledge,validation,77.62393180280924
265,0.34716981649398804,0.5471698045730591,0.5888414174415683,0.04751355445609901,mmlu:clinical_knowledge,test,725.8853784892708
16,0.3125,0.5625,0.6727272727272727,0.21832943335175514,mmlu:college_biology,validation,43.21158929541707
144,0.3333333432674408,0.472222238779068,0.5424262152777777,0.15225434675812724,mmlu:college_biology,test,407.8058575820178
8,0.125,0.75,1.0,0.16947967559099195,mmlu:college_chemistry,validation,23.209799760952592
100,0.14000000059604645,0.6899999976158142,0.7317275747508306,0.07280276834964752,mmlu:college_chemistry,test,271.45027909986675
11,0.09090909361839294,0.4545454680919647,0.6,0.20703424648805097,mmlu:college_computer_science,validation,32.75300831720233
100,0.17000000178813934,0.5,0.45570517363571933,0.2263514471054077,mmlu:college_computer_science,test,291.66715749539435
11,0.0,0.8181818723678589,,0.1970197720961137,mmlu:college_mathematics,validation,31.34099397994578
100,0.14000000059604645,0.7599999904632568,0.7117940199335548,0.06986295938491821,mmlu:college_mathematics,test,290.7617169264704
22,0.3636363744735718,0.3636363744735718,0.39285714285714285,0.28885555267333984,mmlu:college_medicine,validation,60.5499333627522
173,0.34682080149650574,0.4797687828540802,0.5751474926253687,0.14401188957897915,mmlu:college_medicine,test,474.87851780653
11,0.27272728085517883,0.6363636255264282,0.9166666666666666,0.25109918551011523,mmlu:college_physics,validation,31.463203631341457
102,0.1666666716337204,0.686274528503418,0.7100346020761246,0.0747679103823269,mmlu:college_physics,test,280.9806403461844
11,0.4545454680919647,0.6363636255264282,0.6666666666666667,0.3601561242883855,mmlu:computer_security,validation,31.313450826331973
100,0.44999998807907104,0.5,0.603030303030303,0.14469190180301664,mmlu:computer_security,test,272.0725628528744
26,0.3461538553237915,0.6153846383094788,0.607843137254902,0.036715358495712266,mmlu:conceptual_physics,validation,68.80371912941337
235,0.4340425431728363,0.5659574270248413,0.5947589562140646,0.028513821135176,mmlu:conceptual_physics,test,624.2591692078859
12,0.0833333358168602,0.4166666865348816,0.7272727272727273,0.1706451972325643,mmlu:econometrics,validation,32.77456621453166
114,0.14912280440330505,0.4385964870452881,0.5745906610066707,0.21514412656165005,mmlu:econometrics,test,312.54679256118834
16,0.1875,0.5625,0.6923076923076923,0.2164212167263031,mmlu:electrical_engineering,validation,43.10331749729812
145,0.24137930572032928,0.6275861859321594,0.561038961038961,0.03420622143252143,mmlu:electrical_engineering,test,390.20417463965714
41,0.2195121943950653,0.6829267740249634,0.6805555555555556,0.11966799526679807,mmlu:elementary_mathematics,validation,112.60718408972025
378,0.32804232835769653,0.6058200597763062,0.5718186436372872,0.027618719629509694,mmlu:elementary_mathematics,test,1018.7377891484648
14,0.2857142984867096,0.3571428656578064,0.55,0.3396650127002171,mmlu:formal_logic,validation,38.533565228804946
126,0.2698412835597992,0.3492063581943512,0.40313299232736577,0.31594437881121556,mmlu:formal_logic,test,349.53997173532844
10,0.20000000298023224,0.4000000059604645,0.875,0.19321895837783815,mmlu:global_facts,validation,28.669722830876708
100,0.1899999976158142,0.28999999165534973,0.5685510071474984,0.3566826158761978,mmlu:global_facts,test,272.8066951688379
32,0.21875,0.375,0.5142857142857142,0.2888114359229803,mmlu:high_school_biology,validation,87.0646753218025
310,0.43225806951522827,0.5,0.5810507123473541,0.1488644224982108,mmlu:high_school_biology,test,838.4484465718269
22,0.13636364042758942,0.4545454680919647,0.5614035087719298,0.17071845856579865,mmlu:high_school_chemistry,validation,60.72325528971851
203,0.14778324961662292,0.5369458198547363,0.5767822736030829,0.10426175212625212,mmlu:high_school_chemistry,test,552.529318202287
9,0.3333333432674408,0.5555555820465088,0.5555555555555556,0.16743387116326225,mmlu:high_school_computer_science,validation,26.313765343278646
100,0.3999999761581421,0.3700000047683716,0.5241666666666667,0.2424450820684433,mmlu:high_school_computer_science,test,278.7665620278567
22,0.4545454680919647,0.5,0.5666666666666667,0.15463548356836493,mmlu:high_school_geography,validation,61.99918281659484
198,0.3737373650074005,0.4141414165496826,0.6223299912816042,0.22100889833286555,mmlu:high_school_geography,test,532.2519568279386
21,0.3333333432674408,0.2857142984867096,0.336734693877551,0.36826802151543764,mmlu:high_school_government_and_politics,validation,56.8424587957561
193,0.4404144883155823,0.46113988757133484,0.6507080610021787,0.2042099234353693,mmlu:high_school_government_and_politics,test,528.6153853554279
43,0.41860464215278625,0.4883720874786377,0.47333333333333333,0.16033104408619012,mmlu:high_school_macroeconomics,validation,140.52403844334185
390,0.3512820601463318,0.464102566242218,0.5419924410720983,0.14369522149746236,mmlu:high_school_macroeconomics,test,1046.7668313160539
29,0.06896551698446274,0.8620689511299133,0.5,0.22699419588878234,mmlu:high_school_mathematics,validation,79.9100843667984
270,0.09259258955717087,0.8629629611968994,0.672734693877551,0.19495718236322757,mmlu:high_school_mathematics,test,727.976187421009
26,0.42307692766189575,0.5769230723381042,0.6909090909090909,0.11113715630311233,mmlu:high_school_microeconomics,validation,68.78848662786186
238,0.3529411852359772,0.4831933081150055,0.5475417439703154,0.12995576432773048,mmlu:high_school_microeconomics,test,633.7867676690221
17,0.05882352963089943,0.7058823704719543,1.0,0.09641930636237653,mmlu:high_school_physics,validation,47.54088247567415
151,0.20529800653457642,0.5960264801979065,0.45981182795698927,0.024732762614622816,mmlu:high_school_physics,test,407.5347940828651
60,0.4833333492279053,0.5166667103767395,0.5839822024471635,0.1989668329556783,mmlu:high_school_psychology,validation,159.0657898504287
545,0.5064220428466797,0.5394495725631714,0.6338155271806476,0.16874918882999945,mmlu:high_school_psychology,test,1455.8133310750127
23,0.1304347813129425,0.6086956858634949,0.6666666666666666,0.0872496185095414,mmlu:high_school_statistics,validation,65.30193410255015
216,0.25,0.6342592835426331,0.5635573845450389,0.04329614617206432,mmlu:high_school_statistics,test,596.2961136288941
22,0.4545454680919647,0.4545454680919647,0.5750000000000001,0.24832592227242212,mmlu:high_school_us_history,validation,68.93466651067138
204,0.6225490570068359,0.5980392098426819,0.5102771244503528,0.09156625411089729,mmlu:high_school_us_history,test,642.8862274121493
23,0.3478260934352875,0.3913043439388275,0.4291666666666666,0.30277731107628864,mmlu:human_aging,validation,61.286992102861404
223,0.3363228738307953,0.40807175636291504,0.6267117117117117,0.29311409579264214,mmlu:human_aging,test,590.4954180046916
12,0.3333333432674408,0.4166666865348816,0.375,0.38672357300917315,mmlu:human_sexuality,validation,32.70691394805908
131,0.4656488597393036,0.48091602325439453,0.5594847775175644,0.1784623706613788,mmlu:human_sexuality,test,347.44253350421786
13,0.3076923191547394,0.38461539149284363,0.5833333333333334,0.27332465006754947,mmlu:international_law,validation,35.75109817273915
121,0.5371900796890259,0.5785123705863953,0.6074175824175825,0.12365787728758883,mmlu:international_law,test,320.4481622669846
11,0.5454545617103577,0.5454545617103577,0.4333333333333333,0.28224479068409314,mmlu:jurisprudence,validation,29.841954251751304
108,0.35185185074806213,0.3888888955116272,0.5161654135338346,0.23913624993077032,mmlu:jurisprudence,test,285.8939438443631
18,0.3888888955116272,0.3333333432674408,0.6103896103896104,0.40074171622594196,mmlu:logical_fallacies,validation,49.07277093268931
163,0.453987717628479,0.4907975196838379,0.5600516246583663,0.19960077408632615,mmlu:logical_fallacies,test,437.49612835235894
11,0.27272728085517883,0.6363636255264282,0.4583333333333333,0.1902487874031067,mmlu:machine_learning,validation,33.59640039689839
112,0.1875000149011612,0.4017857313156128,0.4437467294610152,0.2524872023080077,mmlu:machine_learning,test,303.87073047459126
11,0.4545454680919647,0.5454545617103577,0.7333333333333334,0.16921916874972256,mmlu:management,validation,30.845640681684017
103,0.4757281541824341,0.48543688654899597,0.6369992441421014,0.22792727970382545,mmlu:management,test,284.9330891817808
25,0.3199999928474426,0.3199999928474426,0.3382352941176471,0.35973408937454227,mmlu:marketing,validation,66.93307961523533
234,0.4316239655017853,0.444444477558136,0.6013548723293383,0.21862699740972275,mmlu:marketing,test,625.355892278254
11,0.6363636255264282,0.6363636255264282,0.7142857142857143,0.1648819013075395,mmlu:medical_genetics,validation,30.4135151989758
100,0.4699999988079071,0.44999998807907104,0.5130469690887194,0.20415459871292113,mmlu:medical_genetics,test,268.6726089194417
38,0.3684210479259491,0.44736841320991516,0.6547619047619047,0.14630256201091565,mmlu:moral_disputes,validation,101.88753701932728
346,0.3641618490219116,0.4942196309566498,0.6143759018759019,0.10599424608180978,mmlu:moral_disputes,test,929.3366138264537
33,0.3333333432674408,0.39393940567970276,0.5537190082644627,0.259564018610752,mmlu:nutrition,validation,89.6637731641531
306,0.3692810535430908,0.4248366057872772,0.5323948828465312,0.24831158857719568,mmlu:nutrition,test,886.7147184517235
34,0.3235294222831726,0.38235294818878174,0.6067193675889327,0.22801574889351342,mmlu:philosophy,validation,91.25065637379885
311,0.3086816668510437,0.3954983949661255,0.6241036821705426,0.2204670072368487,mmlu:philosophy,test,821.9598284512758
35,0.3142857253551483,0.5714285969734192,0.696969696969697,0.09108271258217948,mmlu:prehistory,validation,94.93552030436695
324,0.39814814925193787,0.5709876418113708,0.6418604651162791,0.043227720591757036,mmlu:prehistory,test,867.5302724651992
69,0.4637681245803833,0.4492753744125366,0.5244932432432432,0.2069294444028882,mmlu:professional_psychology,validation,183.97139712795615
612,0.3006536066532135,0.33169934153556824,0.4978540227549777,0.3214206726722468,mmlu:professional_psychology,test,1648.6019052527845
12,0.5,0.3333333432674408,0.3611111111111111,0.28652231891949975,mmlu:public_relations,validation,33.66632456704974
110,0.30909091234207153,0.3545454442501068,0.5715944272445821,0.34221032424406567,mmlu:public_relations,test,294.1726747211069
27,0.5925925970077515,0.5555555820465088,0.5284090909090908,0.09545984312340064,mmlu:security_studies,validation,72.93040369451046
245,0.518367350101471,0.5387755036354065,0.5386360603229683,0.04510677614990547,mmlu:security_studies,test,671.161707336083
22,0.4545454680919647,0.6363636255264282,0.6499999999999999,0.18397018042477692,mmlu:sociology,validation,59.24714766070247
201,0.38805970549583435,0.49751242995262146,0.6186158015426307,0.1370992897754878,mmlu:sociology,test,541.8307918589562
11,0.7272727489471436,0.8181818723678589,0.7916666666666667,0.3126029859889637,mmlu:us_foreign_policy,validation,30.712731551378965
100,0.6100000143051147,0.6299999952316284,0.6343001261034048,0.046805101037025475,mmlu:us_foreign_policy,test,272.4397973064333
18,0.5555555820465088,0.3333333432674408,0.375,0.3180418113867442,mmlu:virology,validation,49.3488335441798
166,0.33734938502311707,0.46987950801849365,0.5761363636363636,0.18706964871969567,mmlu:virology,test,442.2887110449374
19,0.7368420958518982,0.7894737124443054,0.6142857142857143,0.17987107603173508,mmlu:world_religions,validation,51.78290567174554
171,0.5906432867050171,0.6140350699424744,0.6033946251768033,0.10744177911713809,mmlu:world_religions,test,447.6581792216748
