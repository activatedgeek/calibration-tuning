N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.0,0.5454545617103577,,0.3153449676253579,mmlu:abstract_algebra,validation,26.209131188690662
100,0.3400000035762787,0.47999998927116394,0.5089126559714794,0.17056876957416536,mmlu:abstract_algebra,test,218.79521149769425
14,0.2142857313156128,0.5714285969734192,0.6363636363636362,0.17460306627409797,mmlu:anatomy,validation,10.53793153911829
135,0.40740740299224854,0.6370370388031006,0.7375,0.05899161056235988,mmlu:anatomy,test,101.88317788764834
16,0.5,0.5625,0.625,0.13437996432185173,mmlu:astronomy,validation,16.93962074816227
152,0.5,0.5855263471603394,0.6765927977839334,0.06286192724579259,mmlu:astronomy,test,161.60689145885408
11,0.4545454680919647,0.5454545617103577,0.7333333333333333,0.14873466166582971,mmlu:business_ethics,validation,11.240756945684552
100,0.3100000023841858,0.3999999761581421,0.4983637213651239,0.21303152322769164,mmlu:business_ethics,test,103.24685387685895
29,0.17241379618644714,0.7241379022598267,0.75,0.16890202514056504,mmlu:clinical_knowledge,validation,31.279070146381855
265,0.29811322689056396,0.5924528241157532,0.6579216006533279,0.03355722584814399,mmlu:clinical_knowledge,test,260.5957076959312
16,0.375,0.5,0.5666666666666667,0.2167542725801468,mmlu:college_biology,validation,26.44932084903121
144,0.3611111044883728,0.6388888955116272,0.657190635451505,0.06047711397210754,mmlu:college_biology,test,162.6638976391405
8,0.0,0.875,,0.32801833748817444,mmlu:college_chemistry,validation,9.27485323511064
100,0.1599999964237213,0.7400000095367432,0.7953869047619048,0.13116786003112796,mmlu:college_chemistry,test,114.94955752417445
11,0.3636363744735718,0.4545454680919647,0.5714285714285714,0.20477059212597934,mmlu:college_computer_science,validation,15.484945444390178
100,0.23999999463558197,0.6299999952316284,0.6557017543859649,0.0826725262403488,mmlu:college_computer_science,test,134.65019574016333
11,0.0,1.0,,0.3262904503128745,mmlu:college_mathematics,validation,29.92538809403777
100,0.10999999940395355,0.7199999690055847,0.6659856996935649,0.09358666360378261,mmlu:college_mathematics,test,188.9122419245541
22,0.3181818127632141,0.5454545617103577,0.6142857142857143,0.1419973265041005,mmlu:college_medicine,validation,25.40155551955104
173,0.4161849617958069,0.6300578117370605,0.6921754675467547,0.05573459650050695,mmlu:college_medicine,test,192.91593304276466
11,0.27272728085517883,0.7272727489471436,0.8333333333333334,0.10523250428113073,mmlu:college_physics,validation,9.61277880705893
102,0.13725490868091583,0.774509847164154,0.6477272727272727,0.13606528032059761,mmlu:college_physics,test,120.00972919911146
11,0.6363636255264282,0.5454545617103577,0.5,0.055322013118050295,mmlu:computer_security,validation,9.154179586097598
100,0.4899999797344208,0.5299999713897705,0.5906362545018007,0.09879286885261535,mmlu:computer_security,test,100.53750335611403
26,0.3461538553237915,0.6153846383094788,0.65359477124183,0.03441500663757324,mmlu:conceptual_physics,validation,25.25566977635026
235,0.46808508038520813,0.6085106134414673,0.6464727272727273,0.04659009537798296,mmlu:conceptual_physics,test,182.4459986295551
12,0.5,0.6666666865348816,0.5555555555555556,0.2892943272988001,mmlu:econometrics,validation,13.160371758043766
114,0.1666666716337204,0.6666666865348816,0.6011080332409973,0.08073036241949649,mmlu:econometrics,test,204.58644019439816
16,0.375,0.6875,0.6000000000000001,0.12766848504543307,mmlu:electrical_engineering,validation,28.552185997366905
145,0.20689654350280762,0.7931034564971924,0.6073913043478262,0.1642023337298426,mmlu:electrical_engineering,test,210.70152211003006
41,0.24390242993831635,0.8048779964447021,0.7354838709677419,0.13889908354456834,mmlu:elementary_mathematics,validation,44.40745590440929
378,0.32275131344795227,0.6878306865692139,0.6468045594262295,0.02844520299522966,mmlu:elementary_mathematics,test,403.80545359663665
14,0.1428571492433548,0.6428571939468384,0.6666666666666666,0.18926421659333365,mmlu:formal_logic,validation,18.325075443834066
126,0.2777777910232544,0.6587302088737488,0.5270015698587127,0.05979414213271366,mmlu:formal_logic,test,200.28095823898911
10,0.30000001192092896,0.699999988079071,0.42857142857142855,0.26174908876419073,mmlu:global_facts,validation,14.272288400679827
100,0.12999999523162842,0.7799999713897705,0.5114942528735632,0.16044277191162115,mmlu:global_facts,test,102.18931372277439
32,0.34375,0.625,0.6796536796536796,0.1274007335305214,mmlu:high_school_biology,validation,34.58180157840252
310,0.42258062958717346,0.6290322542190552,0.637042091347179,0.031341593880807185,mmlu:high_school_biology,test,348.4089526645839
22,0.09090909361839294,0.6818181872367859,0.725,0.24852213263511655,mmlu:high_school_chemistry,validation,30.447326889261603
203,0.1822660118341446,0.7931034564971924,0.6194236405079778,0.15933013696388656,mmlu:high_school_chemistry,test,231.1638897098601
9,0.5555555820465088,0.7777777910232544,0.8,0.1795410911242167,mmlu:high_school_computer_science,validation,13.998486120253801
100,0.44999998807907104,0.5699999928474426,0.5751515151515151,0.04783849418163301,mmlu:high_school_computer_science,test,152.1080258190632
22,0.3181818127632141,0.8181818723678589,0.8571428571428572,0.25243646448308776,mmlu:high_school_geography,validation,23.010236846283078
198,0.39898988604545593,0.6515151262283325,0.6528560791405169,0.06821543128803524,mmlu:high_school_geography,test,229.93010494485497
21,0.6190476417541504,0.761904776096344,0.7019230769230769,0.17335817927405947,mmlu:high_school_government_and_politics,validation,19.57722002454102
193,0.6010362505912781,0.6632124185562134,0.661833855799373,0.0888155751277746,mmlu:high_school_government_and_politics,test,172.02439845725894
43,0.4883720874786377,0.5581395626068115,0.6937229437229437,0.13174229444459426,mmlu:high_school_macroeconomics,validation,57.63528369367123
390,0.3692307770252228,0.6461538672447205,0.5969681571815718,0.03727683669481522,mmlu:high_school_macroeconomics,test,509.68065146915615
29,0.06896551698446274,0.8965517282485962,0.37037037037037035,0.2357349395751953,mmlu:high_school_mathematics,validation,25.80879576690495
270,0.10740740597248077,0.825925886631012,0.6972385176706253,0.18509206087500962,mmlu:high_school_mathematics,test,285.54956545494497
26,0.3076923191547394,0.692307710647583,0.7048611111111112,0.06892994275459874,mmlu:high_school_microeconomics,validation,34.303712509572506
238,0.40756306052207947,0.5966386795043945,0.6292315566279155,0.06128527061278083,mmlu:high_school_microeconomics,test,318.37613240256906
17,0.23529411852359772,0.8235294222831726,0.5769230769230769,0.16593571971444526,mmlu:high_school_physics,validation,24.160471258684993
151,0.18543046712875366,0.7947019934654236,0.47401277584204415,0.15140999784532766,mmlu:high_school_physics,test,188.47546701692045
60,0.5,0.5833333730697632,0.6522222222222223,0.01657732725143435,mmlu:high_school_psychology,validation,55.03866138495505
545,0.5100917220115662,0.6513761281967163,0.7073330099964972,0.06886760182336933,mmlu:high_school_psychology,test,550.36864714697
23,0.21739131212234497,0.739130437374115,0.6555555555555556,0.07423245906829834,mmlu:high_school_statistics,validation,63.36119029484689
216,0.25462964177131653,0.7407407760620117,0.611631846414455,0.07836874933154493,mmlu:high_school_statistics,test,620.1566351596266
22,0.7727273106575012,0.7727273106575012,0.6470588235294117,0.12861729751933704,mmlu:high_school_us_history,validation,41.61474307626486
204,0.6617647409439087,0.6911764740943909,0.7008051529790661,0.045055895751597866,mmlu:high_school_us_history,test,405.0500476360321
23,0.43478262424468994,0.5652173757553101,0.7076923076923076,0.06725903438485184,mmlu:human_aging,validation,22.574117774143815
223,0.3901345431804657,0.5201793909072876,0.5819810682893848,0.06514029144706211,mmlu:human_aging,test,231.81463184393942
12,0.3333333432674408,0.5,0.28125,0.1759886344273885,mmlu:human_sexuality,validation,20.62133607454598
131,0.5190839767456055,0.5496183037757874,0.6374883286647992,0.03826742863837089,mmlu:human_sexuality,test,153.03908649273217
13,0.5384615659713745,0.5384615659713745,0.38095238095238093,0.1846127143272987,mmlu:international_law,validation,21.233396396040916
121,0.6280991435050964,0.6859503984451294,0.5827485380116959,0.05708886128811795,mmlu:international_law,test,186.31686863675714
11,0.1818181872367859,0.4545454680919647,0.5555555555555556,0.08468358083204791,mmlu:jurisprudence,validation,9.86025826446712
108,0.4166666567325592,0.5833333134651184,0.6137566137566137,0.0249295731385549,mmlu:jurisprudence,test,102.77059044502676
18,0.6666666865348816,0.6666666865348816,0.7916666666666666,0.12861477004157174,mmlu:logical_fallacies,validation,16.602864718064666
163,0.43558281660079956,0.6012269854545593,0.6648040416411513,0.04000937317046653,mmlu:logical_fallacies,test,170.25612013041973
11,0.1818181872367859,0.6363636255264282,0.6111111111111112,0.1484143463048068,mmlu:machine_learning,validation,11.414730155840516
112,0.3035714328289032,0.5892857313156128,0.6097285067873304,0.08245160749980379,mmlu:machine_learning,test,125.24009604379535
11,0.6363636255264282,0.3636363744735718,0.42857142857142855,0.22324235330928455,mmlu:management,validation,7.957275664433837
103,0.3786407709121704,0.553398072719574,0.6955128205128205,0.05631567957331835,mmlu:management,test,93.18401768431067
25,0.19999998807907104,0.19999998807907104,0.33,0.3666699314117432,mmlu:marketing,validation,52.44782164692879
234,0.4316239655017853,0.5598291158676147,0.6969775924960916,0.03041821718215943,mmlu:marketing,test,432.21137716434896
11,0.5454545617103577,0.4545454680919647,0.5,0.0925847671248696,mmlu:medical_genetics,validation,21.686074497178197
100,0.5,0.5799999833106995,0.6684,0.01732646107673643,mmlu:medical_genetics,test,156.5696757081896
38,0.5263158082962036,0.6052631735801697,0.6111111111111112,0.03613694874863878,mmlu:moral_disputes,validation,38.8184747248888
346,0.398843914270401,0.5260115265846252,0.5917467948717949,0.039073026593709995,mmlu:moral_disputes,test,322.35807516798377
33,0.27272728085517883,0.4545454680919647,0.5555555555555556,0.13517989534320254,mmlu:nutrition,validation,38.78644046001136
306,0.45098039507865906,0.6274510025978088,0.7089156314699793,0.03791297144360012,mmlu:nutrition,test,371.7722472921014
34,0.2647058963775635,0.7352941036224365,0.7955555555555555,0.16233770987566778,mmlu:philosophy,validation,22.46192497946322
311,0.34726688265800476,0.6655948162078857,0.6828133552271485,0.10388521366180715,mmlu:philosophy,test,231.16411035135388
35,0.37142857909202576,0.6857143044471741,0.7972027972027972,0.11471045017242429,mmlu:prehistory,validation,151.62200001068413
324,0.46296295523643494,0.5833333134651184,0.6486590038314176,0.023867303206596826,mmlu:prehistory,test,321.07291860692203
69,0.36231884360313416,0.6376811861991882,0.6586363636363637,0.06448387926903323,mmlu:professional_psychology,validation,151.30511320754886
612,0.33986929059028625,0.6405228972434998,0.6415056169078446,0.06355055290109972,mmlu:professional_psychology,test,1440.0706361047924
12,0.25,0.3333333432674408,0.46296296296296297,0.2711750070254008,mmlu:public_relations,validation,9.268581103533506
110,0.3181818127632141,0.4272727072238922,0.643047619047619,0.18638146682219076,mmlu:public_relations,test,81.6788840573281
27,0.5555555820465088,0.5555555820465088,0.6083333333333334,0.11031018583862867,mmlu:security_studies,validation,41.63960004411638
245,0.6734693646430969,0.6979591250419617,0.7000757575757577,0.06859127112797332,mmlu:security_studies,test,428.6507936436683
22,0.3636363744735718,0.3181818127632141,0.3303571428571429,0.2818542285399003,mmlu:sociology,validation,20.28261865489185
201,0.43283581733703613,0.5024875402450562,0.6692881629360758,0.1041429413491814,mmlu:sociology,test,183.71831902302802
11,0.6363636255264282,0.5454545617103577,0.5357142857142857,0.14612646536393603,mmlu:us_foreign_policy,validation,10.834415217861533
100,0.6299999952316284,0.7199999690055847,0.6662376662376661,0.13148598670959474,mmlu:us_foreign_policy,test,104.16254251636565
18,0.5555555820465088,0.4444444477558136,0.38749999999999996,0.19361295964982775,mmlu:virology,validation,19.362897528335452
166,0.34337347745895386,0.626505970954895,0.6444551746338323,0.04830500016729516,mmlu:virology,test,178.88780245743692
19,0.6315789222717285,0.8421052694320679,0.8452380952380952,0.21709051885102923,mmlu:world_religions,validation,14.594656256958842
171,0.5964912176132202,0.6491228342056274,0.7029695936345552,0.07021725108051857,mmlu:world_religions,test,128.0866982806474
