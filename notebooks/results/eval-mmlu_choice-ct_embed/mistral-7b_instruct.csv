N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.7651939337903803,0.09090909361839294,0.09090909361839294,0.4,0.5312499783255837,mmlu:abstract_algebra,validation,6.91673252498731
100,0.39509160012006767,0.3100000023841858,0.3100000023841858,0.4894810659186536,0.32253906250000003,mmlu:abstract_algebra,test,7.544445079984143
14,0.4076835555689675,0.5714285969734192,0.5714285969734192,0.5833333333333334,0.0694754379136222,mmlu:anatomy,validation,1.5732451069634408
135,0.2923519690831502,0.6000000238418579,0.6000000238418579,0.45484682213077277,0.03851275841395063,mmlu:anatomy,test,10.19255614420399
16,0.3448701724410057,0.5625,0.5625,0.5,0.22265625,mmlu:astronomy,validation,1.8004236030392349
152,0.2530610722146536,0.6513158082962036,0.6513158082962036,0.5,0.13384046052631582,mmlu:astronomy,test,14.60231802915223
11,0.3004397858272899,0.7272727489471436,0.7272727489471436,0.5,0.10227272727272729,mmlu:business_ethics,validation,1.4040342438966036
100,0.3035771632194519,0.5600000023841858,0.5600000023841858,0.5,0.06499999999999995,mmlu:business_ethics,test,9.77776466193609
29,0.286518938582519,0.6206896305084229,0.6206896305084229,0.31060606060606066,0.027747844827586188,mmlu:clinical_knowledge,validation,2.652097722981125
265,0.213300414355296,0.6905660629272461,0.6905660629272461,0.5191923230707717,0.043646787247567764,mmlu:clinical_knowledge,test,21.5657454370521
16,0.2834133394062519,0.6875,0.6875,0.7545454545454545,0.059814438223838806,mmlu:college_biology,validation,1.723198430147022
144,0.2285563037213352,0.7291666865348816,0.7291666865348816,0.5067155067155067,0.032714850372738295,mmlu:college_biology,test,12.80756834289059
8,0.40875697135925293,0.5,0.5,1.0,0.14306640625,mmlu:college_chemistry,validation,1.1206516879610717
100,0.33300114810466763,0.4699999988079071,0.4699999988079071,0.5778803693295865,0.17214843511581424,mmlu:college_chemistry,test,9.73362598894164
11,0.39023282582109625,0.5454545617103577,0.5454545617103577,0.5,0.040482954545454586,mmlu:college_computer_science,validation,1.7668614371214062
100,0.2289531344175339,0.5199999809265137,0.5199999809265137,0.5,0.06593749999999998,mmlu:college_computer_science,test,12.42725764401257
11,0.37815855849872937,0.5454545617103577,0.5454545617103577,0.5,0.12251420454545459,mmlu:college_mathematics,validation,1.629927635891363
100,0.36705657660961155,0.3100000023841858,0.3100000023841858,0.5,0.35796875,mmlu:college_mathematics,test,9.900777064962313
22,0.29218705133958295,0.6363636255264282,0.6363636255264282,0.6607142857142857,0.07421873103488578,mmlu:college_medicine,validation,2.380612703040242
173,0.3433191684973722,0.5722543597221375,0.5722543597221375,0.6046956046956047,0.1438313036984791,mmlu:college_medicine,test,19.60335884988308
11,0.4926265640692278,0.4545454680919647,0.4545454680919647,0.45,0.1974431709809737,mmlu:college_physics,validation,1.3312931880354881
102,0.4072932612662222,0.4117647111415863,0.4117647111415863,0.6128968253968254,0.24479163920178135,mmlu:college_physics,test,9.12030685110949
11,0.318847580389543,0.6363636255264282,0.6363636255264282,0.75,0.02130680192600598,mmlu:computer_security,validation,1.3256850650068372
100,0.2041048324108124,0.7200000286102295,0.7200000286102295,0.5652281746031745,0.08496095955371856,mmlu:computer_security,test,8.357875128975138
26,0.3283676367539626,0.5,0.5,0.7958579881656805,0.16015625,mmlu:conceptual_physics,validation,2.2564051090739667
235,0.33540841937065125,0.5063830018043518,0.5063830018043518,0.5905172413793103,0.15754651820406002,mmlu:conceptual_physics,test,16.502163308206946
12,0.24004896233479184,0.6666666865348816,0.6666666865348816,0.5,0.21614583333333337,mmlu:econometrics,validation,1.642396125011146
114,0.4409078179221404,0.4035087823867798,0.4035087823867798,0.5,0.47930372807017546,mmlu:econometrics,test,11.942658059997484
16,0.15577726252377033,0.6875,0.6875,0.5363636363636364,0.08691406249999997,mmlu:electrical_engineering,validation,1.5544317190069705
145,0.2902860244800305,0.565517246723175,0.5586206912994385,0.6214672861014325,0.05153556075589412,mmlu:electrical_engineering,test,11.943145910976455
41,0.5717821971672338,0.31707316637039185,0.3414634168148041,0.6030219780219781,0.2154154196018126,mmlu:elementary_mathematics,validation,4.270088930148631
378,0.4266128003124207,0.38359788060188293,0.41798943281173706,0.5273938138227023,0.1454716473029404,mmlu:elementary_mathematics,test,34.66922756796703
14,0.5329604425600597,0.3571428656578064,0.3571428656578064,0.5,0.34207589285714285,mmlu:formal_logic,validation,1.7464117219205946
126,0.4297262392346821,0.3888888955116272,0.3888888955116272,0.5,0.3103298611111111,mmlu:formal_logic,test,13.072355540003628
10,0.6365507602691651,0.20000000298023224,0.20000000298023224,0.75,0.520703125,mmlu:global_facts,validation,1.1927727251313627
100,0.4803885504603386,0.3499999940395355,0.36000001430511475,0.44769965277777773,0.3629296875,mmlu:global_facts,test,7.923766654916108
32,0.21827862970530984,0.6875,0.6875,0.4659090909090909,0.04992675967514519,mmlu:high_school_biology,validation,3.0659398220013827
310,0.18952634373018823,0.7354838848114014,0.7354838848114014,0.5379492939666238,0.03189264497449321,mmlu:high_school_biology,test,28.498654338996857
22,0.3372880667448044,0.5454545617103577,0.5454545617103577,0.49583333333333335,0.1115056601437655,mmlu:high_school_chemistry,validation,2.3415890210308135
203,0.323617057847272,0.5123152732849121,0.5123152732849121,0.6048465423465423,0.14762931005120866,mmlu:high_school_chemistry,test,18.455588011071086
9,0.29119981659783256,0.6666666865348816,0.6666666865348816,0.6666666666666667,0.006944457689921024,mmlu:high_school_computer_science,validation,1.5442487609107047
100,0.2516631653904915,0.6299999952316284,0.6299999952316284,0.5,0.030156249999999996,mmlu:high_school_computer_science,test,13.740431454963982
18,0.11746903922822742,0.8888888955116272,0.8888888955116272,0.5,0.18576388888888884,mmlu:high_school_european_history,validation,6.937104142969474
165,0.2527069671587511,0.7090908885002136,0.7090908885002136,0.5,0.005965909090909105,mmlu:high_school_european_history,test,60.42435035202652
22,0.1021412732926282,0.8636363744735718,0.8636363744735718,0.4298245614035088,0.20188211310993542,mmlu:high_school_geography,validation,1.8949967350345105
198,0.16774489565028086,0.7626262903213501,0.7626262903213501,0.5249401155417782,0.097912713433757,mmlu:high_school_geography,test,15.397159197134897
21,0.19273330484117784,0.761904776096344,0.761904776096344,0.5625,0.10770087015061147,mmlu:high_school_government_and_politics,validation,2.0373119229916483
193,0.12483864281461651,0.8341968655586243,0.8341968655586243,0.5643439440993789,0.18312823834196895,mmlu:high_school_government_and_politics,test,16.55867691198364
43,0.22968695468680805,0.6511628031730652,0.6511628031730652,0.41428571428571426,0.035792173341263216,mmlu:high_school_macroeconomics,validation,3.659555305959657
390,0.3164756006155259,0.5743589997291565,0.5743589997291565,0.515867039586919,0.0931290142047099,mmlu:high_school_macroeconomics,test,29.711320501053706
29,0.3609265150695012,0.3448275923728943,0.6551724076271057,0.3394736842105263,0.13591054390216697,mmlu:high_school_mathematics,validation,2.9321369868703187
270,0.3410188412224805,0.32592591643333435,0.6666666865348816,0.45501373626373626,0.08119213316175673,mmlu:high_school_mathematics,test,24.077364590018988
26,0.2619537722605925,0.6538461446762085,0.6538461446762085,0.4673202614379085,0.024639418491950393,mmlu:high_school_microeconomics,validation,2.485592549899593
238,0.2473950173173632,0.6638655662536621,0.6638655662536621,0.5620253164556962,0.0308232765738704,mmlu:high_school_microeconomics,test,18.857682544970885
17,0.6700863031780019,0.1764705926179886,0.1764705926179886,0.4285714285714286,0.5105698564473321,mmlu:high_school_physics,validation,2.0719081789720803
151,0.4720081732367838,0.3245033025741577,0.3245033025741577,0.5392156862745098,0.3603838828225799,mmlu:high_school_physics,test,14.69663715781644
60,0.14689167439937595,0.8666666746139526,0.8666666746139526,0.6730769230769231,0.20709633032480879,mmlu:high_school_psychology,validation,5.593313251854852
545,0.15268221434650078,0.7963302731513977,0.7963302731513977,0.5610806659193756,0.13619549985325663,mmlu:high_school_psychology,test,48.55456030508503
23,0.3026763537655706,0.52173912525177,0.52173912525177,0.5,0.2009171195652174,mmlu:high_school_statistics,validation,2.9910805001854897
216,0.3601632332084356,0.46296295523643494,0.46296295523643494,0.5,0.25969328703703703,mmlu:high_school_statistics,test,26.463950236095116
22,0.20964317972009835,0.7727272510528564,0.7727272510528564,0.5,0.028053977272727293,mmlu:high_school_us_history,validation,6.650749247986823
204,0.17125022572045231,0.7647058963775635,0.7647058963775635,0.5,0.036075367647058876,mmlu:high_school_us_history,test,59.22751994500868
26,0.27686918698824364,0.7307692170143127,0.7307692170143127,0.5,0.027644230769230727,mmlu:high_school_world_history,validation,5.924499294953421
237,0.2256790781825907,0.746835470199585,0.746835470199585,0.5,0.04371044303797467,mmlu:high_school_world_history,test,48.26920189987868
23,0.28481880478236987,0.739130437374115,0.739130437374115,0.3137254901960784,0.13620922876440958,mmlu:human_aging,validation,1.912701906170696
223,0.27517610227045985,0.6412556171417236,0.6412556171417236,0.49960664335664334,0.02033704813285793,mmlu:human_aging,test,15.584661691915244
12,0.40173492829004925,0.5,0.5,0.5000000000000001,0.1845703125,mmlu:human_sexuality,validation,1.2601931020617485
131,0.18868022099251056,0.6870229244232178,0.6870229244232178,0.4892953929539295,0.008736880680986953,mmlu:human_sexuality,test,10.050840923096985
13,0.04448619714150062,1.0,1.0,,0.2890625,mmlu:international_law,validation,1.880895181093365
121,0.19004106078266111,0.7603305578231812,0.7603305578231812,0.5,0.049393078512396715,mmlu:international_law,test,12.604897669982165
11,0.4031985754316503,0.5454545617103577,0.5454545617103577,0.30000000000000004,0.2361505790190263,mmlu:jurisprudence,validation,1.2582485689781606
108,0.1255185471640693,0.7777777910232544,0.7777777910232544,0.5438988095238095,0.06890193290180625,mmlu:jurisprudence,test,9.134773490019143
18,0.2275563942061531,0.7222222089767456,0.7222222089767456,0.2615384615384615,0.20290798611111113,mmlu:logical_fallacies,validation,1.969449516152963
163,0.20817567856033886,0.699386477470398,0.699386477470398,0.5245255997135696,0.08723161118162187,mmlu:logical_fallacies,test,14.090209748130292
11,0.42730009013956244,0.3636363744735718,0.3636363744735718,0.5,0.39808238636363635,mmlu:machine_learning,validation,1.6463753669522703
112,0.4067602655185121,0.4285714328289032,0.4285714328289032,0.5,0.33314732142857145,mmlu:machine_learning,test,12.523308578878641
11,0.08229747143658728,0.9090909361839294,0.9090909361839294,0.6,0.24360797080126673,mmlu:management,validation,1.2396727800369263
103,0.20908768894602953,0.7475728392601013,0.7475728392601013,0.42357642357642356,0.10235894015691813,mmlu:management,test,7.3652163268998265
25,0.10008924722671511,0.8399999737739563,0.8399999737739563,0.494047619047619,0.17062500000000003,mmlu:marketing,validation,2.721683637937531
234,0.09087320168813068,0.8717948794364929,0.8717948794364929,0.591830065359477,0.20285791999254474,mmlu:marketing,test,19.54428518516943
11,0.048692486502907494,0.9090909361839294,0.9090909361839294,1.0,0.2084517153826627,mmlu:medical_genetics,validation,1.415944165084511
100,0.2749819791316986,0.6499999761581421,0.6499999761581421,0.6736263736263737,0.09644531011581418,mmlu:medical_genetics,test,8.144356708042324
86,0.1800074376339136,0.7325581312179565,0.7325581312179565,0.6853002070393376,0.05282521109248312,mmlu:miscellaneous,validation,6.007800398860127
783,0.1513898644791405,0.7777777910232544,0.7790549397468567,0.5134653652989671,0.09641402906537208,mmlu:miscellaneous,test,53.14287813496776
38,0.3892449532684527,0.5,0.5,0.3171745152354571,0.25113077226438024,mmlu:moral_disputes,validation,3.6180705700535327
346,0.20764597035901394,0.6965317726135254,0.6965317726135254,0.5079628531910689,0.008422138718511326,mmlu:moral_disputes,test,29.73019034205936
100,0.46282217860221864,0.3700000047683716,0.3700000047683716,0.5,0.38390625,mmlu:moral_scenarios,validation,10.598367229104042
895,0.518438325048159,0.31955307722091675,0.31955307722091675,0.5,0.4343531773743017,mmlu:moral_scenarios,test,88.75954511389136
33,0.2051064877799063,0.7272727489471436,0.7272727489471436,0.4791666666666667,0.03989110209725122,mmlu:nutrition,validation,3.799875484080985
306,0.2176828994080911,0.6830065250396729,0.6830065250396729,0.5,0.004493464052287566,mmlu:nutrition,test,30.288728944957256
34,0.24459529974881342,0.7058823704719543,0.7058823704719543,0.49374999999999997,0.07950368172982161,mmlu:philosophy,validation,3.000137535156682
311,0.2292080609744768,0.6881029009819031,0.6881029009819031,0.49913286443780713,0.03406351747236837,mmlu:philosophy,test,22.416323739103973
35,0.28287406734057835,0.6285714507102966,0.6285714507102966,0.5716783216783217,0.10479910714285715,mmlu:prehistory,validation,3.6457451249007136
324,0.21529917106216334,0.6975308656692505,0.6975308656692505,0.4823234603575943,0.04345099131266278,mmlu:prehistory,test,30.038660545134917
31,0.35496044543481636,0.4838709533214569,0.4838709533214569,0.5,0.1919102822580645,mmlu:professional_accounting,validation,4.016610840102658
282,0.3976029378513918,0.45035460591316223,0.45035460591316223,0.5,0.225426640070922,mmlu:professional_accounting,test,30.995353322010487
170,0.38037324495175306,0.48235294222831726,0.48235294222831726,0.5,0.2051470588235294,mmlu:professional_law,validation,37.97219601389952
1534,0.4171539951295554,0.4302477240562439,0.4302477240562439,0.5,0.2572522816166884,mmlu:professional_law,test,343.6643637549132
31,0.3667847168061041,0.6129032373428345,0.6129032373428345,0.5,0.10194052419354838,mmlu:professional_medicine,validation,5.318906477885321
272,0.3293657328056939,0.5845588445663452,0.5845588445663452,0.5,0.1302849264705882,mmlu:professional_medicine,test,44.46374133811332
69,0.23699703078339063,0.695652186870575,0.695652186870575,0.5,0.007472826086956541,mmlu:professional_psychology,validation,7.125416797818616
612,0.2625559676024649,0.6372548937797546,0.6388888955116272,0.5,0.06423611111111116,mmlu:professional_psychology,test,59.5625763759017
12,0.26998764276504517,0.5833333134651184,0.5833333134651184,0.49999999999999994,0.22884113093217218,mmlu:public_relations,validation,1.5181549380067736
110,0.2200350776314735,0.699999988079071,0.699999988079071,0.5730027548209367,0.05806108171289623,mmlu:public_relations,test,9.136613465845585
27,0.32721194073005955,0.6296296119689941,0.6296296119689941,0.5,0.12037037037037035,mmlu:security_studies,validation,4.903726291144267
245,0.21284481676257383,0.7061224579811096,0.7061224579811096,0.5,0.043877551020408134,mmlu:security_studies,test,40.94487293693237
22,0.09881945631720802,0.9090909361839294,0.9090909361839294,0.41250000000000003,0.2283380681818182,mmlu:sociology,validation,2.186473442008719
201,0.15761577890286993,0.8159204125404358,0.8159204125404358,0.6237640079103494,0.13603857263403746,mmlu:sociology,test,16.54944523004815
11,0.09602137045426799,0.9090909361839294,0.9090909361839294,0.3,0.1654829653826627,mmlu:us_foreign_policy,validation,1.329271872062236
100,0.14466072827577592,0.8399999737739563,0.8399999737739563,0.7139136904761905,0.1008593720197678,mmlu:us_foreign_policy,test,8.288691449910402
18,0.30292011300722754,0.6111111044883728,0.6111111044883728,0.525974025974026,0.0759548677338494,mmlu:virology,validation,1.9949326030910015
166,0.4107061060796301,0.4879518151283264,0.4939759075641632,0.4938298490127758,0.19262989709176215,mmlu:virology,test,12.60792033886537
19,0.16149032429644933,0.8421052694320679,0.8421052694320679,0.5416666666666667,0.19531249372582682,mmlu:world_religions,validation,1.6392969721928239
171,0.14589811504235745,0.8304093480110168,0.8304093480110168,0.5139630888780962,0.18000733503821303,mmlu:world_religions,test,10.828718823147938
