N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1974574490026994,0.3636363744735718,0.5454545617103577,0.17857142857142858,0.008522732691331303,mmlu:abstract_algebra,validation,5.419309977994999
100,0.15133172899484634,0.30000001192092896,0.550000011920929,0.4392857142857143,0.021171855926513716,mmlu:abstract_algebra,test,9.486740153006394
14,0.28083460032939916,0.5714285969734192,0.3571428656578064,0.34375,0.17215401785714285,mmlu:anatomy,validation,1.5361630849947687
135,0.18391638354018883,0.5185185074806213,0.45185184478759766,0.43131868131868134,0.07080437342325849,mmlu:anatomy,test,13.403790873009712
16,0.11572423949837685,0.625,0.625,0.5,0.0234375,mmlu:astronomy,validation,2.377627872003359
152,0.2484234453816163,0.5526315569877625,0.5526315569877625,0.5,0.048930921052631526,mmlu:astronomy,test,21.5536660610087
11,0.22676623409444638,0.5454545617103577,0.5454545617103577,0.5,0.018110795454545414,mmlu:business_ethics,validation,1.82442127399554
100,0.23358124196529387,0.5400000214576721,0.5400000214576721,0.5,0.012656250000000036,mmlu:business_ethics,test,13.977019958998426
29,0.29384357764803126,0.517241358757019,0.4137931168079376,0.3142857142857143,0.1109914019190032,mmlu:clinical_knowledge,validation,3.280020815000171
265,0.21524647384319667,0.5660377144813538,0.498113214969635,0.5622898550724639,0.02905363586713683,mmlu:clinical_knowledge,test,29.021085210013553
16,0.2030270304530859,0.5625,0.625,0.6190476190476191,0.0507812537252903,mmlu:college_biology,validation,2.1391343379946193
144,0.2009299904521969,0.5763888955116272,0.5763888955116272,0.5380209362038317,0.013373465173774296,mmlu:college_biology,test,17.981678491996718
8,0.5081976652145386,0.125,0.875,1.0,0.34423828125,mmlu:college_chemistry,validation,1.2770210050075548
100,0.2300338837504387,0.3700000047683716,0.6100000143051147,0.5993135993135994,0.08609376907348631,mmlu:college_chemistry,test,13.498983922996558
11,0.3500310236757452,0.5454545617103577,0.4545454680919647,0.5,0.10404829545454547,mmlu:college_computer_science,validation,2.1960469620098593
100,0.13046191811561583,0.5299999713897705,0.4699999988079071,0.5,0.08859375000000003,mmlu:college_computer_science,test,18.027193490997888
11,0.25505628910931677,0.27272728085517883,0.7272727489471436,0.5,0.1921164772727273,mmlu:college_mathematics,validation,1.7934068650065456
100,0.2144278207421303,0.3499999940395355,0.6499999761581421,0.5,0.11484375000000002,mmlu:college_mathematics,test,13.603839146002429
22,0.45070950416001404,0.3636363744735718,0.3636363744735718,0.7946428571428571,0.23259943452748386,mmlu:college_medicine,validation,3.033515382994665
173,0.28988235878806584,0.4624277353286743,0.4624277353286743,0.5788978494623656,0.1325867120930225,mmlu:college_medicine,test,28.09739395500219
11,0.35103211348707025,0.5454545617103577,0.5454545617103577,0.7166666666666667,0.0007102326913313028,mmlu:college_physics,validation,1.5619683060067473
102,0.37260022467257936,0.2450980395078659,0.7352941036224365,0.6706493506493507,0.17191331877427943,mmlu:college_physics,test,12.21832946500217
11,0.45593208887360315,0.6363636255264282,0.3636363744735718,0.2857142857142857,0.15802557360042224,mmlu:computer_security,validation,1.6357921210001223
100,0.2413292744755745,0.6399999856948853,0.38999998569488525,0.537326388888889,0.1373047089576721,mmlu:computer_security,test,10.747862338001141
26,0.3352957837856733,0.4615384638309479,0.6538461446762085,0.7738095238095237,0.1400240155366751,mmlu:conceptual_physics,validation,2.533759022000595
235,0.32360163495895716,0.40851062536239624,0.5957446694374084,0.6013189448441247,0.07716090628441341,mmlu:conceptual_physics,test,20.035874414999853
12,0.4949806133906046,0.3333333432674408,0.3333333432674408,0.5,0.3971354166666667,mmlu:econometrics,validation,1.9518773479940137
114,0.30560289924604855,0.31578946113586426,0.31578946113586426,0.5,0.4146792763157895,mmlu:econometrics,test,16.607347115001176
16,0.45588679052889347,0.5,0.5,0.40625,0.046875007450580604,mmlu:electrical_engineering,validation,1.9693412350025028
145,0.23437489312270593,0.48965516686439514,0.5586206912994385,0.5913589645984012,0.02653556034482761,mmlu:electrical_engineering,test,15.862813173996983
41,0.2608854894231005,0.4146341383457184,0.5853658318519592,0.6348039215686274,0.09089177992285756,mmlu:elementary_mathematics,validation,5.585537835999276
378,0.30925155088068945,0.33068782091140747,0.6693121790885925,0.47116205533596833,0.0071717844438300565,mmlu:elementary_mathematics,test,48.39013636900927
14,0.5275802676166808,0.0714285746216774,0.0714285746216774,0.5,0.4481026785714286,mmlu:formal_logic,validation,2.1544828159967437
126,0.3190843548093523,0.2936508059501648,0.2936508059501648,0.5,0.22588045634920634,mmlu:formal_logic,test,18.49381029899814
10,0.4928306341171265,0.30000001192092896,0.30000001192092896,0.6190476190476191,0.25859375,mmlu:global_facts,validation,1.3885756689996924
100,0.3210132357478142,0.30000001192092896,0.30000001192092896,0.46595238095238095,0.2670702868700028,mmlu:global_facts,test,11.156154262993368
32,0.2951065404340625,0.5625,0.5625,0.5734126984126984,0.1324462890625,mmlu:high_school_biology,validation,4.251706441005808
310,0.1685357293775005,0.6741935610771179,0.6741935610771179,0.5317873892652423,0.06880039399670021,mmlu:high_school_biology,test,39.89951086699148
22,0.3267563784664328,0.40909090638160706,0.5909090638160706,0.7008547008547008,0.04456675052642818,mmlu:high_school_chemistry,validation,2.977876827993896
203,0.23822169732577697,0.4088670015335083,0.6059113144874573,0.5823293172690763,0.04046719796551862,mmlu:high_school_chemistry,test,25.325268816988682
9,0.22142142719692648,0.6666666865348816,0.3333333432674408,0.5,0.16666666666666669,mmlu:high_school_computer_science,validation,2.0871166360011557
100,0.1494222471117973,0.6000000238418579,0.4000000059604645,0.5,0.09999999999999998,mmlu:high_school_computer_science,test,20.174945132996072
18,0.1720835847987069,0.8333333134651184,0.8333333134651184,0.5,0.22786458333333337,mmlu:high_school_european_history,validation,11.135811240004841
165,0.21913791316928286,0.6848484873771667,0.6848484873771667,0.5,0.07937973484848482,mmlu:high_school_european_history,test,100.09909277300176
22,0.15659447962587528,0.7272727489471436,0.6818181872367859,0.47916666666666674,0.11328124458139588,mmlu:high_school_geography,validation,2.364925811998546
198,0.1713440926990124,0.7121211886405945,0.6969696879386902,0.5520094562647755,0.12427001739993236,mmlu:high_school_geography,test,20.15682828699937
21,0.23234996483439488,0.7142857313156128,0.7142857313156128,0.5166666666666666,0.16331847508748365,mmlu:high_school_government_and_politics,validation,2.7329869120003423
193,0.1403555290995484,0.7927461266517639,0.7927461266517639,0.4759803921568627,0.24356381819038198,mmlu:high_school_government_and_politics,test,22.671176913994714
43,0.3187217435171438,0.4651162922382355,0.4883720874786377,0.4934782608695652,0.11119184105895288,mmlu:high_school_macroeconomics,validation,4.654593441999168
390,0.23806955034916216,0.5307692289352417,0.5333333611488342,0.5153507035189145,0.06627605007244987,mmlu:high_school_macroeconomics,test,40.92068012300297
29,0.2368637878319313,0.27586206793785095,0.7241379022598267,0.5922619047619048,0.030037705240578503,mmlu:high_school_mathematics,validation,3.8159306140005356
270,0.23808817863464354,0.28148147463798523,0.7185184955596924,0.4727346717308736,0.04191263892032477,mmlu:high_school_mathematics,test,33.35057183599565
26,0.2125687048985408,0.6153846383094788,0.6153846383094788,0.48125,0.1356670627227196,mmlu:high_school_microeconomics,validation,2.937425048003206
238,0.21300476626688697,0.5798319578170776,0.5798319578170776,0.5777173913043476,0.026637999951338552,mmlu:high_school_microeconomics,test,25.386395175999496
17,0.4743419324650484,0.29411765933036804,0.3529411852359772,0.7166666666666667,0.16130516809575696,mmlu:high_school_physics,validation,2.588039142996422
151,0.3228851777828292,0.34437087178230286,0.3907284736633301,0.4485236985236985,0.12867343109964535,mmlu:high_school_physics,test,20.408213272996363
60,0.12056558529535932,0.800000011920929,0.46666666865348816,0.4878472222222222,0.04667970736821492,mmlu:high_school_psychology,validation,7.760821711010067
545,0.1326619252152399,0.7486238479614258,0.46422019600868225,0.5250733505080865,0.04972044885705368,mmlu:high_school_psychology,test,69.92034060398873
23,0.31458042497220257,0.3478260934352875,0.3478260934352875,0.5,0.23029891304347827,mmlu:high_school_statistics,validation,4.239831933999085
216,0.24465402105340253,0.3611111044883728,0.3611111044883728,0.5,0.2170138888888889,mmlu:high_school_statistics,test,39.04973642199184
22,0.23554935374043207,0.7272727489471436,0.7272727489471436,0.5,0.09836647727272729,mmlu:high_school_us_history,validation,10.519868897012202
204,0.13857290660049398,0.7401960492134094,0.7401960492134094,0.5,0.11128982843137258,mmlu:high_school_us_history,test,95.82512832200155
26,0.2755839412028973,0.6153846383094788,0.6153846383094788,0.5,0.05288461538461542,mmlu:high_school_world_history,validation,9.19288108299952
237,0.14447074443227628,0.7383966445922852,0.7383966445922852,0.5,0.17589662447257381,mmlu:high_school_world_history,test,76.93532603100175
23,0.23390976242397143,0.695652186870575,0.3478260934352875,0.4508928571428571,0.1808763509211333,mmlu:human_aging,validation,2.202480776992161
223,0.18573621262883927,0.6322869658470154,0.48430493474006653,0.5305742951046531,0.044983180381792,mmlu:human_aging,test,19.439374596011476
12,0.2759020452698072,0.4166666567325592,0.5833333134651184,0.7428571428571428,0.06477864583333337,mmlu:human_sexuality,validation,1.3542852880054852
131,0.20084000771282284,0.6183205842971802,0.572519063949585,0.7096296296296295,0.04454912757145535,mmlu:human_sexuality,test,12.906782777004992
13,0.09948286184897794,0.8461538553237915,0.1538461595773697,0.5,0.36959134615384615,mmlu:international_law,validation,2.1598084370052675
121,0.15452220912807246,0.7438016533851624,0.25619834661483765,0.5,0.267239152892562,mmlu:international_law,test,17.904440165992128
11,0.28702737526460126,0.4545454680919647,0.3636363744735718,0.31666666666666665,0.21519886363636362,mmlu:jurisprudence,validation,1.3827851320093032
108,0.07802043137726959,0.75,0.7407407164573669,0.46090534979423875,0.1535373076244637,mmlu:jurisprudence,test,11.543254723990685
18,0.24995947215292189,0.7222222089767456,0.7222222089767456,0.6230769230769231,0.14127606484625077,mmlu:logical_fallacies,validation,2.356186817996786
163,0.19532882527339684,0.6809815764427185,0.6809815764427185,0.5700796950796951,0.10254508256912227,mmlu:logical_fallacies,test,18.636275894998107
11,0.3918234353715723,0.27272728085517883,0.27272728085517883,0.5,0.3405539772727273,mmlu:machine_learning,validation,1.870605855001486
112,0.4253287336656026,0.2946428656578064,0.2946428656578064,0.5,0.31863839285714285,mmlu:machine_learning,test,16.766029113001423
11,0.19583951343189585,0.8181818127632141,0.7272727489471436,0.5277777777777778,0.18146304108879785,mmlu:management,validation,1.1033187189896125
103,0.12938599621207972,0.7281553149223328,0.708737850189209,0.5197619047619048,0.1520782743842857,mmlu:management,test,8.338321375005762
25,0.16847306013107297,0.800000011920929,0.800000011920929,0.65,0.23562501668930058,mmlu:marketing,validation,2.982842551005888
234,0.06053689911834193,0.811965823173523,0.811965823173523,0.5639354066985646,0.24537593610266337,mmlu:marketing,test,24.767064539992134
11,0.19213878566568549,0.7272727489471436,0.7272727489471436,0.7083333333333333,0.125,mmlu:medical_genetics,validation,1.3946862290031277
100,0.23054085969924926,0.5600000023841858,0.5699999928474426,0.5450487012987013,0.06960938215255737,mmlu:medical_genetics,test,9.76750089500274
86,0.1663382084563721,0.6627907156944275,0.4651162922382355,0.6424682395644282,0.06617913966955141,mmlu:miscellaneous,validation,7.4866250610066345
783,0.12437413927848005,0.7407407164573669,0.3575989902019501,0.5806522846950909,0.16841773390008724,mmlu:miscellaneous,test,68.96622401100467
38,0.2750846571043918,0.4736842215061188,0.4736842215061188,0.5722222222222222,0.056640606177480624,mmlu:moral_disputes,validation,4.601732658004039
346,0.21023098978004012,0.6011560559272766,0.6011560559272766,0.5288809921962095,0.07093341502151052,mmlu:moral_disputes,test,40.78695331999916
100,0.40612256377935413,0.25,0.25,0.5,0.3203125,mmlu:moral_scenarios,validation,14.71722303100978
895,0.41758067374788854,0.22234636545181274,0.22234636545181274,0.5,0.3479661312849162,mmlu:moral_scenarios,test,131.40261681399716
33,0.12732311089833578,0.6969696879386902,0.6969696879386902,0.5,0.04071969696969702,mmlu:nutrition,validation,4.974600660003489
306,0.198469851336448,0.6045751571655273,0.6045751571655273,0.5,0.05167483660130723,mmlu:nutrition,test,44.33599463100836
34,0.35916966813452106,0.5588235259056091,0.5882353186607361,0.45964912280701753,0.09283088235294118,mmlu:philosophy,validation,3.386949314008234
311,0.26256365187681757,0.6141479015350342,0.610932469367981,0.4586823734729494,0.06179660692858929,mmlu:philosophy,test,28.86275926900271
35,0.21211651563644407,0.6285714507102966,0.6285714507102966,0.5052447552447552,0.059040166650499604,mmlu:prehistory,validation,4.782717643000069
324,0.24364728066656324,0.5987654328346252,0.5987654328346252,0.5170697858842188,0.0294415214915334,mmlu:prehistory,test,41.560380555005395
31,0.3145434991005928,0.4516128897666931,0.5483871102333069,0.5,0.0023941532258064946,mmlu:professional_accounting,validation,5.158942096008104
282,0.18436649832742436,0.40425533056259155,0.5957446694374084,0.5,0.0449634308510638,mmlu:professional_accounting,test,45.61690499099495
170,0.3331159968586529,0.38235294818878174,0.38235294818878174,0.5,0.18014705882352944,mmlu:professional_law,validation,61.22566157700203
1534,0.3078311076375621,0.4002607464790344,0.4002607464790344,0.5,0.1622392438070404,mmlu:professional_law,test,587.9052928460005
31,0.26948743289516824,0.4838709533214569,0.4838709533214569,0.5,0.0590977822580645,mmlu:professional_medicine,validation,7.892821151996031
272,0.12061821483075617,0.529411792755127,0.529411792755127,0.5,0.01355698529411764,mmlu:professional_medicine,test,71.45225948600273
69,0.24589078409084375,0.5942028760910034,0.5942028760910034,0.5,0.05123414855072461,mmlu:professional_psychology,validation,10.307848046999425
612,0.23834817914986142,0.5539215803146362,0.5539215803146362,0.5,0.010952818627451011,mmlu:professional_psychology,test,89.8342135839921
12,0.4489505539337794,0.5,0.4166666567325592,0.41666666666666663,0.14225258429845172,mmlu:public_relations,validation,2.2230857249960536
110,0.15075297572396018,0.6454545259475708,0.6545454263687134,0.5899241603466955,0.1485440145839345,mmlu:public_relations,test,13.16037818598852
27,0.33861775309951214,0.5555555820465088,0.5555555820465088,0.5,0.03038194444444442,mmlu:security_studies,validation,8.424787953990744
245,0.25127739298100377,0.6448979377746582,0.6448979377746582,0.5,0.05896045918367343,mmlu:security_studies,test,67.14827606700419
22,0.11302886496890674,0.8181818127632141,0.8181818127632141,0.4097222222222222,0.24751421538266272,mmlu:sociology,validation,3.1163286869996227
201,0.1635524873709797,0.7611940503120422,0.7611940503120422,0.5717592592592593,0.19474892918743306,mmlu:sociology,test,23.64757332399313
11,0.07452987540851938,0.9090909361839294,0.9090909361839294,0.3,0.3210227326913313,mmlu:us_foreign_policy,validation,2.5861326470039785
100,0.12262817621231081,0.7900000214576721,0.7799999713897705,0.5123568414707655,0.19488282501697538,mmlu:us_foreign_policy,test,11.559060567989945
18,0.453576640950309,0.4444444477558136,0.5555555820465088,0.65,0.027126736111111112,mmlu:virology,validation,3.1558871239976725
166,0.3417032912194011,0.47590360045433044,0.6144578456878662,0.6159610068383531,0.10106834948781025,mmlu:virology,test,20.000116603987408
19,0.14529098021356684,0.7894737124443054,0.3684210479259491,0.7666666666666667,0.15193256265238714,mmlu:world_religions,validation,2.013026036991505
171,0.07563390247305932,0.7836257219314575,0.35087719559669495,0.4776119402985074,0.1698647465622216,mmlu:world_religions,test,18.52999689700664
