N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.17018335515802555,0.4545454680919647,0.5454545617103577,0.4,0.008167608217759526,mmlu:abstract_algebra,validation,5.623585293069482
100,0.043980423361063,0.33000001311302185,0.6700000166893005,0.5334690185436455,0.1425781083106995,mmlu:abstract_algebra,test,8.197731998050585
14,0.12516065154756817,0.6428571343421936,0.6428571343421936,0.5333333333333333,0.06333707060132707,mmlu:anatomy,validation,1.6081041109282523
135,0.07553706279507391,0.5777778029441833,0.5777778029441833,0.42577597840755743,0.07910880380206638,mmlu:anatomy,test,11.150536534842104
16,0.12928905338048935,0.625,0.625,0.5,0.140625,mmlu:astronomy,validation,2.0418284388724715
152,0.07584191113710403,0.6578947305679321,0.6578947305679321,0.5,0.10773026315789469,mmlu:astronomy,test,15.961990935029462
11,0.36880690401250665,0.4545454680919647,0.4545454680919647,0.5,0.09623579545454547,mmlu:business_ethics,validation,1.6886439069639891
100,0.09758620858192443,0.5899999737739563,0.5899999737739563,0.5,0.03921874999999997,mmlu:business_ethics,test,10.599793032975867
29,0.24320986969717617,0.6206896305084229,0.6206896305084229,0.46464646464646464,0.0420258435709723,mmlu:clinical_knowledge,validation,3.1177814239636064
265,0.09750527672047885,0.6754717230796814,0.6754717230796814,0.49853839158113555,0.08276828122588828,mmlu:clinical_knowledge,test,23.597826285054907
16,0.1347656361758709,0.625,0.625,0.5416666666666667,0.080078125,mmlu:college_biology,validation,2.1133222240023315
144,0.04710646718740463,0.7152777910232544,0.7152777910232544,0.5114847264977503,0.025689005023903345,mmlu:college_biology,test,13.933464476838708
8,0.3223490081727505,0.25,0.25,0.5,0.33837890625,mmlu:college_chemistry,validation,1.2693628461565822
100,0.0631174963712692,0.47999998927116394,0.4699999988079071,0.5665064102564104,0.13136718153953553,mmlu:college_chemistry,test,10.545250959927216
11,0.06236901066519998,0.4545454680919647,0.5454545617103577,0.5,0.044389204545454586,mmlu:college_computer_science,validation,1.9828870170749724
100,0.1660211804509163,0.5400000214576721,0.46000000834465027,0.5,0.12984374999999998,mmlu:college_computer_science,test,13.414228710811585
11,0.0985872122374448,0.27272728085517883,0.27272728085517883,0.5,0.3053977272727273,mmlu:college_mathematics,validation,1.76600465294905
100,0.09338311880826951,0.3499999940395355,0.3499999940395355,0.5,0.22812500000000002,mmlu:college_mathematics,test,10.306904712924734
22,0.20120580629868942,0.5454545617103577,0.5454545617103577,0.5625,0.17897724834355438,mmlu:college_medicine,validation,2.5396762241143733
173,0.0414742293385412,0.6300578117370605,0.6300578117370605,0.47269208715596334,0.09844651938862883,mmlu:college_medicine,test,20.250934466952458
11,0.27771310914646496,0.3636363744735718,0.3636363744735718,0.8571428571428572,0.3654119372367859,mmlu:college_physics,validation,1.4608368559274822
102,0.0993184745311737,0.4215686321258545,0.4215686321258545,0.6403232163973197,0.28753064894208713,mmlu:college_physics,test,9.313424422871321
11,0.3703038475730202,0.8181818127632141,0.8181818127632141,0.75,0.25319601730866864,mmlu:computer_security,validation,1.3531271999236196
100,0.05424466729164127,0.7699999809265137,0.7599999904632568,0.6278938452851497,0.19046877264976503,mmlu:computer_security,test,8.741439599078149
26,0.2384749192457933,0.42307692766189575,0.42307692766189575,0.6393939393939394,0.1965144230769231,mmlu:conceptual_physics,validation,2.3780512490775436
235,0.06336895924933414,0.6042553186416626,0.6042553186416626,0.5977207330001515,0.011170212765957479,mmlu:conceptual_physics,test,16.813211382832378
12,0.22919477025667825,0.6666666865348816,0.6666666865348816,0.5,0.12239583333333337,mmlu:econometrics,validation,1.8238906569313258
114,0.061843172761431905,0.5,0.5,0.5,0.2890625,mmlu:econometrics,test,12.50363045791164
16,0.26017797738313675,0.625,0.625,0.7250000000000001,0.08618166670203206,mmlu:electrical_engineering,validation,1.7519455950241536
145,0.04798555004185644,0.565517246723175,0.5034482479095459,0.5984320557491289,0.019638987245230832,mmlu:electrical_engineering,test,12.8196577350609
41,0.1277144900182398,0.4146341383457184,0.5853658318519592,0.5710784313725491,0.07783917392172468,mmlu:elementary_mathematics,validation,4.46952516795136
378,0.07350501418113708,0.4021163880825043,0.5978835821151733,0.5031293665579878,0.06521786804552436,mmlu:elementary_mathematics,test,37.14453959395178
14,0.2780844122171402,0.2142857164144516,0.7857142686843872,0.5,0.2622767857142857,mmlu:formal_logic,validation,1.928954959148541
126,0.08739520301894535,0.3968254029750824,0.60317462682724,0.5,0.07973710317460314,mmlu:formal_logic,test,14.260181754129007
10,0.18303847908973697,0.6000000238418579,0.6000000238418579,0.6875,0.06054685115814207,mmlu:global_facts,validation,1.370289352023974
100,0.06439917892217638,0.3199999928474426,0.3199999928474426,0.5310202205882353,0.21640627861022949,mmlu:global_facts,test,8.915057561127469
32,0.109920903109014,0.6875,0.6875,0.5363636363636363,0.0332031324505806,mmlu:high_school_biology,validation,3.528458703076467
310,0.04330083997018876,0.7612903118133545,0.7612903118133545,0.532180485570316,0.06415071679699809,mmlu:high_school_biology,test,30.39865842089057
22,0.336632411588322,0.3636363744735718,0.5,0.4955357142857143,0.0832741368900646,mmlu:high_school_chemistry,validation,2.5436085988767445
203,0.032795608337289596,0.5123152732849121,0.546798050403595,0.568084693084693,0.034598212230381724,mmlu:high_school_chemistry,test,19.69492665794678
9,0.29575566781891716,0.6666666865348816,0.6666666865348816,0.5,0.07161458333333337,mmlu:high_school_computer_science,validation,1.8142705969512463
100,0.14218660235404967,0.7300000190734863,0.7300000190734863,0.5,0.008281250000000018,mmlu:high_school_computer_science,test,14.672426455188543
18,0.30340122514300877,0.7222222089767456,0.7222222089767456,0.5,0.07769097222222221,mmlu:high_school_european_history,validation,7.2946872159373015
165,0.06843155821164448,0.7636363506317139,0.7636363506317139,0.5,0.11910511363636367,mmlu:high_school_european_history,test,62.18057600106113
22,0.18262522328983655,0.8181818127632141,0.8181818127632141,0.5208333333333334,0.19495741074735468,mmlu:high_school_geography,validation,2.2831150200217962
198,0.035832466501178176,0.808080792427063,0.808080792427063,0.4891447368421053,0.17175665136539578,mmlu:high_school_geography,test,16.47375388117507
21,0.2009876540728978,0.8571428656578064,0.8571428656578064,0.5,0.23474700394130882,mmlu:high_school_government_and_politics,validation,2.279017857974395
193,0.07055158056125738,0.8860103487968445,0.8860103487968445,0.4864433811802233,0.2757245855010235,mmlu:high_school_government_and_politics,test,17.716174320084974
43,0.08322383359421132,0.6511628031730652,0.6511628031730652,0.5630952380952381,0.05595932034559029,mmlu:high_school_macroeconomics,validation,4.103678259067237
390,0.07889645802669039,0.6538461446762085,0.6487179398536682,0.5679883805374001,0.04773635558592967,mmlu:high_school_macroeconomics,test,32.39634693507105
29,0.09204062511181012,0.2068965584039688,0.7931034564971924,0.6992753623188406,0.10924028528147733,mmlu:high_school_mathematics,validation,3.2210386800579727
270,0.049816260845572856,0.3185185194015503,0.6814814805984497,0.46233569261880686,0.01841723874763205,mmlu:high_school_mathematics,test,25.790356976911426
26,0.14385099823658284,0.7307692170143127,0.7307692170143127,0.5639097744360901,0.045372619078709556,mmlu:high_school_microeconomics,validation,2.5819849520921707
238,0.05148605952242845,0.6722689270973206,0.6722689270973206,0.5717948717948719,0.014361209979578272,mmlu:high_school_microeconomics,test,20.025085892993957
17,0.1623183383661158,0.23529411852359772,0.23529411852359772,0.43269230769230765,0.5523897234131309,mmlu:high_school_physics,validation,2.4022501190192997
151,0.06380645486692718,0.34437087178230286,0.34437087178230286,0.36810411810411814,0.4433205707973202,mmlu:high_school_physics,test,15.482056197943166
60,0.06861836363871893,0.8833333253860474,0.8833333253860474,0.6078167115902965,0.21256512800852456,mmlu:high_school_psychology,validation,6.062287306878716
545,0.024298798108319603,0.8165137767791748,0.8165137767791748,0.5087977528089888,0.14608660312967567,mmlu:high_school_psychology,test,51.97457929211669
23,0.13325972142426865,0.52173912525177,0.52173912525177,0.5,0.1266983695652174,mmlu:high_school_statistics,validation,3.33942815894261
216,0.08938277112665001,0.5787037014961243,0.5787037014961243,0.5,0.06973379629629628,mmlu:high_school_statistics,test,28.18297530594282
22,0.16132216968319635,0.7727272510528564,0.7727272510528564,0.5,0.04616477272727271,mmlu:high_school_us_history,validation,6.9631984629668295
204,0.039715321332800625,0.7745097875595093,0.7745097875595093,0.5,0.04794730392156865,mmlu:high_school_us_history,test,60.7960439468734
26,0.17852042730037984,0.7307692170143127,0.7307692170143127,0.5,0.11358173076923073,mmlu:high_school_world_history,validation,6.29426180687733
237,0.057549775652744564,0.75527423620224,0.75527423620224,0.5,0.13808676160337552,mmlu:high_school_world_history,test,50.65483632707037
23,0.18107274174690252,0.739130437374115,0.739130437374115,0.20098039215686272,0.1136209446450938,mmlu:human_aging,validation,2.08256439701654
223,0.07521940333426268,0.6995515823364258,0.6995515823364258,0.5793149636433219,0.08877523036281086,mmlu:human_aging,test,16.724349250085652
12,0.2105246310432752,0.5833333134651184,0.5833333134651184,0.7142857142857142,0.19759114583333331,mmlu:human_sexuality,validation,1.4824332450516522
131,0.10232193733899647,0.8015267252922058,0.7938931584358215,0.5492673992673993,0.20255846012639633,mmlu:human_sexuality,test,10.869431486120448
13,0.10194548735251793,0.9230769276618958,0.9230769276618958,0.5,0.29026442307692313,mmlu:international_law,validation,1.8306199971120805
121,0.05805432205357827,0.7933884263038635,0.7933884263038635,0.5,0.16057592975206614,mmlu:international_law,test,13.47821196098812
11,0.2690740092234178,0.6363636255264282,0.6363636255264282,0.4285714285714286,0.07705966992811725,mmlu:jurisprudence,validation,1.5883357129059732
108,0.12221521966987187,0.8148148059844971,0.8148148059844971,0.4903409090909091,0.1541883829567167,mmlu:jurisprudence,test,9.584865756100044
18,0.20434738198916116,0.7222222089767456,0.7222222089767456,0.4923076923076924,0.07313367393281725,mmlu:logical_fallacies,validation,2.0797318138647825
163,0.09247886220370331,0.803680956363678,0.803680956363678,0.5409112595419847,0.12672546121971734,mmlu:logical_fallacies,test,14.68569235689938
11,0.2018365128473802,0.27272728085517883,0.27272728085517883,0.5,0.4186789772727273,mmlu:machine_learning,validation,1.7060650519561023
112,0.12399928271770477,0.375,0.375,0.5,0.31640625,mmlu:machine_learning,test,12.87368456996046
11,0.16547433625568045,0.9090909361839294,0.9090909361839294,0.35,0.3473011580380526,mmlu:management,validation,1.2409314659889787
103,0.042513576526086304,0.7961165308952332,0.7572815418243408,0.576945412311266,0.1936437857961192,mmlu:management,test,7.580472614150494
25,0.11829211235046386,0.8799999952316284,0.8799999952316284,0.4393939393939394,0.2734375047683716,mmlu:marketing,validation,2.707670573145151
234,0.04439549428275506,0.867521345615387,0.867521345615387,0.4743365644366757,0.25848024141075265,mmlu:marketing,test,19.481868694070727
11,0.13500616767189721,1.0,1.0,,0.37393465909090906,mmlu:medical_genetics,validation,1.5253891660831869
100,0.11493014007806779,0.7300000190734863,0.7300000190734863,0.6286149162861492,0.10984372973442076,mmlu:medical_genetics,test,8.327285134000704
86,0.08882987568544788,0.7674418687820435,0.7674418687820435,0.7034090909090909,0.20521436874256577,mmlu:miscellaneous,validation,6.694593622116372
783,0.04395729360452559,0.8173691034317017,0.7458493113517761,0.5727436625874126,0.17789648874813876,mmlu:miscellaneous,test,56.98544493597001
38,0.1661682050479086,0.6315789222717285,0.6315789222717285,0.36607142857142855,0.13003699716768768,mmlu:moral_disputes,validation,3.7849001428112388
346,0.0584012302704629,0.7052023410797119,0.7052023410797119,0.546046287367406,0.11451183509275403,mmlu:moral_disputes,test,32.23560094111599
100,0.13669809579849243,0.4099999964237213,0.4099999964237213,0.5,0.19546875000000002,mmlu:moral_scenarios,validation,11.314357310067862
895,0.06356477018175177,0.37318435311317444,0.37318435311317444,0.5,0.23228439245810056,mmlu:moral_scenarios,test,94.94381418009289
33,0.1369313398996989,0.7272727489471436,0.7272727489471436,0.5,0.0007102272727272929,mmlu:nutrition,validation,4.095285599119961
306,0.09520230291326062,0.741830050945282,0.741830050945282,0.5,0.015267565359477153,mmlu:nutrition,test,32.258463972015306
34,0.22579511123545035,0.7352941036224365,0.7352941036224365,0.34444444444444444,0.14510570203556739,mmlu:philosophy,validation,3.246379805961624
311,0.03980188086101864,0.7202572226524353,0.700964629650116,0.45543411330049266,0.11604448491737386,mmlu:philosophy,test,24.0437536269892
35,0.16099082486970084,0.5714285969734192,0.5714285969734192,0.52,0.16049107142857144,mmlu:prehistory,validation,4.024168943986297
324,0.022805552699683616,0.7407407164573669,0.7407407164573669,0.5970982142857142,0.025860800971219577,mmlu:prehistory,test,31.508360127918422
31,0.1648519971678334,0.4516128897666931,0.5483871102333069,0.5,0.014112903225806495,mmlu:professional_accounting,validation,4.221640849951655
282,0.0664195701585594,0.5106382966041565,0.4893617033958435,0.5,0.07313829787234044,mmlu:professional_accounting,test,33.350214544916525
170,0.07522207375834968,0.4529411792755127,0.4529411792755127,0.5,0.12909007352941176,mmlu:professional_law,validation,40.00802408880554
1534,0.03781230397998431,0.4537157714366913,0.4537157714366913,0.5,0.12831547425032597,mmlu:professional_law,test,358.9519962191116
31,0.2296288888300619,0.5483871102333069,0.5483871102333069,0.5,0.1313004032258065,mmlu:professional_medicine,validation,5.692950731841847
272,0.09225848952637,0.6764705777168274,0.6764705777168274,0.5,0.003216911764705843,mmlu:professional_medicine,test,46.96026713401079
69,0.10513200967208197,0.7101449370384216,0.7101449370384216,0.5,0.06951992753623193,mmlu:professional_psychology,validation,7.890127362916246
612,0.05439026449240889,0.6813725233078003,0.6813725233078003,0.5,0.040747549019607865,mmlu:professional_psychology,test,63.07720075384714
12,0.2725921496748924,0.5,0.5833333134651184,0.6666666666666666,0.034505218267440754,mmlu:public_relations,validation,1.5917791249230504
110,0.07899739335883746,0.6636363863945007,0.5090909004211426,0.5386893743058127,0.02982956821268258,mmlu:public_relations,test,9.835772769059986
27,0.140475841584029,0.7037037014961243,0.7037037014961243,0.5,0.06582754629629628,mmlu:security_studies,validation,5.233301342930645
245,0.0749469412832844,0.7469387650489807,0.7469387650489807,0.5,0.022592474489795955,mmlu:security_studies,test,43.66852999199182
22,0.12233782898296008,0.8636363744735718,0.8636363744735718,0.736842105263158,0.30894888260147785,mmlu:sociology,validation,2.459132655058056
201,0.03701394321906625,0.8358209133148193,0.8407959938049316,0.5790945165945165,0.2961753965610295,mmlu:sociology,test,17.998413368826732
11,0.18971927057613028,0.9090909361839294,0.9090909361839294,0.15000000000000002,0.2855113419619474,mmlu:us_foreign_policy,validation,1.5219103759154677
100,0.08733016997575761,0.8799999952316284,0.8799999952316284,0.6036931818181818,0.24839843273162843,mmlu:us_foreign_policy,test,8.276202843058854
18,0.3344945990377003,0.6666666865348816,0.6666666865348816,0.48611111111111105,0.1310763955116272,mmlu:virology,validation,2.219860292971134
166,0.21905659570033292,0.5301204919815063,0.5301204919815063,0.558784965034965,0.08640815874180163,mmlu:virology,test,13.82140620588325
19,0.20538539008090367,0.8947368264198303,0.42105263471603394,0.8970588235294117,0.09087169484088298,mmlu:world_religions,validation,1.7764901919290423
171,0.04527864260980259,0.8187134265899658,0.2923976480960846,0.4567972350230415,0.2210343650907104,mmlu:world_religions,test,12.301844446919858
