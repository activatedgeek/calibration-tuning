N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.0696131939237768,0.1818181872367859,0.1818181872367859,0.5555555555555556,0.34197444265538995,mmlu:abstract_algebra,validation,5.345126097090542
100,0.062481691688299174,0.33000001311302185,0.3499999940395355,0.43057440072365444,0.17371096611022951,mmlu:abstract_algebra,test,9.409253214951605
14,0.12325577012130193,0.5,0.5,0.4693877551020408,0.013671875,mmlu:anatomy,validation,1.537151084979996
135,0.1060570167170631,0.5185185074806213,0.5185185074806213,0.49659340659340656,0.0041666737309208335,mmlu:anatomy,test,13.154721048194915
16,0.232487965375185,0.625,0.625,0.5,0.078125,mmlu:astronomy,validation,2.386694092070684
152,0.11130888250313306,0.4934210479259491,0.4934210479259491,0.5,0.05345394736842107,mmlu:astronomy,test,21.435188017087057
11,0.24546931277621875,0.3636363744735718,0.6363636255264282,0.5,0.10511363636363635,mmlu:business_ethics,validation,1.792854696046561
100,0.10062643349170684,0.5199999809265137,0.47999998927116394,0.5,0.05125000000000002,mmlu:business_ethics,test,14.023880346911028
29,0.17387458990360125,0.5862069129943848,0.5517241358757019,0.5833333333333334,0.026266159682438284,mmlu:clinical_knowledge,validation,3.32874219189398
265,0.058063485487452084,0.5962263941764832,0.6075471639633179,0.5946705311723649,0.08267981398780389,mmlu:clinical_knowledge,test,28.58424151618965
16,0.22307050228118896,0.5625,0.625,0.5158730158730159,0.08154297247529027,mmlu:college_biology,validation,2.094955143984407
144,0.05422817170619965,0.5486111044883728,0.5416666865348816,0.45589094449853945,0.01757810430394277,mmlu:college_biology,test,17.875703890109435
8,0.2814292460680008,0.5,0.5,0.09375,0.0283203125,mmlu:college_chemistry,validation,1.2992974589578807
100,0.07826841533184052,0.4399999976158142,0.4699999988079071,0.5150162337662337,0.05929687500000003,mmlu:college_chemistry,test,13.43465069704689
11,0.23915172706950794,0.5454545617103577,0.5454545617103577,0.5,0.018110795454545414,mmlu:college_computer_science,validation,2.2112530642189085
100,0.11487072974443437,0.4399999976158142,0.4399999976158142,0.5,0.08734375,mmlu:college_computer_science,test,17.976159929996356
11,0.17525375431234186,0.1818181872367859,0.1818181872367859,0.5,0.3689630681818182,mmlu:college_mathematics,validation,1.796809489140287
100,0.06233548492193221,0.3100000023841858,0.3100000023841858,0.5,0.24078125,mmlu:college_mathematics,test,13.503694739891216
22,0.15730334141037683,0.5454545617103577,0.5454545617103577,0.6124999999999999,0.010298268361525142,mmlu:college_medicine,validation,3.012831597821787
173,0.07321169403936133,0.5491329431533813,0.5491329431533813,0.5708502024291497,0.012960615185643933,mmlu:college_medicine,test,28.177455825032666
11,0.12884083119305698,0.5454545617103577,0.4545454680919647,0.7166666666666667,0.09517048163847491,mmlu:college_physics,validation,1.5874010319821537
102,0.18728521553909075,0.23529411852359772,0.7450980544090271,0.7369123931623932,0.18401502043593165,mmlu:college_physics,test,12.125246894080192
11,0.31622943011197174,0.8181818127632141,0.27272728085517883,0.8888888888888888,0.2659801027991555,mmlu:computer_security,validation,1.548316140891984
100,0.05812181204557419,0.699999988079071,0.3400000035762787,0.44500000000000006,0.19859373807907105,mmlu:computer_security,test,10.69088919297792
26,0.1564652782220107,0.42307692766189575,0.5769230723381042,0.4757575757575758,0.013972346599285368,mmlu:conceptual_physics,validation,2.5012330051977187
235,0.1324305961740778,0.3787234127521515,0.6212766170501709,0.587386486070494,0.056682207736563184,mmlu:conceptual_physics,test,19.832175489049405
12,0.16740141312281293,0.25,0.25,0.5,0.44921875,mmlu:econometrics,validation,1.9667138860095292
114,0.1380235351491393,0.2719298303127289,0.2719298303127289,0.5,0.4272889254385965,mmlu:econometrics,test,16.46954385819845
16,0.22651579603552818,0.3125,0.6875,0.6181818181818183,0.060058601200580576,mmlu:electrical_engineering,validation,1.9421579570043832
145,0.07684717507197941,0.4482758641242981,0.5517241358757019,0.578846153846154,0.07887930335669678,mmlu:electrical_engineering,test,15.773908460047096
41,0.11319765666636025,0.3658536672592163,0.6341463327407837,0.5269230769230768,0.07698171313216048,mmlu:elementary_mathematics,validation,5.516911798156798
378,0.0972330496897773,0.32275131344795227,0.6772486567497253,0.48477523053278687,0.06818369456699919,mmlu:elementary_mathematics,test,48.13852131809108
14,0.12619798524039133,0.2857142984867096,0.7142857313156128,0.5,0.1947544642857143,mmlu:formal_logic,validation,2.156866633100435
126,0.03215286679684172,0.3571428656578064,0.6428571343421936,0.5,0.1233258928571429,mmlu:formal_logic,test,18.384041214128956
10,0.16201186776161192,0.5,0.5,0.5800000000000001,0.013671875,mmlu:global_facts,validation,1.3927538730204105
100,0.10517410397529603,0.3499999940395355,0.6399999856948853,0.47736263736263734,0.12890626430511476,mmlu:global_facts,test,10.941764497896656
32,0.12172777019441128,0.53125,0.5,0.16862745098039214,0.049438476562500014,mmlu:high_school_biology,validation,4.247468087822199
310,0.08067745210662966,0.6580645442008972,0.6548386812210083,0.46631058083610805,0.09992441804178298,mmlu:high_school_biology,test,39.688462051097304
22,0.12493294883858076,0.3636363744735718,0.40909090638160706,0.6116071428571429,0.12464490261944855,mmlu:high_school_chemistry,validation,2.939106173813343
203,0.05575069344689694,0.47783252596855164,0.4729064106941223,0.5265512546197237,0.06425109579058118,mmlu:high_school_chemistry,test,25.321648984914646
9,0.26322924759652877,0.6666666865348816,0.3333333432674408,0.5,0.16666666666666669,mmlu:high_school_computer_science,validation,2.0712557991500944
100,0.12126098752021791,0.550000011920929,0.44999998807907104,0.5,0.04999999999999999,mmlu:high_school_computer_science,test,20.01040325500071
18,0.21657157772117192,0.6666666865348816,0.6666666865348816,0.5,0.16276041666666663,mmlu:high_school_european_history,validation,11.119157628854737
165,0.07021790941556295,0.6484848260879517,0.6484848260879517,0.5,0.14457859848484844,mmlu:high_school_european_history,test,100.04303589905612
22,0.1206256137652831,0.7272727489471436,0.6363636255264282,0.3697916666666667,0.11914063583720813,mmlu:high_school_geography,validation,2.3687925348058343
198,0.07263806537546293,0.7222222089767456,0.7171717286109924,0.5328035600762874,0.19793640423302694,mmlu:high_school_geography,test,20.079679407877848
21,0.1852072931471325,0.7142857313156128,0.5714285969734192,0.5055555555555555,0.0641740901129586,mmlu:high_school_government_and_politics,validation,2.670778007945046
193,0.07061314428408529,0.8341968655586243,0.4455958604812622,0.4473020186335404,0.0626618917741924,mmlu:high_school_government_and_politics,test,22.562551771989092
43,0.12308676021043644,0.4883720874786377,0.4883720874786377,0.5173160173160173,0.03452032250027326,mmlu:high_school_macroeconomics,validation,4.634046670049429
390,0.08908910621435215,0.5435897707939148,0.5384615659713745,0.6042108331566673,0.015314491895528914,mmlu:high_school_macroeconomics,test,40.34626187989488
29,0.11224446214478592,0.24137930572032928,0.7586206793785095,0.7629870129870129,0.16540947453729032,mmlu:high_school_mathematics,validation,3.8128646868281066
270,0.0799310932556788,0.24444444477558136,0.7555555701255798,0.5055332739156269,0.162586799815849,mmlu:high_school_mathematics,test,33.34974269988015
26,0.1624302909924434,0.6538461446762085,0.6538461446762085,0.4084967320261438,0.12469954215563261,mmlu:high_school_microeconomics,validation,2.8480396068189293
238,0.0833617255968206,0.5840336084365845,0.5840336084365845,0.5703073904512753,0.05373555922708595,mmlu:high_school_microeconomics,test,25.054540782934055
17,0.1716516771737267,0.23529411852359772,0.7647058963775635,0.3942307692307692,0.23207722691928634,mmlu:high_school_physics,validation,2.616001451155171
151,0.06615366327841553,0.41059601306915283,0.5827814340591431,0.3910837259876767,0.05264385843908548,mmlu:high_school_physics,test,20.202588665066287
60,0.11583499262730279,0.800000011920929,0.5666666626930237,0.4548611111111111,0.05677080551783242,mmlu:high_school_psychology,validation,7.657755570020527
545,0.056013657849863036,0.763302743434906,0.526605486869812,0.561782573047108,0.01786126478002703,mmlu:high_school_psychology,test,69.04422369995154
23,0.10543480645055357,0.3913043439388275,0.6086956262588501,0.5,0.10478940217391308,mmlu:high_school_statistics,validation,4.230878742877394
216,0.04311546021037632,0.4583333432674408,0.5416666865348816,0.5,0.03776041666666663,mmlu:high_school_statistics,test,38.879714770941064
22,0.1829272142865441,0.7727272510528564,0.7727272510528564,0.5,0.2414772727272727,mmlu:high_school_us_history,validation,10.493833161890507
204,0.06136218823638616,0.75,0.75,0.5,0.21875,mmlu:high_school_us_history,test,95.97247425816022
26,0.1794874771283223,0.5384615659713745,0.5384615659713745,0.5,0.007211538461538436,mmlu:high_school_world_history,validation,9.174545583082363
237,0.051091996426320785,0.7257384061813354,0.7257384061813354,0.5,0.1944883966244726,mmlu:high_school_world_history,test,76.74612796283327
23,0.3181648306224657,0.5652173757553101,0.47826087474823,0.4307692307692308,0.03311819356420764,mmlu:human_aging,validation,2.229249030118808
223,0.07719957734971838,0.605381190776825,0.4932735562324524,0.5245791245791246,0.020967616361352914,mmlu:human_aging,test,19.452811320777982
12,0.23632426559925082,0.4166666567325592,0.4166666567325592,0.48571428571428577,0.0976562698682149,mmlu:human_sexuality,validation,1.4100886220112443
131,0.09733276467286903,0.6106870174407959,0.5572519302368164,0.6287990196078431,0.03945014676974934,mmlu:human_sexuality,test,12.993633250007406
13,0.1827215964977558,0.7692307829856873,0.7692307829856873,0.5,0.2575120192307693,mmlu:international_law,validation,2.157225330825895
121,0.08156253237369632,0.7190082669258118,0.7190082669258118,0.5,0.20728951446280997,mmlu:international_law,test,18.03520196606405
11,0.2184979725967754,0.4545454680919647,0.4545454680919647,0.06666666666666668,0.09268466992811725,mmlu:jurisprudence,validation,1.4166483429726213
108,0.12156277619026327,0.7222222089767456,0.7222222089767456,0.46965811965811965,0.163519991768731,mmlu:jurisprudence,test,11.446571710053831
18,0.1765345086654027,0.7777777910232544,0.3333333432674408,0.5,0.18511287371317547,mmlu:logical_fallacies,validation,2.3182074630167335
163,0.07610305193011746,0.6441717743873596,0.4049079716205597,0.5301313628899835,0.11661234114067687,mmlu:logical_fallacies,test,18.514564789133146
11,0.18800130757418546,0.4545454680919647,0.4545454680919647,0.5,0.07279829545454547,mmlu:machine_learning,validation,1.8738135620951653
112,0.18364768049546648,0.2232142835855484,0.2232142835855484,0.5,0.3041294642857143,mmlu:machine_learning,test,16.77694619796239
11,0.13454832001165912,0.7272727489471436,0.8181818127632141,0.6875,0.3014915043657477,mmlu:management,validation,1.160348042845726
103,0.08853922220109736,0.7572815418243408,0.6699029207229614,0.438974358974359,0.15264712954030457,mmlu:management,test,8.31212281016633
25,0.24610543847084046,0.8399999737739563,0.7599999904632568,0.7321428571428572,0.2484374737739563,mmlu:marketing,validation,2.9872070611454546
234,0.0726083690284664,0.7991452813148499,0.7136752009391785,0.5267379679144385,0.201138509134961,mmlu:marketing,test,24.83653162000701
11,0.17787489565936004,0.8181818127632141,0.8181818127632141,0.7777777777777778,0.2315340746532787,mmlu:medical_genetics,validation,1.3730619370471686
100,0.13138089478015902,0.5799999833106995,0.5699999928474426,0.5543924466338258,0.017578141689300577,mmlu:medical_genetics,test,9.792803420918062
86,0.08592159768869709,0.6627907156944275,0.6976743936538696,0.7734422262552932,0.17986919990805694,mmlu:miscellaneous,validation,7.685967234894633
783,0.056328266021696834,0.7586206793785095,0.725415050983429,0.5705690057541909,0.206093330569042,mmlu:miscellaneous,test,68.87079616892152
38,0.1724564589952168,0.5,0.4736842215061188,0.32271468144044324,0.0583881547576503,mmlu:moral_disputes,validation,4.601898716995493
346,0.05548769166703859,0.6040462255477905,0.39306357502937317,0.5505186323472916,0.13854767993695472,mmlu:moral_disputes,test,40.620155029930174
100,0.08906677156686785,0.33000001311302185,0.33000001311302185,0.5,0.19343749999999998,mmlu:moral_scenarios,validation,14.861349359154701
895,0.07549112196075183,0.35754188895225525,0.35754188895225525,0.5,0.1658956005586592,mmlu:moral_scenarios,test,129.51832985295914
33,0.1590046322706974,0.7575757503509521,0.7575757503509521,0.5,0.22241950757575757,mmlu:nutrition,validation,4.954742243979126
306,0.09267530517250881,0.6307189464569092,0.6307189464569092,0.5,0.09556270424836599,mmlu:nutrition,test,43.93067173892632
34,0.20768010265686931,0.6470588445663452,0.5588235259056091,0.35037878787878785,0.03779870622298298,mmlu:philosophy,validation,3.779819694114849
311,0.09510084574628873,0.6495176553726196,0.5723472833633423,0.49911436097738215,0.05525271436409174,mmlu:philosophy,test,29.080758934142068
35,0.14031588009425572,0.6571428775787354,0.6000000238418579,0.39855072463768115,0.0822544455528259,mmlu:prehistory,validation,4.888806620845571
324,0.05882724328541461,0.6358024477958679,0.6203703880310059,0.5188003949317097,0.1003688993277373,mmlu:prehistory,test,42.08433712902479
31,0.14624394428345464,0.29032257199287415,0.7096773982048035,0.5,0.18233366935483875,mmlu:professional_accounting,validation,5.255737223895267
282,0.03571194600551686,0.41489362716674805,0.585106372833252,0.5,0.057762632978723416,mmlu:professional_accounting,test,46.60961351683363
170,0.12842015641577104,0.38235294818878174,0.38235294818878174,0.5,0.14108455882352944,mmlu:professional_law,validation,61.46474589104764
1534,0.09026802297210446,0.40612778067588806,0.40612778067588806,0.5,0.11730972946544982,mmlu:professional_law,test,558.9191112520639
31,0.19196684706595632,0.4516128897666931,0.4516128897666931,0.5,0.07182459677419356,mmlu:professional_medicine,validation,7.975641858996823
272,0.09498748511952512,0.5404411554336548,0.5404411554336548,0.5,0.017003676470588203,mmlu:professional_medicine,test,69.2314254490193
69,0.15919146891953287,0.5652173757553101,0.5652173757553101,0.5,0.06131114130434778,mmlu:professional_psychology,validation,10.17094551678747
612,0.0768520909976336,0.5539215803146362,0.5539215803146362,0.5,0.05001531862745101,mmlu:professional_psychology,test,85.08547759312205
12,0.4198806956410408,0.5,0.4166666567325592,0.4027777777777778,0.10188802083333331,mmlu:public_relations,validation,1.680867844959721
110,0.08595223860307172,0.6454545259475708,0.48181816935539246,0.4898880462260744,0.03188921755010432,mmlu:public_relations,test,12.317811680957675
27,0.22061538365152147,0.6296296119689941,0.6296296119689941,0.5,0.05541087962962965,mmlu:security_studies,validation,7.398265453986824
245,0.05831849891312268,0.6204081773757935,0.6204081773757935,0.5,0.04618941326530612,mmlu:security_studies,test,65.25038146902807
22,0.20658719404177228,0.8181818127632141,0.1818181872367859,0.11805555555555555,0.3268821293657476,mmlu:sociology,validation,2.6928613970521837
201,0.0791623977879387,0.7761194109916687,0.4029850661754608,0.5694444444444445,0.10638215292745562,mmlu:sociology,test,22.913590307813138
11,0.13104425235228107,0.9090909361839294,0.9090909361839294,0.5,0.3753550973805514,mmlu:us_foreign_policy,validation,1.4291294398717582
100,0.08155262723565102,0.8399999737739563,0.8399999737739563,0.5186011904761905,0.3099218869209289,mmlu:us_foreign_policy,test,10.941586045082659
18,0.2801609834035238,0.4444444477558136,0.6111111044883728,0.76875,0.08138019508785677,mmlu:virology,validation,2.359889233019203
166,0.1782420268618917,0.4397590458393097,0.5,0.5333627927529827,0.02190793889114654,mmlu:virology,test,16.237879804102704
19,0.09875376914676866,0.7894737124443054,0.2631579041481018,0.3833333333333333,0.26583058583109004,mmlu:world_religions,validation,1.7221469630021602
171,0.05092698492501912,0.7602339386940002,0.31578946113586426,0.5454033771106942,0.210320698587518,mmlu:world_religions,test,13.20969988917932
