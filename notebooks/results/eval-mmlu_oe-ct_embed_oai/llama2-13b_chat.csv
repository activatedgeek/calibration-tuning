N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.1818181872367859,0.09999999999999998,0.46271307901902625,mmlu:abstract_algebra,validation,2.0664585229824297
100,0.3499999940395355,0.3799999952316284,0.5986813186813187,0.2869140779972077,mmlu:abstract_algebra,test,2.7132799619575962
14,0.2857142984867096,0.2857142984867096,0.5499999999999999,0.544921875,mmlu:anatomy,validation,0.49049420800292864
135,0.42222222685813904,0.42222222685813904,0.6916329284750338,0.35980901144169,mmlu:anatomy,test,3.599435036012437
16,0.5,0.5,0.7109375,0.3918456956744194,mmlu:astronomy,validation,0.49903430399717763
152,0.5263158082962036,0.5263158082962036,0.5661458333333333,0.3771844270982241,mmlu:astronomy,test,3.994378552015405
11,0.5454545617103577,0.5454545617103577,0.4666666666666667,0.13174715367230502,mmlu:business_ethics,validation,0.5237299059517682
100,0.3199999928474426,0.33000001311302185,0.560202205882353,0.24949217915534974,mmlu:business_ethics,test,2.734480112034362
29,0.24137930572032928,0.27586206793785095,0.49350649350649345,0.34146013136567743,mmlu:clinical_knowledge,validation,0.9201277199899778
265,0.2981131970882416,0.3207547068595886,0.6360078943786579,0.30658902897025053,mmlu:clinical_knowledge,test,7.1511906769592315
16,0.25,0.25,0.5104166666666667,0.5878906212747097,mmlu:college_biology,validation,0.5664961989969015
144,0.3958333432674408,0.3958333432674408,0.5768300060496068,0.4474283787939284,mmlu:college_biology,test,3.5967532049980946
8,0.0,0.0,,0.8833007887005806,mmlu:college_chemistry,validation,0.38170225301291794
100,0.17000000178813934,0.17000000178813934,0.632884479092842,0.7088281106948853,mmlu:college_chemistry,test,2.7124097710475326
11,0.27272728085517883,0.6363636255264282,0.8125,0.15234372832558374,mmlu:college_computer_science,validation,0.5591434299713001
100,0.23999999463558197,0.5099999904632568,0.5468749999999999,0.09683593392372133,mmlu:college_computer_science,test,2.7010689210146666
11,0.0,1.0,,0.2705965909090909,mmlu:college_mathematics,validation,0.537290446984116
100,0.09000000357627869,0.8500000238418579,0.6123321123321124,0.1289452975988388,mmlu:college_mathematics,test,2.6375932719674893
22,0.5,0.5,0.640495867768595,0.3792613717642698,mmlu:college_medicine,validation,0.7396856830455363
173,0.3988439440727234,0.3988439440727234,0.6290412486064659,0.4745529418046764,mmlu:college_medicine,test,4.624536787974648
11,0.27272728085517883,0.27272728085517883,0.7708333333333333,0.6477272673086687,mmlu:college_physics,validation,0.5145502290106378
102,0.1568627506494522,0.1568627506494522,0.5944767441860465,0.7725949924366147,mmlu:college_physics,test,2.691871438990347
11,0.5454545617103577,0.6363636255264282,0.7666666666666667,0.22123579545454547,mmlu:computer_security,validation,0.5409680349985138
100,0.550000011920929,0.550000011920929,0.6236363636363637,0.17242186307907106,mmlu:computer_security,test,2.8007496299687773
26,0.3461538553237915,0.38461539149284363,0.5915032679738562,0.3804086515536675,mmlu:conceptual_physics,validation,0.9336603980045766
235,0.4553191363811493,0.4553191363811493,0.49222400700934577,0.26743683738911406,mmlu:conceptual_physics,test,6.101062158006243
12,0.25,0.25,0.7407407407407407,0.4023437599341075,mmlu:econometrics,validation,0.5087427139515057
114,0.1315789520740509,0.14912280440330505,0.47138047138047134,0.47457510546634074,mmlu:econometrics,test,3.184619373001624
16,0.25,0.3125,0.5104166666666666,0.3452148474752903,mmlu:electrical_engineering,validation,0.5889519869815558
145,0.24827586114406586,0.2896551787853241,0.6246177370030582,0.37793643063512344,mmlu:electrical_engineering,test,3.8836116659804247
41,0.26829269528388977,0.26829269528388977,0.5348484848484848,0.4310213327407837,mmlu:elementary_mathematics,validation,1.2677392169716768
378,0.3174603283405304,0.32275131344795227,0.49337855297157623,0.3824404695677379,mmlu:elementary_mathematics,test,9.643493651994504
14,0.2142857164144516,0.2142857164144516,0.5454545454545454,0.3420759013720921,mmlu:formal_logic,validation,0.5486179619911127
126,0.261904776096344,0.261904776096344,0.6404366243075922,0.3049045290265764,mmlu:formal_logic,test,3.3160394690348767
10,0.20000000298023224,0.20000000298023224,0.46875,0.47304687500000003,mmlu:global_facts,validation,0.5837424889905378
100,0.12999999523162842,0.12999999523162842,0.3421750663129974,0.5603124880790711,mmlu:global_facts,test,2.7216945869731717
32,0.3125,0.3125,0.6409090909090909,0.5815429501235485,mmlu:high_school_biology,validation,1.032113755994942
310,0.42258065938949585,0.42258065938949585,0.5458868182012027,0.4804813717642138,mmlu:high_school_biology,test,8.108224180003162
22,0.1818181872367859,0.1818181872367859,0.3819444444444444,0.716796880418604,mmlu:high_school_chemistry,validation,0.7295772110228427
203,0.1822660118341446,0.1822660118341446,0.5029306414848583,0.717133631259937,mmlu:high_school_chemistry,test,5.162471127987374
9,0.6666666865348816,0.7777777910232544,0.5555555555555556,0.2048610978656345,mmlu:high_school_computer_science,validation,0.5684453179710545
100,0.4300000071525574,0.44999998807907104,0.6756425948592412,0.2393749767541886,mmlu:high_school_computer_science,test,2.721962595009245
18,0.7777777910232544,0.7222222089767456,0.2232142857142857,0.1634114450878567,mmlu:high_school_european_history,validation,0.7433185650152154
165,0.7575757503509521,0.7454545497894287,0.5683999999999999,0.07116477995207812,mmlu:high_school_european_history,test,4.29090039501898
22,0.5,0.5,0.371900826446281,0.16317469694397665,mmlu:high_school_geography,validation,0.6500627159839496
198,0.39393940567970276,0.39393940567970276,0.6106303418803418,0.2625867892997434,mmlu:high_school_geography,test,5.07124640600523
21,0.523809552192688,0.523809552192688,0.8136363636363636,0.22340029761904762,mmlu:high_school_government_and_politics,validation,0.7358298079925589
193,0.6321243643760681,0.6321243643760681,0.6006695913184021,0.10131961971984631,mmlu:high_school_government_and_politics,test,5.006388187990524
43,0.4883720874786377,0.5116279125213623,0.6785714285714286,0.1211845736170924,mmlu:high_school_macroeconomics,validation,1.2606224509654567
390,0.3692307770252228,0.3692307770252228,0.5888380758807588,0.251302086084317,mmlu:high_school_macroeconomics,test,10.06105611298699
29,0.06896551698446274,0.931034505367279,0.5185185185185185,0.10129312811226684,mmlu:high_school_mathematics,validation,0.9445034289965406
270,0.10000000149011612,0.8999999761581421,0.5390946502057613,0.05230034722222223,mmlu:high_school_mathematics,test,7.010627555020619
26,0.3076923191547394,0.3076923191547394,0.6770833333333334,0.43088943224686843,mmlu:high_school_microeconomics,validation,0.9034730709972791
238,0.36554622650146484,0.36554622650146484,0.5659968029230419,0.3634617934707834,mmlu:high_school_microeconomics,test,5.975916352996137
17,0.29411765933036804,0.29411765933036804,0.5333333333333333,0.5381433683283189,mmlu:high_school_physics,validation,0.7432303790119477
151,0.17218543589115143,0.17218543589115143,0.5393846153846154,0.6244308715624526,mmlu:high_school_physics,test,3.934227755002212
60,0.6000000238418579,0.6000000238418579,0.532986111111111,0.06289063692092897,mmlu:high_school_psychology,validation,1.6915898160077631
545,0.5064220428466797,0.5064220428466797,0.543895803027854,0.13599486263520127,mmlu:high_school_psychology,test,13.706138014036696
23,0.17391304671764374,0.260869562625885,0.48684210526315796,0.3547894151314446,mmlu:high_school_statistics,validation,0.7747381609515287
216,0.25925925374031067,0.4444444477558136,0.5819196428571427,0.17871092949752457,mmlu:high_school_statistics,test,5.368394456978422
22,0.7727272510528564,0.7727272510528564,0.6941176470588235,0.17755679921670392,mmlu:high_school_us_history,validation,0.7130250349873677
204,0.6764705777168274,0.6666666865348816,0.5709815546772067,0.05763634279662489,mmlu:high_school_us_history,test,5.3241773509653285
26,0.6538461446762085,0.6538461446762085,0.3790849673202614,0.1532451762602879,mmlu:high_school_world_history,validation,1.050863818032667
237,0.6033755540847778,0.6033755540847778,0.5453801517631304,0.06647218832989783,mmlu:high_school_world_history,test,6.03587310394505
23,0.3913043439388275,0.3913043439388275,0.6547619047619048,0.2894021687300309,mmlu:human_aging,validation,0.815010862017516
223,0.3901345431804657,0.3856502175331116,0.5955882352941176,0.25912626361633095,mmlu:human_aging,test,5.513081144017633
12,0.3333333432674408,0.3333333432674408,0.484375,0.3528645733992259,mmlu:human_sexuality,validation,0.5358366590226069
131,0.5114504098892212,0.5114504098892212,0.5295009328358209,0.1848163263488362,mmlu:human_sexuality,test,3.375076632015407
13,0.6153846383094788,0.6153846383094788,0.19999999999999996,0.2493990522164565,mmlu:international_law,validation,0.48747341299895197
121,0.6280992031097412,0.6280992031097412,0.5809941520467836,0.18365830429329366,mmlu:international_law,test,3.1688923130277544
11,0.1818181872367859,0.1818181872367859,0.3055555555555556,0.5774147727272728,mmlu:jurisprudence,validation,0.5775639270432293
108,0.3611111044883728,0.3611111044883728,0.4243775548123374,0.39051649250366066,mmlu:jurisprudence,test,2.883509836043231
18,0.6666666865348816,0.6666666865348816,0.40277777777777785,0.16297745704650884,mmlu:logical_fallacies,validation,0.6942980600288138
163,0.48466256260871887,0.48466256260871887,0.6503164556962026,0.3347632054902293,mmlu:logical_fallacies,test,4.133779636991676
11,0.27272728085517883,0.27272728085517883,0.6666666666666666,0.37926135279915546,mmlu:machine_learning,validation,0.6019559840206057
112,0.2946428656578064,0.2946428656578064,0.48983505945531264,0.37869698234966825,mmlu:machine_learning,test,2.838552778994199
11,0.6363636255264282,0.6363636255264282,0.2857142857142857,0.17968751083720813,mmlu:management,validation,0.49089537403779104
103,0.42718446254730225,0.4757281541824341,0.7083975346687211,0.14692051896771183,mmlu:management,test,2.6224016069900244
25,0.23999999463558197,0.23999999463558197,0.7236842105263158,0.38749999284744263,mmlu:marketing,validation,0.8413286709692329
234,0.44871795177459717,0.4572649598121643,0.6174603174603176,0.17190839439375785,mmlu:marketing,test,6.002810499980114
11,0.9090909361839294,0.9090909361839294,0.25,0.02769888531077988,mmlu:medical_genetics,validation,0.7361607420025393
100,0.44999998807907104,0.44999998807907104,0.636969696969697,0.40519530534744264,mmlu:medical_genetics,test,2.6600475650047883
86,0.5581395626068115,0.5581395626068115,0.6669407894736842,0.1386264417060586,mmlu:miscellaneous,validation,2.2608168899896555
783,0.618135392665863,0.6168582439422607,0.6567414798640094,0.07797532672321811,mmlu:miscellaneous,test,19.20431321201613
38,0.42105263471603394,0.42105263471603394,0.5923295454545454,0.33141449878090307,mmlu:moral_disputes,validation,1.1020173029974103
346,0.43063583970069885,0.43063583970069885,0.58002589173168,0.30658417802325566,mmlu:moral_disputes,test,8.693117817980237
100,0.4300000071525574,0.4300000071525574,0.38310893512851896,0.15339840948581696,mmlu:moral_scenarios,validation,2.6649007109808736
895,0.38100558519363403,0.38100558519363403,0.4842415067173423,0.19581444889473515,mmlu:moral_scenarios,test,21.76796461601043
33,0.3333333432674408,0.3333333432674408,0.6053719008264463,0.6115056818181818,mmlu:nutrition,validation,1.1536389500251971
306,0.4542483687400818,0.4542483687400818,0.5448455606772067,0.49152367430574756,mmlu:nutrition,test,7.729032427014317
34,0.3235294222831726,0.3235294222831726,0.4565217391304348,0.4526654534480151,mmlu:philosophy,validation,1.110454335983377
311,0.3633440434932709,0.3633440434932709,0.6019263430767855,0.4119774850618418,mmlu:philosophy,test,9.290118767006788
35,0.37142857909202576,0.37142857909202576,0.4615384615384615,0.36372766835348946,mmlu:prehistory,validation,1.2089847990428098
324,0.4413580298423767,0.4413580298423767,0.6203685816945486,0.29833383067154595,mmlu:prehistory,test,8.507985998992808
31,0.16129031777381897,0.8064516186714172,0.5538461538461539,0.18321570850187732,mmlu:professional_accounting,validation,0.9953595389961265
282,0.1879432648420334,0.7730496525764465,0.5805388481502842,0.1387411377108689,mmlu:professional_accounting,test,7.511600531986915
170,0.38235294818878174,0.3705882430076599,0.46014652014652013,0.23419117261381708,mmlu:professional_law,validation,5.006027676980011
1534,0.34810951352119446,0.3722294569015503,0.4986928838951311,0.22904527945033576,mmlu:professional_law,test,39.9985324239824
31,0.35483869910240173,0.3870967626571655,0.4704545454545455,0.2463457584381104,mmlu:professional_medicine,validation,1.0353945870301686
272,0.2904411852359772,0.3235294222831726,0.4939004394307077,0.30553480456857124,mmlu:professional_medicine,test,6.86697005602764
69,0.37681159377098083,0.4057970941066742,0.4825581395348837,0.15896738957667694,mmlu:professional_psychology,validation,1.930029874027241
612,0.3464052379131317,0.3692810535430908,0.5391332547169811,0.20233991829787987,mmlu:professional_psychology,test,15.635175378993154
12,0.1666666716337204,0.1666666716337204,0.3,0.5309244791666667,mmlu:public_relations,validation,0.6596644560340792
110,0.30909091234207153,0.3181818127632141,0.6269349845201239,0.38398437174883754,mmlu:public_relations,test,2.8204737909836695
27,0.5555555820465088,0.5555555820465088,0.7694444444444444,0.19097221118432503,mmlu:security_studies,validation,1.000206951983273
245,0.6612244844436646,0.6612244844436646,0.6191432396251674,0.07820470089815101,mmlu:security_studies,test,6.131084339984227
22,0.5909090638160706,0.5909090638160706,0.7008547008547009,0.10795453461733731,mmlu:sociology,validation,0.8184002469643019
201,0.447761207818985,0.447761207818985,0.5867367367367369,0.23655163233553003,mmlu:sociology,test,5.128536406031344
11,0.7272727489471436,0.7272727489471436,0.6666666666666667,0.10404828461733731,mmlu:us_foreign_policy,validation,0.5642368309781887
100,0.5899999737739563,0.5899999737739563,0.6085159156676313,0.05210936665534976,mmlu:us_foreign_policy,test,2.887018312991131
18,0.5555555820465088,0.5555555820465088,0.5687500000000001,0.18880208333333331,mmlu:virology,validation,0.8054182790219784
166,0.34939759969711304,0.34939759969711304,0.5357598978288634,0.3913780206657318,mmlu:virology,test,4.3158160670427606
19,0.6315789222717285,0.6315789222717285,0.5714285714285714,0.2588404605263158,mmlu:world_religions,validation,0.8542099099722691
171,0.6081871390342712,0.6081871390342712,0.46634615384615385,0.2973775469768814,mmlu:world_religions,test,4.496010543021839
