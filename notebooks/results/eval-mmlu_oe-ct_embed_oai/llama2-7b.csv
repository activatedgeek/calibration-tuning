N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.8181818127632141,0.33333333333333337,0.2613636417822405,mmlu:abstract_algebra,validation,2.116988770896569
100,0.2199999988079071,0.7799999713897705,0.6156759906759908,0.16074220240116116,mmlu:abstract_algebra,test,1.3786989380605519
14,0.2857142984867096,0.2857142984867096,0.75,0.4991629293986729,mmlu:anatomy,validation,0.3158065341413021
135,0.4148148000240326,0.4148148000240326,0.5797920433996383,0.37708333421636514,mmlu:anatomy,test,1.8349893228150904
16,0.4375,0.4375,0.5873015873015873,0.3732910081744194,mmlu:astronomy,validation,0.3507802200037986
152,0.5065789222717285,0.5065789222717285,0.5645021645021645,0.29186367674877767,mmlu:astronomy,test,2.0020830689463764
11,0.6363636255264282,0.6363636255264282,0.3214285714285714,0.32102273269133136,mmlu:business_ethics,validation,0.3203131570480764
100,0.30000001192092896,0.30000001192092896,0.5345238095238096,0.5275390434265137,mmlu:business_ethics,test,1.4343093209899962
29,0.24137930572032928,0.24137930572032928,0.6525974025974026,0.6057381547730544,mmlu:clinical_knowledge,validation,0.5336117609404027
265,0.35849055647850037,0.35849055647850037,0.6052631578947368,0.48357900133672754,mmlu:clinical_knowledge,test,3.64010899909772
16,0.3125,0.3125,0.4545454545454546,0.3813476525247097,mmlu:college_biology,validation,0.32314218604005873
144,0.2986111044883728,0.2916666567325592,0.5543403177527056,0.43958877482348024,mmlu:college_biology,test,1.9431495459284633
8,0.125,0.125,0.4285714285714286,0.5961913987994194,mmlu:college_chemistry,validation,0.2072004519868642
100,0.14000000059604645,0.1599999964237213,0.5323920265780732,0.5783593815565109,mmlu:college_chemistry,test,1.4193355641327798
11,0.0,0.7272727489471436,,0.140625,mmlu:college_computer_science,validation,0.3414594179484993
100,0.17000000178813934,0.5799999833106995,0.5145287030474841,0.10769530057907103,mmlu:college_computer_science,test,1.4578865051735193
11,0.0,1.0,,0.1384943127632141,mmlu:college_mathematics,validation,0.3321410689968616
100,0.1599999964237213,0.8299999833106995,0.613095238095238,0.01710936665534975,mmlu:college_mathematics,test,1.3950134657789022
22,0.3636363744735718,0.3636363744735718,0.7633928571428572,0.42436079816384753,mmlu:college_medicine,validation,0.44986043288372457
173,0.36994218826293945,0.36994218826293945,0.5338302752293578,0.47245302021158914,mmlu:college_medicine,test,2.2750859411899
11,0.27272728085517883,0.27272728085517883,0.7083333333333333,0.58984375,mmlu:college_physics,validation,0.3634979701600969
102,0.14705882966518402,0.14705882966518402,0.47011494252873565,0.7226562464938444,mmlu:college_physics,test,1.4120372331235558
11,0.7272727489471436,0.8181818127632141,0.8333333333333333,0.11221591450951314,mmlu:computer_security,validation,0.3472181048709899
100,0.4300000071525574,0.46000000834465027,0.5944512443900449,0.303320324420929,mmlu:computer_security,test,1.4190071050543338
26,0.3076923191547394,0.692307710647583,0.5104166666666666,0.08203126833989068,mmlu:conceptual_physics,validation,0.5512974290177226
235,0.4127659499645233,0.5829787254333496,0.6092932914985806,0.038464077229195426,mmlu:conceptual_physics,test,3.1116381930187345
12,0.0833333358168602,0.0833333358168602,1.0,0.6149088491996129,mmlu:econometrics,validation,0.35118771088309586
114,0.14912280440330505,0.15789473056793213,0.5285021224984839,0.4984580477078756,mmlu:econometrics,test,1.6006372619885951
16,0.125,0.125,0.5892857142857143,0.7871093638241291,mmlu:electrical_engineering,validation,0.3251814590767026
145,0.1862068921327591,0.1862068921327591,0.5010985561833019,0.7256465578901357,mmlu:electrical_engineering,test,2.038696954958141
41,0.26829269528388977,0.7317073345184326,0.6,0.043445143757796865,mmlu:elementary_mathematics,validation,0.7883710530586541
378,0.32275131344795227,0.6772486567497253,0.48355852971311475,0.10697749399003532,mmlu:elementary_mathematics,test,4.901927516795695
14,0.5,0.5,0.5816326530612245,0.1361607313156128,mmlu:formal_logic,validation,0.34830943308770657
126,0.30158731341362,0.6984127163887024,0.5279605263157895,0.07136654144241694,mmlu:formal_logic,test,1.7430625571869314
10,0.30000001192092896,0.30000001192092896,0.5714285714285714,0.40078125596046443,mmlu:global_facts,validation,0.34890578500926495
100,0.17000000178813934,0.17000000178813934,0.5053153791637136,0.5376953214406966,mmlu:global_facts,test,1.4381919431034476
32,0.15625,0.21875,0.5666666666666667,0.41528319008648396,mmlu:high_school_biology,validation,0.5771281719207764
310,0.41290321946144104,0.4161290228366852,0.5468964629120879,0.24125504859032174,mmlu:high_school_biology,test,3.94621671596542
22,0.13636364042758942,0.13636364042758942,0.6052631578947368,0.6091974350539121,mmlu:high_school_chemistry,validation,0.43605091399513185
203,0.16748768091201782,0.16748768091201782,0.5904977375565612,0.5714093326347802,mmlu:high_school_chemistry,test,2.714683256112039
9,0.2222222238779068,0.2222222238779068,0.4285714285714286,0.3593750132454766,mmlu:high_school_computer_science,validation,0.3351006591692567
100,0.3700000047683716,0.49000000953674316,0.5368940368940369,0.12124999701976776,mmlu:high_school_computer_science,test,1.395252174930647
18,0.7222222089767456,0.2777777910232544,0.6692307692307693,0.4385850694444446,mmlu:high_school_european_history,validation,0.4423907578457147
165,0.6727272868156433,0.34545454382896423,0.5915081748415081,0.368252850301338,mmlu:high_school_european_history,test,2.22613667184487
22,0.4545454680919647,0.4545454680919647,0.7833333333333334,0.2478693290190263,mmlu:high_school_geography,validation,0.4859303389675915
198,0.3636363744735718,0.3636363744735718,0.5498787477954145,0.30151121965562455,mmlu:high_school_geography,test,2.5624939168337733
21,0.4285714328289032,0.4285714328289032,0.34259259259259256,0.15290176016943796,mmlu:high_school_government_and_politics,validation,0.4461932291742414
193,0.48704662919044495,0.4715026021003723,0.4624973135611434,0.1104072014284875,mmlu:high_school_government_and_politics,test,2.6278477399609983
43,0.41860464215278625,0.44186046719551086,0.49777777777777776,0.20139898810275764,mmlu:high_school_macroeconomics,validation,0.7643957759719342
390,0.34358975291252136,0.3589743673801422,0.5637826492537313,0.2626702868021452,mmlu:high_school_macroeconomics,test,5.067969484021887
29,0.03448275849223137,0.9655172228813171,0.9642857142857143,0.15059267857979083,mmlu:high_school_mathematics,validation,0.5529286949895322
270,0.08148147910833359,0.9185185432434082,0.563966275659824,0.09911746471016497,mmlu:high_school_mathematics,test,3.5028727459721267
26,0.3076923191547394,0.6153846383094788,0.5069444444444444,0.1364182967406053,mmlu:high_school_microeconomics,validation,0.5631341449916363
238,0.32773110270500183,0.5798319578170776,0.5459535256410256,0.044413063956909804,mmlu:high_school_microeconomics,test,3.088454628130421
17,0.23529411852359772,0.23529411852359772,0.4615384615384615,0.3876378571285921,mmlu:high_school_physics,validation,0.4005794080439955
151,0.17880794405937195,0.26490065455436707,0.6000597371565113,0.3592197989785908,mmlu:high_school_physics,test,1.9895911919884384
60,0.5,0.5833333134651184,0.5833333333333335,0.05826821327209468,mmlu:high_school_psychology,validation,0.9359128219075501
545,0.5064220428466797,0.5174311995506287,0.5157184418942945,0.016642750840668304,mmlu:high_school_psychology,test,6.9351415450219065
23,0.1304347813129425,0.8260869383811951,0.7,0.20091712733973627,mmlu:high_school_statistics,validation,0.46259334892965853
216,0.24074074625968933,0.7037037014961243,0.48680816135084426,0.09588395224677188,mmlu:high_school_statistics,test,2.7899685432203114
22,0.5909090638160706,0.3181818127632141,0.37179487179487186,0.3224431655623696,mmlu:high_school_us_history,validation,0.4617556289304048
204,0.5980392098426819,0.4313725531101227,0.5091463414634148,0.21011411939181535,mmlu:high_school_us_history,test,2.759384236065671
26,0.5384615659713745,0.42307692766189575,0.449404761904762,0.23016826235331023,mmlu:high_school_world_history,validation,0.5468831830658019
237,0.4345991611480713,0.5654008388519287,0.5056151282422837,0.12244528657776393,mmlu:high_school_world_history,test,3.117339194053784
23,0.21739129722118378,0.21739129722118378,0.5611111111111111,0.5237771661385247,mmlu:human_aging,validation,0.48242462798953056
223,0.340807169675827,0.340807169675827,0.5652971715001791,0.3900819899255385,mmlu:human_aging,test,3.03641001903452
12,0.4166666567325592,0.5,0.6571428571428571,0.2714843600988388,mmlu:human_sexuality,validation,0.3434156961739063
131,0.47328245639801025,0.47328245639801025,0.4898316970546984,0.25256442523184625,mmlu:human_sexuality,test,1.8865449239965528
13,0.23076923191547394,0.23076923191547394,0.31666666666666665,0.379807696892665,mmlu:international_law,validation,0.3603720448445529
121,0.4876033067703247,0.4958677589893341,0.5422361946418809,0.14427297223698007,mmlu:international_law,test,1.7204488718416542
11,0.4545454680919647,0.4545454680919647,0.5333333333333332,0.08842329545454547,mmlu:jurisprudence,validation,0.3412169481161982
108,0.37037035822868347,0.4166666567325592,0.5413602941176471,0.12405959930684832,mmlu:jurisprudence,test,1.526510963914916
18,0.4444444477558136,0.3333333432674408,0.41874999999999996,0.1833767096201579,mmlu:logical_fallacies,validation,0.44951847195625305
163,0.42944785952568054,0.4969325065612793,0.5331797235023041,0.019099882409616464,mmlu:logical_fallacies,test,2.2144842040725052
11,0.27272728085517883,0.7272727489471436,0.7916666666666666,0.2613636472008445,mmlu:machine_learning,validation,0.29004147415980697
112,0.2857142984867096,0.4642857015132904,0.6285156249999999,0.10581753881914277,mmlu:machine_learning,test,1.5102724258322269
11,0.4545454680919647,0.6363636255264282,0.7,0.12144888531077991,mmlu:management,validation,0.35234798211604357
103,0.4563106894493103,0.49514561891555786,0.6183510638297872,0.10546875694423044,mmlu:management,test,1.4557283779140562
25,0.2800000011920929,0.2800000011920929,0.5238095238095237,0.46453125000000006,mmlu:marketing,validation,0.5207210269290954
234,0.4572649598121643,0.4572649598121643,0.6123335050408419,0.3024672845489958,mmlu:marketing,test,3.1270545651204884
11,0.7272727489471436,0.7272727489471436,0.33333333333333337,0.2698863744735718,mmlu:medical_genetics,validation,0.3538891579955816
100,0.4699999988079071,0.4699999988079071,0.6949016459253312,0.4396484273672103,mmlu:medical_genetics,test,1.4478679930325598
86,0.5465116500854492,0.45348837971687317,0.5324604473540644,0.16728744395943576,mmlu:miscellaneous,validation,1.3076164769008756
783,0.5874840617179871,0.4687100946903229,0.526241755283349,0.14029073699985276,mmlu:miscellaneous,test,9.947611804120243
38,0.42105263471603394,0.42105263471603394,0.5497159090909091,0.3005756516205637,mmlu:moral_disputes,validation,0.66120569803752
346,0.41040462255477905,0.41329479217529297,0.5597210715272024,0.27693732298178475,mmlu:moral_disputes,test,4.4216935120057315
100,0.3499999940395355,0.5199999809265137,0.4731868131868132,0.028437500000000036,mmlu:moral_scenarios,validation,1.4845943008549511
895,0.3173184394836426,0.5966480374336243,0.49606682649086004,0.06062322974870986,mmlu:moral_scenarios,test,11.413778454065323
33,0.3636363744735718,0.3636363744735718,0.5753968253968256,0.3836411093220566,mmlu:nutrition,validation,0.6829923409968615
306,0.38235294818878174,0.379084974527359,0.5814905259349704,0.29173047441283084,mmlu:nutrition,test,3.9796421818900853
34,0.29411765933036804,0.29411765933036804,0.475,0.3871782965519849,mmlu:philosophy,validation,0.6601657702121884
311,0.3247588276863098,0.3279742896556854,0.4999528524281,0.343762561247663,mmlu:philosophy,test,3.956369796069339
35,0.3142857253551483,0.2857142984867096,0.5965909090909091,0.40200891835348945,mmlu:prehistory,validation,0.6449507558718324
324,0.4166666567325592,0.4413580298423767,0.5724279835390946,0.24294705504988445,mmlu:prehistory,test,4.232016986003146
31,0.12903225421905518,0.12903225421905518,0.3472222222222222,0.5551915361035255,mmlu:professional_accounting,validation,0.568894725991413
282,0.152482271194458,0.1631205677986145,0.549625377055561,0.5216921341757403,mmlu:professional_accounting,test,3.665428234031424
170,0.3117647171020508,0.6882352828979492,0.5299145299145299,0.044370389335295746,mmlu:professional_law,validation,2.4055126840248704
1534,0.2777053415775299,0.721642792224884,0.5254805003305028,0.027865752597209543,mmlu:professional_law,test,19.292361901141703
31,0.4193548262119293,0.4193548262119293,0.4850427350427351,0.21219758449062223,mmlu:professional_medicine,validation,0.5583367918152362
272,0.27941176295280457,0.5404411554336548,0.5436023093447906,0.06278720322777244,mmlu:professional_medicine,test,3.5889943779911846
69,0.3913043439388275,0.37681159377098083,0.5868606701940035,0.28442030022109765,mmlu:professional_psychology,validation,1.0704962031450123
612,0.30882352590560913,0.36437907814979553,0.4999437127096702,0.2586550391187855,mmlu:professional_psychology,test,7.892271416960284
12,0.4166666567325592,0.3333333432674408,0.5428571428571428,0.26171875,mmlu:public_relations,validation,0.3553443739656359
110,0.3181818127632141,0.3181818127632141,0.5348571428571428,0.2634943311864679,mmlu:public_relations,test,1.5399872118141502
27,0.5925925970077515,0.5925925970077515,0.6164772727272727,0.1944444356141267,mmlu:security_studies,validation,0.5865003310609609
245,0.5306122303009033,0.5306122303009033,0.5762541806020066,0.24443557335405933,mmlu:security_studies,test,3.2320283378940076
22,0.3181818127632141,0.7272727489471436,0.657142857142857,0.17045454003594135,mmlu:sociology,validation,0.46320110210217535
201,0.3781094551086426,0.6318408250808716,0.6096315789473684,0.04864349887145694,mmlu:sociology,test,2.7154528838582337
11,0.6363636255264282,0.6363636255264282,0.5714285714285714,0.16441760279915552,mmlu:us_foreign_policy,validation,0.3331760901492089
100,0.5799999833106995,0.5799999833106995,0.5272988505747127,0.16117188692092896,mmlu:us_foreign_policy,test,1.4111659349873662
18,0.5,0.5,0.4506172839506173,0.3502604199780358,mmlu:virology,validation,0.45406336593441665
166,0.3313252925872803,0.3313252925872803,0.5302211302211302,0.518942935639117,mmlu:virology,test,2.240890401881188
19,0.7368420958518982,0.5263158082962036,0.5857142857142857,0.03207237155813919,mmlu:world_religions,validation,0.4662020050454885
171,0.5847952961921692,0.4912280738353729,0.48640845070422534,0.07038104987283895,mmlu:world_religions,test,2.288409628206864
