N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.0,1.0,,0.25239661065014923,mmlu:abstract_algebra,validation,27.934439415112138
100,0.3499999940395355,0.6200000047683716,0.3789010989010989,0.08012320816516874,mmlu:abstract_algebra,test,224.9466634131968
14,0.2857142984867096,0.7142857313156128,0.8,0.1512260607310704,mmlu:anatomy,validation,9.849241215735674
135,0.4148148000240326,0.7111110687255859,0.41150542495479203,0.03964508330380476,mmlu:anatomy,test,98.44282106682658
16,0.5,0.6875,0.34375,0.1277349889278412,mmlu:astronomy,validation,17.864614855498075
152,0.5394737124443054,0.6447368264198303,0.45897212543554,0.04928081168940195,mmlu:astronomy,test,164.1830640938133
11,0.3636363744735718,0.6363636255264282,0.75,0.090830997987227,mmlu:business_ethics,validation,9.084785597398877
100,0.3400000035762787,0.5399999618530273,0.6468360071301248,0.08666425704956053,mmlu:business_ethics,test,106.78608571365476
29,0.13793103396892548,0.7241379022598267,0.57,0.08904328222932482,mmlu:clinical_knowledge,validation,32.58675207570195
265,0.3358490467071533,0.7094339728355408,0.4421284473953013,0.05222237245091854,mmlu:clinical_knowledge,test,872.0705386325717
16,0.3125,0.75,0.4727272727272728,0.07372630760073659,mmlu:college_biology,validation,25.630984669551253
144,0.3611111044883728,0.7430555820465088,0.48254598662207354,0.07779782679345876,mmlu:college_biology,test,172.44675376825035
8,0.0,1.0,,0.33288728445768356,mmlu:college_chemistry,validation,9.469239104539156
100,0.17000000178813934,0.8799999952316284,0.5315379163713677,0.16644308388233184,mmlu:college_chemistry,test,115.99727992154658
11,0.27272728085517883,0.8181818723678589,0.16666666666666666,0.21381125125018036,mmlu:college_computer_science,validation,15.762386469170451
100,0.25,0.7999999523162842,0.4952,0.10018129646778107,mmlu:college_computer_science,test,130.90779942460358
11,0.0,1.0,,0.22454239021648062,mmlu:college_mathematics,validation,31.527330609038472
100,0.10999999940395355,0.8799999952316284,0.30847803881511754,0.10587307393550874,mmlu:college_mathematics,test,197.55560594797134
22,0.4545454680919647,0.6818181872367859,0.30833333333333335,0.24735581874847412,mmlu:college_medicine,validation,25.10579756833613
173,0.4393063485622406,0.6705201864242554,0.5200759631036354,0.08202587283415602,mmlu:college_medicine,test,196.7462677191943
11,0.27272728085517883,0.8181818723678589,0.0,0.1915777271444147,mmlu:college_physics,validation,10.519732976332307
102,0.13725490868091583,0.8333333730697632,0.36485389610389607,0.12437305380316344,mmlu:college_physics,test,121.87508170865476
11,0.5454545617103577,0.6363636255264282,0.4833333333333334,0.1162266731262207,mmlu:computer_security,validation,8.910660307854414
100,0.5099999904632568,0.6399999856948853,0.525610244097639,0.01542596817016599,mmlu:computer_security,test,101.87958656065166
26,0.42307692766189575,0.6153846383094788,0.6909090909090909,0.2156027280367338,mmlu:conceptual_physics,validation,25.35983157902956
235,0.4382978677749634,0.612765908241272,0.3927625772285966,0.10266542891238598,mmlu:conceptual_physics,test,181.8187821432948
12,0.3333333432674408,0.5,0.734375,0.22253514826297763,mmlu:econometrics,validation,15.459538294002414
114,0.1666666716337204,0.6578947305679321,0.6293628808864266,0.05956873715969556,mmlu:econometrics,test,213.7244447041303
16,0.3125,0.875,0.2909090909090909,0.12992137670516968,mmlu:electrical_engineering,validation,29.83295141160488
145,0.2620689570903778,0.751724123954773,0.45696015740285295,0.05473272430485691,mmlu:electrical_engineering,test,210.54920579493046
41,0.24390242993831635,0.7804877758026123,0.5806451612903226,0.18314110942003206,mmlu:elementary_mathematics,validation,46.739161249250174
378,0.32804232835769653,0.7354497313499451,0.45659766319532635,0.09291861328498398,mmlu:elementary_mathematics,test,411.282085897401
14,0.2857142984867096,0.7142857313156128,0.4375,0.059564024209976196,mmlu:formal_logic,validation,19.75049166753888
126,0.2936508059501648,0.6746032238006592,0.49969632553902216,0.048749910460578055,mmlu:formal_logic,test,203.35029654949903
10,0.20000000298023224,0.800000011920929,0.5625,0.11626329421997073,mmlu:global_facts,validation,12.325143966823816
100,0.14999999105930328,0.7799999713897705,0.46392156862745093,0.12041477501392366,mmlu:global_facts,test,103.8738704957068
32,0.34375,0.71875,0.5238095238095238,0.10073582269251347,mmlu:high_school_biology,validation,34.331038096919656
310,0.43870967626571655,0.6935483813285828,0.4802019945909398,0.022537200489351813,mmlu:high_school_biology,test,349.9504055362195
22,0.27272728085517883,0.7727273106575012,0.3020833333333333,0.10587958043271845,mmlu:high_school_chemistry,validation,29.166929146274924
203,0.22660097479820251,0.7980295419692993,0.4171282193298255,0.10339361341128794,mmlu:high_school_chemistry,test,239.08717343211174
9,0.7777777910232544,0.6666666865348816,0.7857142857142857,0.34400935305489433,mmlu:high_school_computer_science,validation,13.808740518987179
100,0.38999998569488525,0.699999988079071,0.5088272383354351,0.05334363520145416,mmlu:high_school_computer_science,test,158.27015636861324
22,0.5,0.7272727489471436,0.6487603305785123,0.1089308126406236,mmlu:high_school_geography,validation,23.847875339910388
198,0.4141414165496826,0.7424242496490479,0.5166631623212783,0.07319018244743349,mmlu:high_school_geography,test,231.34542635083199
21,0.4761904776096344,0.9047619104385376,0.5181818181818182,0.2355606783004034,mmlu:high_school_government_and_politics,validation,18.22376550361514
193,0.590673565864563,0.7046632170677185,0.6500666222518321,0.036975510379811026,mmlu:high_school_government_and_politics,test,176.37560757249594
43,0.44186046719551086,0.6976743936538696,0.2642543859649123,0.10462547596110851,mmlu:high_school_macroeconomics,validation,60.23857606947422
390,0.34871795773506165,0.7102564573287964,0.3698471514590088,0.0398804498024476,mmlu:high_school_macroeconomics,test,546.2911941278726
29,0.06896551698446274,0.8965517282485962,0.2685185185185185,0.1704080413127768,mmlu:high_school_mathematics,validation,26.880623657256365
270,0.0962962955236435,0.8999999761581421,0.3489123581336696,0.1462825437386831,mmlu:high_school_mathematics,test,288.64740951545537
26,0.38461539149284363,0.7307692766189575,0.559375,0.15607497783807608,mmlu:high_school_microeconomics,validation,34.73056966252625
238,0.3781512677669525,0.6428571939468384,0.5762387387387388,0.038068609828708584,mmlu:high_school_microeconomics,test,332.8490351270884
17,0.23529411852359772,0.7647058963775635,0.4807692307692307,0.1810941345551435,mmlu:high_school_physics,validation,24.867187831550837
151,0.19205297529697418,0.7947019934654236,0.42580553985302433,0.06422911100829672,mmlu:high_school_physics,test,188.37036952748895
60,0.6166666746139526,0.7666667103767395,0.5916568742655699,0.14846272071202593,mmlu:high_school_psychology,validation,55.128177454695106
545,0.5119265913963318,0.6697247624397278,0.5585064812569058,0.016540718297345932,mmlu:high_school_psychology,test,534.63746182248
23,0.17391304671764374,0.739130437374115,0.7763157894736842,0.17423646087231842,mmlu:high_school_statistics,validation,64.63183859735727
216,0.2777777910232544,0.6990740895271301,0.5325854700854702,0.055343630965109206,mmlu:high_school_statistics,test,639.6046336274594
22,0.7727273106575012,0.7272727489471436,0.8529411764705881,0.19739307598634198,mmlu:high_school_us_history,validation,41.878820687532425
204,0.686274528503418,0.75,0.7607700892857143,0.08283245358981337,mmlu:high_school_us_history,test,420.63495015352964
23,0.52173912525177,0.5652173757553101,0.35984848484848486,0.1596907895544301,mmlu:human_aging,validation,21.783485190942883
223,0.39910316467285156,0.6681614518165588,0.4727066912627872,0.04958070366906478,mmlu:human_aging,test,238.88921664468944
12,0.5,0.6666666865348816,0.27777777777777773,0.11302804946899414,mmlu:human_sexuality,validation,18.19721296802163
131,0.49618321657180786,0.6106870174407959,0.47412587412587415,0.07110425852637255,mmlu:human_sexuality,test,159.1583115812391
13,0.46153849363327026,0.692307710647583,0.45238095238095244,0.31600943895486683,mmlu:international_law,validation,22.132222708314657
121,0.6198346614837646,0.652892529964447,0.46855072463768116,0.040902206227799096,mmlu:international_law,test,195.54234293289483
11,0.27272728085517883,0.8181818723678589,0.5208333333333333,0.3234930255196311,mmlu:jurisprudence,validation,10.41991676390171
108,0.37962964177131653,0.7129629850387573,0.469421186749181,0.07554572048010649,mmlu:jurisprudence,test,108.90415633283556
18,0.6666666865348816,0.7222222089767456,0.6527777777777778,0.23945396145184836,mmlu:logical_fallacies,validation,16.540606947615743
163,0.4417177736759186,0.6932514905929565,0.6211080586080586,0.033314757551883636,mmlu:logical_fallacies,test,173.4359294231981
11,0.27272728085517883,0.7272727489471436,0.16666666666666666,0.24047646197405728,mmlu:machine_learning,validation,12.384761994704604
112,0.25,0.723214328289032,0.48235544217687076,0.060576877955879516,mmlu:machine_learning,test,100.95740870758891
11,0.5454545617103577,0.6363636255264282,0.7166666666666667,0.11370091004805132,mmlu:management,validation,7.49984055198729
103,0.40776699781417847,0.7669903039932251,0.4389149102263856,0.11611618868355614,mmlu:management,test,85.58136517368257
25,0.23999999463558197,0.6800000071525574,0.35964912280701755,0.1019266176223755,mmlu:marketing,validation,54.569624334573746
234,0.4401709735393524,0.7307692766189575,0.4707996739049878,0.09199777754962955,mmlu:marketing,test,452.9418363031
11,0.6363636255264282,0.6363636255264282,0.6964285714285714,0.19791783527894455,mmlu:medical_genetics,validation,21.386648263782263
100,0.429999977350235,0.7099999785423279,0.5410036719706243,0.05834820985794066,mmlu:medical_genetics,test,160.96811206266284
38,0.5263158082962036,0.6578947305679321,0.49722222222222223,0.08967248075886776,mmlu:moral_disputes,validation,36.64981543086469
346,0.39017340540885925,0.6300578117370605,0.5372125680182552,0.024356148146480475,mmlu:moral_disputes,test,333.0962333958596
33,0.27272728085517883,0.7272727489471436,0.4722222222222222,0.11918427546819052,mmlu:nutrition,validation,39.34720432013273
306,0.46078431606292725,0.7189542651176453,0.5835804857081454,0.05883657114178528,mmlu:nutrition,test,989.2815062701702
34,0.3235294222831726,0.7352941036224365,0.7608695652173912,0.08693362860118639,mmlu:philosophy,validation,23.339226799085736
311,0.3858520984649658,0.6463022232055664,0.5959424083769633,0.03626097360224586,mmlu:philosophy,test,228.34255603514612
35,0.4000000059604645,0.6285714507102966,0.41496598639455784,0.19535165003367833,mmlu:prehistory,validation,40.82035312615335
324,0.42592594027519226,0.6666666865348816,0.4464118747078074,0.01603554225998158,mmlu:prehistory,test,329.39939441904426
69,0.4057971239089966,0.6376811861991882,0.6916376306620209,0.04959953867870828,mmlu:professional_psychology,validation,169.1251634415239
612,0.3415032625198364,0.6666666865348816,0.5529046505277405,0.024570276145062412,mmlu:professional_psychology,test,1425.118175374344
12,0.25,0.75,0.3703703703703704,0.18711610635121664,mmlu:public_relations,validation,9.21886383742094
110,0.33636361360549927,0.7363635897636414,0.44983339503887454,0.12458795038136566,mmlu:public_relations,test,84.82344754971564
27,0.7037037014961243,0.8148148059844971,0.5098684210526315,0.23216219743092856,mmlu:security_studies,validation,42.74050621315837
245,0.6489795446395874,0.636734664440155,0.4585344449319877,0.07795422223149513,mmlu:security_studies,test,446.73019884712994
22,0.5454545617103577,0.7272727489471436,0.4541666666666666,0.10218633575872943,mmlu:sociology,validation,25.51516438089311
201,0.4527363181114197,0.6716417670249939,0.5615884115884117,0.0699456772994046,mmlu:sociology,test,188.82980722934008
11,0.6363636255264282,0.7272727489471436,0.6964285714285714,0.24148452823812314,mmlu:us_foreign_policy,validation,11.576594052836299
100,0.5999999642372131,0.7199999690055847,0.5870833333333334,0.06812508225440982,mmlu:us_foreign_policy,test,104.59672016836703
18,0.5,0.5555555820465088,0.4135802469135802,0.26432601941956413,mmlu:virology,validation,18.657626951113343
166,0.379518061876297,0.6867469549179077,0.487286176606565,0.03986777419067292,mmlu:virology,test,190.28842679597437
19,0.6842105388641357,0.7894737124443054,0.75,0.12337030862507067,mmlu:world_religions,validation,18.828657129779458
171,0.6023392081260681,0.7309941649436951,0.7680611079383209,0.07063287705705877,mmlu:world_religions,test,128.09840663336217
