N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.7272727489471436,0.09999999999999998,0.2413062236525796,mmlu:abstract_algebra,validation,45.81772501207888
100,0.23999999463558197,0.7299999594688416,0.34621710526315785,0.0720565730333328,mmlu:abstract_algebra,test,391.3043075799942
14,0.2857142984867096,0.8571429252624512,0.55,0.2053089780466897,mmlu:anatomy,validation,53.40050230920315
135,0.4740740656852722,0.6740740537643433,0.5269586267605634,0.051104130568327716,mmlu:anatomy,test,523.7366944365203
16,0.3125,0.75,0.5272727272727272,0.15469028800725937,mmlu:astronomy,validation,63.98449452780187
152,0.46710526943206787,0.7565789818763733,0.562945574682664,0.0864860297817933,mmlu:astronomy,test,595.8629664126784
11,0.4545454680919647,0.8181818723678589,0.4,0.24796730821782892,mmlu:business_ethics,validation,42.95887224748731
100,0.3199999928474426,0.6800000071525574,0.5045955882352942,0.0949521952867508,mmlu:business_ethics,test,393.5805500522256
29,0.24137930572032928,0.7586206793785095,0.41558441558441556,0.12819012074634947,mmlu:clinical_knowledge,validation,112.9574979916215
265,0.324528306722641,0.7735849022865295,0.501851370663895,0.05150004760274345,mmlu:clinical_knowledge,test,1028.1028860360384
16,0.25,0.75,0.6458333333333334,0.18558189272880554,mmlu:college_biology,validation,63.58275347948074
144,0.4375,0.7152777910232544,0.5205761316872428,0.07881455827090476,mmlu:college_biology,test,564.3228176832199
8,0.125,1.0,0.1428571428571429,0.2536490336060524,mmlu:college_chemistry,validation,31.132769213989377
100,0.1899999976158142,0.85999995470047,0.49480181936322293,0.17525419056415556,mmlu:college_chemistry,test,396.3138678204268
11,0.1818181872367859,0.8181818723678589,0.2777777777777778,0.19405355236747046,mmlu:college_computer_science,validation,44.45558593608439
100,0.2199999988079071,0.7899999618530273,0.4344405594405594,0.1550886130332947,mmlu:college_computer_science,test,407.274509685114
11,0.09090909361839294,0.9090909361839294,0.19999999999999996,0.19487571716308594,mmlu:college_mathematics,validation,43.62176993303001
100,0.10999999940395355,0.8899999856948853,0.2783452502553626,0.11545628190040585,mmlu:college_mathematics,test,399.49892843700945
22,0.5454545617103577,0.7272727489471436,0.5875,0.06658165021376176,mmlu:college_medicine,validation,82.02434272132814
173,0.31213873624801636,0.710982620716095,0.6269063180827887,0.04266163207202977,mmlu:college_medicine,test,644.0929021071643
11,0.3636363744735718,0.8181818723678589,0.6071428571428571,0.1205762678926641,mmlu:college_physics,validation,41.48581047169864
102,0.21568627655506134,0.6960784792900085,0.6795454545454546,0.13603502395106296,mmlu:college_physics,test,380.4438771326095
11,0.3636363744735718,0.6363636255264282,0.7321428571428572,0.253556023944508,mmlu:computer_security,validation,40.52055133320391
100,0.4599999785423279,0.6299999952316284,0.4150563607085346,0.04357029259204864,mmlu:computer_security,test,366.0691966712475
26,0.3076923191547394,0.6538462042808533,0.2534722222222222,0.20342836242455703,mmlu:conceptual_physics,validation,97.88739710114896
235,0.46382978558540344,0.612765908241272,0.3561598951507209,0.1606227867146756,mmlu:conceptual_physics,test,861.1745760645717
12,0.1666666716337204,0.8333333730697632,0.9500000000000001,0.16352543234825132,mmlu:econometrics,validation,45.876867623999715
114,0.15789473056793213,0.8245614171028137,0.6053240740740741,0.1726519585701457,mmlu:econometrics,test,423.4792823884636
16,0.4375,0.625,0.7460317460317459,0.15625744685530663,mmlu:electrical_engineering,validation,58.24904992617667
145,0.22758620977401733,0.7793103456497192,0.4082792207792208,0.0555812671266753,mmlu:electrical_engineering,test,532.6567057650536
41,0.2682926654815674,0.7317072749137878,0.40454545454545454,0.06703373280967155,mmlu:elementary_mathematics,validation,155.61235125735402
378,0.36772486567497253,0.6507936120033264,0.37580145088949757,0.11925368964987457,mmlu:elementary_mathematics,test,1403.3068445548415
14,0.4285714626312256,0.6428571939468384,0.08333333333333333,0.19120415619441436,mmlu:formal_logic,validation,51.9248973056674
126,0.2063492238521576,0.7698413133621216,0.5653846153846153,0.07544910718524268,mmlu:formal_logic,test,468.10129937157035
10,0.20000000298023224,0.699999988079071,0.59375,0.1362044036388397,mmlu:global_facts,validation,36.91628476604819
100,0.2199999988079071,0.7299999594688416,0.5195221445221445,0.06890681207180024,mmlu:global_facts,test,974.8443951234221
32,0.375,0.625,0.5083333333333333,0.13506466709077358,mmlu:high_school_biology,validation,122.40822261199355
310,0.47096773982048035,0.6064516305923462,0.33152355496157704,0.13396683739077667,mmlu:high_school_biology,test,1167.3451989628375
22,0.1818181872367859,0.8636363744735718,0.29166666666666663,0.10554483261975378,mmlu:high_school_chemistry,validation,82.24813585169613
203,0.1822660118341446,0.8029556274414062,0.2982741777922501,0.09305745598130624,mmlu:high_school_chemistry,test,751.3540102820843
9,0.2222222238779068,0.7777777910232544,0.7142857142857143,0.24749624729156494,mmlu:high_school_computer_science,validation,35.19376285560429
100,0.47999998927116394,0.7199999690055847,0.6011618589743589,0.0611274468898773,mmlu:high_school_computer_science,test,376.43486747704446
22,0.4545454680919647,0.6363636255264282,0.45416666666666666,0.09458837454969231,mmlu:high_school_geography,validation,81.88549463450909
198,0.39393940567970276,0.7020202279090881,0.35491452991452993,0.05563682558560612,mmlu:high_school_geography,test,725.367428664118
21,0.4761904776096344,0.523809552192688,0.5954545454545453,0.2686914773214431,mmlu:high_school_government_and_politics,validation,78.13240404985845
193,0.5181347131729126,0.6580310463905334,0.6429569892473117,0.07039688072056353,mmlu:high_school_government_and_politics,test,708.0999107230455
43,0.41860464215278625,0.6511628031730652,0.39222222222222225,0.11295520011768787,mmlu:high_school_macroeconomics,validation,156.0816200952977
390,0.34358975291252136,0.6948718428611755,0.30070837220149255,0.06682343146739864,mmlu:high_school_macroeconomics,test,1431.5468495097011
29,0.17241379618644714,0.8275861740112305,0.525,0.009498252950865685,mmlu:high_school_mathematics,validation,107.37676622346044
270,0.10000000149011612,0.9074074029922485,0.29599146471574456,0.09909724173722448,mmlu:high_school_mathematics,test,986.2422007247806
26,0.3461538553237915,0.6153846383094788,0.3464052287581699,0.05063487245486332,mmlu:high_school_microeconomics,validation,96.53048644773662
238,0.3613445460796356,0.7436975240707397,0.5040544675642595,0.05844426029870493,mmlu:high_school_microeconomics,test,868.0764838829637
17,0.1764705926179886,0.7647058963775635,0.9523809523809523,0.1412309443249422,mmlu:high_school_physics,validation,62.86102091148496
151,0.251655638217926,0.6225165724754333,0.6000232883092688,0.10658518881197793,mmlu:high_school_physics,test,562.2280608303845
60,0.5666667222976685,0.7500000596046448,0.7268099547511312,0.09074676831563314,mmlu:high_school_psychology,validation,220.5481778047979
545,0.5412843823432922,0.6642202138900757,0.658128813559322,0.0493451063786078,mmlu:high_school_psychology,test,2030.1241434123367
23,0.1304347813129425,0.739130437374115,0.8833333333333333,0.08123152411502343,mmlu:high_school_statistics,validation,91.97105656936765
216,0.25,0.6666666865348816,0.5643004115226335,0.05256365212025465,mmlu:high_school_statistics,test,815.6286028251052
22,0.6363636255264282,0.6818181872367859,0.42410714285714285,0.06532739238305524,mmlu:high_school_us_history,validation,95.75099010765553
204,0.6372549533843994,0.6323529481887817,0.42011434511434514,0.09106084353783551,mmlu:high_school_us_history,test,903.1539846602827
23,0.260869562625885,0.739130437374115,0.27941176470588236,0.050744375456934374,mmlu:human_aging,validation,83.78106613084674
223,0.3677130341529846,0.7443946599960327,0.34327970939283864,0.043371337946220334,mmlu:human_aging,test,815.4322581589222
12,0.25,0.75,0.3888888888888889,0.35682431856791175,mmlu:human_sexuality,validation,43.689970226958394
131,0.3893129825592041,0.7557252049446106,0.39362745098039215,0.07679717367842001,mmlu:human_sexuality,test,478.78571991063654
13,0.3076923191547394,0.692307710647583,0.4722222222222222,0.20746950002817008,mmlu:international_law,validation,48.0042726919055
121,0.5371900796890259,0.5371900796890259,0.4244505494505495,0.08164221935035769,mmlu:international_law,test,448.94035384617746
11,0.3636363744735718,0.7272727489471436,0.5892857142857143,0.21831500530242923,mmlu:jurisprudence,validation,40.235727071762085
108,0.40740740299224854,0.6851851940155029,0.46253551136363635,0.0564255079737416,mmlu:jurisprudence,test,399.17070010490716
18,0.6111111044883728,0.944444477558136,0.9675324675324675,0.21669673919677734,mmlu:logical_fallacies,validation,65.49293920770288
163,0.47239261865615845,0.7668711543083191,0.7063575958924797,0.09214963210872346,mmlu:logical_fallacies,test,597.5623920187354
11,0.27272728085517883,0.9090909361839294,0.6666666666666666,0.21386792443015357,mmlu:machine_learning,validation,40.48856005072594
112,0.25,0.723214328289032,0.41581632653061223,0.11800683928387509,mmlu:machine_learning,test,413.52720284834504
11,0.7272727489471436,0.27272728085517883,0.5,0.4009226072918285,mmlu:management,validation,39.27383426390588
103,0.4466019570827484,0.6893203854560852,0.38558352402745993,0.0626766045116684,mmlu:management,test,316.5743648800999
25,0.2800000011920929,0.4399999976158142,0.4801587301587301,0.24088605165481566,mmlu:marketing,validation,93.67941214330494
234,0.47435900568962097,0.6581196784973145,0.5220098146927415,0.02429850233925715,mmlu:marketing,test,859.7166383638978
11,0.7272727489471436,0.8181818723678589,0.75,0.16107637773860584,mmlu:medical_genetics,validation,40.596231780946255
100,0.47999998927116394,0.7299999594688416,0.4975961538461539,0.08078317046165466,mmlu:medical_genetics,test,363.0977057572454
38,0.28947368264198303,0.7894737124443054,0.6599326599326599,0.13353558276828972,mmlu:moral_disputes,validation,140.45280126482248
346,0.43352600932121277,0.6445086598396301,0.4063605442176871,0.022963917152040988,mmlu:moral_disputes,test,1274.5267103035003
33,0.3030303120613098,0.696969747543335,0.4260869565217391,0.20045780774318817,mmlu:nutrition,validation,120.97240527719259
306,0.38562092185020447,0.6830065250396729,0.545708618824378,0.055880408466251856,mmlu:nutrition,test,1119.7999940682203
34,0.2647058963775635,0.7058823704719543,0.6422222222222222,0.18907286840326645,mmlu:philosophy,validation,122.84334647841752
311,0.3376205861568451,0.6784566044807434,0.5090846047156727,0.06725110635880105,mmlu:philosophy,test,1135.9162128400058
35,0.2857142984867096,0.800000011920929,0.324,0.15530824150357928,mmlu:prehistory,validation,128.30722765997052
324,0.4753086566925049,0.6574074029922485,0.4466004583651642,0.08112897549146489,mmlu:prehistory,test,1198.8801199961454
69,0.37681159377098083,0.47826087474823,0.6028622540250448,0.2148579350416211,mmlu:professional_psychology,validation,255.81180600635707
612,0.3137255012989044,0.6388888955116272,0.5763144841269843,0.06024341548190395,mmlu:professional_psychology,test,2276.7420679330826
12,0.25,0.8333333730697632,0.2592592592592593,0.1665633718172709,mmlu:public_relations,validation,44.30678955838084
110,0.3181818127632141,0.7272726893424988,0.4419047619047619,0.14785666249015111,mmlu:public_relations,test,404.7819944601506
27,0.48148149251937866,0.5925925970077515,0.5247252747252747,0.2288022019245006,mmlu:security_studies,validation,100.49279174208641
245,0.5346938371658325,0.6571428179740906,0.4518548279094683,0.030305459304731736,mmlu:security_studies,test,915.5450870804489
22,0.5454545617103577,0.5454545617103577,0.19583333333333333,0.27697406302798877,mmlu:sociology,validation,81.08511197380722
201,0.3980099558830261,0.6716417670249939,0.33429752066115703,0.07815290386997056,mmlu:sociology,test,744.1297702677548
11,0.4545454680919647,0.7272727489471436,0.6666666666666667,0.25224205038764264,mmlu:us_foreign_policy,validation,40.55172913894057
100,0.6200000047683716,0.7400000095367432,0.6426146010186757,0.0617474293708801,mmlu:us_foreign_policy,test,368.48647930286825
18,0.2777777910232544,0.7777777910232544,0.26153846153846155,0.23080530431535506,mmlu:virology,validation,66.80089591629803
166,0.3674698770046234,0.6626505851745605,0.3088992974238876,0.09830177440700759,mmlu:virology,test,608.3240698445588
19,0.6842105388641357,0.8421052694320679,0.5897435897435898,0.11611894557350559,mmlu:world_religions,validation,66.33632515743375
171,0.6432748436927795,0.7309941649436951,0.6935916542473919,0.04474008397052163,mmlu:world_religions,test,620.8136607334018
