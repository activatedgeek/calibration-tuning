N,fuzzy_gpt-3.5-turbo-1106_acc,fuzzy_gpt-3.5-turbo-1106_unc_acc,fuzzy_gpt-3.5-turbo-1106_unc_auroc,fuzzy_gpt-3.5-turbo-1106_unc_ece,dataset,split,ts
11,0.1818181872367859,0.8181818723678589,0.6666666666666667,0.1497006145390597,mmlu:abstract_algebra,validation,36.15465486049652
100,0.22999998927116394,0.7299999594688416,0.4023150762281197,0.07816322863101959,mmlu:abstract_algebra,test,314.03575145453215
14,0.2857142984867096,0.7142857313156128,0.25,0.24344594563756666,mmlu:anatomy,validation,44.691030234098434
135,0.4148148000240326,0.6518518328666687,0.35849909584086803,0.10129699177212183,mmlu:anatomy,test,462.1801784336567
16,0.5,0.6875,0.53125,0.16451507806777957,mmlu:astronomy,validation,56.13411611877382
152,0.5,0.7434210777282715,0.5399930747922437,0.08896703076990028,mmlu:astronomy,test,507.7529337145388
11,0.6363636255264282,0.4545454680919647,0.8392857142857142,0.3133416609330611,mmlu:business_ethics,validation,36.92747194506228
100,0.32999998331069946,0.429999977350235,0.7356399819086387,0.28447028815746306,mmlu:business_ethics,test,330.8104244787246
29,0.27586206793785095,0.7586206793785095,0.3571428571428572,0.09401329837996383,mmlu:clinical_knowledge,validation,94.43250069394708
265,0.3698113262653351,0.7132075428962708,0.4801417573017231,0.06428932828723259,mmlu:clinical_knowledge,test,884.9652772154659
16,0.25,0.75,0.0729166666666667,0.23337581753730774,mmlu:college_biology,validation,53.03064227476716
144,0.3125,0.6666666865348816,0.3529741863075197,0.08366534445020887,mmlu:college_biology,test,481.7719557899982
8,0.125,0.875,0.2857142857142857,0.2970215976238251,mmlu:college_chemistry,validation,27.213736237958074
100,0.10999999940395355,0.85999995470047,0.14913176710929518,0.11863979220390318,mmlu:college_chemistry,test,333.8340433202684
11,0.0,0.9090909361839294,,0.25134329904209485,mmlu:college_computer_science,validation,36.662303145974874
100,0.17000000178813934,0.8499999642372131,0.4596031183557761,0.1538885885477066,mmlu:college_computer_science,test,338.8688451461494
11,0.0,1.0,,0.16526502912694757,mmlu:college_mathematics,validation,36.93303117156029
100,0.14999999105930328,0.8499999642372131,0.2654901960784314,0.05480746030807496,mmlu:college_mathematics,test,337.8316886294633
22,0.27272728085517883,0.8181818723678589,0.4895833333333333,0.1508513932878321,mmlu:college_medicine,validation,76.01375621557236
173,0.3583815097808838,0.7225433588027954,0.4654896832316187,0.06214018122998277,mmlu:college_medicine,test,597.0524936020374
11,0.27272728085517883,0.9090909361839294,0.3125,0.24032554301348602,mmlu:college_physics,validation,38.806475756689906
102,0.14705882966518402,0.8235294222831726,0.332183908045977,0.1489953796068827,mmlu:college_physics,test,368.0858834106475
11,0.5454545617103577,0.7272727489471436,0.7666666666666666,0.10792501948096536,mmlu:computer_security,validation,36.73310031555593
100,0.44999998807907104,0.6200000047683716,0.5670707070707071,0.11208077192306518,mmlu:computer_security,test,335.6895095985383
26,0.3461538553237915,0.692307710647583,0.2647058823529412,0.13776475649613598,mmlu:conceptual_physics,validation,80.82288585230708
235,0.42553189396858215,0.5574467778205872,0.4564814814814815,0.14798072779432253,mmlu:conceptual_physics,test,721.5892288070172
12,0.0833333358168602,0.8333333730697632,0.8181818181818182,0.2916912337144216,mmlu:econometrics,validation,37.36220109835267
114,0.14912280440330505,0.8157894611358643,0.5512431776834444,0.1432663547365289,mmlu:econometrics,test,360.0689817648381
16,0.25,0.8125,0.45833333333333337,0.2890469953417778,mmlu:electrical_engineering,validation,49.1296864412725
145,0.24137930572032928,0.7310344576835632,0.4292207792207792,0.021930725821133312,mmlu:electrical_engineering,test,447.9059921950102
41,0.24390242993831635,0.7804877758026123,0.34838709677419355,0.08669446008961373,mmlu:elementary_mathematics,validation,125.98765885643661
378,0.3095237910747528,0.6719576716423035,0.4175917739136131,0.027532630654239193,mmlu:elementary_mathematics,test,1780.621753172949
14,0.4285714626312256,0.6428571939468384,0.08333333333333333,0.14498270409447803,mmlu:formal_logic,validation,43.692669585347176
126,0.2777777910232544,0.7619048357009888,0.5489795918367346,0.10089372926288183,mmlu:formal_logic,test,392.1996165793389
10,0.20000000298023224,0.5,0.3125,0.14964618086814885,mmlu:global_facts,validation,30.5464523229748
100,0.1599999964237213,0.699999988079071,0.6447172619047619,0.1136480337381363,mmlu:global_facts,test,302.8904606271535
32,0.1875,0.8125,0.3141025641025641,0.10709630697965622,mmlu:high_school_biology,validation,96.87142580375075
310,0.41290321946144104,0.6645160913467407,0.3682606456043956,0.05591391805679568,mmlu:high_school_biology,test,935.1862734537572
22,0.09090909361839294,0.8181818723678589,0.3125,0.2022525830702348,mmlu:high_school_chemistry,validation,67.00971165671945
203,0.15763546526432037,0.842364490032196,0.2552997076023392,0.10166236449932232,mmlu:high_school_chemistry,test,627.1150502413511
9,0.3333333432674408,0.8888888955116272,0.6111111111111112,0.14968127012252808,mmlu:high_school_computer_science,validation,27.72856042906642
100,0.4099999964237213,0.6100000143051147,0.4940057875155023,0.08889234304428102,mmlu:high_school_computer_science,test,306.53444106690586
22,0.4545454680919647,0.6818181872367859,0.225,0.11474432186646896,mmlu:high_school_geography,validation,67.29585559852421
198,0.36868685483932495,0.7020202279090881,0.3186301369863014,0.06799380104951183,mmlu:high_school_geography,test,601.0470202900469
21,0.4285714328289032,0.5714285969734192,0.49999999999999994,0.1095180766923087,mmlu:high_school_government_and_politics,validation,64.55742424912751
193,0.5077720284461975,0.6735751032829285,0.6185821697099894,0.056107200180310686,mmlu:high_school_government_and_politics,test,602.619763771072
43,0.4651162624359131,0.6279069781303406,0.43043478260869567,0.12722765151844467,mmlu:high_school_macroeconomics,validation,133.54639518260956
390,0.33076924085617065,0.720512866973877,0.46562119457067325,0.07430615730774712,mmlu:high_school_macroeconomics,test,1200.5720398910344
29,0.03448275849223137,0.9655172228813171,0.3214285714285714,0.1500535381251368,mmlu:high_school_mathematics,validation,89.13305377960205
270,0.07037036865949631,0.9185184836387634,0.4280771650241141,0.13937176510139748,mmlu:high_school_mathematics,test,831.7604975327849
26,0.3076923191547394,0.7307692766189575,0.3958333333333333,0.10954316075031574,mmlu:high_school_microeconomics,validation,78.98960024863482
238,0.33193278312683105,0.6470588445663452,0.3446381657511345,0.08120210481291056,mmlu:high_school_microeconomics,test,721.0848712548614
17,0.29411765933036804,0.7058823704719543,0.5333333333333333,0.10875782195259545,mmlu:high_school_physics,validation,52.81266104988754
151,0.21854305267333984,0.7417218685150146,0.41332819722650227,0.11406277820763996,mmlu:high_school_physics,test,479.32863013632596
60,0.5166667103767395,0.7166666984558105,0.6779755283648499,0.12066086033980053,mmlu:high_school_psychology,validation,191.14922308921814
545,0.49724769592285156,0.6256880760192871,0.6461806771352385,0.07956205825193215,mmlu:high_school_psychology,test,1720.2523760534823
23,0.1304347813129425,0.8260869979858398,0.21666666666666662,0.15295025058414624,mmlu:high_school_statistics,validation,71.83668995089829
216,0.236111119389534,0.694444477558136,0.46981580510992277,0.03316239847077262,mmlu:high_school_statistics,test,675.8974621519446
22,0.6818181872367859,0.7727273106575012,0.9,0.09935745325955479,mmlu:high_school_us_history,validation,76.92699488252401
204,0.6715686321258545,0.7352941632270813,0.801993681228892,0.053873619612525514,mmlu:high_school_us_history,test,723.736934941262
23,0.30434784293174744,0.695652186870575,0.4241071428571429,0.07589940143668135,mmlu:human_aging,validation,69.78123099915683
223,0.3363228738307953,0.726457417011261,0.42563063063063067,0.06435872594337293,mmlu:human_aging,test,681.6548484526575
12,0.5,0.4166666865348816,0.16666666666666669,0.37092672785123193,mmlu:human_sexuality,validation,37.06957979500294
131,0.47328245639801025,0.6641221642494202,0.6014492753623188,0.10357207105359963,mmlu:human_sexuality,test,407.6226440127939
13,0.23076924681663513,0.38461539149284363,0.7166666666666667,0.33530215575144845,mmlu:international_law,validation,40.616255747154355
121,0.5041322112083435,0.6280991435050964,0.6534153005464481,0.1015615542072895,mmlu:international_law,test,374.1703005284071
11,0.4545454680919647,0.6363636255264282,0.18333333333333335,0.23380551554939963,mmlu:jurisprudence,validation,34.85255813598633
108,0.3888888955116272,0.7222222089767456,0.41450216450216454,0.05535476903120678,mmlu:jurisprudence,test,332.06283307261765
18,0.5555555820465088,0.5555555820465088,0.65625,0.10266950395372178,mmlu:logical_fallacies,validation,55.257054939866066
163,0.460122674703598,0.6564416885375977,0.5659090909090908,0.05828745306635192,mmlu:logical_fallacies,test,498.3174772746861
11,0.3636363744735718,0.7272727489471436,0.14285714285714285,0.1920061003078114,mmlu:machine_learning,validation,34.32450916431844
112,0.2410714328289032,0.7321428656578064,0.4294117647058824,0.04433962809188026,mmlu:machine_learning,test,346.37056986801326
11,0.4545454680919647,0.9090909361839294,0.06666666666666668,0.2628543051806363,mmlu:management,validation,33.32473170384765
103,0.42718446254730225,0.6796116828918457,0.4192989214175655,0.05848724112927336,mmlu:management,test,312.65484364517033
25,0.2800000011920929,0.5199999809265137,0.7103174603174603,0.2953706526756287,mmlu:marketing,validation,76.44520519301295
234,0.4572649896144867,0.636752188205719,0.7199941128854221,0.055948807133568645,mmlu:marketing,test,723.2608756199479
11,0.7272727489471436,0.7272727489471436,0.875,0.2988696206699718,mmlu:medical_genetics,validation,33.84065705165267
100,0.44999998807907104,0.6899999976158142,0.5822222222222223,0.07082870841026306,mmlu:medical_genetics,test,303.4169785119593
38,0.3684210479259491,0.6578947305679321,0.6607142857142858,0.16520502535920392,mmlu:moral_disputes,validation,116.67797304689884
346,0.38728323578834534,0.6647398471832275,0.46659391720642085,0.037488492065771456,mmlu:moral_disputes,test,1067.4023203328252
33,0.39393940567970276,0.6666666865348816,0.75,0.09117711312843094,mmlu:nutrition,validation,103.6140290312469
306,0.3529411852359772,0.5980392098426819,0.5329685746352413,0.07135404110733981,mmlu:nutrition,test,956.9173483159393
34,0.29411765933036804,0.3529411852359772,0.6104166666666667,0.3995989105280708,mmlu:philosophy,validation,102.78437898121774
311,0.3408360183238983,0.3633440434932709,0.6429590427979752,0.3843797391633896,mmlu:philosophy,test,948.0796439554542
35,0.3142857253551483,0.6285714507102966,0.32765151515151514,0.12214003801345825,mmlu:prehistory,validation,106.76128901727498
324,0.4382716119289398,0.6666666865348816,0.4691998142702368,0.056902403264869894,mmlu:prehistory,test,988.8487481884658
69,0.36231884360313416,0.5072463750839233,0.6749999999999999,0.14268984915553662,mmlu:professional_psychology,validation,213.08469321765006
612,0.29738563299179077,0.5375816822052002,0.6156657296192181,0.11336372490801844,mmlu:professional_psychology,test,1995.3168304953724
12,0.3333333432674408,0.6666666865348816,0.40625,0.151301771402359,mmlu:public_relations,validation,39.10119121521711
110,0.2818181812763214,0.7090908885002136,0.39118007349938755,0.05510109933939848,mmlu:public_relations,test,505.85705847106874
27,0.5925925970077515,0.5925925970077515,0.5880681818181819,0.11640631490283541,mmlu:security_studies,validation,88.17166696675122
245,0.5469387769699097,0.669387698173523,0.5896530859217426,0.05870093812747876,mmlu:security_studies,test,802.6114280540496
22,0.5,0.6363636255264282,0.4545454545454545,0.1454310390082273,mmlu:sociology,validation,71.76504788547754
201,0.42288556694984436,0.641791045665741,0.4803752535496957,0.057178701927412805,mmlu:sociology,test,654.337966138497
11,0.7272727489471436,0.5454545617103577,0.37500000000000006,0.36908802119168366,mmlu:us_foreign_policy,validation,36.16140346415341
100,0.5799999833106995,0.5799999833106995,0.5075944170771757,0.09920794606208802,mmlu:us_foreign_policy,test,327.9390933737159
18,0.5555555820465088,0.3888888955116272,0.58125,0.3093954424063365,mmlu:virology,validation,58.992692951112986
166,0.3072288930416107,0.6325300931930542,0.3537084398976982,0.09412638142884498,mmlu:virology,test,545.2851971797645
19,0.7368420958518982,0.7894737124443054,0.6499999999999999,0.10543316602706908,mmlu:world_religions,validation,67.96054876223207
171,0.6023392081260681,0.6959064602851868,0.7879069103369504,0.048886620161826135,mmlu:world_religions,test,561.4947736524045
