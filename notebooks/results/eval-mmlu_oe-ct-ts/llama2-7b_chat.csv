N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.8181818723678589,0.4,0.17429236390373926,mmlu:abstract_algebra,validation,10.061337351799011
100,0.2199999988079071,0.75,0.30477855477855476,0.05466389536857604,mmlu:abstract_algebra,test,82.28060905635357
14,0.2142857313156128,0.8571429252624512,0.28787878787878785,0.1115773788520268,mmlu:anatomy,validation,14.484939629212022
135,0.3777777850627899,0.6814814805984497,0.41573295985060693,0.05663898256089951,mmlu:anatomy,test,140.44322117231786
16,0.375,0.625,0.5499999999999999,0.2595244273543358,mmlu:astronomy,validation,27.24253181926906
152,0.42105263471603394,0.6776315569877625,0.5940163352272727,0.03311268083359065,mmlu:astronomy,test,199.37672838568687
11,0.4545454680919647,0.4545454680919647,0.6333333333333333,0.22997638854113492,mmlu:business_ethics,validation,10.076318558305502
100,0.4099999964237213,0.6899999976158142,0.46568830095080616,0.07605272650718689,mmlu:business_ethics,test,117.5267277173698
29,0.17241379618644714,0.7931034564971924,0.16666666666666669,0.09241725658548287,mmlu:clinical_knowledge,validation,32.17532320134342
265,0.29056602716445923,0.7584905624389648,0.4354103343465046,0.06805015015152267,mmlu:clinical_knowledge,test,329.4211196284741
16,0.375,0.75,0.3416666666666666,0.10367555916309357,mmlu:college_biology,validation,18.65416431799531
144,0.3263888955116272,0.6736111044883728,0.4508664180741392,0.0599244236946106,mmlu:college_biology,test,172.86319760978222
8,0.0,0.875,,0.2054588496685028,mmlu:college_chemistry,validation,10.358482152223587
100,0.14999999105930328,0.8499999642372131,0.33725490196078434,0.060395964980125436,mmlu:college_chemistry,test,109.15189005620778
11,0.3636363744735718,0.7272727489471436,0.5178571428571429,0.16228851405057038,mmlu:college_computer_science,validation,12.861816368997097
100,0.17999999225139618,0.8100000023841858,0.48136856368563685,0.0922323668003082,mmlu:college_computer_science,test,116.94651663862169
11,0.0,0.9090909361839294,,0.0999669541012157,mmlu:college_mathematics,validation,11.597134249284863
100,0.20999999344348907,0.7699999809265137,0.45328511151295947,0.07459618747234348,mmlu:college_mathematics,test,686.292521359399
22,0.3181818127632141,0.7727273106575012,0.31428571428571433,0.08157184449109162,mmlu:college_medicine,validation,25.74771816469729
173,0.3005780279636383,0.7572253942489624,0.40813731722822627,0.0598145037717213,mmlu:college_medicine,test,219.60876642353833
11,0.09090909361839294,0.9090909361839294,0.14999999999999997,0.1276876384561712,mmlu:college_physics,validation,12.741032024845481
102,0.0784313753247261,0.8725490570068359,0.4880319148936171,0.10008600880117974,mmlu:college_physics,test,121.87798247486353
11,0.7272727489471436,0.7272727489471436,0.5208333333333333,0.15897166187112982,mmlu:computer_security,validation,15.853671539574862
100,0.5,0.5899999737739563,0.4524,0.11105259120464323,mmlu:computer_security,test,138.83730798587203
26,0.3076923191547394,0.692307710647583,0.4236111111111111,0.1773527425069075,mmlu:conceptual_physics,validation,52.92944515682757
235,0.40851062536239624,0.6212765574455261,0.37923411270983215,0.08301974890079906,mmlu:conceptual_physics,test,512.9989969003946
12,0.0833333358168602,0.3333333432674408,1.0,0.3644060343503952,mmlu:econometrics,validation,14.744752457365394
114,0.14912280440330505,0.6666666865348816,0.5906610066707096,0.02937877596470348,mmlu:econometrics,test,191.44753130339086
16,0.25,0.8125,0.2604166666666667,0.18861423060297966,mmlu:electrical_engineering,validation,15.93673767708242
145,0.2137930989265442,0.7724137902259827,0.3367289190718732,0.06460844196122267,mmlu:electrical_engineering,test,155.37935896031559
41,0.3658536374568939,0.6829267740249634,0.30512820512820515,0.08499130533962714,mmlu:elementary_mathematics,validation,33.10613435134292
378,0.2936507761478424,0.738095223903656,0.36660255761379357,0.07143655498191794,mmlu:elementary_mathematics,test,417.40032274089754
14,0.4285714626312256,0.5714285969734192,0.5729166666666667,0.22784680553845002,mmlu:formal_logic,validation,23.979543063789606
126,0.2301587462425232,0.7222222685813904,0.5435478137220051,0.10099695031605069,mmlu:formal_logic,test,168.8299095761031
10,0.10000000149011612,0.9000000357627869,0.11111111111111116,0.18295297026634216,mmlu:global_facts,validation,13.889211786910892
100,0.10999999940395355,0.8899999856948853,0.6292134831460674,0.19739430308341976,mmlu:global_facts,test,143.42789203859866
32,0.21875,0.59375,0.4685714285714285,0.09016138128936292,mmlu:high_school_biology,validation,41.830744944512844
310,0.4000000059604645,0.6806451678276062,0.5171262573707943,0.04651745557785035,mmlu:high_school_biology,test,448.6951317694038
22,0.13636364042758942,0.8181818723678589,0.5087719298245614,0.21467344869266858,mmlu:high_school_chemistry,validation,23.88257445767522
203,0.1625615805387497,0.8226600885391235,0.38716577540106956,0.07199630801900858,mmlu:high_school_chemistry,test,226.35355599410832
9,0.3333333432674408,0.7777777910232544,0.3333333333333333,0.28350190321604407,mmlu:high_school_computer_science,validation,13.900622321292758
100,0.3999999761581421,0.6299999952316284,0.38562500000000005,0.1157316291332245,mmlu:high_school_computer_science,test,198.5796632245183
22,0.5454545617103577,0.6818181872367859,0.16666666666666669,0.12104908986525101,mmlu:high_school_geography,validation,34.11682247184217
198,0.3737373650074005,0.7171717286109924,0.31909328683522237,0.07977199795270205,mmlu:high_school_geography,test,880.1395658496767
21,0.523809552192688,0.5714285969734192,0.4590909090909091,0.24352767921629406,mmlu:high_school_government_and_politics,validation,54.90998850390315
193,0.5492227673530579,0.6994818449020386,0.4823248752982,0.038981080055236816,mmlu:high_school_government_and_politics,test,458.2249180879444
43,0.41860464215278625,0.6511628031730652,0.4288888888888889,0.10746294121409573,mmlu:high_school_macroeconomics,validation,78.34860755689442
390,0.30000001192092896,0.7358974814414978,0.3894680817757741,0.03553750453851163,mmlu:high_school_macroeconomics,test,775.543817140162
29,0.0,1.0,,0.16683371519220286,mmlu:high_school_mathematics,validation,18.552428232505918
270,0.0555555559694767,0.940740704536438,0.4233986928104575,0.13062952624426952,mmlu:high_school_mathematics,test,186.81451246887445
26,0.3461538553237915,0.7307692766189575,0.45424836601307184,0.12484518381265493,mmlu:high_school_microeconomics,validation,33.96002613566816
238,0.3529411852359772,0.680672287940979,0.4784709338280767,0.048087651739601334,mmlu:high_school_microeconomics,test,357.94905196502805
17,0.1764705926179886,0.6470588445663452,0.5357142857142857,0.11624955780365888,mmlu:high_school_physics,validation,19.25852708145976
151,0.13245032727718353,0.6887417435646057,0.448854961832061,0.047532951594977974,mmlu:high_school_physics,test,181.18157958053052
60,0.4833333492279053,0.5833333730697632,0.48720800889877647,0.11650318503379822,mmlu:high_school_psychology,validation,75.55418374203146
545,0.5027523040771484,0.6623853445053101,0.6644355859616989,0.048906235082433844,mmlu:high_school_psychology,test,739.4056915566325
23,0.21739131212234497,0.695652186870575,0.2888888888888889,0.11170696953068611,mmlu:high_school_statistics,validation,25.318686716258526
216,0.20370370149612427,0.6990740895271301,0.49478065539112054,0.05362465894884535,mmlu:high_school_statistics,test,291.4867763072252
22,0.6818181872367859,0.7727273106575012,0.7714285714285714,0.10836430842226201,mmlu:high_school_us_history,validation,34.28310841135681
204,0.6176470518112183,0.7303921580314636,0.6692612942612944,0.05725263935678143,mmlu:high_school_us_history,test,336.13404912501574
23,0.30434784293174744,0.739130437374115,0.34375,0.23135409666144333,mmlu:human_aging,validation,27.276334136724472
223,0.3632287085056305,0.726457417011261,0.40245174752217,0.0486698514142913,mmlu:human_aging,test,359.9669891670346
12,0.25,0.8333333730697632,0.4444444444444444,0.08486560483773546,mmlu:human_sexuality,validation,23.460860915482044
131,0.39694657921791077,0.6564885377883911,0.5019474196689386,0.07440810895148123,mmlu:human_sexuality,test,227.2441611830145
13,0.46153849363327026,0.692307710647583,0.6190476190476191,0.2939452483103826,mmlu:international_law,validation,20.65038113668561
121,0.5454545021057129,0.652892529964447,0.6121212121212122,0.0691077054039506,mmlu:international_law,test,191.10892428457737
11,0.4545454680919647,0.7272727489471436,0.06666666666666668,0.058063940568403735,mmlu:jurisprudence,validation,20.29571956768632
108,0.472222238779068,0.6759259104728699,0.31871345029239767,0.05337598147215667,mmlu:jurisprudence,test,171.02353680878878
18,0.2222222238779068,0.4444444477558136,0.5,0.44991915424664813,mmlu:logical_fallacies,validation,25.151478918269277
163,0.38650307059288025,0.6932514905929565,0.5802380952380952,0.05294631595260525,mmlu:logical_fallacies,test,219.24564385600388
11,0.3636363744735718,0.6363636255264282,0.4285714285714286,0.1089747819033536,mmlu:machine_learning,validation,18.144759824499488
112,0.2232142984867096,0.7678571939468384,0.484367816091954,0.10917464005095617,mmlu:machine_learning,test,146.22412591986358
11,0.1818181872367859,1.0,0.5555555555555556,0.2960688796910373,mmlu:management,validation,25.026420628651977
103,0.3883495330810547,0.6990291476249695,0.32103174603174606,0.04939664046741227,mmlu:management,test,182.1858982089907
25,0.11999999731779099,0.7599999904632568,0.6439393939393939,0.10114155530929567,mmlu:marketing,validation,31.7658118493855
234,0.41880345344543457,0.6538462042808533,0.4106767707082833,0.02402328043921384,mmlu:marketing,test,289.085494864732
11,0.8181818723678589,0.8181818723678589,0.7777777777777777,0.1650414683602073,mmlu:medical_genetics,validation,31.926352586597204
100,0.3999999761581421,0.699999988079071,0.489375,0.07459444880485532,mmlu:medical_genetics,test,263.4254284929484
38,0.44736841320991516,0.6578947305679321,0.27450980392156865,0.1933244576579646,mmlu:moral_disputes,validation,70.76527039334178
346,0.4421965181827545,0.6358381509780884,0.42067120457855,0.05212678178886461,mmlu:moral_disputes,test,589.442291630432
33,0.3636363744735718,0.696969747543335,0.4424603174603175,0.14686672434662326,mmlu:nutrition,validation,45.93657276034355
306,0.4117647111415863,0.6699346303939819,0.39173280423280415,0.0664990421603708,mmlu:nutrition,test,435.4911430813372
34,0.3235294222831726,0.7352941036224365,0.6897233201581028,0.15558639694662654,mmlu:philosophy,validation,54.6563361659646
311,0.37620577216148376,0.6237941980361938,0.564917613886686,0.038801494518660294,mmlu:philosophy,test,548.5482267607003
35,0.34285715222358704,0.7714285850524902,0.39855072463768115,0.12714614527566093,mmlu:prehistory,validation,90.52388924919069
324,0.37962964177131653,0.7037037014961243,0.4452938559236338,0.05282875895500186,mmlu:prehistory,test,808.5440204590559
69,0.37681159377098083,0.6376811861991882,0.45304114490161,0.14028146474257758,mmlu:professional_psychology,validation,98.59492114000022
612,0.3284313678741455,0.6895424723625183,0.41636706976068566,0.03273435326573116,mmlu:professional_psychology,test,846.0954420883209
12,0.25,0.8333333730697632,0.8148148148148149,0.29526085158189136,mmlu:public_relations,validation,13.714876284822822
110,0.3545454442501068,0.7727272510528564,0.46099674972914406,0.0948377332904122,mmlu:public_relations,test,100.51341240666807
27,0.7407407760620117,0.5925925970077515,0.49642857142857144,0.2077349821726481,mmlu:security_studies,validation,50.30404985137284
245,0.6408162713050842,0.718367338180542,0.3737333526346265,0.05595212980192533,mmlu:security_studies,test,469.8231540787965
22,0.40909093618392944,0.6818181872367859,0.5128205128205128,0.03309340368617662,mmlu:sociology,validation,49.75287911109626
201,0.4378109276294708,0.7014925479888916,0.40456556717618675,0.02959469450053885,mmlu:sociology,test,456.8509857561439
11,0.5454545617103577,0.9090909361839294,0.5,0.21243574944409457,mmlu:us_foreign_policy,validation,13.686121191829443
100,0.5799999833106995,0.6499999761581421,0.5012315270935961,0.08370630264282228,mmlu:us_foreign_policy,test,118.14195520244539
18,0.3888888955116272,0.7222222089767456,0.6883116883116883,0.33433440658781266,mmlu:virology,validation,25.125910829752684
166,0.34337347745895386,0.6927710771560669,0.4096249798808949,0.08729901443044823,mmlu:virology,test,292.61687717959285
19,0.6315789222717285,0.5789473652839661,0.16666666666666669,0.11573809385299681,mmlu:world_religions,validation,15.326946111395955
171,0.5380116701126099,0.6023392081260681,0.27084479911942766,0.10910870945244507,mmlu:world_religions,test,153.11473815143108
18,0.8333333134651184,0.7222222089767456,0.8444444444444444,0.20222404930326673,mmlu:high_school_european_history,validation,7.247847470920533
165,0.7090908885002136,0.7696969509124756,0.7783119658119657,0.061492701010270545,mmlu:high_school_european_history,test,49.458406093064696
26,0.7307692170143127,0.692307710647583,0.7819548872180451,0.11144643792739282,mmlu:high_school_world_history,validation,4.462690843036398
237,0.552742600440979,0.6582278609275818,0.7224542704882616,0.07938625666662612,mmlu:high_school_world_history,test,36.088421148015186
86,0.41860464215278625,0.6976743936538696,0.7277777777777779,0.05429450994314145,mmlu:miscellaneous,validation,2.5213171881623566
783,0.4533844292163849,0.7305236458778381,0.7680992497038306,0.029530165828812,mmlu:miscellaneous,test,21.196649773977697
100,0.5099999904632568,0.5,0.6586634653861545,0.24880120515823362,mmlu:moral_scenarios,validation,5.992802024818957
895,0.46145251393318176,0.5452513694763184,0.6090869359910784,0.19292955032274045,mmlu:moral_scenarios,test,52.15219522919506
31,0.06451612710952759,0.7096773982048035,0.6551724137931034,0.08131301979864798,mmlu:professional_accounting,validation,2.1717169070616364
282,0.1560283750295639,0.7659574747085571,0.6528838808250574,0.0665370335815646,mmlu:professional_accounting,test,18.549085390986875
170,0.30588236451148987,0.5352941155433655,0.586294002607562,0.1387508132878472,mmlu:professional_law,validation,24.72782585816458
1534,0.3200782239437103,0.5306388735771179,0.5907485262041775,0.11801697541091404,mmlu:professional_law,test,226.8293252689764
31,0.25806450843811035,0.6451612710952759,0.6766304347826086,0.05380186534697009,mmlu:professional_medicine,validation,3.682197037152946
272,0.23529411852359772,0.716911792755127,0.6448317307692308,0.04451670475742393,mmlu:professional_medicine,test,31.6317614170257
