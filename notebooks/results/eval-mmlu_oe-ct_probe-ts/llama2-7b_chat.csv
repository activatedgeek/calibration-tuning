N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
18,0.8333333134651184,0.7222222089767456,0.6444444444444445,0.08495484789212546,mmlu:high_school_european_history,validation,7.749855355126783
165,0.7090908885002136,0.7212121486663818,0.7267628205128206,0.06967020179286147,mmlu:high_school_european_history,test,52.1646725339815
26,0.7307692170143127,0.6538461446762085,0.4887218045112782,0.15036998116053069,mmlu:high_school_world_history,validation,4.605611480074003
237,0.552742600440979,0.6118143200874329,0.6534279130059053,0.040109681680735684,mmlu:high_school_world_history,test,37.862579609965906
86,0.41860464215278625,0.5813953280448914,0.7088888888888889,0.11551443781963615,mmlu:miscellaneous,validation,2.4593477870803326
783,0.4533844292163849,0.6385695934295654,0.7262110043438199,0.0657630482091453,mmlu:miscellaneous,test,21.12222713814117
100,0.5099999904632568,0.49000000953674316,0.6188475390156063,0.11572057008743286,mmlu:moral_scenarios,validation,6.08350876509212
895,0.46145251393318176,0.5765362977981567,0.6454894356645534,0.04859968963282068,mmlu:moral_scenarios,test,53.196775613119826
31,0.06451612710952759,0.8387096524238586,0.9482758620689655,0.17485457658767706,mmlu:professional_accounting,validation,2.219170606927946
282,0.1560283750295639,0.7446808218955994,0.600983575248281,0.08248456572809966,mmlu:professional_accounting,test,19.190981138963252
170,0.30588236451148987,0.4588235318660736,0.5673076923076923,0.1838964900549721,mmlu:professional_law,validation,26.010336220962927
1534,0.3200782239437103,0.4947848618030548,0.619994024756255,0.14016000081383112,mmlu:professional_law,test,238.14516594912857
31,0.25806450843811035,0.6451612710952759,0.625,0.1500488596577798,mmlu:professional_medicine,validation,3.81864202208817
272,0.23529411852359772,0.6397058963775635,0.5939378004807692,0.019774262738578467,mmlu:professional_medicine,test,33.052444283152
11,0.09090909361839294,0.8181818723678589,0.6,0.13229535384611651,mmlu:abstract_algebra,validation,6.298589935991913
100,0.2199999988079071,0.75,0.5227272727272727,0.084766982793808,mmlu:abstract_algebra,test,39.311642416752875
14,0.2142857313156128,0.7142857313156128,0.7878787878787878,0.11365196534565518,mmlu:anatomy,validation,5.454875950701535
135,0.37037035822868347,0.6518518328666687,0.5710588235294117,0.087000251699377,mmlu:anatomy,test,52.8943303800188
16,0.375,0.8125,0.6333333333333333,0.13550277799367907,mmlu:astronomy,validation,9.622568631079048
152,0.42105263471603394,0.6710526347160339,0.6552734375,0.06519910379459982,mmlu:astronomy,test,81.82578101428226
11,0.5454545617103577,0.6363636255264282,0.6666666666666666,0.09484069455753674,mmlu:business_ethics,validation,6.658185749780387
100,0.2800000011920929,0.6800000071525574,0.6736111111111112,0.11319776535034183,mmlu:business_ethics,test,57.71509501012042
29,0.10344827175140381,0.8275861740112305,0.8205128205128205,0.15248195467324094,mmlu:clinical_knowledge,validation,12.56436817580834
265,0.29811322689056396,0.7056604027748108,0.7027358105349122,0.09148949677089475,mmlu:clinical_knowledge,test,125.0316646201536
16,0.4375,0.625,0.7142857142857143,0.09532237797975539,mmlu:college_biology,validation,7.221407535020262
144,0.3194444477558136,0.6527777910232544,0.614463176574978,0.04673874750733373,mmlu:college_biology,test,74.39952035713941
8,0.0,1.0,,0.294615663588047,mmlu:college_chemistry,validation,5.259895217139274
100,0.17000000178813934,0.7400000095367432,0.5924875974486179,0.06344375252723694,mmlu:college_chemistry,test,48.748020485043526
11,0.27272728085517883,0.5454545617103577,0.41666666666666663,0.27275311946868896,mmlu:college_computer_science,validation,7.060055676847696
100,0.14000000059604645,0.5399999618530273,0.5415282392026578,0.151956604719162,mmlu:college_computer_science,test,55.87019191775471
11,0.0,1.0,,0.21405986764214255,mmlu:college_mathematics,validation,7.14494395814836
100,0.22999998927116394,0.7099999785423279,0.4678147939017504,0.08120315313339233,mmlu:college_mathematics,test,44.82405474735424
22,0.3636363744735718,0.7272727489471436,0.8125,0.14456939968195828,mmlu:college_medicine,validation,12.245815463829786
173,0.27167630195617676,0.797687828540802,0.737757514353259,0.06092006278175838,mmlu:college_medicine,test,115.96797207789496
11,0.09090909361839294,0.7272727489471436,0.4,0.28092390840703796,mmlu:college_physics,validation,7.227777876891196
102,0.10784313827753067,0.8333333730697632,0.615884115884116,0.122147400005191,mmlu:college_physics,test,45.77480397699401
11,0.7272727489471436,0.6363636255264282,0.9583333333333334,0.12608497793024237,mmlu:computer_security,validation,8.23053657868877
100,0.44999998807907104,0.5999999642372131,0.5822222222222222,0.08894422590732576,mmlu:computer_security,test,63.37000546697527
26,0.38461539149284363,0.6538462042808533,0.59375,0.14001851127697873,mmlu:conceptual_physics,validation,18.000102067366242
235,0.37021276354789734,0.6340425610542297,0.6209226467847159,0.09936938133645563,mmlu:conceptual_physics,test,137.95327484467998
12,0.25,0.5833333730697632,0.6296296296296297,0.17035323381423953,mmlu:econometrics,validation,7.551539700012654
114,0.1315789520740509,0.859649121761322,0.6787878787878788,0.14106020174528422,mmlu:econometrics,test,70.91657970706001
16,0.1875,0.875,0.6666666666666666,0.11782097443938253,mmlu:electrical_engineering,validation,5.662085453048348
145,0.19310344755649567,0.8137931227684021,0.6260683760683761,0.0626511187388979,mmlu:electrical_engineering,test,55.287248368840665
41,0.31707316637039185,0.7317072749137878,0.6730769230769231,0.0375959509756507,mmlu:elementary_mathematics,validation,14.70799951814115
378,0.30687829852104187,0.658730149269104,0.6189951302974468,0.027374585942616533,mmlu:elementary_mathematics,test,356.3356666392647
14,0.5,0.4285714626312256,0.5306122448979593,0.24474005188260758,mmlu:formal_logic,validation,9.568166823126376
126,0.2460317611694336,0.7460317611694336,0.7541595925297113,0.07705623573727077,mmlu:formal_logic,test,88.68170561781153
10,0.20000000298023224,0.800000011920929,0.8125,0.06993483901023867,mmlu:global_facts,validation,6.762902471236885
100,0.07999999821186066,0.9399999976158142,0.671875,0.21168009877204896,mmlu:global_facts,test,160.65030585275963
32,0.28125,0.5625,0.34782608695652173,0.17299516312777996,mmlu:high_school_biology,validation,17.50525521999225
310,0.40645161271095276,0.625806450843811,0.6400103519668737,0.06983680725097655,mmlu:high_school_biology,test,172.77312907064334
22,0.09090909361839294,0.8636363744735718,0.55,0.1898970603942871,mmlu:high_school_chemistry,validation,11.605950066354126
203,0.1428571343421936,0.7635467648506165,0.5883868410622274,0.07515619306141519,mmlu:high_school_chemistry,test,224.29777660081163
9,0.4444444477558136,0.7777777910232544,0.9,0.11749049690034653,mmlu:high_school_computer_science,validation,6.465818996075541
100,0.429999977350235,0.5,0.561607507139943,0.17726428508758546,mmlu:high_school_computer_science,test,65.76105101918802
22,0.4545454680919647,0.5,0.7166666666666667,0.3074064390225844,mmlu:high_school_geography,validation,12.775301672052592
198,0.4141414165496826,0.6010100841522217,0.6454478553406223,0.15702336966389357,mmlu:high_school_geography,test,102.68052328797057
21,0.5714285969734192,0.5714285969734192,0.712962962962963,0.22127162842523487,mmlu:high_school_government_and_politics,validation,13.561333376914263
193,0.5336787700653076,0.5854921936988831,0.6816612729234088,0.10094737605109734,mmlu:high_school_government_and_politics,test,104.47720974171534
43,0.39534884691238403,0.604651153087616,0.5803167420814479,0.17606058231619903,mmlu:high_school_macroeconomics,validation,25.761703313793987
390,0.2897436022758484,0.6974359154701233,0.6881888757547683,0.07951956070386443,mmlu:high_school_macroeconomics,test,227.83886319724843
29,0.0,0.9655172228813171,,0.22770554854952058,mmlu:high_school_mathematics,validation,9.115037766750902
270,0.0555555559694767,0.9296296238899231,0.5096732026143791,0.16568228734864127,mmlu:high_school_mathematics,test,92.42639350611717
26,0.3461538553237915,0.692307710647583,0.630718954248366,0.10460790991783142,mmlu:high_school_microeconomics,validation,13.60533952480182
238,0.3571428656578064,0.6680672764778137,0.6467512495194156,0.08586203050212697,mmlu:high_school_microeconomics,test,126.15156095707789
17,0.05882352963089943,0.8235294222831726,0.375,0.09637350895825553,mmlu:high_school_physics,validation,11.127738329116255
151,0.1589404046535492,0.807947039604187,0.6069553805774278,0.08166465419807181,mmlu:high_school_physics,test,69.52888409234583
60,0.5,0.5333333611488342,0.6466666666666667,0.1566851536432902,mmlu:high_school_psychology,validation,31.11232133815065
545,0.4880734086036682,0.5486238598823547,0.6157867787748943,0.125197887311288,mmlu:high_school_psychology,test,394.2414272641763
23,0.21739131212234497,0.782608687877655,0.8333333333333334,0.09626171899878458,mmlu:high_school_statistics,validation,11.430361895356327
216,0.2083333283662796,0.7731481790542603,0.6810266406757635,0.07215233754228663,mmlu:high_school_statistics,test,123.52058685338125
22,0.7727273106575012,0.6818181872367859,0.6352941176470588,0.06924339316108008,mmlu:high_school_us_history,validation,25.35216447012499
204,0.593137264251709,0.6813725829124451,0.6699691327292641,0.06761151464546424,mmlu:high_school_us_history,test,238.53347964491695
23,0.30434784293174744,0.5652173757553101,0.6339285714285714,0.1698555894519972,mmlu:human_aging,validation,12.674648551270366
223,0.3408071994781494,0.5964125990867615,0.5590762620837809,0.076668584827885,mmlu:human_aging,test,107.29648242844269
12,0.3333333432674408,0.6666666865348816,0.8125,0.19779326518376666,mmlu:human_sexuality,validation,9.010503894183785
131,0.4198473393917084,0.5877862572669983,0.5717703349282296,0.13374468388448232,mmlu:human_sexuality,test,67.55673231044784
13,0.38461539149284363,0.46153849363327026,0.45000000000000007,0.21775755973962638,mmlu:international_law,validation,5.295885466039181
121,0.5702478885650635,0.6115702390670776,0.6557971014492754,0.03612789585570657,mmlu:international_law,test,58.599298550281674
11,0.4545454680919647,0.5454545617103577,0.8666666666666667,0.29145739295265893,mmlu:jurisprudence,validation,86.549617534969
108,0.49074074625968933,0.5370370149612427,0.6169811320754718,0.10798597887710289,mmlu:jurisprudence,test,180.88503579236567
18,0.5555555820465088,0.5,0.6000000000000001,0.1354740858078003,mmlu:logical_fallacies,validation,9.747040826827288
163,0.4171779155731201,0.5644171833992004,0.6337461300309598,0.09678982774172823,mmlu:logical_fallacies,test,81.9574178867042
11,0.3636363744735718,0.4545454680919647,0.5357142857142857,0.26566395976326684,mmlu:machine_learning,validation,9.174397672060877
112,0.2142857313156128,0.7678571939468384,0.6640625,0.1310181479368891,mmlu:machine_learning,test,54.08348920522258
11,0.1818181872367859,0.9090909361839294,0.8333333333333334,0.2063255418430675,mmlu:management,validation,8.749821790959686
103,0.34951457381248474,0.6310679912567139,0.5881011608623549,0.11204151216062526,mmlu:management,test,54.35485265729949
25,0.19999998807907104,0.7999999523162842,0.8200000000000001,0.20722132682800293,mmlu:marketing,validation,15.45433690585196
234,0.39316239953041077,0.6153846383094788,0.634491733006736,0.07792282002603908,mmlu:marketing,test,123.43499613692984
11,0.7272727489471436,0.1818181872367859,0.25,0.44156991893594916,mmlu:medical_genetics,validation,8.659270951058716
100,0.4099999964237213,0.6899999976158142,0.6730053741215378,0.05026935517787931,mmlu:medical_genetics,test,54.11550739873201
38,0.42105263471603394,0.5,0.5369318181818181,0.14073637284730614,mmlu:moral_disputes,validation,23.359834203962237
346,0.41329479217529297,0.5982658863067627,0.588101553618795,0.08708806637394634,mmlu:moral_disputes,test,185.92291148379445
33,0.39393940567970276,0.6060606241226196,0.5692307692307692,0.09938720862070723,mmlu:nutrition,validation,18.918384866788983
306,0.4215686321258545,0.6078431606292725,0.6590242193316691,0.0519567133944019,mmlu:nutrition,test,264.63294442836195
34,0.3529411852359772,0.6470588445663452,0.5795454545454546,0.10439554908696341,mmlu:philosophy,validation,21.404483882244676
311,0.350482314825058,0.6430867910385132,0.5920383322735944,0.030561283087040453,mmlu:philosophy,test,212.51078449143097
35,0.2857142984867096,0.6857143044471741,0.6280000000000001,0.07616244043622697,mmlu:prehistory,validation,21.54041989799589
324,0.31790122389793396,0.694444477558136,0.7182708781795017,0.052485925915800535,mmlu:prehistory,test,183.9663665466942
69,0.3333333432674408,0.7246376872062683,0.6720226843100189,0.10183890574220297,mmlu:professional_psychology,validation,37.60756712919101
612,0.31699347496032715,0.6764705777168274,0.6132479159473191,0.040880489972681816,mmlu:professional_psychology,test,316.18128436012194
12,0.25,0.8333333730697632,0.9259259259259258,0.24019921322663626,mmlu:public_relations,validation,6.505806415807456
110,0.3181818127632141,0.6909090876579285,0.6697142857142857,0.017348190871152,mmlu:public_relations,test,41.079663208685815
27,0.6296296119689941,0.7407407760620117,0.6705882352941176,0.15002266786716603,mmlu:security_studies,validation,19.07092265971005
245,0.6408162713050842,0.7061223983764648,0.7403372900984364,0.06740585127655342,mmlu:security_studies,test,133.52599636558443
22,0.3636363744735718,0.5454545617103577,0.5625,0.14919667623259802,mmlu:sociology,validation,13.400826070923358
201,0.4527363181114197,0.5870646834373474,0.5995004995004996,0.09090675821351768,mmlu:sociology,test,110.3817660859786
11,0.5454545617103577,0.5454545617103577,0.5333333333333333,0.145337391983379,mmlu:us_foreign_policy,validation,4.820226518902928
100,0.5600000023841858,0.5199999809265137,0.658887987012987,0.13152719378471378,mmlu:us_foreign_policy,test,36.862107407301664
18,0.2222222238779068,0.6666666865348816,0.3571428571428571,0.17366242739889357,mmlu:virology,validation,10.571663056034595
166,0.3253012001514435,0.668674647808075,0.5711805555555555,0.0820891444223473,mmlu:virology,test,88.65418935520574
19,0.5789473652839661,0.6315789222717285,0.9090909090909091,0.20398570989307604,mmlu:world_religions,validation,8.087243796791881
171,0.5263158082962036,0.5555555820465088,0.6811385459533609,0.12733650695510776,mmlu:world_religions,test,74.92596066277474
