N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
18,0.7222222089767456,0.7222222089767456,0.8615384615384616,0.1267050802707672,mmlu:high_school_european_history,validation,14.53555153007619
165,0.6000000238418579,0.5939394235610962,0.6136363636363635,0.12817698283628984,mmlu:high_school_european_history,test,85.34275930305012
26,0.6153846383094788,0.5384615659713745,0.55625,0.20095425156446603,mmlu:high_school_world_history,validation,7.444012067979202
237,0.5274261832237244,0.6244725584983826,0.6317857142857143,0.1701528673936546,mmlu:high_school_world_history,test,61.58195821288973
86,0.604651153087616,0.7558139562606812,0.7884615384615384,0.033434445081755165,mmlu:miscellaneous,validation,10.570230341982096
783,0.6168582439422607,0.7828863263130188,0.834454796411318,0.03604232732059095,mmlu:miscellaneous,test,32.504832020029426
100,0.47999998927116394,0.5199999809265137,0.6376201923076923,0.1879177391529083,mmlu:moral_scenarios,validation,9.94646547199227
895,0.44134077429771423,0.5586591958999634,0.6299139240506328,0.15350793047324238,mmlu:moral_scenarios,test,87.4098071840126
31,0.09677419066429138,0.5806451439857483,0.5,0.1348770106992414,mmlu:professional_accounting,validation,3.521507180063054
282,0.14539006352424622,0.5957446694374084,0.5814694868940391,0.08345287361889023,mmlu:professional_accounting,test,31.058912098873407
170,0.364705890417099,0.43529412150382996,0.4874551971326165,0.196929489514407,mmlu:professional_law,validation,41.77983469096944
1534,0.29400262236595154,0.47718381881713867,0.5665372732800609,0.15181575585375243,mmlu:professional_law,test,385.38360755494796
31,0.35483869910240173,0.6451612710952759,0.7318181818181818,0.1442079986295392,mmlu:professional_medicine,validation,6.09700715309009
272,0.3345588147640228,0.6213235259056091,0.6153542590006679,0.06887607166872303,mmlu:professional_medicine,test,53.82215418596752
11,0.09090909361839294,0.5454545617103577,1.0,0.4886417334729975,mmlu:abstract_algebra,validation,13.273585358634591
100,0.2199999988079071,0.44999998807907104,0.6363636363636364,0.29661244213581084,mmlu:abstract_algebra,test,66.85420336108655
14,0.2857142984867096,0.5,0.925,0.224371041570391,mmlu:anatomy,validation,9.067079887725413
135,0.4740740656852722,0.5703703761100769,0.761993838028169,0.16621219714482624,mmlu:anatomy,test,83.13237162027508
16,0.375,0.6875,0.8166666666666667,0.2351129986345768,mmlu:astronomy,validation,10.82011636160314
152,0.5394737124443054,0.6973684430122375,0.7043554006968641,0.08218180976415936,mmlu:astronomy,test,103.08140336442739
11,0.4545454680919647,0.6363636255264282,0.8666666666666667,0.15705655379728836,mmlu:business_ethics,validation,10.24082181788981
100,0.3700000047683716,0.47999998927116394,0.5836550836550837,0.1949178898334503,mmlu:business_ethics,test,74.81881776545197
29,0.27586206793785095,0.8275861740112305,0.75,0.1320382747156867,mmlu:clinical_knowledge,validation,19.292295646853745
265,0.2943396270275116,0.7056604027748108,0.7851707116412999,0.03875372814682298,mmlu:clinical_knowledge,test,167.66904187202454
16,0.1875,0.5625,0.4615384615384615,0.33993249014019966,mmlu:college_biology,validation,10.889403753913939
144,0.3819444477558136,0.5763888955116272,0.6927477017364658,0.10312970644897883,mmlu:college_biology,test,96.88841190561652
8,0.125,0.375,1.0,0.4464584067463875,mmlu:college_chemistry,validation,5.860889654606581
100,0.14999999105930328,0.5999999642372131,0.7749019607843137,0.13929561197757723,mmlu:college_chemistry,test,77.4445669380948
11,0.1818181872367859,0.7272727489471436,0.9444444444444444,0.1936296712268483,mmlu:college_computer_science,validation,12.855591021478176
100,0.2199999988079071,0.550000011920929,0.6328671328671327,0.2050354301929474,mmlu:college_computer_science,test,100.22013020887971
11,0.09090909361839294,0.9090909361839294,1.0,0.13649177009409125,mmlu:college_mathematics,validation,11.352895277552307
100,0.11999999731779099,0.6499999761581421,0.609375,0.12548162162303925,mmlu:college_mathematics,test,83.08344859071076
22,0.5,0.6818181872367859,0.7768595041322315,0.06217131289568812,mmlu:college_medicine,validation,16.36141006089747
173,0.3410404622554779,0.647398829460144,0.7694023193577163,0.06727316165935095,mmlu:college_medicine,test,146.88272179756314
11,0.3636363744735718,0.7272727489471436,0.5714285714285714,0.20823871005665173,mmlu:college_physics,validation,10.600661835633218
102,0.19607843458652496,0.7156863212585449,0.6253048780487804,0.044218714330710625,mmlu:college_physics,test,76.65541159361601
11,0.4545454680919647,0.7272727489471436,0.7666666666666667,0.2098313244906339,mmlu:computer_security,validation,9.66963397525251
100,0.4599999785423279,0.6200000047683716,0.7024959742351046,0.09319207072257997,mmlu:computer_security,test,71.3198443101719
26,0.42307692766189575,0.692307710647583,0.696969696969697,0.1535995396283957,mmlu:conceptual_physics,validation,18.41750915441662
235,0.4553191363811493,0.5787233710289001,0.5848422897196262,0.1556779491140487,mmlu:conceptual_physics,test,144.746673068963
12,0.0833333358168602,0.1666666716337204,0.5454545454545454,0.6295459618171056,mmlu:econometrics,validation,11.572966187261045
114,0.19298246502876282,0.359649121761322,0.6301877470355732,0.34882013212170515,mmlu:econometrics,test,98.00882254727185
16,0.3125,0.625,0.8363636363636364,0.1592336669564247,mmlu:electrical_engineering,validation,11.11968332156539
145,0.1862068921327591,0.634482741355896,0.7129629629629629,0.06763687503748926,mmlu:electrical_engineering,test,101.33500230964273
41,0.2926829159259796,0.707317054271698,0.7902298850574713,0.08533149230770945,mmlu:elementary_mathematics,validation,33.057650342583656
378,0.37830686569213867,0.6164020895957947,0.6735009671179883,0.08297897804351086,mmlu:elementary_mathematics,test,370.3777484437451
14,0.3571428656578064,0.4285714626312256,0.6444444444444445,0.30182827370507376,mmlu:formal_logic,validation,11.069739897735417
126,0.222222238779068,0.4761905074119568,0.6596209912536444,0.22137979098728722,mmlu:formal_logic,test,99.31390910968184
10,0.30000001192092896,0.6000000238418579,0.6666666666666666,0.126970112323761,mmlu:global_facts,validation,9.13304219674319
100,0.20999999344348907,0.7199999690055847,0.7790837854128994,0.0751085925102234,mmlu:global_facts,test,66.28265755344182
32,0.375,0.53125,0.5916666666666666,0.2040641140192747,mmlu:high_school_biology,validation,21.827929163351655
310,0.47741934657096863,0.5774193406105042,0.6536953620286954,0.12613854831264865,mmlu:high_school_biology,test,214.2484171492979
22,0.13636364042758942,0.6363636255264282,0.631578947368421,0.14729932221499362,mmlu:high_school_chemistry,validation,17.572160307317972
203,0.19211822748184204,0.5123152732849121,0.6697154471544715,0.20194295063394635,mmlu:high_school_chemistry,test,155.5963016571477
9,0.2222222238779068,0.6666666865348816,1.0,0.32838218741946745,mmlu:high_school_computer_science,validation,10.765320535749197
100,0.44999998807907104,0.5799999833106995,0.6329292929292929,0.11528293251991271,mmlu:high_school_computer_science,test,93.20039838086814
22,0.3636363744735718,0.5454545617103577,0.6785714285714286,0.13187958977439185,mmlu:high_school_geography,validation,15.13401397690177
198,0.39393940567970276,0.6969696879386902,0.7893696581196582,0.05727882066158335,mmlu:high_school_geography,test,264.01833024807274
21,0.6666666865348816,0.523809552192688,0.46938775510204084,0.15958962270191737,mmlu:high_school_government_and_politics,validation,14.97378679458052
193,0.5388600826263428,0.5854921936988831,0.6546024200518583,0.11460309911886024,mmlu:high_school_government_and_politics,test,126.58687703963369
43,0.44186046719551086,0.5813953280448914,0.6557017543859649,0.20235789515251337,mmlu:high_school_macroeconomics,validation,28.18683742824942
390,0.33076924085617065,0.6256410479545593,0.7515518726424902,0.07882838875819478,mmlu:high_school_macroeconomics,test,246.07483694981784
29,0.10344827175140381,0.8275861740112305,0.8333333333333334,0.18445229735867727,mmlu:high_school_mathematics,validation,23.294496243819594
270,0.0962962955236435,0.8222222328186035,0.6227931904161412,0.07770061448768333,mmlu:high_school_mathematics,test,204.19583810307086
26,0.42307692766189575,0.3461538553237915,0.5696969696969697,0.38214077399327206,mmlu:high_school_microeconomics,validation,19.14641939289868
238,0.3613445460796356,0.49159666895866394,0.6646649326805385,0.2362746128014156,mmlu:high_school_microeconomics,test,265.96833449881524
17,0.11764705926179886,0.5882353186607361,0.6333333333333333,0.2373689097516677,mmlu:high_school_physics,validation,16.22203651908785
151,0.20529800653457642,0.6225165724754333,0.5799731182795699,0.11116166777958145,mmlu:high_school_physics,test,110.72171002347022
60,0.5666667222976685,0.6166666746139526,0.6572398190045249,0.07845485607783002,mmlu:high_school_psychology,validation,43.72515197657049
545,0.5467889904975891,0.631192684173584,0.6772273999402222,0.07383187692099755,mmlu:high_school_psychology,test,381.04817629698664
23,0.1304347813129425,0.695652186870575,0.85,0.10023220466530841,mmlu:high_school_statistics,validation,21.894087471999228
216,0.25462964177131653,0.5925925970077515,0.6283455674760023,0.16167760916330198,mmlu:high_school_statistics,test,186.87415157537907
22,0.5909091234207153,0.5,0.4700854700854701,0.24033627726814968,mmlu:high_school_us_history,validation,46.570474626496434
204,0.6372549533843994,0.7058823704719543,0.7108108108108109,0.06209749333998737,mmlu:high_school_us_history,test,418.6625753957778
23,0.260869562625885,0.260869562625885,0.45098039215686275,0.48803170867588214,mmlu:human_aging,validation,14.193318759091198
223,0.3766816258430481,0.5022422075271606,0.7203237410071943,0.25304943510235156,mmlu:human_aging,test,134.44490801542997
12,0.4166666865348816,0.6666666865348816,0.7428571428571429,0.16608766714731857,mmlu:human_sexuality,validation,9.237212598323822
131,0.4198473393917084,0.7633587718009949,0.7647129186602871,0.10229488411022507,mmlu:human_sexuality,test,84.18541412148625
13,0.3076923191547394,0.692307710647583,0.7777777777777778,0.25170224446516776,mmlu:international_law,validation,9.846487237140536
121,0.5206611156463623,0.586776852607727,0.6160372194854953,0.12512381756601254,mmlu:international_law,test,175.1760871792212
11,0.4545454680919647,0.5454545617103577,0.4666666666666667,0.28820840337059717,mmlu:jurisprudence,validation,9.003545342944562
108,0.4166666567325592,0.5277777910232544,0.5615520282186949,0.24210719874611608,mmlu:jurisprudence,test,71.57571418117732
18,0.3888888955116272,0.5,0.6753246753246753,0.2898044652409024,mmlu:logical_fallacies,validation,14.409956940449774
163,0.4969325065612793,0.6564416885375977,0.7276422764227642,0.0711826239626832,mmlu:logical_fallacies,test,110.07515211217105
11,0.27272728085517883,0.27272728085517883,0.4583333333333333,0.46991430629383435,mmlu:machine_learning,validation,10.453068331815302
112,0.196428582072258,0.4375000298023224,0.6032828282828283,0.2408749285553183,mmlu:machine_learning,test,87.52276428416371
11,0.8181818723678589,0.5454545617103577,0.4444444444444444,0.2416925105181607,mmlu:management,validation,8.585401651449502
103,0.4466019570827484,0.6310679912567139,0.6721967963386728,0.09464854407079012,mmlu:management,test,61.60294387675822
25,0.3199999928474426,0.35999998450279236,0.6470588235294118,0.40353740453720094,mmlu:marketing,validation,19.198296611197293
234,0.4829060137271881,0.5512821078300476,0.6638996562568567,0.1970769464969635,mmlu:marketing,test,264.73009026423097
11,0.6363636255264282,0.7272727489471436,0.6785714285714286,0.16794706474650992,mmlu:medical_genetics,validation,8.659019365906715
100,0.5,0.7799999713897705,0.8229999999999998,0.09280183792114255,mmlu:medical_genetics,test,61.18642091844231
38,0.3684210479259491,0.42105263471603394,0.7410714285714286,0.37920589823471873,mmlu:moral_disputes,validation,27.971732477657497
346,0.4017340838909149,0.48843929171562195,0.6427553609286483,0.2509990589467087,mmlu:moral_disputes,test,224.44124448299408
33,0.3636363744735718,0.42424243688583374,0.6309523809523809,0.3024377389387651,mmlu:nutrition,validation,29.03616751357913
306,0.3529411852359772,0.5424836874008179,0.7070940890385334,0.16113880257201352,mmlu:nutrition,test,216.12121842522174
34,0.2647058963775635,0.3235294222831726,0.4666666666666666,0.464481111835031,mmlu:philosophy,validation,24.8608282180503
311,0.3086816668510437,0.4083601236343384,0.5953730620155039,0.3222335845327837,mmlu:philosophy,test,190.41974572651088
35,0.37142857909202576,0.5428571701049805,0.5524475524475525,0.22287243264062065,mmlu:prehistory,validation,45.99100193195045
324,0.4753086566925049,0.6141975522041321,0.6972880061115355,0.12082912726902667,mmlu:prehistory,test,213.11287155281752
69,0.42028987407684326,0.52173912525177,0.5922413793103448,0.25265581797862396,mmlu:professional_psychology,validation,50.341319343075156
612,0.31699347496032715,0.5392156839370728,0.6374241602130913,0.14077822922491556,mmlu:professional_psychology,test,575.973235600628
12,0.1666666716337204,0.5833333730697632,0.7,0.17381782333056134,mmlu:public_relations,validation,9.505239843390882
110,0.3272727131843567,0.581818163394928,0.7593843843843845,0.12102825479073955,mmlu:public_relations,test,72.15083020552993
27,0.48148149251937866,0.5185185074806213,0.631868131868132,0.18128584490882027,mmlu:security_studies,validation,22.13179822359234
245,0.5428571105003357,0.5836734175682068,0.6001611170784104,0.07949175226445103,mmlu:security_studies,test,185.85812348034233
22,0.5,0.6363636255264282,0.6694214876033058,0.08202224157073282,mmlu:sociology,validation,14.392053343355656
201,0.4378109276294708,0.5820895433425903,0.7004223652453742,0.10505696108092122,mmlu:sociology,test,127.45670652482659
11,0.6363636255264282,0.6363636255264282,0.8571428571428571,0.2875855727629228,mmlu:us_foreign_policy,validation,9.052970450371504
100,0.6200000047683716,0.7299999594688416,0.7487266553480475,0.07636651396751405,mmlu:us_foreign_policy,test,63.218382116407156
18,0.2777777910232544,0.7222222089767456,0.8307692307692307,0.16049680444929337,mmlu:virology,validation,14.882065766490996
166,0.3192771077156067,0.6385542154312134,0.6911003506428453,0.06453771189034706,mmlu:virology,test,103.89544547814876
19,0.7368420958518982,0.7894737124443054,0.6285714285714286,0.1907130730779547,mmlu:world_religions,validation,13.617857744917274
171,0.6315789222717285,0.6725146174430847,0.6762933568489125,0.11548666961011828,mmlu:world_religions,test,102.95953636802733
