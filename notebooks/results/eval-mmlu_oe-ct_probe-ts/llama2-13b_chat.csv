N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.0,1.0,,0.23170424591411243,mmlu:abstract_algebra,validation,14.695596765726805
100,0.3499999940395355,0.5999999642372131,0.5,0.1208623903989792,mmlu:abstract_algebra,test,67.26783571392298
14,0.2142857313156128,0.8571429252624512,0.6969696969696969,0.17941428508077348,mmlu:anatomy,validation,3.56806655600667
135,0.4148148000240326,0.6592592597007751,0.7376808318264015,0.0680314898490906,mmlu:anatomy,test,33.67618461325765
16,0.5,0.5625,0.796875,0.1633150354027748,mmlu:astronomy,validation,6.24710901081562
152,0.5131579041481018,0.5657894611358643,0.691961191961192,0.11859305438242458,mmlu:astronomy,test,62.43057136237621
11,0.27272728085517883,0.4545454680919647,0.41666666666666663,0.18570484898307107,mmlu:business_ethics,validation,4.272658508270979
100,0.3400000035762787,0.4899999797344208,0.5169340463458111,0.14265194833278658,mmlu:business_ethics,test,42.265185970813036
29,0.17241379618644714,0.8275861740112305,0.675,0.11948908197468724,mmlu:clinical_knowledge,validation,10.984728332608938
265,0.2943396270275116,0.7056604027748108,0.6704716851775675,0.06171746658829025,mmlu:clinical_knowledge,test,100.70608678460121
16,0.1875,0.75,0.43589743589743585,0.10363686457276344,mmlu:college_biology,validation,9.493513345718384
144,0.375,0.6666666865348816,0.5961934156378601,0.11285255932145648,mmlu:college_biology,test,67.19153088331223
8,0.0,1.0,,0.24086985737085342,mmlu:college_chemistry,validation,3.359965030103922
100,0.14999999105930328,0.8399999737739563,0.7949019607843139,0.13921940326690677,mmlu:college_chemistry,test,49.47289488837123
11,0.27272728085517883,0.5454545617103577,0.5833333333333333,0.2367557937448675,mmlu:college_computer_science,validation,9.988839164376259
100,0.22999998927116394,0.699999988079071,0.658385093167702,0.07382741570472719,mmlu:college_computer_science,test,79.80586191266775
11,0.0,1.0,,0.2590027722445401,mmlu:college_mathematics,validation,9.339673202484846
100,0.11999999731779099,0.8199999928474426,0.6912878787878788,0.0970129984617233,mmlu:college_mathematics,test,82.4007975794375
22,0.5,0.4545454680919647,0.615702479338843,0.24325701052492316,mmlu:college_medicine,validation,11.164534404873848
173,0.3815028667449951,0.7167630195617676,0.7461059190031153,0.06085622207277772,mmlu:college_medicine,test,134.97842940688133
11,0.27272728085517883,0.8181818723678589,0.8333333333333333,0.12064985253594138,mmlu:college_physics,validation,4.468163326382637
102,0.14705882966518402,0.7941176891326904,0.6344827586206897,0.10081574320793156,mmlu:college_physics,test,58.4406452216208
11,0.6363636255264282,0.7272727489471436,0.7857142857142857,0.07538245482878253,mmlu:computer_security,validation,4.081077471375465
100,0.5399999618530273,0.6200000047683716,0.6441223832528179,0.06055778861045839,mmlu:computer_security,test,44.04093350842595
26,0.46153849363327026,0.6538462042808533,0.7499999999999999,0.17785571400935835,mmlu:conceptual_physics,validation,10.741777133196592
235,0.4510638117790222,0.5787233710289001,0.6280166739798158,0.1339796494930349,mmlu:conceptual_physics,test,74.47042287886143
12,0.25,0.1666666716337204,0.2962962962962963,0.5216439813375474,mmlu:econometrics,validation,8.589623879641294
114,0.18421052396297455,0.42105263471603394,0.5714285714285714,0.24057107484131526,mmlu:econometrics,test,92.0639419183135
16,0.3125,0.6875,0.7454545454545455,0.18188871070742607,mmlu:electrical_engineering,validation,10.308804046362638
145,0.22068965435028076,0.751724123954773,0.6717367256637168,0.060795569830927335,mmlu:electrical_engineering,test,86.24909457564354
41,0.2682926654815674,0.6829267740249634,0.6196969696969696,0.07212676507670705,mmlu:elementary_mathematics,validation,23.22950116544962
378,0.3253968060016632,0.6243386268615723,0.6639885222381636,0.055047223492274214,mmlu:elementary_mathematics,test,148.22503046691418
14,0.3571428656578064,0.4285714626312256,0.4222222222222223,0.3972754648753575,mmlu:formal_logic,validation,9.329534374177456
126,0.2857142984867096,0.5873016119003296,0.6141975308641975,0.08564524234287323,mmlu:formal_logic,test,81.16291753202677
10,0.20000000298023224,0.800000011920929,0.6875,0.11609544754028321,mmlu:global_facts,validation,6.006881400942802
100,0.14999999105930328,0.8499999642372131,0.6462745098039215,0.10134647369384767,mmlu:global_facts,test,43.64382726326585
32,0.28125,0.65625,0.5144927536231885,0.10629611089825633,mmlu:high_school_biology,validation,11.251437980681658
310,0.4000000059604645,0.6548386812210083,0.6312218175511619,0.05720544265162558,mmlu:high_school_biology,test,120.7873103916645
22,0.13636364042758942,0.8181818723678589,0.6491228070175439,0.10083908113566313,mmlu:high_school_chemistry,validation,12.368700485676527
203,0.19211822748184204,0.7832512259483337,0.7262351469668543,0.12836203111216354,mmlu:high_school_chemistry,test,91.15027904883027
9,0.5555555820465088,0.6666666865348816,0.75,0.26356815629535246,mmlu:high_school_computer_science,validation,8.286622531712055
100,0.41999998688697815,0.5699999928474426,0.5174466338259441,0.11645867168903354,mmlu:high_school_computer_science,test,78.25047253444791
22,0.40909093618392944,0.7272727489471436,0.7222222222222222,0.08978759158741344,mmlu:high_school_geography,validation,9.686260558664799
198,0.4141414165496826,0.631313145160675,0.6910744322960471,0.05650342775113656,mmlu:high_school_geography,test,81.61228175461292
21,0.523809552192688,0.523809552192688,0.7272727272727273,0.21631272633870444,mmlu:high_school_government_and_politics,validation,6.499240644276142
193,0.5803108811378479,0.5077720284461975,0.703097442680776,0.17968193113495035,mmlu:high_school_government_and_politics,test,58.32968183606863
43,0.4651162624359131,0.6279069781303406,0.7206521739130435,0.13582421458044716,mmlu:high_school_macroeconomics,validation,19.281358767300844
390,0.35384616255760193,0.6307692527770996,0.6268259719346676,0.05607189750060057,mmlu:high_school_macroeconomics,test,173.0836783759296
29,0.03448275849223137,0.6551724076271057,0.5357142857142857,0.0964583076279739,mmlu:high_school_mathematics,validation,11.809166859835386
270,0.10000000149011612,0.7814814448356628,0.6789361377838744,0.09121302366256716,mmlu:high_school_mathematics,test,126.17314788326621
26,0.23076924681663513,0.7692307829856873,0.6041666666666666,0.06782624125480649,mmlu:high_school_microeconomics,validation,11.6549311876297
238,0.3529411852359772,0.6554622054100037,0.655921459492888,0.032029707892602226,mmlu:high_school_microeconomics,test,117.54646082222462
17,0.29411765933036804,0.7058823704719543,0.5833333333333334,0.16029972889844107,mmlu:high_school_physics,validation,10.587011527270079
151,0.15231788158416748,0.7814569473266602,0.5861073369565217,0.05475439456914431,mmlu:high_school_physics,test,86.03875945135951
60,0.5,0.6166666746139526,0.6455555555555555,0.09008126854896545,mmlu:high_school_psychology,validation,21.99018958583474
545,0.5119265913963318,0.6623853445053101,0.7229835341040773,0.023578356602870026,mmlu:high_school_psychology,test,239.87357204407454
23,0.21739131212234497,0.6521739363670349,0.65,0.15955480803614078,mmlu:high_school_statistics,validation,20.579660691320896
216,0.2638888955116272,0.6111111044883728,0.5802162639302658,0.08302780654695302,mmlu:high_school_statistics,test,187.29855478554964
22,0.6818181872367859,0.5909091234207153,0.6857142857142857,0.16496742855418814,mmlu:high_school_us_history,validation,30.85408853366971
204,0.6911764740943909,0.7205882668495178,0.6963300686704943,0.029068489869435627,mmlu:high_school_us_history,test,291.1544225886464
23,0.3913043439388275,0.6521739363670349,0.6825396825396826,0.12802591790323675,mmlu:human_aging,validation,9.446110121905804
223,0.38565024733543396,0.6098654866218567,0.6107621795959939,0.08949354865625833,mmlu:human_aging,test,104.80101035162807
12,0.3333333432674408,0.6666666865348816,0.234375,0.18839601675669354,mmlu:human_sexuality,validation,9.346603866666555
131,0.5267175436019897,0.49618321657180786,0.665965404394577,0.21581050548844663,mmlu:human_sexuality,test,67.4319926649332
13,0.6153846383094788,0.38461539149284363,0.35000000000000003,0.24526842740865856,mmlu:international_law,validation,7.325675688683987
121,0.6115702390670776,0.42148759961128235,0.49956871765382405,0.20386250304781706,mmlu:international_law,test,54.93359459191561
11,0.3636363744735718,0.6363636255264282,0.3928571428571429,0.2364793744954196,mmlu:jurisprudence,validation,4.078368812799454
108,0.3611111044883728,0.6018518805503845,0.5776662950575995,0.07881298937179425,mmlu:jurisprudence,test,37.55408891662955
18,0.6666666865348816,0.5555555820465088,0.7777777777777778,0.23412346839904788,mmlu:logical_fallacies,validation,7.370089378207922
163,0.42331287264823914,0.6441717743873596,0.668054270736972,0.06031765784222652,mmlu:logical_fallacies,test,65.63916150480509
11,0.27272728085517883,0.4545454680919647,0.4583333333333333,0.30106202038851654,mmlu:machine_learning,validation,7.84908539801836
112,0.2767857313156128,0.6964285969734192,0.5404221425726803,0.03240061710987774,mmlu:machine_learning,test,44.726095389574766
11,0.5454545617103577,0.7272727489471436,0.8,0.1418929912827232,mmlu:management,validation,3.029092162847519
103,0.3980582654476166,0.5728155374526978,0.6357199055861527,0.07925993724934106,mmlu:management,test,34.16230635344982
25,0.19999998807907104,0.3999999761581421,0.63,0.23011123418807986,mmlu:marketing,validation,19.12126788124442
234,0.44871798157691956,0.6196581721305847,0.7292727943890736,0.06189324611272568,mmlu:marketing,test,150.8589332588017
11,0.7272727489471436,0.3636363744735718,0.2916666666666667,0.30201528289101337,mmlu:medical_genetics,validation,8.414508868008852
100,0.5099999904632568,0.5299999713897705,0.6674669867947179,0.1559122771024704,mmlu:medical_genetics,test,56.22514530271292
38,0.5,0.5526315569877625,0.7340720221606648,0.1575842311507777,mmlu:moral_disputes,validation,13.523162424564362
346,0.4161849617958069,0.621387243270874,0.6443378712871287,0.09058014833169176,mmlu:moral_disputes,test,110.44012792408466
33,0.39393940567970276,0.5151515007019043,0.573076923076923,0.16328311688972244,mmlu:nutrition,validation,18.36183350533247
306,0.46405228972435,0.6045751571655273,0.6804577464788732,0.06842797838784512,mmlu:nutrition,test,153.81051856651902
34,0.3529411852359772,0.7058823704719543,0.7537878787878788,0.06574367425021005,mmlu:philosophy,validation,8.730968657881021
311,0.379421204328537,0.6881029009819031,0.7001844208307719,0.023815463976844715,mmlu:philosophy,test,122.17968379706144
35,0.4285714328289032,0.6285714507102966,0.7183333333333333,0.12848358494894846,mmlu:prehistory,validation,15.34468386694789
324,0.4475308656692505,0.6111111044883728,0.6466962049701406,0.06602196965688541,mmlu:prehistory,test,120.91463853046298
69,0.3478260934352875,0.7101449370384216,0.7143518518518519,0.046779904676520295,mmlu:professional_psychology,validation,49.2454714551568
612,0.3464052379131317,0.656862735748291,0.6342334905660377,0.04564915461088317,mmlu:professional_psychology,test,427.3473011739552
12,0.1666666716337204,0.6666666865348816,0.75,0.24366388221581778,mmlu:public_relations,validation,3.877347942441702
110,0.3272727131843567,0.6181818246841431,0.6525900900900901,0.08564929311925715,mmlu:public_relations,test,33.97297648712993
27,0.6666666865348816,0.40740740299224854,0.5432098765432098,0.22555928980862655,mmlu:security_studies,validation,14.911618456244469
245,0.636734664440155,0.5755102038383484,0.7128349178910977,0.06871935932003723,mmlu:security_studies,test,162.2772743999958
22,0.4545454680919647,0.5454545617103577,0.65,0.22673082351684573,mmlu:sociology,validation,6.356040965765715
201,0.42786067724227905,0.606965184211731,0.7023761375126389,0.12238259013019388,mmlu:sociology,test,61.766819067299366
11,0.7272727489471436,0.27272728085517883,0.5416666666666667,0.40493181618777185,mmlu:us_foreign_policy,validation,5.014112211763859
100,0.5699999928474426,0.47999998927116394,0.6319869441044472,0.18679032266139986,mmlu:us_foreign_policy,test,41.45504290610552
18,0.4444444477558136,0.5555555820465088,0.36875,0.35216968589358855,mmlu:virology,validation,9.077259697020054
166,0.35542166233062744,0.6024096012115479,0.5928243307460795,0.09122476592121356,mmlu:virology,test,73.40679980814457
19,0.6315789222717285,0.6842105388641357,0.7380952380952381,0.205117476613898,mmlu:world_religions,validation,5.585996992886066
171,0.5555555820465088,0.6666666865348816,0.714819944598338,0.06504275889424554,mmlu:world_religions,test,45.483083453029394
