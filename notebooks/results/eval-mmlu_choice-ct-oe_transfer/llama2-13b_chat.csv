N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1974574490026994,0.3636363744735718,0.5454545617103577,0.5,0.17873597686940976,mmlu:abstract_algebra,validation,6.606004195986316
100,0.15133172899484634,0.30000001192092896,0.699999988079071,0.6535714285714286,0.07981810629367828,mmlu:abstract_algebra,test,15.863903009099886
14,0.28083460032939916,0.5714285969734192,0.5714285969734192,0.6041666666666667,0.1764920609337943,mmlu:anatomy,validation,2.3944949351716787
135,0.18391638354018883,0.5185185074806213,0.6740740537643433,0.7257142857142858,0.10391414033042061,mmlu:anatomy,test,22.94024930195883
16,0.11572423949837685,0.625,0.75,0.7083333333333333,0.27724918723106384,mmlu:astronomy,validation,4.387459269026294
152,0.2484234453816163,0.5526315569877625,0.5986841917037964,0.657563025210084,0.19058625556920702,mmlu:astronomy,test,37.36661528609693
11,0.22676623409444638,0.5454545617103577,0.9090909361839294,0.8666666666666667,0.24630834297700363,mmlu:business_ethics,validation,2.833059858996421
100,0.23358124196529387,0.5400000214576721,0.7400000095367432,0.8280998389694041,0.043804813027381914,mmlu:business_ethics,test,24.419613203965127
29,0.29384357764803126,0.517241358757019,0.6896551847457886,0.7523809523809525,0.1680753580455122,mmlu:clinical_knowledge,validation,5.495113481068984
265,0.21524647384319667,0.5660377144813538,0.6679245233535767,0.7228985507246376,0.07681179226569412,mmlu:clinical_knowledge,test,49.37858461495489
16,0.2030270304530859,0.5625,0.8125,0.8174603174603174,0.21739214286208153,mmlu:college_biology,validation,3.4916107510216534
144,0.2009299904521969,0.5763888955116272,0.6944444179534912,0.7133122654552637,0.12461546104815271,mmlu:college_biology,test,31.415125153027475
8,0.5081976652145386,0.125,0.625,0.7142857142857143,0.2729414775967598,mmlu:college_chemistry,validation,2.0794924271758646
100,0.2300338837504387,0.3700000047683716,0.6200000047683716,0.6443586443586443,0.14468354761600494,mmlu:college_chemistry,test,23.49345767311752
11,0.3500310236757452,0.5454545617103577,0.3636363744735718,0.5833333333333333,0.3581918586384166,mmlu:college_computer_science,validation,3.6184189550112933
100,0.13046191811561583,0.5299999713897705,0.5899999737739563,0.61641910879165,0.16081157922744752,mmlu:college_computer_science,test,32.25120217399672
11,0.25505628910931677,0.27272728085517883,0.6363636255264282,0.4583333333333333,0.27416229248046875,mmlu:college_mathematics,validation,2.804873106069863
100,0.2144278207421303,0.3499999940395355,0.6100000143051147,0.5162637362637362,0.17295138180255887,mmlu:college_mathematics,test,23.554564442951232
22,0.45070950416001404,0.3636363744735718,0.7272727489471436,0.8214285714285714,0.07237917184829709,mmlu:college_medicine,validation,5.085941251832992
173,0.28988235878806584,0.4624277353286743,0.6011560559272766,0.6585349462365592,0.15112137622226868,mmlu:college_medicine,test,50.50504786102101
11,0.35103211348707025,0.5454545617103577,0.7272727489471436,0.9166666666666667,0.0530997027050365,mmlu:college_physics,validation,2.4387924848124385
102,0.37260022467257936,0.2450980395078659,0.6274510025978088,0.5332467532467533,0.08631171782811482,mmlu:college_physics,test,21.192534120054916
11,0.45593208887360315,0.6363636255264282,0.1818181872367859,0.3214285714285714,0.5349115350029686,mmlu:computer_security,validation,2.3794651448260993
100,0.2413292744755745,0.6399999856948853,0.6399999856948853,0.6883680555555556,0.12685994029045103,mmlu:computer_security,test,18.187630272936076
26,0.3352957837856733,0.4615384638309479,0.5769230723381042,0.5029761904761905,0.3034885296454797,mmlu:conceptual_physics,validation,3.8207551408559084
235,0.32360163495895716,0.40851062536239624,0.5914893746376038,0.5954736211031175,0.1347992070177768,mmlu:conceptual_physics,test,33.065250511979684
12,0.4949806133906046,0.3333333432674408,0.4166666567325592,0.421875,0.3322471032540003,mmlu:econometrics,validation,3.2452148490119725
114,0.30560289924604855,0.31578946113586426,0.6315789222717285,0.5366809116809117,0.0869454192487817,mmlu:econometrics,test,28.989837785018608
16,0.45588679052889347,0.5,0.375,0.4921875,0.4150552749633789,mmlu:electrical_engineering,validation,3.134076891001314
145,0.23437489312270593,0.48965516686439514,0.634482741355896,0.6560715645222687,0.09821096206533496,mmlu:electrical_engineering,test,27.589595424942672
41,0.2608854894231005,0.4146341383457184,0.6829268336296082,0.6262254901960784,0.2137622048215168,mmlu:elementary_mathematics,validation,9.523114082869142
378,0.30925155088068945,0.33068782091140747,0.5846560597419739,0.6117470355731225,0.13261148002412587,mmlu:elementary_mathematics,test,84.63465672684833
14,0.5275802676166808,0.0714285746216774,0.7142857313156128,0.5,0.12232788119997298,mmlu:formal_logic,validation,3.6409179258625954
126,0.3190843548093523,0.2936508059501648,0.7222222089767456,0.6202550865472214,0.08792695071962145,mmlu:formal_logic,test,32.32005397998728
10,0.4928306341171265,0.30000001192092896,0.5,0.6666666666666667,0.2219384729862213,mmlu:global_facts,validation,2.047886169049889
100,0.3210132357478142,0.30000001192092896,0.5899999737739563,0.5683333333333332,0.13211295306682586,mmlu:global_facts,test,18.889976777136326
32,0.2951065404340625,0.5625,0.625,0.6547619047619047,0.1762658804655075,mmlu:high_school_biology,validation,7.236752626951784
310,0.1685357293775005,0.6741935610771179,0.6612903475761414,0.6827419584063669,0.13195715642744496,mmlu:high_school_biology,test,69.690494120121
22,0.3267563784664328,0.40909090638160706,0.6363636255264282,0.6324786324786325,0.14671954241665927,mmlu:high_school_chemistry,validation,5.037169381976128
203,0.23822169732577697,0.4088670015335083,0.6206896305084229,0.5913654618473896,0.14810307331273123,mmlu:high_school_chemistry,test,44.57430151896551
9,0.22142142719692648,0.6666666865348816,0.7777777910232544,0.7222222222222223,0.2527830402056376,mmlu:high_school_computer_science,validation,3.3607094769831747
100,0.1494222471117973,0.6000000238418579,0.6399999856948853,0.699375,0.09690290987491607,mmlu:high_school_computer_science,test,36.292332821991295
18,0.1720835847987069,0.8333333134651184,0.8333333134651184,0.9555555555555556,0.16115162438816494,mmlu:high_school_european_history,validation,20.9487367849797
165,0.21913791316928286,0.6848484873771667,0.7333333492279053,0.7095813478556842,0.08829494714736935,mmlu:high_school_european_history,test,192.06701285601594
22,0.15659447962587528,0.7272727489471436,0.7272727489471436,0.71875,0.09529443762519144,mmlu:high_school_geography,validation,3.793511835159734
198,0.1713440926990124,0.7121211886405945,0.6717171669006348,0.6763095682468582,0.11443912441080265,mmlu:high_school_geography,test,34.34934903192334
21,0.23234996483439488,0.7142857313156128,0.6666666865348816,0.6666666666666666,0.15025633573532107,mmlu:high_school_government_and_politics,validation,4.340561629971489
193,0.1403555290995484,0.7927461266517639,0.7512953281402588,0.6766339869281045,0.08398906678115767,mmlu:high_school_government_and_politics,test,39.13785256096162
43,0.3187217435171438,0.4651162922382355,0.6976743936538696,0.7934782608695653,0.1333562717881314,mmlu:high_school_macroeconomics,validation,7.663026637863368
390,0.23806955034916216,0.5307692289352417,0.6666666865348816,0.6765792877695942,0.12462479365177642,mmlu:high_school_macroeconomics,test,69.88354303594679
29,0.2368637878319313,0.27586206793785095,0.6896551847457886,0.33333333333333337,0.12046043420660088,mmlu:high_school_mathematics,validation,6.378381823189557
270,0.23808817863464354,0.28148147463798523,0.6925926208496094,0.538659793814433,0.12146112433186283,mmlu:high_school_mathematics,test,58.187132713152096
26,0.2125687048985408,0.6153846383094788,0.5769230723381042,0.634375,0.17517546507028434,mmlu:high_school_microeconomics,validation,4.650768609018996
238,0.21300476626688697,0.5798319578170776,0.5882353186607361,0.6026811594202899,0.1614323669121045,mmlu:high_school_microeconomics,test,43.593109084060416
17,0.4743419324650484,0.29411765933036804,0.6470588445663452,0.5416666666666667,0.23096824744168448,mmlu:high_school_physics,validation,4.212250679032877
151,0.3228851777828292,0.34437087178230286,0.5231788158416748,0.4753302253302253,0.17695110088942068,mmlu:high_school_physics,test,35.53500835504383
60,0.12056558529535932,0.800000011920929,0.8166666626930237,0.8194444444444444,0.04171338578065239,mmlu:high_school_psychology,validation,13.207605092786252
545,0.1326619252152399,0.7486238479614258,0.7376146912574768,0.7484435379991412,0.06663162238007295,mmlu:high_school_psychology,test,121.7350055591669
23,0.31458042497220257,0.3478260934352875,0.739130437374115,0.7291666666666667,0.05941583540128627,mmlu:high_school_statistics,validation,7.325323428027332
216,0.24465402105340253,0.3611111044883728,0.6620370149612427,0.6361947231512448,0.11581701592162803,mmlu:high_school_statistics,test,69.89343382208608
22,0.23554935374043207,0.7272727489471436,0.7272727489471436,0.6875,0.17745634913444516,mmlu:high_school_us_history,validation,19.729206325951964
204,0.13857290660049398,0.7401960492134094,0.7647058963775635,0.7385355491690617,0.06205105372503692,mmlu:high_school_us_history,test,182.52279299101792
26,0.2755839412028973,0.6153846383094788,0.6538461446762085,0.621875,0.22235821989866406,mmlu:high_school_world_history,validation,16.892255739076063
237,0.14447074443227628,0.7383966445922852,0.7890295386314392,0.7859447004608295,0.03812534195461356,mmlu:high_school_world_history,test,144.1897009680979
23,0.23390976242397143,0.695652186870575,0.695652186870575,0.7901785714285714,0.0992813395417255,mmlu:human_aging,validation,3.5308390399441123
223,0.18573621262883927,0.6322869658470154,0.6771300435066223,0.7294585711814566,0.08269112954759811,mmlu:human_aging,test,32.672054067021236
12,0.2759020452698072,0.4166666567325592,0.8333333134651184,0.8285714285714286,0.16739416619141897,mmlu:human_sexuality,validation,2.10105585004203
131,0.20084000771282284,0.6183205842971802,0.5954198241233826,0.6138271604938271,0.14472592604979306,mmlu:human_sexuality,test,22.089635112090036
13,0.09948286184897794,0.8461538553237915,0.9230769276618958,0.8636363636363636,0.15448231421984163,mmlu:international_law,validation,3.5549619579687715
121,0.15452220912807246,0.7438016533851624,0.6859503984451294,0.6749103942652328,0.08435273810851672,mmlu:international_law,test,31.51392883504741
11,0.28702737526460126,0.4545454680919647,0.6363636255264282,0.75,0.23237010565671054,mmlu:jurisprudence,validation,2.110348626971245
108,0.07802043137726959,0.75,0.6851851940155029,0.7261088248742571,0.05675696112491466,mmlu:jurisprudence,test,19.630024085985497
18,0.24995947215292189,0.7222222089767456,0.6666666865348816,0.7384615384615385,0.14076194167137146,mmlu:logical_fallacies,validation,3.6499966389965266
163,0.19532882527339684,0.6809815764427185,0.7484662532806396,0.7376126126126128,0.07058502267474777,mmlu:logical_fallacies,test,32.096875589108095
11,0.3918234353715723,0.27272728085517883,0.6363636255264282,0.5833333333333334,0.2760759483684193,mmlu:machine_learning,validation,3.0232753090094775
112,0.4253287336656026,0.2946428656578064,0.7410714030265808,0.7752205600306866,0.094206693981375,mmlu:machine_learning,test,29.601560413837433
11,0.19583951343189585,0.8181818127632141,0.9090909361839294,1.0,0.2047289284792813,mmlu:management,validation,1.6460867100395262
103,0.12938599621207972,0.7281553149223328,0.6893203854560852,0.6861904761904761,0.10482577560017409,mmlu:management,test,13.945404585916549
25,0.16847306013107297,0.800000011920929,0.8799999952316284,0.8400000000000001,0.07687957525253297,mmlu:marketing,validation,4.762776934076101
234,0.06053689911834193,0.811965823173523,0.807692289352417,0.8101076555023924,0.029957755763306546,mmlu:marketing,test,42.71159619092941
11,0.19213878566568549,0.7272727489471436,0.9090909361839294,0.8541666666666667,0.13234405084089804,mmlu:medical_genetics,validation,2.022695713909343
100,0.23054085969924926,0.5600000023841858,0.6200000047683716,0.6686282467532467,0.1518983715772629,mmlu:medical_genetics,test,16.39116090699099
86,0.1663382084563721,0.6627907156944275,0.7558139562606812,0.8330308529945554,0.06925412596658219,mmlu:miscellaneous,validation,12.425797560950741
783,0.12437413927848005,0.7407407164573669,0.7573435306549072,0.8003821980635298,0.06284010113427463,mmlu:miscellaneous,test,116.5509608250577
38,0.2750846571043918,0.4736842215061188,0.6315789222717285,0.7513888888888889,0.12518934042830218,mmlu:moral_disputes,validation,7.86259409179911
346,0.21023098978004012,0.6011560559272766,0.589595377445221,0.6258535395763657,0.11752036437822902,mmlu:moral_disputes,test,71.36598009592853
100,0.40612256377935413,0.25,0.6000000238418579,0.6301333333333334,0.17351552307605747,mmlu:moral_scenarios,validation,25.945891001960263
895,0.41758067374788854,0.22234636545181274,0.7139664888381958,0.7326719805926184,0.1401542529047535,mmlu:moral_scenarios,test,229.83005987410434
33,0.12732311089833578,0.6969696879386902,0.7878788113594055,0.8260869565217391,0.15972299467433582,mmlu:nutrition,validation,8.331840268103406
306,0.198469851336448,0.6045751571655273,0.6143791079521179,0.6782666964485147,0.1245503924251382,mmlu:nutrition,test,77.20586378290318
34,0.35916966813452106,0.5588235259056091,0.7647058963775635,0.7596491228070175,0.15413784805466146,mmlu:philosophy,validation,5.526252422947437
311,0.26256365187681757,0.6141479015350342,0.6559485793113708,0.661780104712042,0.10432694425920198,mmlu:philosophy,test,49.70784237002954
35,0.21211651563644407,0.6285714507102966,0.5428571701049805,0.5979020979020979,0.2050633089882987,mmlu:prehistory,validation,8.32633709302172
324,0.24364728066656324,0.5987654328346252,0.6574074029922485,0.6849524187153053,0.0912411555095955,mmlu:prehistory,test,74.68605245416984
31,0.3145434991005928,0.4516128897666931,0.5161290168762207,0.46428571428571425,0.20278121002258792,mmlu:professional_accounting,validation,9.209187930915505
282,0.18436649832742436,0.40425533056259155,0.6134752035140991,0.6230419799498746,0.08285392239584147,mmlu:professional_accounting,test,82.65495984116569
170,0.3331159968586529,0.38235294818878174,0.5764706134796143,0.6222710622710623,0.1033996788894429,mmlu:professional_law,validation,115.49538851389661
1534,0.3078311076375621,0.4002607464790344,0.5938722491264343,0.5875584194873248,0.10545035920833203,mmlu:professional_law,test,1054.807914213976
31,0.26948743289516824,0.4838709533214569,0.6774193644523621,0.6020833333333333,0.21504709989793838,mmlu:professional_medicine,validation,14.48373951902613
272,0.12061821483075617,0.529411792755127,0.5551470518112183,0.5806206597222222,0.13332672702038992,mmlu:professional_medicine,test,128.16415928700007
69,0.24589078409084375,0.5942028760910034,0.6086956262588501,0.6415505226480837,0.14621932351070902,mmlu:professional_psychology,validation,17.39368712203577
612,0.23834817914986142,0.5539215803146362,0.6062091588973999,0.6405610122424282,0.13124124832402648,mmlu:professional_psychology,test,148.0702041280456
12,0.4489505539337794,0.5,0.4166666567325592,0.5277777777777777,0.4014582534631093,mmlu:public_relations,validation,2.59690680494532
110,0.15075297572396018,0.6454545259475708,0.699999988079071,0.7939689418562658,0.05778617154468189,mmlu:public_relations,test,21.072129951091483
27,0.33861775309951214,0.5555555820465088,0.5185185074806213,0.6055555555555556,0.2330929460348906,mmlu:security_studies,validation,13.293255242984742
245,0.25127739298100377,0.6448979377746582,0.6897959113121033,0.6758693438091081,0.08390186733129074,mmlu:security_studies,test,120.66033313795924
22,0.11302886496890674,0.8181818127632141,0.7727272510528564,0.4166666666666667,0.21446801315654407,mmlu:sociology,validation,4.354902716120705
201,0.1635524873709797,0.7611940503120422,0.7164179086685181,0.682121459694989,0.10604865782296481,mmlu:sociology,test,39.466738645220175
11,0.07452987540851938,0.9090909361839294,0.6363636255264282,0.7,0.16148366169496015,mmlu:us_foreign_policy,validation,2.241287915967405
100,0.12262817621231081,0.7900000214576721,0.7900000214576721,0.6757082579867391,0.09274324059486386,mmlu:us_foreign_policy,test,18.650753130903468
18,0.453576640950309,0.4444444477558136,0.7222222089767456,0.74375,0.18432453937000698,mmlu:virology,validation,3.7661505590658635
166,0.3417032912194011,0.47590360045433044,0.5542168617248535,0.6132693147097338,0.18902491266468918,mmlu:virology,test,27.85940091405064
19,0.14529098021356684,0.7894737124443054,0.8421052694320679,0.75,0.17016021515193738,mmlu:world_religions,validation,2.58005656208843
171,0.07563390247305932,0.7836257219314575,0.7777777910232544,0.7835820895522388,0.03287467691633435,mmlu:world_religions,test,22.1642040500883
