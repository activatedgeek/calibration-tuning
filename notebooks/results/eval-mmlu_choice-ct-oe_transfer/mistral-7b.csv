N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.17018335515802555,0.4545454680919647,0.4545454680919647,0.2666666666666667,0.404514567418532,mmlu:abstract_algebra,validation,3.2432460419368
100,0.043980423361063,0.33000001311302185,0.4699999988079071,0.6295793758480326,0.2766907358169556,mmlu:abstract_algebra,test,9.561076949117705
14,0.12516065154756817,0.6428571343421936,0.6428571343421936,0.6444444444444444,0.3914024233818054,mmlu:anatomy,validation,1.49680130998604
135,0.07553706279507391,0.5777778029441833,0.5777778029441833,0.7498875393612237,0.26521879478737154,mmlu:anatomy,test,13.48423951282166
16,0.12928905338048935,0.625,0.5625,0.7916666666666666,0.29129786416888237,mmlu:astronomy,validation,2.432051094947383
152,0.07584191113710403,0.6578947305679321,0.6578947305679321,0.6716346153846154,0.20401687763239212,mmlu:astronomy,test,21.237796957837418
11,0.36880690401250665,0.4545454680919647,0.5454545617103577,0.9333333333333333,0.4114171374927868,mmlu:business_ethics,validation,1.697132162982598
100,0.09758620858192443,0.5899999737739563,0.5899999737739563,0.8110789582472095,0.29029127597808835,mmlu:business_ethics,test,13.606452508131042
29,0.24320986969717617,0.6206896305084229,0.6551724076271057,0.6287878787878787,0.20399384251956282,mmlu:clinical_knowledge,validation,3.253393199061975
265,0.09750527672047885,0.6754717230796814,0.6754717230796814,0.7397362608808626,0.1539104677596182,mmlu:clinical_knowledge,test,28.60261680581607
16,0.1347656361758709,0.625,0.6875,0.8416666666666668,0.21958119794726375,mmlu:college_biology,validation,2.115174731006846
144,0.04710646718740463,0.7152777910232544,0.6597222089767456,0.740942457968269,0.21005714933077493,mmlu:college_biology,test,17.996998723829165
8,0.3223490081727505,0.25,0.5,0.7916666666666667,0.4869268983602524,mmlu:college_chemistry,validation,1.3742118629161268
100,0.0631174963712692,0.47999998927116394,0.44999998807907104,0.5657051282051282,0.3374674928188324,mmlu:college_chemistry,test,13.75968372891657
11,0.06236901066519998,0.4545454680919647,0.4545454680919647,0.45,0.41427982937205926,mmlu:college_computer_science,validation,2.2403603410348296
100,0.1660211804509163,0.5400000214576721,0.5600000023841858,0.6002415458937198,0.26654199361801145,mmlu:college_computer_science,test,18.795950289117172
11,0.0985872122374448,0.27272728085517883,0.3636363744735718,0.6666666666666666,0.3736213987523859,mmlu:college_mathematics,validation,1.775147080887109
100,0.09338311880826951,0.3499999940395355,0.49000000953674316,0.5457142857142857,0.23229630649089814,mmlu:college_mathematics,test,13.853793730027974
22,0.20120580629868942,0.5454545617103577,0.5,0.6208333333333333,0.35095195878635754,mmlu:college_medicine,validation,2.971349274041131
173,0.0414742293385412,0.6300578117370605,0.6184971332550049,0.6961725917431193,0.22871056285207675,mmlu:college_medicine,test,28.31215795688331
11,0.27771310914646496,0.3636363744735718,0.3636363744735718,1.0,0.5120344270359386,mmlu:college_physics,validation,1.4951874730177224
102,0.0993184745311737,0.4215686321258545,0.4313725531101227,0.6308632242806465,0.36122988310514714,mmlu:college_physics,test,12.125965710030869
11,0.3703038475730202,0.8181818127632141,0.7272727489471436,0.6388888888888888,0.13723023371262982,mmlu:computer_security,validation,1.4485816911328584
100,0.05424466729164127,0.7699999809265137,0.7400000095367432,0.7063805759457933,0.13534028410911558,mmlu:computer_security,test,10.521096377866343
26,0.2384749192457933,0.42307692766189575,0.5384615659713745,0.9151515151515152,0.333948185810676,mmlu:conceptual_physics,validation,2.3302516418043524
235,0.06336895924933414,0.6042553186416626,0.6297872066497803,0.6541344843253066,0.2141779869160754,mmlu:conceptual_physics,test,19.422081507043913
12,0.22919477025667825,0.6666666865348816,0.5833333134651184,0.796875,0.3063991020123164,mmlu:econometrics,validation,2.0445467019453645
114,0.061843172761431905,0.5,0.5175438523292542,0.5914127423822715,0.3364311958614149,mmlu:econometrics,test,16.9978002270218
16,0.26017797738313675,0.625,0.5625,0.7250000000000001,0.28145865350961685,mmlu:electrical_engineering,validation,1.9431189340539277
145,0.04798555004185644,0.565517246723175,0.6068965792655945,0.667634533488192,0.22225718169376768,mmlu:electrical_engineering,test,15.796320321038365
41,0.1277144900182398,0.4146341383457184,0.4390243887901306,0.6017156862745098,0.38828537958424264,mmlu:elementary_mathematics,validation,5.57318002008833
378,0.07350501418113708,0.4021163880825043,0.39947089552879333,0.6050884955752214,0.44617628168176726,mmlu:elementary_mathematics,test,49.022649419959635
14,0.2780844122171402,0.2142857164144516,0.2142857164144516,0.6818181818181819,0.6114263960293361,mmlu:formal_logic,validation,2.3147756438702345
126,0.08739520301894535,0.3968254029750824,0.420634925365448,0.7132894736842105,0.4113117229370844,mmlu:formal_logic,test,19.323947597062215
10,0.18303847908973697,0.6000000238418579,0.699999988079071,0.6458333333333333,0.1223357141017914,mmlu:global_facts,validation,1.2895402780268341
100,0.06439917892217638,0.3199999928474426,0.41999998688697815,0.6091452205882353,0.3178983807563782,mmlu:global_facts,test,10.752803693059832
32,0.109920903109014,0.6875,0.53125,0.6045454545454545,0.2814492750912905,mmlu:high_school_biology,validation,4.264416444115341
310,0.04330083997018876,0.7612903118133545,0.7096773982048035,0.6939990838295922,0.15863467839456377,mmlu:high_school_biology,test,40.35801675193943
22,0.336632411588322,0.3636363744735718,0.27272728085517883,0.47321428571428575,0.5496142912994731,mmlu:high_school_chemistry,validation,3.0669241920113564
203,0.032795608337289596,0.5123152732849121,0.4876847267150879,0.6052836052836053,0.3113850173104573,mmlu:high_school_chemistry,test,25.77663975697942
9,0.29575566781891716,0.6666666865348816,0.6666666865348816,0.6944444444444444,0.3087136745452881,mmlu:high_school_computer_science,validation,2.0223907220643014
100,0.14218660235404967,0.7300000190734863,0.699999988079071,0.771943176052765,0.16054531693458557,mmlu:high_school_computer_science,test,20.899304929887876
18,0.30340122514300877,0.7222222089767456,0.7222222089767456,0.7230769230769232,0.14579556385676068,mmlu:high_school_european_history,validation,11.904190129833296
165,0.06843155821164448,0.7636363506317139,0.7575757503509521,0.71998371998372,0.15100566040385852,mmlu:high_school_european_history,test,108.80258410680108
22,0.18262522328983655,0.8181818127632141,0.7727272510528564,0.6527777777777778,0.17513913999904288,mmlu:high_school_geography,validation,2.318759660003707
198,0.035832466501178176,0.808080792427063,0.6969696879386902,0.629029605263158,0.16414465988525237,mmlu:high_school_geography,test,19.752021426102147
21,0.2009876540728978,0.8571428656578064,0.6666666865348816,0.6944444444444444,0.22050475506555464,mmlu:high_school_government_and_politics,validation,2.535422425949946
193,0.07055158056125738,0.8860103487968445,0.803108811378479,0.6788942052099947,0.09284435529165316,mmlu:high_school_government_and_politics,test,21.96357788494788
43,0.08322383359421132,0.6511628031730652,0.7209302186965942,0.6666666666666667,0.20280522662539816,mmlu:high_school_macroeconomics,validation,4.4476042171008885
390,0.07889645802669039,0.6538461446762085,0.6410256624221802,0.6716920842411038,0.2240744612155816,mmlu:high_school_macroeconomics,test,38.950937098124996
29,0.09204062511181012,0.2068965584039688,0.37931033968925476,0.4528985507246377,0.24936019346631808,mmlu:high_school_mathematics,validation,3.8584470879286528
270,0.049816260845572856,0.3185185194015503,0.4444444477558136,0.5461008594539938,0.22560749738304706,mmlu:high_school_mathematics,test,33.876521463971585
26,0.14385099823658284,0.7307692170143127,0.7307692170143127,0.7518796992481203,0.14324804223500764,mmlu:high_school_microeconomics,validation,2.804937477922067
238,0.05148605952242845,0.6722689270973206,0.651260495185852,0.6542467948717948,0.21524444848549468,mmlu:high_school_microeconomics,test,24.61569795408286
17,0.1623183383661158,0.23529411852359772,0.23529411852359772,0.41346153846153844,0.6052242482409758,mmlu:high_school_physics,validation,2.6134075520094484
151,0.06380645486692718,0.34437087178230286,0.4039735198020935,0.578962703962704,0.3832094862761087,mmlu:high_school_physics,test,20.61117826984264
60,0.06861836363871893,0.8833333253860474,0.8999999761581421,0.8800539083557951,0.04680071175098418,mmlu:high_school_psychology,validation,7.416004833998159
545,0.024298798108319603,0.8165137767791748,0.8073394298553467,0.7660898876404495,0.11697149167367081,mmlu:high_school_psychology,test,67.11009932891466
23,0.13325972142426865,0.52173912525177,0.52173912525177,0.7007575757575758,0.2646942164586938,mmlu:high_school_statistics,validation,4.416908864164725
216,0.08938277112665001,0.5787037014961243,0.5185185074806213,0.6043076923076923,0.27336654618934353,mmlu:high_school_statistics,test,40.55143336602487
22,0.16132216968319635,0.7727272510528564,0.7727272510528564,0.6,0.15350982004945926,mmlu:high_school_us_history,validation,11.26663605403155
204,0.039715321332800625,0.7745097875595093,0.7598039507865906,0.781714364336819,0.11951457928208746,mmlu:high_school_us_history,test,103.10431477311067
26,0.17852042730037984,0.7307692170143127,0.7307692170143127,0.7593984962406015,0.18960168269964361,mmlu:high_school_world_history,validation,9.53577884286642
237,0.057549775652744564,0.75527423620224,0.7679324746131897,0.8199287227894433,0.1414326021942911,mmlu:high_school_world_history,test,80.72401233296841
23,0.18107274174690252,0.739130437374115,0.739130437374115,0.7745098039215687,0.18209887846656472,mmlu:human_aging,validation,2.1364644900895655
223,0.07521940333426268,0.6995515823364258,0.726457417011261,0.7442594718714121,0.14675431481391327,mmlu:human_aging,test,19.004522989038378
12,0.2105246310432752,0.5833333134651184,0.5833333134651184,0.5428571428571428,0.22946976621945697,mmlu:human_sexuality,validation,1.3670746500138193
131,0.10232193733899647,0.8015267252922058,0.7633587718009949,0.6831501831501833,0.09862040108396805,mmlu:human_sexuality,test,12.816768888849765
13,0.10194548735251793,0.9230769276618958,0.9230769276618958,0.8333333333333334,0.12002614369759193,mmlu:international_law,validation,2.1843135128729045
121,0.05805432205357827,0.7933884263038635,0.7685950398445129,0.7050000000000001,0.12878614368517538,mmlu:international_law,test,18.116873438004404
11,0.2690740092234178,0.6363636255264282,0.8181818127632141,0.8571428571428572,0.106977793303403,mmlu:jurisprudence,validation,1.3840023111552
108,0.12221521966987187,0.8148148059844971,0.7129629850387573,0.5463068181818183,0.1511791111142547,mmlu:jurisprudence,test,11.339457968017086
18,0.20434738198916116,0.7222222089767456,0.7222222089767456,0.7307692307692308,0.22886570625834998,mmlu:logical_fallacies,validation,2.150772658875212
163,0.09247886220370331,0.803680956363678,0.7852760553359985,0.7099236641221374,0.07974499208064169,mmlu:logical_fallacies,test,18.133971583098173
11,0.2018365128473802,0.27272728085517883,0.5454545617103577,0.8333333333333333,0.4372591918165033,mmlu:machine_learning,validation,1.9137229840271175
112,0.12399928271770477,0.375,0.5089285969734192,0.6862244897959184,0.25361886088337215,mmlu:machine_learning,test,17.389348486904055
11,0.16547433625568045,0.9090909361839294,0.7272727489471436,0.35,0.20120608806610107,mmlu:management,validation,1.0973415351472795
103,0.042513576526086304,0.7961165308952332,0.7184466123580933,0.7186411149825784,0.15859230166500057,mmlu:management,test,8.2489879259374
25,0.11829211235046386,0.8799999952316284,0.8399999737739563,0.8181818181818182,0.09627080202102664,mmlu:marketing,validation,2.8136730259284377
234,0.04439549428275506,0.867521345615387,0.8333333134651184,0.7590179564595584,0.09101155756885171,mmlu:marketing,test,24.137897041859105
11,0.13500616767189721,1.0,1.0,,0.04827170480381359,mmlu:medical_genetics,validation,1.6194548781495541
100,0.11493014007806779,0.7300000190734863,0.6600000262260437,0.6671740233384069,0.20548328697681428,mmlu:medical_genetics,test,9.638222597073764
86,0.08882987568544788,0.7674418687820435,0.7558139562606812,0.8401515151515151,0.15817734529805738,mmlu:miscellaneous,validation,7.43816826492548
783,0.04395729360452559,0.8173691034317017,0.7931034564971924,0.8048022290209791,0.10143035505618779,mmlu:miscellaneous,test,68.53143483796157
38,0.1661682050479086,0.6315789222717285,0.6315789222717285,0.7559523809523809,0.20448424471052074,mmlu:moral_disputes,validation,4.630584507016465
346,0.0584012302704629,0.7052023410797119,0.6936416029930115,0.6663854066216651,0.15061897470082852,mmlu:moral_disputes,test,40.78737399610691
100,0.13669809579849243,0.4099999964237213,0.4399999976158142,0.46858205870194297,0.26055231451988226,mmlu:moral_scenarios,validation,14.987674246076494
895,0.06356477018175177,0.37318435311317444,0.40111732482910156,0.47045748076040433,0.3081204591516676,mmlu:moral_scenarios,test,131.22484865086153
33,0.1369313398996989,0.7272727489471436,0.8181818127632141,0.8564814814814815,0.07813602144067941,mmlu:nutrition,validation,4.80479931505397
306,0.09520230291326062,0.741830050945282,0.6895424723625183,0.6498633803602297,0.1602788016297459,mmlu:nutrition,test,43.72468481888063
34,0.22579511123545035,0.7352941036224365,0.7941176295280457,0.9044444444444444,0.10130549529019527,mmlu:philosophy,validation,3.42416499578394
311,0.03980188086101864,0.7202572226524353,0.7234726548194885,0.7441502463054187,0.13197498747006872,mmlu:philosophy,test,29.113786726025864
35,0.16099082486970084,0.5714285969734192,0.6285714507102966,0.8316666666666667,0.2619963867323739,mmlu:prehistory,validation,4.813550069928169
324,0.022805552699683616,0.7407407164573669,0.7253086566925049,0.7220982142857142,0.13448663938928535,mmlu:prehistory,test,41.957943700952455
31,0.1648519971678334,0.4516128897666931,0.5161290168762207,0.680672268907563,0.2567522545014658,mmlu:professional_accounting,validation,5.382742322050035
282,0.0664195701585594,0.5106382966041565,0.5106382966041565,0.6445249597423511,0.29368461087240394,mmlu:professional_accounting,test,46.76143782888539
170,0.07522207375834968,0.4529411792755127,0.4882352948188782,0.6209328306102497,0.3193443014341242,mmlu:professional_law,validation,64.34065703791566
1534,0.03781230397998431,0.4537157714366913,0.4804432988166809,0.5988224563136092,0.3322757660487795,mmlu:professional_law,test,586.2791012418456
31,0.2296288888300619,0.5483871102333069,0.5806451439857483,0.7563025210084034,0.30120911905842446,mmlu:professional_medicine,validation,8.145730190211907
272,0.09225848952637,0.6764705777168274,0.6727941036224365,0.6898468379446641,0.157089526162428,mmlu:professional_medicine,test,71.02422298491001
69,0.10513200967208197,0.7101449370384216,0.7101449370384216,0.7117346938775511,0.1474471446396648,mmlu:professional_psychology,validation,10.026413198094815
612,0.05439026449240889,0.6813725233078003,0.6993464231491089,0.6947611141855746,0.17486426078416162,mmlu:professional_psychology,test,83.79204463493079
12,0.2725921496748924,0.5,0.6666666865348816,0.7222222222222223,0.3143739948670069,mmlu:public_relations,validation,1.5749625831376761
110,0.07899739335883746,0.6636363863945007,0.6818181872367859,0.7691595705294335,0.19893993030894885,mmlu:public_relations,test,11.782854859950021
27,0.140475841584029,0.7037037014961243,0.5925925970077515,0.5592105263157894,0.2940239376491971,mmlu:security_studies,validation,7.425543159944937
245,0.0749469412832844,0.7469387650489807,0.6571428775787354,0.6104794641283271,0.16510928552977894,mmlu:security_studies,test,66.23304944206029
22,0.12233782898296008,0.8636363744735718,0.8636363744735718,0.6140350877192982,0.10707702149044387,mmlu:sociology,validation,2.5467385400552303
201,0.03701394321906625,0.8358209133148193,0.7860696315765381,0.7302489177489178,0.09197629328390855,mmlu:sociology,test,21.895693658152595
11,0.18971927057613028,0.9090909361839294,0.8181818127632141,0.8,0.11599141901189636,mmlu:us_foreign_policy,validation,1.4205457919742912
100,0.08733016997575761,0.8799999952316284,0.8500000238418579,0.7272727272727273,0.052133165597915615,mmlu:us_foreign_policy,test,10.57292790687643
18,0.3344945990377003,0.6666666865348816,0.6666666865348816,0.5972222222222223,0.11319181985325283,mmlu:virology,validation,2.280026698950678
166,0.21905659570033292,0.5301204919815063,0.5542168617248535,0.5593677156177156,0.2907874034829887,mmlu:virology,test,16.15685406816192
19,0.20538539008090367,0.8947368264198303,0.9473684430122375,0.9705882352941176,0.08681260912041915,mmlu:world_religions,validation,1.6617037658579648
171,0.04527864260980259,0.8187134265899658,0.8187134265899658,0.8057603686635945,0.10586926776763289,mmlu:world_religions,test,13.090572447050363
