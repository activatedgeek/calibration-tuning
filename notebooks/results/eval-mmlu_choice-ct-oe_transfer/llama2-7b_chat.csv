N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.435711451552131,0.27272728085517883,0.3636363744735718,0.29166666666666663,0.22308489951220425,mmlu:abstract_algebra,validation,5.368075608043
100,0.34320432335138323,0.2199999988079071,0.6800000071525574,0.7132867132867133,0.09196468353271482,mmlu:abstract_algebra,test,9.71542842197232
14,0.13757130077907015,0.7857142686843872,0.7142857313156128,0.7424242424242423,0.0964553611619132,mmlu:anatomy,validation,1.4997887418139726
135,0.23850399101222003,0.43703705072402954,0.6592592597007751,0.7608162355040143,0.02120617142430057,mmlu:anatomy,test,13.636873212875798
16,0.2690412849187851,0.3125,0.5625,0.7272727272727273,0.1416667960584164,mmlu:astronomy,validation,2.4513174649327993
152,0.24981828916229698,0.3618420958518982,0.6907894611358643,0.7208059981255857,0.17423099671539502,mmlu:astronomy,test,22.24976185709238
11,0.2799422686750239,0.5454545617103577,0.7272727489471436,0.7333333333333333,0.11385642398487439,mmlu:business_ethics,validation,1.724049505079165
100,0.23370743960142135,0.4699999988079071,0.6700000166893005,0.7460859092733843,0.0635831940174103,mmlu:business_ethics,test,14.522029191022739
29,0.31901082602040526,0.48275861144065857,0.517241358757019,0.6380952380952382,0.16527125547672142,mmlu:clinical_knowledge,validation,3.2748359008692205
265,0.2069326614433864,0.501886785030365,0.6037735939025879,0.6577808156755525,0.07159970099071288,mmlu:clinical_knowledge,test,29.153173197060823
16,0.342888206243515,0.25,0.8125,0.9270833333333334,0.20019738003611565,mmlu:college_biology,validation,2.1029919809661806
144,0.1770010516047478,0.4722222089767456,0.6597222089767456,0.7319078947368421,0.02759788723455537,mmlu:college_biology,test,18.788133207010105
8,0.40616875141859055,0.25,0.625,0.37500000000000006,0.3400840237736702,mmlu:college_chemistry,validation,1.2670271380338818
100,0.36922240763902664,0.17000000178813934,0.7699999809265137,0.6871013465627214,0.09149224460124969,mmlu:college_chemistry,test,13.964794002939016
11,0.3835678913376548,0.1818181872367859,0.8181818127632141,0.8333333333333334,0.23618223992261023,mmlu:college_computer_science,validation,2.244879717938602
100,0.35432183086872104,0.20000000298023224,0.7599999904632568,0.6834374999999999,0.17704281747341158,mmlu:college_computer_science,test,19.205532249994576
11,0.169007192958485,0.4545454680919647,0.5454545617103577,0.4833333333333334,0.09142657301642676,mmlu:college_mathematics,validation,1.7175658461637795
100,0.22035382628440858,0.25999999046325684,0.7200000286102295,0.5356029106029107,0.14305258691310885,mmlu:college_mathematics,test,13.969117814907804
22,0.3394288732246919,0.3181818127632141,0.6818181872367859,0.8238095238095238,0.09625815532424234,mmlu:college_medicine,validation,3.127372331917286
173,0.33964149042361047,0.34682080149650574,0.5780346989631653,0.6932153392330384,0.07416512545822673,mmlu:college_medicine,test,29.910796554991975
11,0.34916770729151636,0.4545454680919647,0.4545454680919647,0.35,0.26030319929122925,mmlu:college_physics,validation,1.5180834990460426
102,0.32260790233518566,0.23529411852359772,0.6274510025978088,0.6212606837606838,0.08110374971932059,mmlu:college_physics,test,12.57715758588165
11,0.43841116536747315,0.3636363744735718,0.8181818127632141,0.75,0.28030458363619715,mmlu:computer_security,validation,1.4878031730186194
100,0.26215096294879914,0.49000000953674316,0.6700000166893005,0.7643057222889156,0.08104838252067567,mmlu:computer_security,test,10.810046759201214
26,0.38970727301560915,0.3461538553237915,0.4615384638309479,0.7679738562091503,0.1969260458762829,mmlu:conceptual_physics,validation,2.37430972000584
235,0.3170571749514722,0.4170212745666504,0.47659575939178467,0.542343214658126,0.18260548216231332,mmlu:conceptual_physics,test,20.02710332488641
12,0.5215101192394892,0.0833333358168602,0.5,0.5,0.279992938041687,mmlu:econometrics,validation,1.9816255080513656
114,0.26633992477467183,0.3245614171028137,0.6140350699424744,0.5745875745875746,0.020973442939289818,mmlu:econometrics,test,17.271291657118127
16,0.3756761681288481,0.1875,0.8125,0.6666666666666666,0.13841264694929123,mmlu:electrical_engineering,validation,1.9097232150379568
145,0.30078245134189213,0.2896551787853241,0.7586206793785095,0.7052704576976422,0.13547867084371634,mmlu:electrical_engineering,test,16.001260736957192
41,0.2963081983531394,0.17073170840740204,0.7317073345184326,0.7352941176470588,0.07953392005548245,mmlu:elementary_mathematics,validation,5.715528958942741
378,0.3342761815225006,0.14814814925193787,0.8015872836112976,0.7592335847382432,0.15622003605126078,mmlu:elementary_mathematics,test,50.56757600302808
14,0.40794134778635843,0.2142857164144516,0.6428571343421936,0.7575757575757576,0.05197072029113768,mmlu:formal_logic,validation,2.210757400142029
126,0.3623097070625851,0.1587301641702652,0.6904761791229248,0.6537735849056605,0.09359869124397399,mmlu:formal_logic,test,19.149519074941054
10,0.3196156546473503,0.5,0.5,0.74,0.2300771951675415,mmlu:global_facts,validation,1.2919276440516114
100,0.1995510682463646,0.3799999952316284,0.5600000023841858,0.5182512733446519,0.06787598848342895,mmlu:global_facts,test,10.999603542964906
32,0.2674458120018244,0.34375,0.65625,0.6601731601731602,0.10531497374176978,mmlu:high_school_biology,validation,4.3915127099025995
310,0.19146540328379597,0.448387086391449,0.6645161509513855,0.7468761832639151,0.07459563939802108,mmlu:high_school_biology,test,41.648080269107595
22,0.29074718735434796,0.3181818127632141,0.8181818127632141,0.7714285714285715,0.28512794592163787,mmlu:high_school_chemistry,validation,3.072651971131563
203,0.3154352559831929,0.2857142984867096,0.6354680061340332,0.6456599286563615,0.07573545213990614,mmlu:high_school_chemistry,test,26.508808752987534
9,0.3600997924804687,0.3333333432674408,0.5555555820465088,0.8333333333333333,0.3243537015385098,mmlu:high_school_computer_science,validation,2.0442937079351395
100,0.31326128482818605,0.3100000023841858,0.699999988079071,0.7905563347358578,0.07170566380023959,mmlu:high_school_computer_science,test,21.436373815871775
18,0.4509513485762808,0.2222222238779068,0.7222222089767456,0.9642857142857143,0.12491331497828166,mmlu:high_school_european_history,validation,12.523680724902079
165,0.3561936970913049,0.34545454382896423,0.6242424249649048,0.8461663417803769,0.0725966088699572,mmlu:high_school_european_history,test,114.39920612401329
22,0.11429377712986687,0.6818181872367859,0.8181818127632141,0.8047619047619048,0.21138307452201843,mmlu:high_school_geography,validation,2.35463411686942
198,0.22402376779402147,0.5101010203361511,0.6666666865348816,0.7095539450852302,0.033361695330552346,mmlu:high_school_geography,test,20.73876542202197
21,0.4873556877885546,0.3333333432674408,0.7142857313156128,0.9081632653061225,0.15485854375930058,mmlu:high_school_government_and_politics,validation,2.6514357670675963
193,0.11746774065679837,0.6994818449020386,0.7098445892333984,0.710536398467433,0.03975814766216772,mmlu:high_school_government_and_politics,test,23.582038596039638
43,0.28634950310684915,0.44186046719551086,0.5348837375640869,0.625,0.14803249475567837,mmlu:high_school_macroeconomics,validation,4.6574255879968405
390,0.24269767533510161,0.4076923131942749,0.6641025543212891,0.693035476054344,0.028653370417081422,mmlu:high_school_macroeconomics,test,41.55365885607898
29,0.3373511238344785,0.2068965584039688,0.7586206793785095,0.3804347826086957,0.1609999105848115,mmlu:high_school_mathematics,validation,3.881392925977707
270,0.2797751958723422,0.20370370149612427,0.7518518567085266,0.49999999999999994,0.12032345665825735,mmlu:high_school_mathematics,test,34.52865405916236
26,0.3587234341181242,0.38461539149284363,0.6153846383094788,0.7124999999999999,0.19002222556334272,mmlu:high_school_microeconomics,validation,2.8542318870313466
238,0.30095428666647744,0.34873950481414795,0.6092436909675598,0.697240575204042,0.0995990345958902,mmlu:high_school_microeconomics,test,25.819325878983364
17,0.2866739718353047,0.1764705926179886,0.47058823704719543,0.6309523809523809,0.1533247618114247,mmlu:high_school_physics,validation,2.5451291271019727
151,0.26189394265610655,0.22516556084156036,0.5298013091087341,0.5529160382101559,0.1426375981987707,mmlu:high_school_physics,test,21.246092966990545
60,0.17472776869932813,0.6666666865348816,0.75,0.81375,0.07174012959003448,mmlu:high_school_psychology,validation,7.9680272249970585
545,0.13937156069169354,0.5834862589836121,0.695412814617157,0.7984720028814452,0.03261383695339938,mmlu:high_school_psychology,test,72.6502905129455
23,0.25763335435286816,0.260869562625885,0.6521739363670349,0.803921568627451,0.0719164920889813,mmlu:high_school_statistics,validation,4.391217470169067
216,0.3012111377384928,0.24074074625968933,0.5462962985038757,0.5253283302063789,0.08379497958554163,mmlu:high_school_statistics,test,41.37485035602003
22,0.25062222101471643,0.5,0.6363636255264282,0.7975206611570248,0.15280019424178384,mmlu:high_school_us_history,validation,11.769735823152587
204,0.1585016294437296,0.5245097875595093,0.6960784196853638,0.7901531939493208,0.039822470908071464,mmlu:high_school_us_history,test,108.3951952198986
26,0.32303870068146634,0.42307692766189575,0.5,0.7090909090909091,0.22968641381997332,mmlu:high_school_world_history,validation,10.073981077875942
237,0.13938282662806128,0.5569620132446289,0.7383966445922852,0.8463924963924965,0.050058329407172884,mmlu:high_school_world_history,test,85.20937547599897
23,0.24969118056089978,0.695652186870575,0.739130437374115,0.7633928571428572,0.09492495785588803,mmlu:human_aging,validation,2.145214321790263
223,0.14104987300030322,0.5560538172721863,0.6726457476615906,0.7281280547409579,0.017894987033621596,mmlu:human_aging,test,19.897186926100403
12,0.22208079198996222,0.4166666567325592,0.5833333134651184,0.4857142857142857,0.20710952083269757,mmlu:human_sexuality,validation,1.3264201420824975
131,0.18937305070971716,0.5038167834281921,0.6183205842971802,0.686946386946387,0.03494129153608368,mmlu:human_sexuality,test,13.355397233972326
13,0.13257774481406578,0.9230769276618958,0.8461538553237915,0.9166666666666666,0.16986671777871937,mmlu:international_law,validation,2.198024700861424
121,0.18286301799056942,0.6198347210884094,0.64462810754776,0.7334782608695652,0.08710045558361967,mmlu:international_law,test,18.91722618904896
11,0.28368493914604187,0.3636363744735718,0.6363636255264282,0.875,0.0809713060205633,mmlu:jurisprudence,validation,1.3333842281717807
108,0.16812362604671055,0.5370370149612427,0.6666666865348816,0.7137931034482758,0.033119473744321726,mmlu:jurisprudence,test,11.73910591402091
18,0.2873121996720632,0.6111111044883728,0.7777777910232544,0.7987012987012987,0.1642471386326684,mmlu:logical_fallacies,validation,2.1908315310720354
163,0.23609467463259318,0.46625766158103943,0.7300613522529602,0.8179824561403508,0.08145494036879276,mmlu:logical_fallacies,test,19.412670541089028
11,0.4027558429674669,0.09090909361839294,0.7272727489471436,0.95,0.236024948683652,mmlu:machine_learning,validation,1.869802039815113
112,0.38370391460401665,0.1875,0.8392857313156128,0.8304552590266875,0.21168873671974453,mmlu:machine_learning,test,17.607278008945286
11,0.20211967013098978,0.7272727489471436,0.7272727489471436,0.6666666666666667,0.1812837069684809,mmlu:management,validation,1.0382727580145001
103,0.1565075264972391,0.6407766938209534,0.6116504669189453,0.6095413595413595,0.050424237853115034,mmlu:management,test,8.458778721978888
25,0.23161819458007815,0.7200000286102295,0.7599999904632568,0.7658730158730158,0.1408179950714111,mmlu:marketing,validation,2.85232529300265
234,0.06871425494169578,0.7264957427978516,0.747863233089447,0.7895220588235293,0.08324439836363505,mmlu:marketing,test,25.53451159899123
11,0.2477659528905695,0.7272727489471436,0.7272727489471436,1.0,0.2687398574569009,mmlu:medical_genetics,validation,1.2695182140450925
100,0.24025268971920016,0.44999998807907104,0.6899999976158142,0.7909090909090909,0.10559708833694458,mmlu:medical_genetics,test,9.976546346908435
86,0.15050928017427756,0.5813953280448914,0.8023256063461304,0.8883333333333333,0.1235699230848357,mmlu:miscellaneous,validation,7.525827012956142
783,0.1146790961500633,0.6475095748901367,0.7445721626281738,0.7984592516365092,0.055594494592488795,mmlu:miscellaneous,test,70.30682437308133
38,0.3289902782753894,0.4736842215061188,0.5,0.6097222222222223,0.19771022859372592,mmlu:moral_disputes,validation,4.754196391906589
346,0.29000350832939154,0.4566473960876465,0.5924855470657349,0.6446606517640722,0.10393633990618537,mmlu:moral_disputes,test,42.785991412820294
100,0.35280446857213976,0.23999999463558197,0.699999988079071,0.5953947368421053,0.0754598951339722,mmlu:moral_scenarios,validation,15.55484652495943
895,0.35231019854545587,0.24581006169319153,0.7184357643127441,0.6575791245791245,0.08595004667782917,mmlu:moral_scenarios,test,137.1430117590353
33,0.305375851464994,0.39393940567970276,0.6969696879386902,0.9596153846153845,0.08687885241074995,mmlu:nutrition,validation,5.033725189045072
306,0.28601749708839497,0.34967321157455444,0.6176470518112183,0.7979852533696519,0.07570292318568511,mmlu:nutrition,test,46.099039198830724
34,0.3604088644771015,0.5,0.6176470518112183,0.6574394463667821,0.10653077679521898,mmlu:philosophy,validation,3.412111821817234
311,0.22598661391298108,0.5691318511962891,0.6270096302032471,0.709271439413104,0.0664218919070204,mmlu:philosophy,test,29.850761542096734
35,0.33186736617769513,0.37142857909202576,0.6571428775787354,0.7027972027972027,0.08878758805138721,mmlu:prehistory,validation,5.0111618540249765
324,0.23025649224902373,0.4783950746059418,0.6913580298423767,0.7769612521473565,0.04144155096124721,mmlu:prehistory,test,44.47588276513852
31,0.3193904180680552,0.25806450843811035,0.5483871102333069,0.6875,0.09043988297062536,mmlu:professional_accounting,validation,5.522185254143551
282,0.2608700836381168,0.304964542388916,0.5744680762290955,0.6304579971523493,0.0987636719612365,mmlu:professional_accounting,test,49.02308689896017
170,0.3461448287262636,0.24705882370471954,0.4529411792755127,0.59765625,0.22140267841956196,mmlu:professional_law,validation,68.54458341910504
1534,0.3225551533768976,0.2737939953804016,0.5306388735771179,0.6551188338890312,0.139664141419969,mmlu:professional_law,test,624.6395247201435
31,0.22453524124237798,0.35483869910240173,0.7419354915618896,0.825,0.13084640041474374,mmlu:professional_medicine,validation,8.556618992937729
272,0.19499033338883343,0.3345588147640228,0.6213235259056091,0.6677190213101815,0.04355002764393302,mmlu:professional_medicine,test,75.68887496297248
69,0.301143209139506,0.3913043439388275,0.6521739363670349,0.7495590828924162,0.20268309721048328,mmlu:professional_psychology,validation,10.382336920127273
612,0.2958036736140844,0.3741829991340637,0.5898692607879639,0.7169439155369582,0.06695932383630789,mmlu:professional_psychology,test,87.91787432902493
12,0.379655584692955,0.5,0.5833333134651184,0.6944444444444444,0.19136845072110495,mmlu:public_relations,validation,1.5684496678877622
110,0.19797793030738833,0.5454545617103577,0.6090909242630005,0.7311666666666667,0.14256521734324368,mmlu:public_relations,test,12.498838556930423
27,0.3144044489772232,0.48148149251937866,0.40740740299224854,0.5164835164835165,0.3330333873077675,mmlu:security_studies,validation,7.924203626811504
245,0.32743740325071374,0.3510203957557678,0.4326530694961548,0.6389863975427819,0.25922199706642,mmlu:security_studies,test,71.79226406803355
22,0.14946672997691415,0.7727272510528564,0.7727272510528564,0.611764705882353,0.22611251744357022,mmlu:sociology,validation,2.6520125770475715
201,0.15348214756197004,0.6815920472145081,0.676616907119751,0.6973654197080292,0.023481473993899223,mmlu:sociology,test,23.66512689902447
11,0.08332994851199065,0.7272727489471436,0.7272727489471436,0.8125,0.09183129397305574,mmlu:us_foreign_policy,validation,1.3734364761039615
100,0.13942405581474307,0.699999988079071,0.7300000190734863,0.6066666666666667,0.07653918325901032,mmlu:us_foreign_policy,test,11.01112021994777
18,0.21940550456444424,0.4444444477558136,0.4444444477558136,0.43125,0.18556131256951225,mmlu:virology,validation,2.284259996144101
166,0.3263759720756348,0.40963855385780334,0.5421686768531799,0.601515606242497,0.10854231521307704,mmlu:virology,test,16.81047216616571
19,0.07844283078846179,0.7894737124443054,0.8947368264198303,0.8916666666666667,0.1971934469122636,mmlu:world_religions,validation,1.5879672430455685
171,0.08099033522327041,0.6549707651138306,0.7836257219314575,0.8305084745762712,0.12110745837116799,mmlu:world_religions,test,13.235117685981095
