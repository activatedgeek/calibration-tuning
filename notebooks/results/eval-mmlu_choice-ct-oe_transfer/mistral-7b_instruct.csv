N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.7651939337903803,0.09090909361839294,0.6363636255264282,0.30000000000000004,0.20311447165229105,mmlu:abstract_algebra,validation,6.57634337595664
100,0.39509160012006767,0.3100000023841858,0.6600000262260437,0.5995792426367461,0.14623764097690586,mmlu:abstract_algebra,test,9.779235555091873
14,0.4076835555689675,0.5714285969734192,0.5714285969734192,0.7083333333333334,0.2453771105834416,mmlu:anatomy,validation,1.5327106630429626
135,0.2923519690831502,0.6000000238418579,0.6666666865348816,0.7304526748971194,0.13163667166674575,mmlu:anatomy,test,13.267788867931813
16,0.3448701724410057,0.5625,0.6875,0.8492063492063492,0.10876641422510146,mmlu:astronomy,validation,2.482044660951942
152,0.2530610722146536,0.6513158082962036,0.7105262875556946,0.7767295597484276,0.10216801966491496,mmlu:astronomy,test,21.315508036874235
11,0.3004397858272899,0.7272727489471436,0.7272727489471436,0.7708333333333334,0.21862692182714288,mmlu:business_ethics,validation,1.7353176879696548
100,0.3035771632194519,0.5600000023841858,0.6899999976158142,0.8187905844155844,0.11334366381168365,mmlu:business_ethics,test,13.6816242528148
29,0.286518938582519,0.6206896305084229,0.5862069129943848,0.7095959595959596,0.23537188357320324,mmlu:clinical_knowledge,validation,3.2764708439353853
265,0.213300414355296,0.6905660629272461,0.6792452931404114,0.7497667599626816,0.12300055499346751,mmlu:clinical_knowledge,test,28.365574677009135
16,0.2834133394062519,0.6875,0.625,0.7545454545454546,0.21411000564694405,mmlu:college_biology,validation,2.1499508251436055
144,0.2285563037213352,0.7291666865348816,0.7083333134651184,0.7985347985347986,0.1435393409596549,mmlu:college_biology,test,18.13265131902881
8,0.40875697135925293,0.5,0.75,0.75,0.25212904810905457,mmlu:college_chemistry,validation,1.389567653881386
100,0.33300114810466763,0.4699999988079071,0.5799999833106995,0.6621838619028503,0.22385126292705537,mmlu:college_chemistry,test,13.811612640041858
11,0.39023282582109625,0.5454545617103577,0.4545454680919647,0.39999999999999997,0.3660063039172779,mmlu:college_computer_science,validation,2.2837006570771337
100,0.2289531344175339,0.5199999809265137,0.6600000262260437,0.6937099358974359,0.1600722438097,mmlu:college_computer_science,test,18.861433580052108
11,0.37815855849872937,0.5454545617103577,0.3636363744735718,0.3,0.5636139945550399,mmlu:college_mathematics,validation,1.8519950001500547
100,0.36705657660961155,0.3100000023841858,0.7099999785423279,0.6119682094436651,0.12842281103134157,mmlu:college_mathematics,test,13.802436587866396
22,0.29218705133958295,0.6363636255264282,0.5909090638160706,0.7008928571428572,0.1923245516690341,mmlu:college_medicine,validation,2.9815004100091755
173,0.3433191684973722,0.5722543597221375,0.6358381509780884,0.70004095004095,0.17310479679548674,mmlu:college_medicine,test,28.214142352109775
11,0.4926265640692278,0.4545454680919647,0.8181818127632141,0.9333333333333333,0.12182799794457173,mmlu:college_physics,validation,1.5097952750511467
102,0.4072932612662222,0.4117647111415863,0.6764705777168274,0.6730158730158731,0.13583170374234518,mmlu:college_physics,test,12.150236384011805
11,0.318847580389543,0.6363636255264282,0.8181818127632141,0.7142857142857143,0.269435774196278,mmlu:computer_security,validation,1.4797233981080353
100,0.2041048324108124,0.7200000286102295,0.7200000286102295,0.7380952380952381,0.13953027069568633,mmlu:computer_security,test,10.559180592186749
26,0.3283676367539626,0.5,0.7307692170143127,0.7958579881656804,0.13614846422122076,mmlu:conceptual_physics,validation,2.3535982528701425
235,0.33540841937065125,0.5063830018043518,0.6212766170501709,0.6786438713416402,0.16231666803359984,mmlu:conceptual_physics,test,19.534058789955452
12,0.24004896233479184,0.6666666865348816,0.5833333134651184,0.625,0.22983185946941379,mmlu:econometrics,validation,2.0718279518187046
114,0.4409078179221404,0.4035087823867798,0.6315789222717285,0.6504156010230179,0.1475306587261066,mmlu:econometrics,test,17.003107931930572
16,0.15577726252377033,0.6875,0.5625,0.5818181818181819,0.25263549387454987,mmlu:electrical_engineering,validation,1.9389729090034962
145,0.2902860244800305,0.565517246723175,0.6758620738983154,0.7014130855594272,0.17661183003721567,mmlu:electrical_engineering,test,15.926394599955529
41,0.5717821971672338,0.31707316637039185,0.7560975551605225,0.723901098901099,0.06489953616770301,mmlu:elementary_mathematics,validation,5.610940820071846
378,0.4266128003124207,0.38359788060188293,0.6507936716079712,0.6608998076069262,0.12445312139218448,mmlu:elementary_mathematics,test,49.09506770106964
14,0.5329604425600597,0.3571428656578064,0.7142857313156128,0.7111111111111111,0.06999891570636202,mmlu:formal_logic,validation,2.3224923119414598
126,0.4297262392346821,0.3888888955116272,0.6269841194152832,0.6843360720911742,0.14426210191514757,mmlu:formal_logic,test,19.36691349814646
10,0.6365507602691651,0.20000000298023224,0.800000011920929,1.0,0.16783870458602906,mmlu:global_facts,validation,1.3193851169198751
100,0.4803885504603386,0.3499999940395355,0.6299999952316284,0.6417100694444445,0.11657590389251708,mmlu:global_facts,test,10.785372324986383
32,0.21827862970530984,0.6875,0.625,0.6181818181818182,0.20458771288394928,mmlu:high_school_biology,validation,4.296187846921384
310,0.18952634373018823,0.7354838848114014,0.7032257914543152,0.75165810868635,0.13722873253207052,mmlu:high_school_biology,test,40.221511570038274
22,0.3372880667448044,0.5454545617103577,0.40909090638160706,0.3416666666666667,0.3886825686151332,mmlu:high_school_chemistry,validation,3.080812094034627
203,0.323617057847272,0.5123152732849121,0.5270935893058777,0.5692501942501943,0.25664496421813965,mmlu:high_school_chemistry,test,25.784218437969685
9,0.29119981659783256,0.6666666865348816,0.8888888955116272,1.0,0.0948562953207228,mmlu:high_school_computer_science,validation,2.070587361929938
100,0.2516631653904915,0.6299999952316284,0.5899999737739563,0.7207207207207207,0.2048008471727371,mmlu:high_school_computer_science,test,20.988094595028087
18,0.11746903922822742,0.8888888955116272,0.7222222089767456,0.46875,0.0986080633269416,mmlu:high_school_european_history,validation,11.979777361033484
165,0.2527069671587511,0.7090908885002136,0.7151514887809753,0.7265847578347578,0.13832001216483839,mmlu:high_school_european_history,test,109.06769922189415
22,0.1021412732926282,0.8636363744735718,0.7727272510528564,0.7280701754385965,0.13424179228869354,mmlu:high_school_geography,validation,2.3660897579975426
198,0.16774489565028086,0.7626262903213501,0.6565656661987305,0.73629702691278,0.17305501904150453,mmlu:high_school_geography,test,19.772516639903188
21,0.19273330484117784,0.761904776096344,0.761904776096344,0.7875,0.20747572751272295,mmlu:high_school_government_and_politics,validation,2.5843817058485
193,0.12483864281461651,0.8341968655586243,0.7512953281402588,0.7885287267080745,0.11280403081617206,mmlu:high_school_government_and_politics,test,22.064285363070667
43,0.22968695468680805,0.6511628031730652,0.7209302186965942,0.780952380952381,0.1188534456630086,mmlu:high_school_macroeconomics,validation,4.488602564902976
390,0.3164756006155259,0.5743589997291565,0.6256410479545593,0.7022106282271945,0.15458911718466345,mmlu:high_school_macroeconomics,test,39.17767140106298
29,0.3609265150695012,0.3448275923728943,0.6551724076271057,0.4315789473684211,0.23441177606582642,mmlu:high_school_mathematics,validation,3.9028119009453803
270,0.3410188412224805,0.32592591643333435,0.6851851940155029,0.5807942057942058,0.16583085700317665,mmlu:high_school_mathematics,test,33.886990177910775
26,0.2619537722605925,0.6538461446762085,0.7692307829856873,0.8202614379084967,0.12365747873599715,mmlu:high_school_microeconomics,validation,2.863343460019678
238,0.2473950173173632,0.6638655662536621,0.5714285969734192,0.6296281645569619,0.21815890424391804,mmlu:high_school_microeconomics,test,24.704614190850407
17,0.6700863031780019,0.1764705926179886,0.6470588445663452,0.6428571428571429,0.1921325466212104,mmlu:high_school_physics,validation,2.633949975017458
151,0.4720081732367838,0.3245033025741577,0.6423841118812561,0.5350140056022409,0.15582352837189933,mmlu:high_school_physics,test,20.72762059699744
60,0.14689167439937595,0.8666666746139526,0.7833333611488342,0.907451923076923,0.10734529296557108,mmlu:high_school_psychology,validation,7.481210972880945
545,0.15268221434650078,0.7963302731513977,0.7669724822044373,0.7817287333416365,0.08646562602541866,mmlu:high_school_psychology,test,67.26412692782469
23,0.3026763537655706,0.52173912525177,0.739130437374115,0.7765151515151515,0.18502116203308105,mmlu:high_school_statistics,validation,4.475015653995797
216,0.3601632332084356,0.46296295523643494,0.5925925970077515,0.6197413793103448,0.20148676440671637,mmlu:high_school_statistics,test,40.66444064187817
22,0.20964317972009835,0.7727272510528564,0.7272727489471436,0.7235294117647059,0.11434566161849286,mmlu:high_school_us_history,validation,11.354545274982229
204,0.17125022572045231,0.7647058963775635,0.7254902124404907,0.7567441239316239,0.10546539636219249,mmlu:high_school_us_history,test,103.32764472602867
26,0.27686918698824364,0.7307692170143127,0.7692307829856873,0.7218045112781954,0.1592656809550065,mmlu:high_school_world_history,validation,9.60444412799552
237,0.2256790781825907,0.746835470199585,0.746835470199585,0.7863465160075328,0.10020094833293545,mmlu:high_school_world_history,test,80.90987738408148
23,0.28481880478236987,0.739130437374115,0.8260869383811951,0.7941176470588235,0.07795129651608675,mmlu:human_aging,validation,2.178106355946511
223,0.27517610227045985,0.6412556171417236,0.695067286491394,0.7364947552447552,0.1095549523028558,mmlu:human_aging,test,19.04699045792222
12,0.40173492829004925,0.5,0.6666666865348816,0.6944444444444446,0.09600663185119629,mmlu:human_sexuality,validation,1.391507226973772
131,0.18868022099251056,0.6870229244232178,0.6641221642494202,0.7463414634146343,0.15495343927208705,mmlu:human_sexuality,test,12.851778296986595
13,0.04448619714150062,1.0,0.7692307829856873,,0.18245128943369943,mmlu:international_law,validation,2.5166310579515994
121,0.19004106078266111,0.7603305578231812,0.702479362487793,0.6791604197901049,0.14061396525911068,mmlu:international_law,test,18.188256072811782
11,0.4031985754316503,0.5454545617103577,0.8181818127632141,0.9,0.15317268805070358,mmlu:jurisprudence,validation,1.405823296168819
108,0.1255185471640693,0.7777777910232544,0.6574074029922485,0.6619543650793651,0.16362238261434767,mmlu:jurisprudence,test,11.407279253937304
18,0.2275563942061531,0.7222222089767456,0.6666666865348816,0.6692307692307692,0.28551263279385036,mmlu:logical_fallacies,validation,2.1798592109698802
163,0.20817567856033886,0.699386477470398,0.6809815764427185,0.849266022198353,0.1515975802953989,mmlu:logical_fallacies,test,18.153836083132774
11,0.42730009013956244,0.3636363744735718,0.8181818127632141,1.0,0.302446880123832,mmlu:machine_learning,validation,1.9511497898492962
112,0.4067602655185121,0.4285714328289032,0.7053571343421936,0.7327473958333333,0.10912189153688295,mmlu:machine_learning,test,17.460233196849003
11,0.08229747143658728,0.9090909361839294,0.6363636255264282,0.7,0.29049675031141803,mmlu:management,validation,1.125163379125297
103,0.20908768894602953,0.7475728392601013,0.6601941585540771,0.7352647352647352,0.18759253939378612,mmlu:management,test,8.316702971002087
25,0.10008924722671511,0.8399999737739563,0.9200000166893005,0.9642857142857143,0.11584723711013793,mmlu:marketing,validation,2.857411712873727
234,0.09087320168813068,0.8717948794364929,0.807692289352417,0.8154411764705882,0.06277386958782488,mmlu:marketing,test,24.26772210514173
11,0.048692486502907494,0.9090909361839294,1.0,1.0,0.06950866634195502,mmlu:medical_genetics,validation,1.3454301089514047
100,0.2749819791316986,0.6499999761581421,0.7099999785423279,0.7054945054945054,0.17905127942562105,mmlu:medical_genetics,test,9.70517473993823
86,0.1800074376339136,0.7325581312179565,0.8372092843055725,0.9068322981366459,0.06703419463579044,mmlu:miscellaneous,validation,7.505576221970841
783,0.1513898644791405,0.7777777910232544,0.7752234935760498,0.8170804510565716,0.10810836506377086,mmlu:miscellaneous,test,68.5950583119411
38,0.3892449532684527,0.5,0.7105262875556946,0.7797783933518004,0.12962233706524495,mmlu:moral_disputes,validation,4.704215629957616
346,0.20764597035901394,0.6965317726135254,0.6098265647888184,0.6375617466903774,0.17045740154437244,mmlu:moral_disputes,test,40.925951877143234
100,0.46282217860221864,0.3700000047683716,0.699999988079071,0.7224367224367224,0.13765102207660673,mmlu:moral_scenarios,validation,15.07068924093619
895,0.518438325048159,0.31955307722091675,0.7106145024299622,0.7036096087820225,0.11581930361646514,mmlu:moral_scenarios,test,131.59664975316264
33,0.2051064877799063,0.7272727489471436,0.7878788113594055,0.8125,0.12219715118408205,mmlu:nutrition,validation,4.868717857869342
306,0.2176828994080911,0.6830065250396729,0.6633986830711365,0.6787106003058255,0.15640339878649495,mmlu:nutrition,test,43.928925624117255
34,0.24459529974881342,0.7058823704719543,0.8235294222831726,0.8541666666666666,0.13724166680784788,mmlu:philosophy,validation,3.4610608390066773
311,0.2292080609744768,0.6881029009819031,0.6623794436454773,0.7459051931785335,0.12440220029407761,mmlu:philosophy,test,29.185919251991436
35,0.28287406734057835,0.6285714507102966,0.5714285969734192,0.7412587412587412,0.22476635149547033,mmlu:prehistory,validation,4.876028458122164
324,0.21529917106216334,0.6975308656692505,0.6759259104728699,0.7255734152067908,0.11017514158178258,mmlu:prehistory,test,41.990264303050935
31,0.35496044543481636,0.4838709533214569,0.5806451439857483,0.5604166666666666,0.2247780292264877,mmlu:professional_accounting,validation,5.45179084292613
282,0.3976029378513918,0.45035460591316223,0.6595744490623474,0.6699771399542799,0.12240148816548342,mmlu:professional_accounting,test,46.92631463916041
170,0.38037324495175306,0.48235294222831726,0.5882353186607361,0.6182095343680709,0.14171517105663523,mmlu:professional_law,validation,64.60125745483674
1534,0.4171539951295554,0.4302477240562439,0.6036505699157715,0.6088170029817627,0.1397295361858303,mmlu:professional_law,test,587.1974215051159
31,0.3667847168061041,0.6129032373428345,0.6451612710952759,0.743421052631579,0.1071959080234651,mmlu:professional_medicine,validation,8.197815514868125
272,0.3293657328056939,0.5845588445663452,0.6102941036224365,0.6734568931930762,0.14613768063923896,mmlu:professional_medicine,test,71.2496113779489
69,0.23699703078339063,0.695652186870575,0.7101449370384216,0.7981150793650793,0.11206404713616853,mmlu:professional_psychology,validation,10.078123212093487
612,0.2625559676024649,0.6372548937797546,0.6062091588973999,0.6786173056671025,0.16971963634288392,mmlu:professional_psychology,test,84.06557570304722
12,0.26998764276504517,0.5833333134651184,0.6666666865348816,0.6285714285714286,0.2259231805801392,mmlu:public_relations,validation,1.6187751330435276
110,0.2200350776314735,0.699999988079071,0.7454545497894287,0.7528532073986619,0.10280480655756864,mmlu:public_relations,test,11.855861963005736
27,0.32721194073005955,0.6296296119689941,0.5925925970077515,0.5970588235294118,0.25032879246605766,mmlu:security_studies,validation,7.472265081014484
245,0.21284481676257383,0.7061224579811096,0.6734693646430969,0.6911929993577393,0.15433342602788183,mmlu:security_studies,test,66.40212925313972
22,0.09881945631720802,0.9090909361839294,0.7727272510528564,0.375,0.11948947202075608,mmlu:sociology,validation,2.5822472698055208
201,0.15761577890286993,0.8159204125404358,0.7611940503120422,0.7463744232036915,0.10580576118545156,mmlu:sociology,test,21.919935749145225
11,0.09602137045426799,0.9090909361839294,0.8181818127632141,0.7,0.0865283120762218,mmlu:us_foreign_policy,validation,1.4626193300355226
100,0.14466072827577592,0.8399999737739563,0.7699999809265137,0.6808035714285714,0.11165106415748599,mmlu:us_foreign_policy,test,10.600047704996541
18,0.30292011300722754,0.6111111044883728,0.6111111044883728,0.6623376623376623,0.1675411197874281,mmlu:virology,validation,2.2981053609400988
166,0.4107061060796301,0.4879518151283264,0.6265060305595398,0.6536004645760743,0.1941976094820413,mmlu:virology,test,16.112730061169714
19,0.16149032429644933,0.8421052694320679,0.8947368264198303,0.8958333333333335,0.12862357967778257,mmlu:world_religions,validation,1.6972298859618604
171,0.14589811504235745,0.8304093480110168,0.847953200340271,0.8181155900922777,0.0591305340939795,mmlu:world_religions,test,13.202948956983164
