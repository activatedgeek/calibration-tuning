N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.0696131939237768,0.1818181872367859,0.6363636255264282,0.5555555555555556,0.22776296463879672,mmlu:abstract_algebra,validation,6.521708467043936
100,0.062481691688299174,0.33000001311302185,0.5899999737739563,0.47942107643600174,0.23129963576793672,mmlu:abstract_algebra,test,16.231132421875373
14,0.12325577012130193,0.5,0.6428571343421936,0.7142857142857142,0.16755153877394538,mmlu:anatomy,validation,2.444902434013784
135,0.1060570167170631,0.5185185074806213,0.6296296119689941,0.7280219780219781,0.15052674567257918,mmlu:anatomy,test,22.970064386026934
16,0.232487965375185,0.625,0.6875,0.8666666666666667,0.20868877694010735,mmlu:astronomy,validation,4.237316624028608
152,0.11130888250313306,0.4934210479259491,0.5986841917037964,0.680952380952381,0.2386124228176318,mmlu:astronomy,test,37.75910340086557
11,0.24546931277621875,0.3636363744735718,0.8181818127632141,0.8214285714285714,0.3313534368168224,mmlu:business_ethics,validation,2.9370780230965465
100,0.10062643349170684,0.5199999809265137,0.6899999976158142,0.7512019230769231,0.1270869207382202,mmlu:business_ethics,test,24.729775462998077
29,0.17387458990360125,0.5862069129943848,0.5517241358757019,0.5955882352941175,0.2481449883559655,mmlu:clinical_knowledge,validation,5.63370822602883
265,0.058063485487452084,0.5962263941764832,0.6716980934143066,0.7320182183840056,0.14015971984503403,mmlu:clinical_knowledge,test,50.09440021798946
16,0.22307050228118896,0.5625,0.75,0.8333333333333334,0.19189877435564995,mmlu:college_biology,validation,3.572058194782585
144,0.05422817170619965,0.5486111044883728,0.6388888955116272,0.7482960077896786,0.16632812635766137,mmlu:college_biology,test,31.87973775411956
8,0.2814292460680008,0.5,0.375,0.4375,0.283885158598423,mmlu:college_chemistry,validation,2.1362860889639705
100,0.07826841533184052,0.4399999976158142,0.5899999737739563,0.6132305194805194,0.1705687713623047,mmlu:college_chemistry,test,23.794652500888333
11,0.23915172706950794,0.5454545617103577,0.5454545617103577,0.4833333333333333,0.20395547693425958,mmlu:college_computer_science,validation,3.7310613410081714
100,0.11487072974443437,0.4399999976158142,0.5,0.5531655844155845,0.22766389191150663,mmlu:college_computer_science,test,32.602319315075874
11,0.17525375431234186,0.1818181872367859,0.4545454680919647,0.2222222222222222,0.2511729435487227,mmlu:college_mathematics,validation,2.847795484820381
100,0.06233548492193221,0.3100000023841858,0.6000000238418579,0.5100514258999532,0.10698561966419223,mmlu:college_mathematics,test,23.863758475985378
22,0.15730334141037683,0.5454545617103577,0.7272727489471436,0.8416666666666666,0.1862359480424361,mmlu:college_medicine,validation,5.238195409066975
173,0.07321169403936133,0.5491329431533813,0.5491329431533813,0.6334008097165991,0.24830018302608775,mmlu:college_medicine,test,50.99416488199495
11,0.12884083119305698,0.5454545617103577,0.8181818127632141,0.8,0.1979193091392517,mmlu:college_physics,validation,2.5261640960816294
102,0.18728521553909075,0.23529411852359772,0.47058823704719543,0.562767094017094,0.27729206634502784,mmlu:college_physics,test,21.573157154023647
11,0.31622943011197174,0.8181818127632141,0.7272727489471436,0.5555555555555556,0.18132303519682447,mmlu:computer_security,validation,2.458570318063721
100,0.05812181204557419,0.699999988079071,0.6600000262260437,0.7266666666666666,0.15261437296867372,mmlu:computer_security,test,18.375287600792944
26,0.1564652782220107,0.42307692766189575,0.7692307829856873,0.7363636363636363,0.2552425700884599,mmlu:conceptual_physics,validation,3.976767434971407
235,0.1324305961740778,0.3787234127521515,0.5404255390167236,0.6598814837617362,0.23173332823083753,mmlu:conceptual_physics,test,33.93662948906422
12,0.16740141312281293,0.25,0.4166666567325592,0.5925925925925926,0.3854953447977702,mmlu:econometrics,validation,3.3114288828801364
114,0.1380235351491393,0.2719298303127289,0.44736841320991516,0.5668480373105323,0.2670500006592064,mmlu:econometrics,test,29.294567997101694
16,0.22651579603552818,0.3125,0.375,0.6909090909090909,0.4059053584933281,mmlu:electrical_engineering,validation,3.2399525810033083
145,0.07684717507197941,0.4482758641242981,0.6275861859321594,0.7489423076923077,0.1662364047149132,mmlu:electrical_engineering,test,27.67311626393348
41,0.11319765666636025,0.3658536672592163,0.5609756112098694,0.5230769230769231,0.23909892977737804,mmlu:elementary_mathematics,validation,9.727062478894368
378,0.0972330496897773,0.32275131344795227,0.5740740895271301,0.5621477971311475,0.15980551529813697,mmlu:elementary_mathematics,test,85.53417686000466
14,0.12619798524039133,0.2857142984867096,0.6428571343421936,0.7,0.2416609695979527,mmlu:formal_logic,validation,3.7682675011456013
126,0.03215286679684172,0.3571428656578064,0.460317462682724,0.5310013717421125,0.2925741426528446,mmlu:formal_logic,test,32.58420234802179
10,0.16201186776161192,0.5,0.5,0.44,0.37976832389831533,mmlu:global_facts,validation,2.174017762998119
100,0.10517410397529603,0.3499999940395355,0.6000000238418579,0.6050549450549451,0.11753688216209414,mmlu:global_facts,test,19.279713325202465
32,0.12172777019441128,0.53125,0.71875,0.815686274509804,0.1447528563439846,mmlu:high_school_biology,validation,7.513505985029042
310,0.08067745210662966,0.6580645442008972,0.7193548679351807,0.703177025527192,0.17585606940330994,mmlu:high_school_biology,test,70.47174047399312
22,0.12493294883858076,0.3636363744735718,0.5,0.4464285714285714,0.2679964872923764,mmlu:high_school_chemistry,validation,5.202250678092241
203,0.05575069344689694,0.47783252596855164,0.546798050403595,0.5408967127018088,0.21248541442044264,mmlu:high_school_chemistry,test,44.89628982101567
9,0.26322924759652877,0.6666666865348816,0.6666666865348816,0.8333333333333334,0.19598267475763956,mmlu:high_school_computer_science,validation,3.4461548449471593
100,0.12126098752021791,0.550000011920929,0.6600000262260437,0.7357575757575757,0.11988592684268952,mmlu:high_school_computer_science,test,36.53599599795416
18,0.21657157772117192,0.6666666865348816,0.7222222089767456,0.8333333333333334,0.20060696866777208,mmlu:high_school_european_history,validation,21.22891507507302
165,0.07021790941556295,0.6484848260879517,0.7575757503509521,0.7757009345794392,0.08031361789414374,mmlu:high_school_european_history,test,193.24202424986288
22,0.1206256137652831,0.7272727489471436,0.7727272510528564,0.8854166666666666,0.08022710410031407,mmlu:high_school_geography,validation,3.992036957060918
198,0.07263806537546293,0.7222222089767456,0.6212121248245239,0.6690400508582326,0.2330984987995841,mmlu:high_school_geography,test,34.913586516166106
21,0.1852072931471325,0.7142857313156128,0.761904776096344,0.9777777777777779,0.19432277906508671,mmlu:high_school_government_and_politics,validation,4.440729588037357
193,0.07061314428408529,0.8341968655586243,0.7305699586868286,0.6704192546583851,0.13888032170775025,mmlu:high_school_government_and_politics,test,39.76530222897418
43,0.12308676021043644,0.4883720874786377,0.6511628031730652,0.7619047619047618,0.2823215168575908,mmlu:high_school_macroeconomics,validation,7.952106622979045
390,0.08908910621435215,0.5435897707939148,0.6153846383094788,0.6604833580665678,0.1763011950712938,mmlu:high_school_macroeconomics,test,70.88263123808429
29,0.11224446214478592,0.24137930572032928,0.7586206793785095,0.5584415584415584,0.1853752197890446,mmlu:high_school_mathematics,validation,6.540770319988951
270,0.0799310932556788,0.24444444477558136,0.6407407522201538,0.5189393939393939,0.11543107871656066,mmlu:high_school_mathematics,test,59.03239485598169
26,0.1624302909924434,0.6538461446762085,0.6153846383094788,0.5915032679738562,0.20223856430787307,mmlu:high_school_microeconomics,validation,4.829773892881349
238,0.0833617255968206,0.5840336084365845,0.5798319578170776,0.6200857495821525,0.19927940398705107,mmlu:high_school_microeconomics,test,43.95616846997291
17,0.1716516771737267,0.23529411852359772,0.4117647111415863,0.5,0.4080039999064277,mmlu:high_school_physics,validation,4.377694709226489
151,0.06615366327841553,0.41059601306915283,0.4834437072277069,0.5102392171076477,0.25316407585775613,mmlu:high_school_physics,test,36.156335192965344
60,0.11583499262730279,0.800000011920929,0.8666666746139526,0.912326388888889,0.04120554924011229,mmlu:high_school_psychology,validation,13.485447071958333
545,0.056013657849863036,0.763302743434906,0.7431192398071289,0.7063860316040549,0.10682305185073017,mmlu:high_school_psychology,test,122.82581467414275
23,0.10543480645055357,0.3913043439388275,0.5652173757553101,0.76984126984127,0.2398834124855373,mmlu:high_school_statistics,validation,7.432900630170479
216,0.04311546021037632,0.4583333432674408,0.5462962985038757,0.5782180782180784,0.2104031937541785,mmlu:high_school_statistics,test,70.55307315313257
22,0.1829272142865441,0.7727272510528564,0.6363636255264282,0.5294117647058824,0.18860498883507465,mmlu:high_school_us_history,validation,19.98507753596641
204,0.06136218823638616,0.75,0.7450980544090271,0.7430475458157119,0.09558596535056248,mmlu:high_school_us_history,test,183.7226118010003
26,0.1794874771283223,0.5384615659713745,0.7307692170143127,0.8869047619047619,0.12572643160820007,mmlu:high_school_world_history,validation,17.123997417045757
237,0.051091996426320785,0.7257384061813354,0.7721518874168396,0.7677549194991055,0.0782657275723003,mmlu:high_school_world_history,test,144.97814973606728
23,0.3181648306224657,0.5652173757553101,0.739130437374115,0.8192307692307693,0.13911276278288467,mmlu:human_aging,validation,3.5955655451398343
223,0.07719957734971838,0.605381190776825,0.6591928005218506,0.7223484848484849,0.14850280664426863,mmlu:human_aging,test,33.6315382020548
12,0.23632426559925082,0.4166666567325592,0.6666666865348816,0.7714285714285714,0.1930704563856125,mmlu:human_sexuality,validation,2.1741338400170207
131,0.09733276467286903,0.6106870174407959,0.6641221642494202,0.7161764705882353,0.12842447430122902,mmlu:human_sexuality,test,22.600865819025785
13,0.1827215964977558,0.7692307829856873,0.8461538553237915,0.7999999999999999,0.19281192467762875,mmlu:international_law,validation,3.662144646048546
121,0.08156253237369632,0.7190082669258118,0.7355371713638306,0.7194050033806626,0.09912241835239503,mmlu:international_law,test,31.865239338018
11,0.2184979725967754,0.4545454680919647,0.9090909361839294,0.9,0.12247758561914615,mmlu:jurisprudence,validation,2.196744987042621
108,0.12156277619026327,0.7222222089767456,0.7407407164573669,0.7061965811965811,0.07266888022422789,mmlu:jurisprudence,test,20.026021473109722
18,0.1765345086654027,0.7777777910232544,0.7777777910232544,0.5714285714285714,0.1342576874627007,mmlu:logical_fallacies,validation,3.8282535830512643
163,0.07610305193011746,0.6441717743873596,0.7300613522529602,0.7637931034482758,0.10906231476485365,mmlu:logical_fallacies,test,32.543407718185335
11,0.18800130757418546,0.4545454680919647,0.5454545617103577,0.5666666666666667,0.33838351206345996,mmlu:machine_learning,validation,3.097493777051568
112,0.18364768049546648,0.2232142835855484,0.5178571343421936,0.6177011494252873,0.19038640122328485,mmlu:machine_learning,test,29.92640121700242
11,0.13454832001165912,0.7272727489471436,0.6363636255264282,0.7291666666666667,0.25467145442962646,mmlu:management,validation,1.7533940731082112
103,0.08853922220109736,0.7572815418243408,0.6990291476249695,0.7356410256410256,0.15014789289641145,mmlu:management,test,14.534246429800987
25,0.24610543847084046,0.8399999737739563,0.7200000286102295,0.8095238095238095,0.19726813554763795,mmlu:marketing,validation,4.909742038929835
234,0.0726083690284664,0.7991452813148499,0.7179487347602844,0.7424621686198657,0.12034333974887162,mmlu:marketing,test,43.37775149778463
11,0.17787489565936004,0.8181818127632141,0.8181818127632141,0.9166666666666666,0.1415094408121976,mmlu:medical_genetics,validation,2.109039396047592
100,0.13138089478015902,0.5799999833106995,0.6299999952316284,0.6648193760262726,0.17353716015815737,mmlu:medical_genetics,test,16.784816252999008
86,0.08592159768869709,0.6627907156944275,0.7325581312179565,0.8421052631578946,0.14168855062750885,mmlu:miscellaneous,validation,12.814111630897969
783,0.056328266021696834,0.7586206793785095,0.7662835121154785,0.7957974809826662,0.09999644931401025,mmlu:miscellaneous,test,118.42837196588516
38,0.1724564589952168,0.5,0.6315789222717285,0.7271468144044322,0.19913698027008458,mmlu:moral_disputes,validation,8.10927161690779
346,0.05548769166703859,0.6040462255477905,0.647398829460144,0.6865854084448014,0.15204993527748684,mmlu:moral_disputes,test,72.40527878794819
100,0.08906677156686785,0.33000001311302185,0.6800000071525574,0.5587969244685663,0.18820094525814057,mmlu:moral_scenarios,validation,26.317948144860566
895,0.07549112196075183,0.35754188895225525,0.6480447053909302,0.6053233695652174,0.20914589279856757,mmlu:moral_scenarios,test,231.87645798618905
33,0.1590046322706974,0.7575757503509521,0.6969696879386902,0.71,0.13383938507600263,mmlu:nutrition,validation,8.535770448157564
306,0.09267530517250881,0.6307189464569092,0.6699346303939819,0.6833188133339447,0.16324046955389135,mmlu:nutrition,test,77.89854449499398
34,0.20768010265686931,0.6470588445663452,0.7058823704719543,0.7992424242424242,0.15906526761896472,mmlu:philosophy,validation,5.676127772079781
311,0.09510084574628873,0.6495176553726196,0.6816720366477966,0.6623444454537196,0.13775639346174873,mmlu:philosophy,test,50.02944437600672
35,0.14031588009425572,0.6571428775787354,0.5428571701049805,0.6213768115942029,0.23797855547496252,mmlu:prehistory,validation,8.52379895793274
324,0.05882724328541461,0.6358024477958679,0.6358024477958679,0.6729060391640612,0.1646116193797853,mmlu:prehistory,test,74.97163828113116
31,0.14624394428345464,0.29032257199287415,0.4838709533214569,0.5833333333333333,0.2893272273002132,mmlu:professional_accounting,validation,9.334618868073449
282,0.03571194600551686,0.41489362716674805,0.567375898361206,0.6280238280238282,0.1740967669385545,mmlu:professional_accounting,test,83.3501862748526
170,0.12842015641577104,0.38235294818878174,0.47647058963775635,0.6194139194139194,0.31077982047024894,mmlu:professional_law,validation,116.16565475403331
1534,0.09026802297210446,0.40612778067588806,0.5058670043945312,0.5958289357998284,0.27475526004135997,mmlu:professional_law,test,1060.8095698500983
31,0.19196684706595632,0.4516128897666931,0.5806451439857483,0.6911764705882353,0.19015479087829587,mmlu:professional_medicine,validation,14.659125055884942
272,0.09498748511952512,0.5404411554336548,0.6102941036224365,0.6714557823129251,0.16587914701770332,mmlu:professional_medicine,test,128.99312446685508
69,0.15919146891953287,0.5652173757553101,0.6376811861991882,0.7111111111111111,0.13292193758314935,mmlu:professional_psychology,validation,17.521828152937815
612,0.0768520909976336,0.5539215803146362,0.6078431606292725,0.6382702842879834,0.17377795765992085,mmlu:professional_psychology,test,149.0542477951385
12,0.4198806956410408,0.5,0.5833333134651184,0.5555555555555556,0.340147003531456,mmlu:public_relations,validation,2.6920629700180143
110,0.08595223860307172,0.6454545259475708,0.7090908885002136,0.7697724810400868,0.09121004234660757,mmlu:public_relations,test,21.30402148189023
27,0.22061538365152147,0.6296296119689941,0.5925925970077515,0.6176470588235294,0.24889525881520025,mmlu:security_studies,validation,13.433395714964718
245,0.05831849891312268,0.6204081773757935,0.640816330909729,0.646823712507074,0.17263384424910252,mmlu:security_studies,test,121.41318808798678
22,0.20658719404177228,0.8181818127632141,0.7272727489471436,0.6388888888888888,0.1575040979818864,mmlu:sociology,validation,4.435547132045031
201,0.0791623977879387,0.7761194109916687,0.7512437701225281,0.750925925925926,0.13881597827323047,mmlu:sociology,test,39.802818544907495
11,0.13104425235228107,0.9090909361839294,0.8181818127632141,0.8,0.17551352219148114,mmlu:us_foreign_policy,validation,2.317824798868969
100,0.08155262723565102,0.8399999737739563,0.7400000095367432,0.644345238095238,0.10399263978004455,mmlu:us_foreign_policy,test,18.982298623770475
18,0.2801609834035238,0.4444444477558136,0.4444444477558136,0.5375,0.3476095630062951,mmlu:virology,validation,3.8626220209989697
166,0.1782420268618917,0.4397590458393097,0.5662650465965271,0.6146707909854175,0.23676829704319136,mmlu:virology,test,28.514506828039885
19,0.09875376914676866,0.7894737124443054,0.8947368264198303,0.8166666666666667,0.0956712051441795,mmlu:world_religions,validation,2.6165527978446335
171,0.05092698492501912,0.7602339386940002,0.8070175647735596,0.8150093808630394,0.0705542919928567,mmlu:world_religions,test,22.32298278203234
