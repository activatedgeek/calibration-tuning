N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.19600508429787375,0.1818181872367859,0.4545454680919647,0.4444444444444445,0.3884134292602539,mmlu:abstract_algebra,validation,6.904664971167222
100,0.10345885753631592,0.3400000035762787,0.44999998807907104,0.5144830659536542,0.16413219630718234,mmlu:abstract_algebra,test,9.76604822394438
14,0.27451826844896593,0.6428571343421936,0.5714285969734192,0.6777777777777777,0.17466775434357779,mmlu:anatomy,validation,1.493980095954612
135,0.06617017697404932,0.48148149251937866,0.4888888895511627,0.7621978021978023,0.24344941245185,mmlu:anatomy,test,13.686989055015147
16,0.10867198556661603,0.4375,0.4375,0.39682539682539686,0.28577157109975815,mmlu:astronomy,validation,2.481771958991885
152,0.07267576789385394,0.42105263471603394,0.44736841320991516,0.6798650568181819,0.2775425483521662,mmlu:astronomy,test,22.322710273088887
11,0.2740178975191983,0.6363636255264282,0.5454545617103577,0.5178571428571428,0.18897728486494586,mmlu:business_ethics,validation,1.7330540351103991
100,0.0867828518152237,0.47999998927116394,0.5699999928474426,0.678485576923077,0.14407177090644835,mmlu:business_ethics,test,14.587785346899182
29,0.1713621636916851,0.4137931168079376,0.6206896305084229,0.8578431372549019,0.09117992376459057,mmlu:clinical_knowledge,validation,3.329929028172046
265,0.0635473775413801,0.49056604504585266,0.5773584842681885,0.6989173789173788,0.08727846078152926,mmlu:clinical_knowledge,test,29.300076798070222
16,0.14043159037828445,0.3125,0.625,0.7454545454545455,0.21738110482692716,mmlu:college_biology,validation,2.136113773100078
144,0.09594800944129625,0.4375,0.5833333134651184,0.7645502645502644,0.0739868941406409,mmlu:college_biology,test,19.089473854051903
8,0.2831239774823189,0.5,0.25,0.3125,0.41835326701402664,mmlu:college_chemistry,validation,1.3060424330178648
100,0.022121665477752676,0.3499999940395355,0.4699999988079071,0.5791208791208791,0.1406076788902283,mmlu:college_chemistry,test,14.019093245035037
11,0.27322495254603296,0.6363636255264282,0.4545454680919647,0.21428571428571427,0.296886763789437,mmlu:college_computer_science,validation,2.227286885958165
100,0.13088626027107236,0.36000001430511475,0.5699999928474426,0.6039496527777778,0.12297679245471951,mmlu:college_computer_science,test,19.27490134513937
11,0.1655176877975464,0.3636363744735718,0.4545454680919647,0.25,0.13533104007894342,mmlu:college_mathematics,validation,1.7162878240924329
100,0.056095322370529194,0.3499999940395355,0.6499999761581421,0.6204395604395605,0.07572455406188969,mmlu:college_mathematics,test,14.023735146038234
22,0.11802463910796426,0.40909090638160706,0.5,0.7478632478632479,0.2298424243927002,mmlu:college_medicine,validation,3.1398882640060037
173,0.1069928762540652,0.38728323578834534,0.4393063485622406,0.6172205012672487,0.2804393234280492,mmlu:college_medicine,test,30.326844511087984
11,0.17821372909979386,0.4545454680919647,0.6363636255264282,0.75,0.15264751694419168,mmlu:college_physics,validation,1.5339165818877518
102,0.1996084521798526,0.21568627655506134,0.3921568691730499,0.5744318181818181,0.2248760023537804,mmlu:college_physics,test,12.639475487871096
11,0.12465705925768072,0.5454545617103577,0.4545454680919647,0.7833333333333333,0.26097093387083575,mmlu:computer_security,validation,1.496258296072483
100,0.09803613364696503,0.5699999928474426,0.6000000238418579,0.7586699306405549,0.14321017742156986,mmlu:computer_security,test,10.8704832859803
26,0.15487189017809355,0.38461539149284363,0.42307692766189575,0.70625,0.28067198624977696,mmlu:conceptual_physics,validation,2.3972809391561896
235,0.07419210482150952,0.42553192377090454,0.4382978677749634,0.5871851851851851,0.25232663509693554,mmlu:conceptual_physics,test,20.084839169867337
12,0.22426709284385046,0.1666666716337204,0.4166666567325592,0.6,0.21415468553702036,mmlu:econometrics,validation,1.999105226015672
114,0.15179891910469323,0.28947368264198303,0.44736841320991516,0.6487093153759821,0.1480581059790494,mmlu:econometrics,test,17.377150045940652
16,0.20547708123922345,0.5625,0.25,0.3492063492063492,0.38732537254691124,mmlu:electrical_engineering,validation,1.9326407318003476
145,0.08971572210048809,0.4275861978530884,0.5724138021469116,0.5880295375048582,0.1289530791085342,mmlu:electrical_engineering,test,16.074834134895355
41,0.13848892653860695,0.24390244483947754,0.6097561120986938,0.6951612903225807,0.09119911019395036,mmlu:elementary_mathematics,validation,5.753984936047345
378,0.08314153386486901,0.230158731341362,0.4761904776096344,0.4842793379942331,0.14449907563350817,mmlu:elementary_mathematics,test,50.782709163147956
14,0.13452591427734922,0.2142857164144516,0.5,0.7272727272727273,0.07948053308895653,mmlu:formal_logic,validation,2.213213188108057
126,0.04521348386529893,0.3730158805847168,0.4047619104385376,0.5118502558577969,0.1810184305622464,mmlu:formal_logic,test,19.210148284910247
10,0.3186369210481644,0.0,0.5,,0.07709693312644957,mmlu:global_facts,validation,1.2895730470772833
100,0.08433903574943544,0.30000001192092896,0.5699999928474426,0.6457142857142857,0.13771425247192381,mmlu:global_facts,test,11.037846578052267
32,0.17761011514812708,0.34375,0.4375,0.7077922077922079,0.2593786437064409,mmlu:high_school_biology,validation,4.395815460011363
310,0.05050483990100123,0.48064514994621277,0.5548387169837952,0.6959231314352411,0.19256956115845714,mmlu:high_school_biology,test,41.74288018187508
22,0.06607326187870721,0.3636363744735718,0.40909090638160706,0.33035714285714285,0.17911219596862793,mmlu:high_school_chemistry,validation,3.102062518009916
203,0.0466676843283799,0.3694581389427185,0.4532019793987274,0.5986979166666666,0.17699656286850352,mmlu:high_school_chemistry,test,26.56822256091982
9,0.2883785665035247,0.5555555820465088,0.7777777910232544,0.9,0.18195167515012955,mmlu:high_school_computer_science,validation,2.0610369159840047
100,0.09103344589471818,0.3799999952316284,0.5600000023841858,0.7381154499151104,0.1091841411590576,mmlu:high_school_computer_science,test,21.503628296079114
18,0.3306613730059729,0.6111111044883728,0.6111111044883728,0.6428571428571429,0.16353391276465526,mmlu:high_school_european_history,validation,12.574908503796905
165,0.14075853662057358,0.6121212244033813,0.6303030252456665,0.7756033415841584,0.16394838130835332,mmlu:high_school_european_history,test,114.77810943708755
22,0.12117820300839165,0.6818181872367859,0.6363636255264282,0.8571428571428572,0.21075565706599841,mmlu:high_school_geography,validation,2.3547935751266778
198,0.10586895846357249,0.4898989796638489,0.5404040217399597,0.7853424517709503,0.1712083343905632,mmlu:high_school_geography,test,20.855774479918182
21,0.1786493942851112,0.6666666865348816,0.7142857313156128,0.6377551020408163,0.23314719540732248,mmlu:high_school_government_and_politics,validation,2.6823787069879472
193,0.09154047419370147,0.6891191601753235,0.6787564754486084,0.738095238095238,0.09695727466919263,mmlu:high_school_government_and_politics,test,24.185868505155668
43,0.14036800764327825,0.3255814015865326,0.44186046719551086,0.666256157635468,0.21321961214376053,mmlu:high_school_macroeconomics,validation,4.688133999006823
390,0.029747987175599115,0.4384615421295166,0.5461538434028625,0.6494432428102219,0.08363214517251037,mmlu:high_school_macroeconomics,test,41.850501663051546
29,0.0965060406717761,0.4137931168079376,0.4482758641242981,0.4485294117647059,0.12055876542781961,mmlu:high_school_mathematics,validation,3.8928633409086615
270,0.05462032037752647,0.25925925374031067,0.5185185074806213,0.5428214285714286,0.05289714071485732,mmlu:high_school_mathematics,test,34.741582710063085
26,0.3137267323640676,0.26923078298568726,0.42307692766189575,0.7969924812030074,0.33213480848532456,mmlu:high_school_microeconomics,validation,2.8716360670514405
238,0.08233299976637382,0.4495798349380493,0.5,0.6345509024755654,0.1680105353603844,mmlu:high_school_microeconomics,test,25.939650516025722
17,0.135624300031101,0.4117647111415863,0.4117647111415863,0.4071428571428571,0.223858843831455,mmlu:high_school_physics,validation,2.5483554219827056
151,0.10170582963141386,0.2847682237625122,0.42384105920791626,0.5394056847545219,0.15941466400954896,mmlu:high_school_physics,test,21.35089151095599
60,0.167490786810716,0.6833333373069763,0.7333333492279053,0.7830551989730424,0.19692666431268058,mmlu:high_school_psychology,validation,8.025295421946794
545,0.07126192281005582,0.6293578147888184,0.6550458669662476,0.7256660797275063,0.10304692557098671,mmlu:high_school_psychology,test,73.08105363301001
23,0.1275557771972988,0.3478260934352875,0.5652173757553101,0.7458333333333333,0.0766114203826241,mmlu:high_school_statistics,validation,4.435559014091268
216,0.1062640449791043,0.25925925374031067,0.5,0.5687500000000001,0.18187094010688637,mmlu:high_school_statistics,test,41.59107173094526
22,0.2552962045777928,0.6818181872367859,0.6818181872367859,0.6714285714285715,0.10352665998718955,mmlu:high_school_us_history,validation,11.799696051049978
204,0.09984620470626682,0.5686274766921997,0.6274510025978088,0.7768906739811912,0.10441699068920282,mmlu:high_school_us_history,test,108.77626331988722
26,0.15238313491527855,0.5769230723381042,0.5769230723381042,0.706060606060606,0.25384274812845087,mmlu:high_school_world_history,validation,10.075012544170022
237,0.1755296935009051,0.6455696225166321,0.6455696225166321,0.7808512293806412,0.1657441074838115,mmlu:high_school_world_history,test,85.37693373090588
23,0.2850923564123071,0.6521739363670349,0.695652186870575,0.6666666666666667,0.0969294750172159,mmlu:human_aging,validation,2.1552690700627863
223,0.07290999691582581,0.5650224089622498,0.6143497824668884,0.6657257404680085,0.08349224804762766,mmlu:human_aging,test,19.836502494988963
12,0.2745535920063654,0.5833333134651184,0.4166666567325592,0.4571428571428571,0.36942874391873676,mmlu:human_sexuality,validation,1.323730590986088
131,0.08630409222522764,0.5419847369194031,0.5572519302368164,0.667018779342723,0.13362245432293143,mmlu:human_sexuality,test,13.407913414994255
13,0.2099853983292213,0.8461538553237915,0.8461538553237915,0.9545454545454546,0.1746818652519813,mmlu:international_law,validation,2.1981592890806496
121,0.09245428492215052,0.6198347210884094,0.6033057570457458,0.6808695652173914,0.18073779984939198,mmlu:international_law,test,19.001066273078322
11,0.16036485000090164,0.5454545617103577,0.6363636255264282,0.8833333333333333,0.17110470208254724,mmlu:jurisprudence,validation,1.3566555441357195
108,0.11777489604773345,0.5092592835426331,0.5370370149612427,0.7452830188679245,0.15755328867170548,mmlu:jurisprudence,test,11.793265624903142
18,0.24433038135369617,0.7222222089767456,0.7222222089767456,0.7846153846153846,0.05909799536069236,mmlu:logical_fallacies,validation,2.222549560945481
163,0.07949475166987788,0.5398772954940796,0.5644171833992004,0.7145454545454545,0.14327336235280416,mmlu:logical_fallacies,test,19.456866535823792
11,0.16532550074837424,0.1818181872367859,0.5454545617103577,0.75,0.07691499319943515,mmlu:machine_learning,validation,1.8799560139887035
112,0.053231227610792416,0.4017857015132904,0.4464285671710968,0.5235489220563848,0.15093633745397841,mmlu:machine_learning,test,17.67195338010788
11,0.30823718959634955,0.27272728085517883,0.4545454680919647,1.0,0.380808488889174,mmlu:management,validation,1.0514833729248494
103,0.11671582066897052,0.6019417643547058,0.6019417643547058,0.7006294256490952,0.13306688105018394,mmlu:management,test,8.499650599900633
25,0.2095997428894043,0.800000011920929,0.8399999737739563,0.7949999999999999,0.06417102813720701,mmlu:marketing,validation,2.871581112034619
234,0.07044184717357667,0.6666666865348816,0.7094017267227173,0.7767915844838922,0.061009074632938094,mmlu:marketing,test,25.64557488099672
11,0.17338090051304209,0.8181818127632141,0.8181818127632141,0.7222222222222222,0.13051251931623978,mmlu:medical_genetics,validation,1.2700823519844562
100,0.13484414756298066,0.4699999988079071,0.4699999988079071,0.6459253311922923,0.2587056565284729,mmlu:medical_genetics,test,10.015238635009155
86,0.13362047041571418,0.604651153087616,0.6511628031730652,0.8758484162895928,0.17210455827934798,mmlu:miscellaneous,validation,7.546924120979384
783,0.0690558131779443,0.64112389087677,0.6602809429168701,0.8060037430349773,0.12385886679207228,mmlu:miscellaneous,test,70.37107979692519
38,0.20729207600417893,0.3684210479259491,0.3684210479259491,0.8422619047619048,0.40531442981017257,mmlu:moral_disputes,validation,4.796992209041491
346,0.07984148026201766,0.49421966075897217,0.49132949113845825,0.5882873851294904,0.2447756754525135,mmlu:moral_disputes,test,42.93969704792835
100,0.08912282347679136,0.25,0.6600000262260437,0.5885333333333334,0.13848248481750491,mmlu:moral_scenarios,validation,15.614935962948948
895,0.11698284418889265,0.22234636545181274,0.7374301552772522,0.5978419395829724,0.21642602722072068,mmlu:moral_scenarios,test,137.71323255705647
33,0.12149139335661226,0.6666666865348816,0.7575757503509521,0.8636363636363636,0.13044590480399854,mmlu:nutrition,validation,5.063785712001845
306,0.06356700436741698,0.5032680034637451,0.5490196347236633,0.6709671907040328,0.14999654674841686,mmlu:nutrition,test,46.34072984592058
34,0.25986306456958547,0.4117647111415863,0.4117647111415863,0.6964285714285714,0.3815528662765727,mmlu:philosophy,validation,3.4253251110203564
311,0.05007771175007345,0.5691318511962891,0.5723472833633423,0.6491272451302808,0.19446690059551475,mmlu:philosophy,test,29.94031219696626
35,0.18676100288118636,0.4000000059604645,0.48571428656578064,0.6700680272108844,0.22734890324728832,mmlu:prehistory,validation,5.0241933760698885
324,0.08562614612373304,0.5061728358268738,0.5493826866149902,0.7538681402439025,0.187280508287159,mmlu:prehistory,test,44.7741026408039
31,0.2381780435962062,0.25806450843811035,0.29032257199287415,0.6603260869565217,0.3438032384841673,mmlu:professional_accounting,validation,5.55528973788023
282,0.06284227924989469,0.3617021143436432,0.42198580503463745,0.57859477124183,0.1920836889151986,mmlu:professional_accounting,test,49.33006614702754
170,0.08942360790336834,0.3529411852359772,0.34117648005485535,0.4397727272727273,0.31397742033004766,mmlu:professional_law,validation,68.81241982709616
1534,0.028630297684451897,0.3422425091266632,0.38331159949302673,0.619309075463684,0.2721718398968275,mmlu:professional_law,test,626.8180027068593
31,0.10904836462390041,0.4516128897666931,0.4838709533214569,0.5945378151260504,0.2900481723969982,mmlu:professional_medicine,validation,8.603014388820156
272,0.13875008264885233,0.5110294222831726,0.5477941036224365,0.5931465354032563,0.17348177533815884,mmlu:professional_medicine,test,75.97009050287306
69,0.12799802120181097,0.37681159377098083,0.4202898442745209,0.7016994633273704,0.3014741799105769,mmlu:professional_psychology,validation,10.413282488007098
612,0.04183238024025961,0.4215686321258545,0.4346405267715454,0.6207298646695572,0.29760080877861955,mmlu:professional_psychology,test,88.22051678993739
12,0.22806940476099655,0.4166666567325592,0.5833333134651184,0.5714285714285714,0.409113531311353,mmlu:public_relations,validation,1.57699756603688
110,0.08100855242122304,0.5363636612892151,0.6090909242630005,0.7622133599202393,0.15229438164017417,mmlu:public_relations,test,12.553465666016564
27,0.07586135687651457,0.4444444477558136,0.48148149251937866,0.6138888888888889,0.372234355520319,mmlu:security_studies,validation,8.036860453896224
245,0.058859858220937325,0.4612244963645935,0.44489794969558716,0.6198377581120944,0.2958897449532334,mmlu:security_studies,test,71.92758199502714
22,0.12477527152408253,0.6818181872367859,0.5909090638160706,0.4714285714285714,0.2655422037298029,mmlu:sociology,validation,2.6410027251113206
201,0.08385253100845944,0.6318408250808716,0.7014925479888916,0.737231325814003,0.07192459094583692,mmlu:sociology,test,23.846558971097693
11,0.21938796747814523,0.4545454680919647,0.4545454680919647,0.9833333333333334,0.3596453395756808,mmlu:us_foreign_policy,validation,1.3774496419355273
100,0.06875552415847777,0.6499999761581421,0.6399999856948853,0.6378021978021978,0.15227814078330992,mmlu:us_foreign_policy,test,11.04787662695162
18,0.28559624486499363,0.3333333432674408,0.2777777910232544,0.5347222222222222,0.40168968505329555,mmlu:virology,validation,2.320041867205873
166,0.1447548810617033,0.40361446142196655,0.40963855385780334,0.5322629277853158,0.31441629686987543,mmlu:virology,test,16.913880873005837
19,0.2317042586050536,0.7894737124443054,0.7894737124443054,0.6416666666666666,0.11595639115885686,mmlu:world_religions,validation,1.579040447017178
171,0.14489754790451093,0.707602322101593,0.6959064602851868,0.6747933884297521,0.060866778356987145,mmlu:world_religions,test,13.309859579894692
