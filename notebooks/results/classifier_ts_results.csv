N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts,model_name,eval_mode,train_mode,fuzzy_gpt-3.5-turbo-1106_acc,fuzzy_gpt-3.5-turbo-1106_unc_acc,fuzzy_gpt-3.5-turbo-1106_unc_auroc,fuzzy_gpt-3.5-turbo-1106_unc_ece
14,0.4112160929611751,0.5714285969734192,0.4285714626312256,0.5833333333333334,0.42392722623688833,mmlu:anatomy,validation,3.542531879618764,mistral_7b_instruct,choice,choice,,,,
135,0.30549711872030183,0.5999999642372131,0.614814817905426,0.5887059899405579,0.2001916850054706,mmlu:anatomy,test,15.215682519599795,mistral_7b_instruct,choice,choice,,,,
16,0.34233415871858597,0.5625,0.5,0.6666666666666667,0.2549814321100712,mmlu:astronomy,validation,2.928074397146702,mistral_7b_instruct,choice,choice,,,,
152,0.2402420408631626,0.6513158082962036,0.6381579041481018,0.6475128644939965,0.09614056309587077,mmlu:astronomy,test,26.2796410638839,mistral_7b_instruct,choice,choice,,,,
11,0.2133804505521601,0.7272727489471436,0.6363636255264282,0.625,0.23302250016819348,mmlu:business_ethics,validation,1.9673222173005342,mistral_7b_instruct,choice,choice,,,,
100,0.3043138575553894,0.5600000023841858,0.6699999570846558,0.6986607142857143,0.09768201231956483,mmlu:business_ethics,test,16.837190622463822,mistral_7b_instruct,choice,choice,,,,
29,0.2928923409560631,0.6206896305084229,0.6551724076271057,0.7651515151515151,0.09200057284585361,mmlu:clinical_knowledge,validation,3.829222960397601,mistral_7b_instruct,choice,choice,,,,
265,0.21389452466424902,0.6905660629272461,0.701886773109436,0.6375449820071971,0.04749359274810216,mmlu:clinical_knowledge,test,33.51445431821048,mistral_7b_instruct,choice,choice,,,,
16,0.280781714245677,0.6875,0.6875,0.7636363636363637,0.13231129944324493,mmlu:college_biology,validation,2.474926684051752,mistral_7b_instruct,choice,choice,,,,
144,0.22419004763166112,0.7291666865348816,0.6736111044883728,0.6432234432234433,0.0965099905927976,mmlu:college_biology,test,21.526611860841513,mistral_7b_instruct,choice,choice,,,,
8,0.410574235022068,0.5,0.75,0.6875,0.08362984657287599,mmlu:college_chemistry,validation,1.5127430837601423,mistral_7b_instruct,choice,choice,,,,
100,0.3482097971439362,0.44999998807907104,0.6499999761581421,0.610305958132045,0.09148087859153749,mmlu:college_chemistry,test,16.685084270313382,mistral_7b_instruct,choice,choice,,,,
11,0.3158503472805023,0.4545454680919647,0.7272727489471436,0.5,0.33870983123779297,mmlu:college_computer_science,validation,2.82295891828835,mistral_7b_instruct,choice,choice,,,,
100,0.23187010854482654,0.5199999809265137,0.6299999952316284,0.4579326923076923,0.11903350591659546,mmlu:college_computer_science,test,25.473862681537867,mistral_7b_instruct,choice,choice,,,,
11,0.41089535301381896,0.5454545617103577,0.6363636255264282,0.2333333333333333,0.08859606222672894,mmlu:college_mathematics,validation,2.0391697082668543,mistral_7b_instruct,choice,choice,,,,
100,0.36699718654155733,0.3100000023841858,0.7199999690055847,0.453015427769986,0.06598030626773836,mmlu:college_mathematics,test,17.071178544312716,mistral_7b_instruct,choice,choice,,,,
22,0.29160571098327637,0.6363636255264282,0.6818181872367859,0.42857142857142855,0.11121957952325996,mmlu:college_medicine,validation,3.537332948297262,mistral_7b_instruct,choice,choice,,,,
173,0.3358282767279299,0.5780346393585205,0.6647398471832275,0.569109589041096,0.07301646815559079,mmlu:college_medicine,test,32.084085712209344,mistral_7b_instruct,choice,choice,,,,
11,0.493214260448109,0.4545454680919647,0.6363636255264282,0.3333333333333333,0.05589015917344529,mmlu:college_physics,validation,1.7833284698426723,mistral_7b_instruct,choice,choice,,,,
102,0.3972641346501369,0.4117647111415863,0.6568627953529358,0.5043650793650793,0.08560712314119528,mmlu:college_physics,test,14.948118340224028,mistral_7b_instruct,choice,choice,,,,
11,0.3270850831812078,0.6363636255264282,0.4545454680919647,0.4642857142857143,0.2076282663778825,mmlu:computer_security,validation,1.6681788060814142,mistral_7b_instruct,choice,choice,,,,
100,0.20277144402265543,0.7199999690055847,0.6100000143051147,0.5339781746031746,0.09934039831161501,mmlu:computer_security,test,12.216588605195284,mistral_7b_instruct,choice,choice,,,,
26,0.32021135664903205,0.5,0.692307710647583,0.7603550295857988,0.09513235321411717,mmlu:conceptual_physics,validation,2.664577152580023,mistral_7b_instruct,choice,choice,,,,
235,0.3259811748849585,0.5106382966041565,0.612765908241272,0.5352536231884057,0.06912129711597523,mmlu:conceptual_physics,test,22.62423636764288,mistral_7b_instruct,choice,choice,,,,
12,0.23544961710770929,0.6666666865348816,0.8333333730697632,0.6875,0.14223281542460128,mmlu:econometrics,validation,2.4386973436921835,mistral_7b_instruct,choice,choice,,,,
114,0.44112591027167813,0.4035087823867798,0.6140350699424744,0.5385230179028133,0.04906447623905383,mmlu:econometrics,test,20.893084144219756,mistral_7b_instruct,choice,choice,,,,
16,0.15299630351364613,0.6875,0.5625,0.5454545454545454,0.21631880849599838,mmlu:electrical_engineering,validation,2.2645864449441433,mistral_7b_instruct,choice,choice,,,,
145,0.27874617103872634,0.565517246723175,0.5862069129943848,0.5499419279907084,0.16821209685555816,mmlu:electrical_engineering,test,18.72698258794844,mistral_7b_instruct,choice,choice,,,,
41,0.5683083178066626,0.2926829159259796,0.5853658318519592,0.48850574712643674,0.1484626037318532,mmlu:elementary_mathematics,validation,6.854647766798735,mistral_7b_instruct,choice,choice,,,,
378,0.42598307227331494,0.38359788060188293,0.6058200597763062,0.5189137191061122,0.07971983974572841,mmlu:elementary_mathematics,test,60.47509142011404,mistral_7b_instruct,choice,choice,,,,
14,0.5300084905964988,0.3571428656578064,0.3571428656578064,0.7111111111111111,0.3007463855402811,mmlu:formal_logic,validation,2.8109627664089203,mistral_7b_instruct,choice,choice,,,,
126,0.4288197330066136,0.3888889253139496,0.484127014875412,0.5380333951762524,0.1858883424410744,mmlu:formal_logic,test,24.18679179251194,mistral_7b_instruct,choice,choice,,,,
10,0.6482203334569931,0.20000000298023224,0.699999988079071,0.875,0.3878909826278687,mmlu:global_facts,validation,1.453850707039237,mistral_7b_instruct,choice,choice,,,,
100,0.48122519657015805,0.35999998450279236,0.4399999976158142,0.4616044616044616,0.2172621351480484,mmlu:global_facts,test,12.707913048565388,mistral_7b_instruct,choice,choice,,,,
32,0.24558557756245133,0.71875,0.71875,0.7391304347826086,0.08365226536989213,mmlu:high_school_biology,validation,5.21592777594924,mistral_7b_instruct,choice,choice,,,,
310,0.18493177121685397,0.7322580814361572,0.7322580814361572,0.6403853298657185,0.059106680270164254,mmlu:high_school_biology,test,49.500693038105965,mistral_7b_instruct,choice,choice,,,,
22,0.34913468902761285,0.5454545617103577,0.5454545617103577,0.44999999999999996,0.2658220258626071,mmlu:high_school_chemistry,validation,3.6767027527093887,mistral_7b_instruct,choice,choice,,,,
203,0.3300257035957769,0.5024630427360535,0.6009852290153503,0.6399242865463016,0.14733844613794037,mmlu:high_school_chemistry,test,31.352866424247622,mistral_7b_instruct,choice,choice,,,,
9,0.3047038416067759,0.6666666865348816,0.5555555820465088,0.5,0.3480862047937181,mmlu:high_school_computer_science,validation,2.699255893006921,mistral_7b_instruct,choice,choice,,,,
100,0.25101123958826066,0.6299999952316284,0.6200000047683716,0.5115830115830116,0.07784963607788088,mmlu:high_school_computer_science,test,28.52432413958013,mistral_7b_instruct,choice,choice,,,,
22,0.09892364794557745,0.8636363744735718,0.6818181872367859,0.4385964912280702,0.1442515633322976,mmlu:high_school_geography,validation,2.6757603883743286,mistral_7b_instruct,choice,choice,,,,
198,0.16457719137572283,0.7626262903213501,0.7828282713890076,0.6232210793292942,0.038936978337740666,mmlu:high_school_geography,test,23.04169238358736,mistral_7b_instruct,choice,choice,,,,
21,0.18571182092030847,0.761904776096344,0.8095238208770752,0.575,0.14810222954977126,mmlu:high_school_government_and_politics,validation,2.9634361509233713,mistral_7b_instruct,choice,choice,,,,
193,0.12392692507239823,0.8290154933929443,0.772020697593689,0.5783143939393939,0.05402164261575808,mmlu:high_school_government_and_politics,test,26.182017048820853,mistral_7b_instruct,choice,choice,,,,
43,0.22275190713793735,0.6744186282157898,0.7441860437393188,0.6748768472906405,0.13229253957437917,mmlu:high_school_macroeconomics,validation,5.088142009451985,mistral_7b_instruct,choice,choice,,,,
390,0.3108129061949559,0.5769230723381042,0.6333333253860474,0.510006734006734,0.06473544346980563,mmlu:high_school_macroeconomics,test,45.316601540893316,mistral_7b_instruct,choice,choice,,,,
29,0.35391655769841424,0.37931033968925476,0.517241358757019,0.45959595959595956,0.3156191295590894,mmlu:high_school_mathematics,validation,4.677194435149431,mistral_7b_instruct,choice,choice,,,,
270,0.34481427327350334,0.32222220301628113,0.6074073910713196,0.4517618240060297,0.07944230371051365,mmlu:high_school_mathematics,test,41.66667355783284,mistral_7b_instruct,choice,choice,,,,
26,0.2971332107598965,0.6538462042808533,0.7307692766189575,0.5555555555555556,0.06437540512818556,mmlu:high_school_microeconomics,validation,3.225030492991209,mistral_7b_instruct,choice,choice,,,,
238,0.25066431592993377,0.6596639156341553,0.680672287940979,0.5656601399701188,0.06350049451619634,mmlu:high_school_microeconomics,test,28.702153123915195,mistral_7b_instruct,choice,choice,,,,
17,0.576501513228697,0.1764705926179886,0.47058823704719543,0.9761904761904763,0.3304651660077712,mmlu:high_school_physics,validation,3.0215742103755474,mistral_7b_instruct,choice,choice,,,,
151,0.48068022056920645,0.3245033025741577,0.4768211841583252,0.5598239295718287,0.22728843088971074,mmlu:high_school_physics,test,25.11153314076364,mistral_7b_instruct,choice,choice,,,,
60,0.14687878390153253,0.8666667342185974,0.8833333849906921,0.7427884615384616,0.11724495589733124,mmlu:high_school_psychology,validation,9.05186645500362,mistral_7b_instruct,choice,choice,,,,
545,0.1524940463927908,0.7963302731513977,0.8256880640983582,0.67619644723093,0.03930747312143308,mmlu:high_school_psychology,test,81.947973780334,mistral_7b_instruct,choice,choice,,,,
23,0.33509852316068567,0.52173912525177,0.52173912525177,0.5378787878787878,0.1808883495952772,mmlu:high_school_statistics,validation,5.747789811342955,mistral_7b_instruct,choice,choice,,,,
216,0.3680592295196321,0.45370370149612427,0.6203703880310059,0.5775683154617779,0.05573611678900543,mmlu:high_school_statistics,test,55.15248867496848,mistral_7b_instruct,choice,choice,,,,
22,0.20736756649884316,0.7727273106575012,0.6818181872367859,0.7294117647058823,0.10077960924668743,mmlu:high_school_us_history,validation,20.12728918530047,mistral_7b_instruct,choice,choice,,,,
204,0.1760429599705865,0.7647058963775635,0.7647058963775635,0.6491720085470085,0.03648429612318676,mmlu:high_school_us_history,test,185.41094432771206,mistral_7b_instruct,choice,choice,,,,
23,0.2849027877268584,0.739130437374115,0.6521739363670349,0.4509803921568627,0.12969913949137146,mmlu:human_aging,validation,2.453676277771592,mistral_7b_instruct,choice,choice,,,,
223,0.2803503311001132,0.6322870254516602,0.6367713212966919,0.6196159833938764,0.06318356557811855,mmlu:human_aging,test,22.15962822921574,mistral_7b_instruct,choice,choice,,,,
12,0.3910154501597087,0.5,0.6666666865348816,0.5833333333333334,0.2501901139815649,mmlu:human_sexuality,validation,1.4492725152522326,mistral_7b_instruct,choice,choice,,,,
131,0.18673584240538474,0.6870229244232178,0.7557252049446106,0.5081300813008129,0.09271382102529512,mmlu:human_sexuality,test,14.814092122018337,mistral_7b_instruct,choice,choice,,,,
13,0.04825018919431247,1.0,0.7692307829856873,,0.1878830561271081,mmlu:international_law,validation,2.611935492604971,mistral_7b_instruct,choice,choice,,,,
121,0.1990918629179316,0.7520660758018494,0.7272726893424988,0.6362637362637363,0.04220806616396944,mmlu:international_law,test,22.554087547585368,mistral_7b_instruct,choice,choice,,,,
11,0.4057095809416338,0.5454545617103577,0.7272727489471436,0.6,0.3631793748248707,mmlu:jurisprudence,validation,1.5236994549632072,mistral_7b_instruct,choice,choice,,,,
108,0.1348436223687949,0.7777777910232544,0.7685185074806213,0.6696428571428572,0.054496889313062014,mmlu:jurisprudence,test,13.315913612022996,mistral_7b_instruct,choice,choice,,,,
18,0.2286232709884644,0.7222222089767456,0.6666666865348816,0.47692307692307695,0.3034266299671597,mmlu:logical_fallacies,validation,2.4518393203616142,mistral_7b_instruct,choice,choice,,,,
163,0.21580915911797366,0.6932514905929565,0.7607361674308777,0.4617699115044247,0.0848738605990732,mmlu:logical_fallacies,test,21.415037222206593,mistral_7b_instruct,choice,choice,,,,
11,0.4750036895275116,0.27272728085517883,0.5454545617103577,0.5,0.12433848055926239,mmlu:machine_learning,validation,2.243848627433181,mistral_7b_instruct,choice,choice,,,,
112,0.4009351400392396,0.4285714626312256,0.5,0.4967447916666667,0.15773656325680868,mmlu:machine_learning,test,21.71237182430923,mistral_7b_instruct,choice,choice,,,,
11,0.08183464136990637,0.9090909361839294,0.7272727489471436,0.8,0.17187701030211017,mmlu:management,validation,1.113238064572215,mistral_7b_instruct,choice,choice,,,,
103,0.21182832440126284,0.7475728392601013,0.6504854559898376,0.6028971028971029,0.09146271978767173,mmlu:management,test,9.681352939456701,mistral_7b_instruct,choice,choice,,,,
25,0.1364144992828369,0.8399999737739563,0.8799999952316284,0.6904761904761905,0.16435061693191527,mmlu:marketing,validation,3.24522178247571,mistral_7b_instruct,choice,choice,,,,
234,0.09125810224785762,0.8632479310035706,0.7820513248443604,0.6319616336633663,0.05697364226365701,mmlu:marketing,test,28.605658857151866,mistral_7b_instruct,choice,choice,,,,
11,0.0449044406414032,0.9090909361839294,0.9090909361839294,0.9,0.19738409735939721,mmlu:medical_genetics,validation,1.4097182508558035,mistral_7b_instruct,choice,choice,,,,
100,0.2847048228979111,0.6599999666213989,0.7099999785423279,0.5060160427807486,0.055238652825355554,mmlu:medical_genetics,test,11.178424956277013,mistral_7b_instruct,choice,choice,,,,
38,0.40927351775922277,0.5,0.6578947305679321,0.628808864265928,0.16326792302884555,mmlu:moral_disputes,validation,5.6449902802705765,mistral_7b_instruct,choice,choice,,,,
346,0.21625922620296478,0.6878612637519836,0.647398829460144,0.5562507331951668,0.047801978498525,mmlu:moral_disputes,test,49.86416172794998,mistral_7b_instruct,choice,choice,,,,
33,0.20663583278656006,0.7272727489471436,0.7575757503509521,0.4305555555555556,0.2509902408628753,mmlu:nutrition,validation,5.94067863561213,mistral_7b_instruct,choice,choice,,,,
306,0.21835722107123703,0.6764705777168274,0.673202633857727,0.6141121358512664,0.039865722453672134,mmlu:nutrition,test,54.498450342565775,mistral_7b_instruct,choice,choice,,,,
34,0.2439185065381667,0.7058823704719543,0.7352941036224365,0.6041666666666666,0.10418088997111602,mmlu:philosophy,validation,3.882104866206646,mistral_7b_instruct,choice,choice,,,,
311,0.2319063437904959,0.6945337653160095,0.6881029009819031,0.5918615984405459,0.026965171194536494,mmlu:philosophy,test,33.34900714457035,mistral_7b_instruct,choice,choice,,,,
35,0.28488696813583375,0.6285714507102966,0.6571428775787354,0.6363636363636364,0.09684086697442192,mmlu:prehistory,validation,5.813791390508413,mistral_7b_instruct,choice,choice,,,,
324,0.21219177268169548,0.7037037014961243,0.6574074029922485,0.596422697368421,0.07660106265986408,mmlu:prehistory,test,51.675051817670465,mistral_7b_instruct,choice,choice,,,,
69,0.23504126244697013,0.695652186870575,0.6376811861991882,0.5193452380952381,0.10507449378138002,mmlu:professional_psychology,validation,12.330113407224417,mistral_7b_instruct,choice,choice,,,,
612,0.26351112891840783,0.6372548937797546,0.6078431606292725,0.5654314844174932,0.09088613005245433,mmlu:professional_psychology,test,104.05647077783942,mistral_7b_instruct,choice,choice,,,,
12,0.2672729740540186,0.5833333730697632,0.5,0.6,0.2439107398192088,mmlu:public_relations,validation,1.7600688133388758,mistral_7b_instruct,choice,choice,,,,
110,0.22116296250711792,0.699999988079071,0.6727272272109985,0.6119637937819755,0.07325313849882648,mmlu:public_relations,test,13.955726841464639,mistral_7b_instruct,choice,choice,,,,
27,0.29305871327718097,0.6296296119689941,0.7037037014961243,0.588235294117647,0.12682629073107682,mmlu:security_studies,validation,10.565910514444113,mistral_7b_instruct,choice,choice,,,,
245,0.2187763589985517,0.7061223983764648,0.6734693646430969,0.5792790622992936,0.05971183022674248,mmlu:security_studies,test,97.08374887704849,mistral_7b_instruct,choice,choice,,,,
22,0.09615165537053888,0.9090909361839294,0.7727273106575012,0.875,0.10270552743564951,mmlu:sociology,validation,2.9506013486534357,mistral_7b_instruct,choice,choice,,,,
201,0.14599392737322187,0.8208954930305481,0.746268630027771,0.46313131313131317,0.07064304838133097,mmlu:sociology,test,25.87346563115716,mistral_7b_instruct,choice,choice,,,,
11,0.09946483373641965,0.9090909361839294,0.7272727489471436,0.6,0.160442130132155,mmlu:us_foreign_policy,validation,1.5547931361943483,mistral_7b_instruct,choice,choice,,,,
100,0.14641115546226502,0.8399999737739563,0.7899999618530273,0.5758928571428571,0.13569818377494813,mmlu:us_foreign_policy,test,12.530699810013175,mistral_7b_instruct,choice,choice,,,,
18,0.29886655012766516,0.6111111044883728,0.6666666865348816,0.37662337662337664,0.21228489610883922,mmlu:virology,validation,2.47236205637455,mistral_7b_instruct,choice,choice,,,,
166,0.4108055790504777,0.48795178532600403,0.5481927394866943,0.5408681765389083,0.1391209518334952,mmlu:virology,test,18.42729276046157,mistral_7b_instruct,choice,choice,,,,
19,0.16099958984475385,0.8421052694320679,0.6842105388641357,0.2916666666666667,0.2302692689393696,mmlu:world_religions,validation,1.8088750559836626,mistral_7b_instruct,choice,choice,,,,
171,0.13443411651410558,0.8245614171028137,0.7953216433525085,0.6555555555555556,0.043175724863308916,mmlu:world_religions,test,14.80629607476294,mistral_7b_instruct,choice,choice,,,,
14,,,,,,mmlu:anatomy,validation,16.127841097302735,mistral_7b_instruct,oe,oe,0.5714285969734192,0.5,0.4583333333333333,0.2275711468287877
135,,,,,,mmlu:anatomy,test,108.3012416921556,mistral_7b_instruct,oe,oe,0.5407407283782959,0.5925925970077515,0.5288334069818824,0.09144340886010068
16,,,,,,mmlu:astronomy,validation,13.704155154526234,mistral_7b_instruct,oe,oe,0.5,0.625,0.59375,0.1733641065657139
152,,,,,,mmlu:astronomy,test,122.59300376288593,mistral_7b_instruct,oe,oe,0.7171052694320679,0.4802631735801697,0.4969063366759121,0.1761615437112357
11,,,,,,mmlu:business_ethics,validation,10.189559309743345,mistral_7b_instruct,oe,oe,0.4545454680919647,0.7272727489471436,0.5,0.11670686440034346
100,,,,,,mmlu:business_ethics,test,82.94382000621408,mistral_7b_instruct,oe,oe,0.429999977350235,0.5099999904632568,0.5018359853121175,0.16855105638504028
29,,,,,,mmlu:clinical_knowledge,validation,25.944615320302546,mistral_7b_instruct,oe,oe,0.37931033968925476,0.4482758641242981,0.5757575757575757,0.16617241399041538
265,,,,,,mmlu:clinical_knowledge,test,225.0262339003384,mistral_7b_instruct,oe,oe,0.4415094256401062,0.5735849142074585,0.5037826287826288,0.10564753356969582
16,,,,,,mmlu:college_biology,validation,13.247735786251724,mistral_7b_instruct,oe,oe,0.375,0.6875,0.3833333333333333,0.13410313799977303
144,,,,,,mmlu:college_biology,test,118.59648837894201,mistral_7b_instruct,oe,oe,0.4583333432674408,0.569444477558136,0.44541569541569537,0.10320487990975381
8,,,,,,mmlu:college_chemistry,validation,7.129727518185973,mistral_7b_instruct,oe,oe,0.0,0.375,,0.346431665122509
100,,,,,,mmlu:college_chemistry,test,85.26001640874892,mistral_7b_instruct,oe,oe,0.23999999463558197,0.5299999713897705,0.5844298245614036,0.1643619126081467
11,,,,,,mmlu:college_computer_science,validation,10.989646844565868,mistral_7b_instruct,oe,oe,0.3636363744735718,0.5454545617103577,0.4285714285714286,0.2148084965619174
100,,,,,,mmlu:college_computer_science,test,94.49528362229466,mistral_7b_instruct,oe,oe,0.32999998331069946,0.6800000071525574,0.539348710990502,0.12111474990844724
11,,,,,,mmlu:college_mathematics,validation,10.220213741995394,mistral_7b_instruct,oe,oe,0.1818181872367859,0.4545454680919647,0.7777777777777778,0.30448200485923077
100,,,,,,mmlu:college_mathematics,test,87.20898500271142,mistral_7b_instruct,oe,oe,0.17999999225139618,0.6699999570846558,0.532859078590786,0.049250127673149104
22,,,,,,mmlu:college_medicine,validation,19.560676584020257,mistral_7b_instruct,oe,oe,0.5,0.5,0.5702479338842975,0.15857056866992603
173,,,,,,mmlu:college_medicine,test,153.9852171605453,mistral_7b_instruct,oe,oe,0.42774564027786255,0.6242774724960327,0.5221130221130221,0.02664495375804128
11,,,,,,mmlu:college_physics,validation,10.237457180395722,mistral_7b_instruct,oe,oe,0.1818181872367859,0.7272727489471436,0.5,0.3458333394744179
102,,,,,,mmlu:college_physics,test,88.07825271040201,mistral_7b_instruct,oe,oe,0.18627451360225677,0.7058823704719543,0.595434369055168,0.14243822354896396
11,,,,,,mmlu:computer_security,validation,10.115932972170413,mistral_7b_instruct,oe,oe,0.7272727489471436,0.4545454680919647,0.04166666666666667,0.22173896702853113
100,,,,,,mmlu:computer_security,test,82.72582302615047,mistral_7b_instruct,oe,oe,0.6399999856948853,0.5799999833106995,0.46484375,0.1843546748161316
26,,,,,,mmlu:conceptual_physics,validation,22.427637425251305,mistral_7b_instruct,oe,oe,0.46153849363327026,0.46153849363327026,0.4107142857142857,0.1653678371356084
235,,,,,,mmlu:conceptual_physics,test,190.20331989601254,mistral_7b_instruct,oe,oe,0.4170212745666504,0.5957446694374084,0.5169074929241769,0.0496051917684839
12,,,,,,mmlu:econometrics,validation,11.364250369369984,mistral_7b_instruct,oe,oe,0.25,0.4166666865348816,0.6296296296296295,0.23528865476449332
114,,,,,,mmlu:econometrics,test,102.61850638501346,mistral_7b_instruct,oe,oe,0.28070175647735596,0.5964912176132202,0.4504573170731707,0.11860285830079463
16,,,,,,mmlu:electrical_engineering,validation,13.167191470973194,mistral_7b_instruct,oe,oe,0.3125,0.625,0.4,0.056197270750999465
145,,,,,,mmlu:electrical_engineering,test,124.1775800967589,mistral_7b_instruct,oe,oe,0.43448275327682495,0.5586206912994385,0.5322299651567944,0.1175643518053252
41,,,,,,mmlu:elementary_mathematics,validation,36.632058466784656,mistral_7b_instruct,oe,oe,0.3658536374568939,0.6097560524940491,0.5076923076923077,0.19459853666584664
378,,,,,,mmlu:elementary_mathematics,test,317.51082269474864,mistral_7b_instruct,oe,oe,0.4285714030265808,0.5925925970077515,0.49118369913122994,0.10942151007198152
14,,,,,,mmlu:formal_logic,validation,13.635422128252685,mistral_7b_instruct,oe,oe,0.4285714626312256,0.4285714626312256,0.5416666666666666,0.34827551671436857
126,,,,,,mmlu:formal_logic,test,105.95151661988348,mistral_7b_instruct,oe,oe,0.3730158805847168,0.523809552192688,0.5455157554538109,0.16695932689167203
10,,,,,,mmlu:global_facts,validation,9.778393763117492,mistral_7b_instruct,oe,oe,0.5,0.6000000238418579,0.27999999999999997,0.1483909547328949
100,,,,,,mmlu:global_facts,test,81.74454000312835,mistral_7b_instruct,oe,oe,0.22999998927116394,0.429999977350235,0.5830039525691699,0.2599813812971115
32,,,,,,mmlu:high_school_biology,validation,26.835073549300432,mistral_7b_instruct,oe,oe,0.375,0.59375,0.7125,0.19377149641513824
310,,,,,,mmlu:high_school_biology,test,257.2884517032653,mistral_7b_instruct,oe,oe,0.5806451439857483,0.6548386812210083,0.5776282051282051,0.04427128645681567
22,,,,,,mmlu:high_school_chemistry,validation,20.34843084681779,mistral_7b_instruct,oe,oe,0.13636364042758942,0.7272727489471436,0.7543859649122807,0.12089936841617929
203,,,,,,mmlu:high_school_chemistry,test,171.64141473080963,mistral_7b_instruct,oe,oe,0.2807881832122803,0.5665024518966675,0.5752223023311703,0.15520680567313888
9,,,,,,mmlu:high_school_computer_science,validation,10.117380870506167,mistral_7b_instruct,oe,oe,0.5555555820465088,0.5555555820465088,0.5,0.3112228843900892
100,,,,,,mmlu:high_school_computer_science,test,89.68782813195139,mistral_7b_instruct,oe,oe,0.5600000023841858,0.5299999713897705,0.43851461038961037,0.1139674043655396
22,,,,,,mmlu:high_school_geography,validation,19.398983746767044,mistral_7b_instruct,oe,oe,0.40909093618392944,0.4545454680919647,0.4786324786324786,0.1979966028170152
198,,,,,,mmlu:high_school_geography,test,163.85865377634764,mistral_7b_instruct,oe,oe,0.44949495792388916,0.5353535413742065,0.50881352437893,0.1169552456850957
21,,,,,,mmlu:high_school_government_and_politics,validation,19.442149084992707,mistral_7b_instruct,oe,oe,0.7142857313156128,0.6190476417541504,0.6111111111111112,0.22116323312123617
193,,,,,,mmlu:high_school_government_and_politics,test,157.54313084110618,mistral_7b_instruct,oe,oe,0.6269429922103882,0.6269429922103882,0.5293847566574839,0.07580997628869172
43,,,,,,mmlu:high_school_macroeconomics,validation,37.72132379002869,mistral_7b_instruct,oe,oe,0.4651162624359131,0.5116279125213623,0.6326086956521739,0.1663647252459859
390,,,,,,mmlu:high_school_macroeconomics,test,315.6206719689071,mistral_7b_instruct,oe,oe,0.5128205418586731,0.5615384578704834,0.5266710526315789,0.09630380257582052
29,,,,,,mmlu:high_school_mathematics,validation,27.035385626368225,mistral_7b_instruct,oe,oe,0.13793103396892548,0.8275861740112305,0.21000000000000002,0.10234818992943599
270,,,,,,mmlu:high_school_mathematics,test,233.48061103746295,mistral_7b_instruct,oe,oe,0.15555554628372192,0.7592592239379883,0.38894110275689225,0.02287712119243763
26,,,,,,mmlu:high_school_microeconomics,validation,23.511939829215407,mistral_7b_instruct,oe,oe,0.3461538553237915,0.5,0.5816993464052287,0.278871673804063
238,,,,,,mmlu:high_school_microeconomics,test,193.9592157350853,mistral_7b_instruct,oe,oe,0.42436978220939636,0.5714285969734192,0.4932788899327889,0.09323142681803019
17,,,,,,mmlu:high_school_physics,validation,17.012933917343616,mistral_7b_instruct,oe,oe,0.23529411852359772,0.5882353186607361,0.36538461538461536,0.18978105222477634
151,,,,,,mmlu:high_school_physics,test,129.93462892901152,mistral_7b_instruct,oe,oe,0.3178808093070984,0.5894039869308472,0.5059668284789645,0.08885971086704178
60,,,,,,mmlu:high_school_psychology,validation,49.55329911503941,mistral_7b_instruct,oe,oe,0.6333333849906921,0.6000000238418579,0.43361244019138756,0.05990475614865619
545,,,,,,mmlu:high_school_psychology,test,449.469371332787,mistral_7b_instruct,oe,oe,0.60550457239151,0.5926605463027954,0.48705426356589143,0.09200734753127492
23,,,,,,mmlu:high_school_statistics,validation,22.18971659615636,mistral_7b_instruct,oe,oe,0.260869562625885,0.739130437374115,0.6176470588235294,0.11713056978972063
216,,,,,,mmlu:high_school_statistics,test,193.177823795937,mistral_7b_instruct,oe,oe,0.375,0.6805555820465088,0.42313671696387745,0.06399185238061127
22,,,,,,mmlu:high_school_us_history,validation,40.484043466858566,mistral_7b_instruct,oe,oe,0.6818181872367859,0.6818181872367859,0.5714285714285714,0.09180322018536652
204,,,,,,mmlu:high_school_us_history,test,354.6766015663743,mistral_7b_instruct,oe,oe,0.7058823704719543,0.7009804248809814,0.5858217592592592,0.05488074994554709
23,,,,,,mmlu:human_aging,validation,19.55230699200183,mistral_7b_instruct,oe,oe,0.43478262424468994,0.5652173757553101,0.523076923076923,0.32306991452756134
223,,,,,,mmlu:human_aging,test,185.39445363357663,mistral_7b_instruct,oe,oe,0.4663677215576172,0.5291479825973511,0.46687136393018747,0.1504288112636104
12,,,,,,mmlu:human_sexuality,validation,9.93414920475334,mistral_7b_instruct,oe,oe,0.5833333730697632,0.6666666865348816,0.5142857142857142,0.18623937169710797
131,,,,,,mmlu:human_sexuality,test,108.31534103583544,mistral_7b_instruct,oe,oe,0.5572519302368164,0.6412214040756226,0.49338686820973077,0.0642027399922145
13,,,,,,mmlu:international_law,validation,12.365018934942782,mistral_7b_instruct,oe,oe,0.46153849363327026,0.692307710647583,0.5714285714285714,0.30718506758029646
121,,,,,,mmlu:international_law,test,98.35225604660809,mistral_7b_instruct,oe,oe,0.7851239442825317,0.6859503984451294,0.5346153846153846,0.050789005500225956
11,,,,,,mmlu:jurisprudence,validation,10.03596259187907,mistral_7b_instruct,oe,oe,0.7272727489471436,0.4545454680919647,0.45833333333333337,0.2940163937481967
108,,,,,,mmlu:jurisprudence,test,87.40432358067483,mistral_7b_instruct,oe,oe,0.7037037014961243,0.6203703880310059,0.4673108552631579,0.11072695641605945
18,,,,,,mmlu:logical_fallacies,validation,16.418992545455694,mistral_7b_instruct,oe,oe,0.7777777910232544,0.6666666865348816,0.4642857142857143,0.12683768073717755
163,,,,,,mmlu:logical_fallacies,test,135.01072635035962,mistral_7b_instruct,oe,oe,0.5705521106719971,0.48466256260871887,0.4638248847926267,0.16873701364716137
11,,,,,,mmlu:machine_learning,validation,10.438803895376623,mistral_7b_instruct,oe,oe,0.6363636255264282,0.4545454680919647,0.7142857142857143,0.3463265353983099
112,,,,,,mmlu:machine_learning,test,96.26826229505241,mistral_7b_instruct,oe,oe,0.455357164144516,0.4910714626312256,0.47444551591128253,0.18898772820830345
11,,,,,,mmlu:management,validation,8.843160933814943,mistral_7b_instruct,oe,oe,0.7272727489471436,0.5454545617103577,0.4583333333333333,0.2838990742510015
103,,,,,,mmlu:management,test,82.69815997593105,mistral_7b_instruct,oe,oe,0.5145630836486816,0.6504854559898376,0.5583018867924529,0.07806509733200072
25,,,,,,mmlu:marketing,validation,22.593164549209177,mistral_7b_instruct,oe,oe,0.35999998450279236,0.4399999976158142,0.5694444444444444,0.1832575559616089
234,,,,,,mmlu:marketing,test,192.10327871888876,mistral_7b_instruct,oe,oe,0.46581199765205383,0.5341880321502686,0.41893577981651375,0.07997713970322895
11,,,,,,mmlu:medical_genetics,validation,9.73233399912715,mistral_7b_instruct,oe,oe,0.8181818723678589,0.6363636255264282,0.4444444444444444,0.31106754324652935
100,,,,,,mmlu:medical_genetics,test,79.13373290747404,mistral_7b_instruct,oe,oe,0.5799999833106995,0.5600000023841858,0.4316502463054187,0.09065690100193025
38,,,,,,mmlu:moral_disputes,validation,33.21583115961403,mistral_7b_instruct,oe,oe,0.6052631735801697,0.5789473652839661,0.4521739130434782,0.1327941229468898
346,,,,,,mmlu:moral_disputes,test,283.34500585496426,mistral_7b_instruct,oe,oe,0.5953757166862488,0.5982658863067627,0.5061719833564493,0.05787763740285973
33,,,,,,mmlu:nutrition,validation,29.403648752719164,mistral_7b_instruct,oe,oe,0.6060606241226196,0.5454545617103577,0.40384615384615385,0.14854288101196292
306,,,,,,mmlu:nutrition,test,262.469953591004,mistral_7b_instruct,oe,oe,0.5686274766921997,0.5882353186607361,0.5252307558342042,0.13435432607052375
34,,,,,,mmlu:philosophy,validation,27.33830671478063,mistral_7b_instruct,oe,oe,0.4117647111415863,0.5,0.4750000000000001,0.1463959918302648
311,,,,,,mmlu:philosophy,test,251.58662415202707,mistral_7b_instruct,oe,oe,0.43086814880371094,0.5659164190292358,0.5083691710936841,0.07134322568151344
35,,,,,,mmlu:prehistory,validation,29.2330338684842,mistral_7b_instruct,oe,oe,0.5428571701049805,0.5142857432365417,0.5032894736842105,0.1300435679299491
324,,,,,,mmlu:prehistory,test,264.77518158312887,mistral_7b_instruct,oe,oe,0.5925925970077515,0.5246913433074951,0.4998027146464647,0.12842916908823415
69,,,,,,mmlu:professional_psychology,validation,59.56070966180414,mistral_7b_instruct,oe,oe,0.5652173757553101,0.5652173757553101,0.30940170940170936,0.1113283470057059
612,,,,,,mmlu:professional_psychology,test,518.6126929717138,mistral_7b_instruct,oe,oe,0.4542483687400818,0.5718954205513,0.4721869211217852,0.06784476914436993
12,,,,,,mmlu:public_relations,validation,9.991769020445645,mistral_7b_instruct,oe,oe,0.25,0.4166666865348816,0.5555555555555556,0.3096987108389537
110,,,,,,mmlu:public_relations,test,88.79204226471484,mistral_7b_instruct,oe,oe,0.3636363446712494,0.6090908646583557,0.49499999999999994,0.05392733812332155
27,,,,,,mmlu:security_studies,validation,23.666903988458216,mistral_7b_instruct,oe,oe,0.8148148059844971,0.5555555820465088,0.44545454545454544,0.22547724511888292
245,,,,,,mmlu:security_studies,test,211.4422183232382,mistral_7b_instruct,oe,oe,0.7469387650489807,0.5836734175682068,0.5776925788824256,0.12182568968558799
22,,,,,,mmlu:sociology,validation,18.865227513946593,mistral_7b_instruct,oe,oe,0.6363636255264282,0.5,0.4821428571428572,0.1860459501093084
201,,,,,,mmlu:sociology,test,151.88080916833133,mistral_7b_instruct,oe,oe,0.5472636818885803,0.5124378204345703,0.4645354645354645,0.11909304507336214
11,,,,,,mmlu:us_foreign_policy,validation,10.029559223912656,mistral_7b_instruct,oe,oe,0.8181818723678589,0.3636363744735718,0.3333333333333333,0.4283381646329706
100,,,,,,mmlu:us_foreign_policy,test,81.88148858305067,mistral_7b_instruct,oe,oe,0.7899999618530273,0.5999999642372131,0.555455093429777,0.14200032472610472
18,,,,,,mmlu:virology,validation,16.25264505855739,mistral_7b_instruct,oe,oe,0.4444444477558136,0.6666666865348816,0.675,0.12275722954008313
166,,,,,,mmlu:virology,test,140.93431094940752,mistral_7b_instruct,oe,oe,0.6325300931930542,0.6144577860832214,0.5953942232630758,0.11599316331277411
19,,,,,,mmlu:world_religions,validation,16.139753544703126,mistral_7b_instruct,oe,oe,0.7368420958518982,0.42105263471603394,0.2714285714285714,0.26455423392747573
171,,,,,,mmlu:world_religions,test,136.85105738416314,mistral_7b_instruct,oe,oe,0.6842105388641357,0.5730994343757629,0.518201962646407,0.10400758744680394
14,,,,,,mmlu:anatomy,validation,16.616116563323885,mistral_7b,oe,oe,0.3571428656578064,0.2857142984867096,0.5777777777777778,0.433549519096102
135,,,,,,mmlu:anatomy,test,109.83029671013355,mistral_7b,oe,oe,0.555555522441864,0.5259259343147278,0.476,0.21285138924916586
16,,,,,,mmlu:astronomy,validation,13.629958705045283,mistral_7b,oe,oe,0.125,0.375,0.6428571428571428,0.3547225669026375
152,,,,,,mmlu:astronomy,test,126.49554414860904,mistral_7b,oe,oe,0.44078949093818665,0.45394736528396606,0.4932396839332748,0.2732849517150929
11,,,,,,mmlu:business_ethics,validation,101.39921413594857,mistral_7b,oe,oe,0.4545454680919647,0.5454545617103577,0.5,0.19627538052472202
100,,,,,,mmlu:business_ethics,test,87.2731769932434,mistral_7b,oe,oe,0.35999998450279236,0.4699999988079071,0.5670572916666666,0.2662577176094056
29,,,,,,mmlu:clinical_knowledge,validation,26.234526821412146,mistral_7b,oe,oe,0.27586206793785095,0.37931033968925476,0.2232142857142857,0.3524427208407172
265,,,,,,mmlu:clinical_knowledge,test,222.17785419058055,mistral_7b,oe,oe,0.33207547664642334,0.44528302550315857,0.48321135079609656,0.2413472351038231
16,,,,,,mmlu:college_biology,validation,13.807289915159345,mistral_7b,oe,oe,0.25,0.4375,0.5,0.3778352364897728
144,,,,,,mmlu:college_biology,test,123.4544841251336,mistral_7b,oe,oe,0.3819444477558136,0.4652777910232544,0.5544433094994893,0.2688567398322953
8,,,,,,mmlu:college_chemistry,validation,6.89660657197237,mistral_7b,oe,oe,0.25,0.375,0.41666666666666663,0.2872758284211159
100,,,,,,mmlu:college_chemistry,test,84.4625547947362,mistral_7b,oe,oe,0.2199999988079071,0.6599999666213989,0.6264568764568764,0.08623115837574005
11,,,,,,mmlu:college_computer_science,validation,11.110965869855136,mistral_7b,oe,oe,0.0,0.1818181872367859,,0.6566593430259011
100,,,,,,mmlu:college_computer_science,test,94.56749352673069,mistral_7b,oe,oe,0.2199999988079071,0.41999998688697815,0.594988344988345,0.3881205427646637
11,,,,,,mmlu:college_mathematics,validation,10.794587828218937,mistral_7b,oe,oe,0.1818181872367859,0.5454545617103577,0.3888888888888889,0.3699165528470819
100,,,,,,mmlu:college_mathematics,test,90.74790119379759,mistral_7b,oe,oe,0.17999999225139618,0.5199999809265137,0.5396341463414633,0.3358374786376953
22,,,,,,mmlu:college_medicine,validation,19.72203683387488,mistral_7b,oe,oe,0.40909093618392944,0.5454545617103577,0.547008547008547,0.29717731475830084
173,,,,,,mmlu:college_medicine,test,155.06026100413874,mistral_7b,oe,oe,0.39306357502937317,0.4797687828540802,0.5539915966386555,0.21782844707455937
11,,,,,,mmlu:college_physics,validation,10.450696870218962,mistral_7b,oe,oe,0.4545454680919647,0.5454545617103577,0.2833333333333333,0.24150985479354858
102,,,,,,mmlu:college_physics,test,90.33249094989151,mistral_7b,oe,oe,0.22549019753932953,0.6078431606292725,0.5842047330764997,0.15505934755007428
11,,,,,,mmlu:computer_security,validation,10.078524527139962,mistral_7b,oe,oe,0.5454545617103577,0.3636363744735718,0.4,0.32028231295672327
100,,,,,,mmlu:computer_security,test,82.91056053480133,mistral_7b,oe,oe,0.4599999785423279,0.5299999713897705,0.44565217391304346,0.20143812894821167
26,,,,,,mmlu:conceptual_physics,validation,23.173273426946253,mistral_7b,oe,oe,0.26923078298568726,0.3461538553237915,0.3533834586466166,0.37471969769551206
235,,,,,,mmlu:conceptual_physics,test,192.50975099392235,mistral_7b,oe,oe,0.4723404049873352,0.48085105419158936,0.5079555361813427,0.18902682623964673
12,,,,,,mmlu:econometrics,validation,10.484378596767783,mistral_7b,oe,oe,0.4166666865348816,0.5,0.8571428571428572,0.33909982442855835
114,,,,,,mmlu:econometrics,test,103.36524125793949,mistral_7b,oe,oe,0.24561403691768646,0.41228070855140686,0.36669435215946844,0.27698097887792084
16,,,,,,mmlu:electrical_engineering,validation,13.815410807263106,mistral_7b,oe,oe,0.1875,0.4375,0.4615384615384615,0.33242758736014366
145,,,,,,mmlu:electrical_engineering,test,128.93347604386508,mistral_7b,oe,oe,0.2896551787853241,0.48275861144065857,0.4813915857605178,0.21506244314127956
41,,,,,,mmlu:elementary_mathematics,validation,35.90169002721086,mistral_7b,oe,oe,0.39024388790130615,0.7317072749137878,0.31375,0.18475069941543948
378,,,,,,mmlu:elementary_mathematics,test,327.98144458187744,mistral_7b,oe,oe,0.4603174328804016,0.5502645373344421,0.528242618886635,0.20602305745952343
14,,,,,,mmlu:formal_logic,validation,13.510584537871182,mistral_7b,oe,oe,0.3571428656578064,0.5,0.5111111111111111,0.3069893292018345
126,,,,,,mmlu:formal_logic,test,111.64437206974253,mistral_7b,oe,oe,0.2936508059501648,0.5317460894584656,0.5672638931065896,0.12488032333434575
10,,,,,,mmlu:global_facts,validation,9.981726896949112,mistral_7b,oe,oe,0.20000000298023224,0.5,0.375,0.18061399459838867
100,,,,,,mmlu:global_facts,test,84.92760518193245,mistral_7b,oe,oe,0.19999998807907104,0.6599999666213989,0.4375,0.11257091939449311
32,,,,,,mmlu:high_school_biology,validation,26.52270275913179,mistral_7b,oe,oe,0.375,0.53125,0.5916666666666667,0.2037829589098692
310,,,,,,mmlu:high_school_biology,test,264.2361427540891,mistral_7b,oe,oe,0.48709675669670105,0.4903225600719452,0.5252613603232121,0.24385329581076098
22,,,,,,mmlu:high_school_chemistry,validation,20.390250358730555,mistral_7b,oe,oe,0.22727273404598236,0.5909091234207153,0.7882352941176471,0.08743315664204687
203,,,,,,mmlu:high_school_chemistry,test,177.46893474459648,mistral_7b,oe,oe,0.18719211220741272,0.5960590839385986,0.5838915470494418,0.07637876419011007
9,,,,,,mmlu:high_school_computer_science,validation,10.47325551416725,mistral_7b,oe,oe,0.4444444477558136,0.4444444477558136,0.9500000000000001,0.380560643143124
100,,,,,,mmlu:high_school_computer_science,test,90.71190859889612,mistral_7b,oe,oe,0.550000011920929,0.5600000023841858,0.5842424242424242,0.16526227414608002
22,,,,,,mmlu:high_school_geography,validation,20.02584907412529,mistral_7b,oe,oe,0.4545454680919647,0.4545454680919647,0.325,0.24703445759686557
198,,,,,,mmlu:high_school_geography,test,165.91756955580786,mistral_7b,oe,oe,0.43939393758773804,0.5202020406723022,0.516723620171896,0.1813457262034368
21,,,,,,mmlu:high_school_government_and_politics,validation,19.7351258341223,mistral_7b,oe,oe,0.4285714328289032,0.2857142984867096,0.2916666666666667,0.4735523206847055
193,,,,,,mmlu:high_school_government_and_politics,test,163.12349645234644,mistral_7b,oe,oe,0.5544041395187378,0.5388600826263428,0.46131275809606603,0.16933105708403912
43,,,,,,mmlu:high_school_macroeconomics,validation,37.002480793278664,mistral_7b,oe,oe,0.3720930218696594,0.5813953280448914,0.41319444444444453,0.13252880406934162
390,,,,,,mmlu:high_school_macroeconomics,test,321.9982301732525,mistral_7b,oe,oe,0.3512820601463318,0.5435897707939148,0.4123510573843801,0.16189171136953898
29,,,,,,mmlu:high_school_mathematics,validation,27.68179390160367,mistral_7b,oe,oe,0.10344827175140381,0.5862069129943848,0.6025641025641025,0.15776031592796588
270,,,,,,mmlu:high_school_mathematics,test,237.25427029002458,mistral_7b,oe,oe,0.11851851642131805,0.7518518567085266,0.3776917016806723,0.04658691883087156
26,,,,,,mmlu:high_school_microeconomics,validation,23.36664669169113,mistral_7b,oe,oe,0.38461539149284363,0.38461539149284363,0.45625,0.3307045514766987
238,,,,,,mmlu:high_school_microeconomics,test,197.24115996994078,mistral_7b,oe,oe,0.36554622650146484,0.4663865864276886,0.4883915658065007,0.25009218259018007
17,,,,,,mmlu:high_school_physics,validation,17.175076502840966,mistral_7b,oe,oe,0.11764705926179886,0.5882353186607361,0.2,0.10454841571695664
151,,,,,,mmlu:high_school_physics,test,132.0422191945836,mistral_7b,oe,oe,0.1986754983663559,0.5364238619804382,0.5504132231404959,0.1864729965759429
60,,,,,,mmlu:high_school_psychology,validation,51.34022520156577,mistral_7b,oe,oe,0.550000011920929,0.5333333611488342,0.5067340067340067,0.1969452758630117
545,,,,,,mmlu:high_school_psychology,test,464.1056387242861,mistral_7b,oe,oe,0.5651376247406006,0.5688073635101318,0.5657090799495863,0.16248765702641338
23,,,,,,mmlu:high_school_statistics,validation,21.78337460383773,mistral_7b,oe,oe,0.260869562625885,0.5652173757553101,0.5490196078431373,0.23168758205745532
216,,,,,,mmlu:high_school_statistics,test,195.19584600580856,mistral_7b,oe,oe,0.30092594027519226,0.4305555522441864,0.4879266428935304,0.2620776944138386
22,,,,,,mmlu:high_school_us_history,validation,40.707771725952625,mistral_7b,oe,oe,0.6363636255264282,0.5,0.41964285714285715,0.24001249400052158
204,,,,,,mmlu:high_school_us_history,test,372.7044117632322,mistral_7b,oe,oe,0.6421568989753723,0.5980392098426819,0.42915403116176937,0.0999330565625546
23,,,,,,mmlu:human_aging,validation,19.70095464028418,mistral_7b,oe,oe,0.3478260934352875,0.43478262424468994,0.44166666666666665,0.2968815513279127
223,,,,,,mmlu:human_aging,test,185.20064360741526,mistral_7b,oe,oe,0.3632287085056305,0.6233184337615967,0.5755086071987481,0.12765346968655095
12,,,,,,mmlu:human_sexuality,validation,10.039726838003844,mistral_7b,oe,oe,0.3333333432674408,0.25,0.3125,0.6101532578468323
131,,,,,,mmlu:human_sexuality,test,120.2089326013811,mistral_7b,oe,oe,0.49618321657180786,0.5648854970932007,0.5473193473193474,0.18205321881607295
13,,,,,,mmlu:international_law,validation,13.372911609243602,mistral_7b,oe,oe,0.38461539149284363,0.46153849363327026,0.375,0.43542836721126854
121,,,,,,mmlu:international_law,test,104.98760918108746,mistral_7b,oe,oe,0.5785123705863953,0.4793388247489929,0.5490196078431373,0.2657885753418789
11,,,,,,mmlu:jurisprudence,validation,10.299589877016842,mistral_7b,oe,oe,0.4545454680919647,0.4545454680919647,0.43333333333333335,0.3851751685142517
108,,,,,,mmlu:jurisprudence,test,89.71284805424511,mistral_7b,oe,oe,0.5185185074806213,0.5462962985038757,0.5885989010989011,0.22782685083371623
18,,,,,,mmlu:logical_fallacies,validation,16.774034256115556,mistral_7b,oe,oe,0.6666666865348816,0.6111111044883728,0.7222222222222223,0.2022483845551809
163,,,,,,mmlu:logical_fallacies,test,137.64569743303582,mistral_7b,oe,oe,0.5030674934387207,0.546012282371521,0.5212285456187895,0.2124258550398189
11,,,,,,mmlu:machine_learning,validation,10.367929816711694,mistral_7b,oe,oe,0.27272728085517883,0.6363636255264282,0.5833333333333333,0.09009564464742484
112,,,,,,mmlu:machine_learning,test,97.76419232832268,mistral_7b,oe,oe,0.2767857313156128,0.4017857313156128,0.4681401831939466,0.2911328396626881
11,,,,,,mmlu:management,validation,9.635399756021798,mistral_7b,oe,oe,0.6363636255264282,0.7272727489471436,0.6785714285714286,0.17424652793190695
103,,,,,,mmlu:management,test,84.96959021408111,mistral_7b,oe,oe,0.3980582654476166,0.49514564871788025,0.4948859166011015,0.18019085833169882
25,,,,,,mmlu:marketing,validation,23.48598054330796,mistral_7b,oe,oe,0.2800000011920929,0.3999999761581421,0.4920634920634921,0.3534419536590576
234,,,,,,mmlu:marketing,test,194.72290551895276,mistral_7b,oe,oe,0.47435900568962097,0.5170940160751343,0.5245001098659634,0.2232098760258438
11,,,,,,mmlu:medical_genetics,validation,10.810846664942801,mistral_7b,oe,oe,0.6363636255264282,0.4545454680919647,0.6428571428571428,0.33567197756333783
100,,,,,,mmlu:medical_genetics,test,81.56879006093368,mistral_7b,oe,oe,0.5399999618530273,0.5600000023841858,0.553743961352657,0.1560647886991501
38,,,,,,mmlu:moral_disputes,validation,33.60266434401274,mistral_7b,oe,oe,0.2631579041481018,0.34210526943206787,0.39642857142857146,0.38015396187179973
346,,,,,,mmlu:moral_disputes,test,294.6098739267327,mistral_7b,oe,oe,0.39306357502937317,0.4219653010368347,0.5316701680672269,0.27364160490862904
33,,,,,,mmlu:nutrition,validation,30.48438085289672,mistral_7b,oe,oe,0.42424243688583374,0.5151515007019043,0.7011278195488722,0.1797203475778753
306,,,,,,mmlu:nutrition,test,260.9657487841323,mistral_7b,oe,oe,0.39542484283447266,0.49673202633857727,0.49484029484029485,0.22755806781108082
34,,,,,,mmlu:philosophy,validation,30.031994208227843,mistral_7b,oe,oe,0.3235294222831726,0.47058823704719543,0.4545454545454546,0.3071515139411478
311,,,,,,mmlu:philosophy,test,261.723120061215,mistral_7b,oe,oe,0.36012861132621765,0.37620577216148376,0.4899946159368269,0.3518617998365421
35,,,,,,mmlu:prehistory,validation,29.991006950847805,mistral_7b,oe,oe,0.34285715222358704,0.34285715222358704,0.5036231884057971,0.397087402003152
324,,,,,,mmlu:prehistory,test,270.88725178688765,mistral_7b,oe,oe,0.46296295523643494,0.45679011940956116,0.5464942528735631,0.26706915486741956
69,,,,,,mmlu:professional_psychology,validation,60.49729023501277,mistral_7b,oe,oe,0.3478260934352875,0.5072463750839233,0.6055555555555555,0.2391222283460092
612,,,,,,mmlu:professional_psychology,test,525.7797695081681,mistral_7b,oe,oe,0.3692810535430908,0.44607844948768616,0.5267779357146133,0.24682397731378966
12,,,,,,mmlu:public_relations,validation,10.228107907343656,mistral_7b,oe,oe,0.1666666716337204,0.3333333432674408,0.6,0.3221569408973058
110,,,,,,mmlu:public_relations,test,94.68625181214884,mistral_7b,oe,oe,0.30909091234207153,0.3545454442501068,0.518188854489164,0.3921026305718856
27,,,,,,mmlu:security_studies,validation,24.881826125085354,mistral_7b,oe,oe,0.6296296119689941,0.6296296119689941,0.7235294117647059,0.15162874371917162
245,,,,,,mmlu:security_studies,test,216.1899199350737,mistral_7b,oe,oe,0.5061224102973938,0.5306122303009033,0.5681484937350041,0.2323816844395229
22,,,,,,mmlu:sociology,validation,19.659075025003403,mistral_7b,oe,oe,0.5,0.5,0.6115702479338843,0.27344376932490955
201,,,,,,mmlu:sociology,test,169.74379492690787,mistral_7b,oe,oe,0.4527363181114197,0.4925372898578644,0.4686813186813187,0.2548491388411071
11,,,,,,mmlu:us_foreign_policy,validation,9.792627778835595,mistral_7b,oe,oe,0.6363636255264282,0.8181818723678589,0.42857142857142855,0.175314182584936
100,,,,,,mmlu:us_foreign_policy,test,82.15285314107314,mistral_7b,oe,oe,0.6399999856948853,0.5600000023841858,0.4828559027777778,0.19871014595031739
18,,,,,,mmlu:virology,validation,16.701257122680545,mistral_7b,oe,oe,0.3333333432674408,0.4444444477558136,0.4583333333333333,0.3674969904952579
166,,,,,,mmlu:virology,test,138.85661480901763,mistral_7b,oe,oe,0.34939756989479065,0.42168673872947693,0.4829182630906769,0.3020126697528793
19,,,,,,mmlu:world_religions,validation,16.303561800625175,mistral_7b,oe,oe,0.6842105388641357,0.7368420958518982,0.576923076923077,0.2649621838017514
171,,,,,,mmlu:world_religions,test,140.5066955029033,mistral_7b,oe,oe,0.6783626079559326,0.6666666865348816,0.5771943573667712,0.09619879862021283
14,,,,,,mmlu:anatomy,validation,20.17976194806397,llama2_7b,oe,oe,0.2142857313156128,0.2142857313156128,0.8181818181818181,0.5413702641214644
135,,,,,,mmlu:anatomy,test,117.16101211123168,llama2_7b,oe,oe,0.4148148000240326,0.5037037134170532,0.6195750452079567,0.18206219805611507
16,,,,,,mmlu:astronomy,validation,13.433906687423587,llama2_7b,oe,oe,0.4375,0.375,0.49206349206349204,0.32404353469610214
152,,,,,,mmlu:astronomy,test,133.77900352329016,llama2_7b,oe,oe,0.5,0.5921052694320679,0.5254501385041551,0.053433964519124265
11,,,,,,mmlu:business_ethics,validation,10.314210306853056,llama2_7b,oe,oe,0.5454545617103577,0.7272727489471436,0.8,0.08517581224441528
100,,,,,,mmlu:business_ethics,test,88.7701129745692,llama2_7b,oe,oe,0.3100000023841858,0.5399999618530273,0.561711079943899,0.11628323853015902
29,,,,,,mmlu:clinical_knowledge,validation,27.94113010726869,llama2_7b,oe,oe,0.20689654350280762,0.3448275923728943,0.35507246376811596,0.29951213351611433
265,,,,,,mmlu:clinical_knowledge,test,236.960253668949,llama2_7b,oe,oe,0.3358490467071533,0.46037736535072327,0.6754979570990807,0.19606162152200374
16,,,,,,mmlu:college_biology,validation,15.642003826797009,llama2_7b,oe,oe,0.3125,0.4375,0.509090909090909,0.20046107843518257
144,,,,,,mmlu:college_biology,test,126.85681803524494,llama2_7b,oe,oe,0.3194444477558136,0.5347222089767456,0.5342724046140195,0.13097686734464434
8,,,,,,mmlu:college_chemistry,validation,8.456944193691015,llama2_7b,oe,oe,0.125,0.375,0.7142857142857143,0.2664787843823433
100,,,,,,mmlu:college_chemistry,test,91.87784466333687,llama2_7b,oe,oe,0.1599999964237213,0.6399999856948853,0.5665922619047619,0.05158064067363742
11,,,,,,mmlu:college_computer_science,validation,14.092937085777521,llama2_7b,oe,oe,0.09090909361839294,0.6363636255264282,0.6,0.30537017908963293
100,,,,,,mmlu:college_computer_science,test,97.49597924016416,llama2_7b,oe,oe,0.17000000178813934,0.5600000023841858,0.5531537916371367,0.1272367113828659
11,,,,,,mmlu:college_mathematics,validation,10.839553726837039,llama2_7b,oe,oe,0.0,0.9090909361839294,,0.1077350378036499
100,,,,,,mmlu:college_mathematics,test,96.22753344848752,llama2_7b,oe,oe,0.14000000059604645,0.8399999737739563,0.3338870431893688,0.05814598441123962
22,,,,,,mmlu:college_medicine,validation,22.92069222405553,llama2_7b,oe,oe,0.3636363744735718,0.40909093618392944,0.5,0.2581399895928123
173,,,,,,mmlu:college_medicine,test,162.43022480234504,llama2_7b,oe,oe,0.3815028667449951,0.49132946133613586,0.5147267063154913,0.17914372992653377
11,,,,,,mmlu:college_physics,validation,12.853618772700429,llama2_7b,oe,oe,0.27272728085517883,0.8181818723678589,0.5416666666666666,0.20125714215365326
102,,,,,,mmlu:college_physics,test,97.52475176006556,llama2_7b,oe,oe,0.1666666716337204,0.7549020051956177,0.34048442906574394,0.07158131751359678
11,,,,,,mmlu:computer_security,validation,12.310828456655145,llama2_7b,oe,oe,0.3636363744735718,0.6363636255264282,0.5357142857142857,0.2861072637818077
100,,,,,,mmlu:computer_security,test,83.5226913522929,llama2_7b,oe,oe,0.4599999785423279,0.5099999904632568,0.5062399355877617,0.1771860754489899
26,,,,,,mmlu:conceptual_physics,validation,27.016620943322778,llama2_7b,oe,oe,0.38461539149284363,0.6538462042808533,0.56875,0.2591499571616833
235,,,,,,mmlu:conceptual_physics,test,202.24205670133233,llama2_7b,oe,oe,0.4212765693664551,0.5319148898124695,0.47411616161616166,0.11947320826510166
12,,,,,,mmlu:econometrics,validation,12.098244013264775,llama2_7b,oe,oe,0.0,0.5,,0.16156770288944244
114,,,,,,mmlu:econometrics,test,104.65540657378733,llama2_7b,oe,oe,0.15789473056793213,0.6228070259094238,0.4210069444444445,0.05069446772859809
16,,,,,,mmlu:electrical_engineering,validation,12.932145977392793,llama2_7b,oe,oe,0.25,0.6875,0.5,0.13433315604925158
145,,,,,,mmlu:electrical_engineering,test,132.7330684121698,llama2_7b,oe,oe,0.1862068921327591,0.475862056016922,0.5546139359698682,0.18375683981796792
41,,,,,,mmlu:elementary_mathematics,validation,40.81147093139589,llama2_7b,oe,oe,0.17073169350624084,0.8536584973335266,0.33613445378151263,0.09228189253225559
378,,,,,,mmlu:elementary_mathematics,test,341.70066495239735,llama2_7b,oe,oe,0.32275131344795227,0.6666666269302368,0.4901703381147541,0.11589173633585535
14,,,,,,mmlu:formal_logic,validation,16.045344796031713,llama2_7b,oe,oe,0.4285714626312256,0.3571428656578064,0.41666666666666663,0.35106330258505686
126,,,,,,mmlu:formal_logic,test,117.09586722776294,llama2_7b,oe,oe,0.2857142984867096,0.3333333432674408,0.3563271604938271,0.3572937600196354
10,,,,,,mmlu:global_facts,validation,11.69417574070394,llama2_7b,oe,oe,0.20000000298023224,0.6000000238418579,0.625,0.03944578766822815
100,,,,,,mmlu:global_facts,test,98.92603436298668,llama2_7b,oe,oe,0.1599999964237213,0.35999998450279236,0.47321428571428575,0.23276023983955388
32,,,,,,mmlu:high_school_biology,validation,30.568990236148238,llama2_7b,oe,oe,0.25,0.53125,0.4557291666666667,0.11610798165202141
310,,,,,,mmlu:high_school_biology,test,290.66070310398936,llama2_7b,oe,oe,0.4161290228366852,0.5677419304847717,0.5619726754893143,0.09361214445483299
22,,,,,,mmlu:high_school_chemistry,validation,21.910196125507355,llama2_7b,oe,oe,0.09090909361839294,0.7272727489471436,0.625,0.12238701365210797
203,,,,,,mmlu:high_school_chemistry,test,179.9030866380781,llama2_7b,oe,oe,0.15270934998989105,0.6157635450363159,0.6178732183045761,0.08668470353328536
9,,,,,,mmlu:high_school_computer_science,validation,11.52931110560894,llama2_7b,oe,oe,0.2222222238779068,0.6666666865348816,0.35714285714285715,0.31075723965962726
100,,,,,,mmlu:high_school_computer_science,test,97.99862879514694,llama2_7b,oe,oe,0.3999999761581421,0.5299999713897705,0.5404166666666665,0.11657165288925171
22,,,,,,mmlu:high_school_geography,validation,22.557107850909233,llama2_7b,oe,oe,0.4545454680919647,0.4545454680919647,0.7666666666666667,0.16778718070550397
198,,,,,,mmlu:high_school_geography,test,166.0978598650545,llama2_7b,oe,oe,0.3888888955116272,0.6010100841522217,0.5218954599119888,0.03390218061630171
21,,,,,,mmlu:high_school_government_and_politics,validation,22.63826180435717,llama2_7b,oe,oe,0.4285714328289032,0.4285714328289032,0.7222222222222222,0.18701503390357604
193,,,,,,mmlu:high_school_government_and_politics,test,170.8901462852955,llama2_7b,oe,oe,0.47668391466140747,0.5077720284461975,0.5931446405510116,0.12408184603705925
43,,,,,,mmlu:high_school_macroeconomics,validation,38.060287019237876,llama2_7b,oe,oe,0.41860464215278625,0.4651162624359131,0.51,0.21692035919012023
390,,,,,,mmlu:high_school_macroeconomics,test,337.71246055699885,llama2_7b,oe,oe,0.3333333432674408,0.5,0.5248668639053254,0.1695568740367889
29,,,,,,mmlu:high_school_mathematics,validation,29.95942302234471,llama2_7b,oe,oe,0.03448275849223137,0.8620689511299133,0.3214285714285714,0.1932261565635944
270,,,,,,mmlu:high_school_mathematics,test,250.7811495848,llama2_7b,oe,oe,0.08148147910833359,0.8629629611968994,0.4417155425219942,0.10346593260765075
26,,,,,,mmlu:high_school_microeconomics,validation,26.32417391985655,llama2_7b,oe,oe,0.3461538553237915,0.6538462042808533,0.4901960784313725,0.15817942527624282
238,,,,,,mmlu:high_school_microeconomics,test,209.94147068448365,llama2_7b,oe,oe,0.3571428656578064,0.5252100825309753,0.5468281430219146,0.10304150561324688
17,,,,,,mmlu:high_school_physics,validation,19.021303998306394,llama2_7b,oe,oe,0.1764705926179886,0.47058823704719543,0.11904761904761901,0.2777000665664673
151,,,,,,mmlu:high_school_physics,test,140.4543502125889,llama2_7b,oe,oe,0.1986754983663559,0.5827814340591431,0.4714876033057851,0.13981370341698854
60,,,,,,mmlu:high_school_psychology,validation,54.77948881499469,llama2_7b,oe,oe,0.4833333492279053,0.5166667103767395,0.4949944382647386,0.13415410220623017
545,,,,,,mmlu:high_school_psychology,test,484.5546442139894,llama2_7b,oe,oe,0.4990825653076172,0.5651376247406006,0.583164996767938,0.09596535711113466
23,,,,,,mmlu:high_school_statistics,validation,23.489992087706923,llama2_7b,oe,oe,0.17391304671764374,0.8260869979858398,0.2763157894736842,0.17754053810368417
216,,,,,,mmlu:high_school_statistics,test,201.07785510085523,llama2_7b,oe,oe,0.24074074625968933,0.6712962985038757,0.42471857410881797,0.04002242038647333
22,,,,,,mmlu:high_school_us_history,validation,42.765412690117955,llama2_7b,oe,oe,0.6363636255264282,0.6363636255264282,0.5,0.16705032099377026
204,,,,,,mmlu:high_school_us_history,test,386.4597472883761,llama2_7b,oe,oe,0.6127451062202454,0.5147058963775635,0.46850632911392415,0.09719415710252874
23,,,,,,mmlu:human_aging,validation,21.231445532292128,llama2_7b,oe,oe,0.3478260934352875,0.30434784293174744,0.44166666666666665,0.3276865223179693
223,,,,,,mmlu:human_aging,test,194.98516373708844,llama2_7b,oe,oe,0.3766816258430481,0.5695067644119263,0.6015758821514218,0.061685715021039325
12,,,,,,mmlu:human_sexuality,validation,12.036657260730863,llama2_7b,oe,oe,0.25,0.6666666865348816,0.9629629629629629,0.3108293463786443
131,,,,,,mmlu:human_sexuality,test,117.45541235618293,llama2_7b,oe,oe,0.45038166642189026,0.6717557311058044,0.5920433145009417,0.12875502391625906
13,,,,,,mmlu:international_law,validation,15.772509016096592,llama2_7b,oe,oe,0.23076924681663513,0.5384615659713745,0.39999999999999997,0.08163322852208066
121,,,,,,mmlu:international_law,test,110.78907472454011,llama2_7b,oe,oe,0.5041322112083435,0.4793388247489929,0.5654371584699454,0.17027134639172514
11,,,,,,mmlu:jurisprudence,validation,11.348921585828066,llama2_7b,oe,oe,0.27272728085517883,0.27272728085517883,0.6666666666666666,0.42011719942092896
108,,,,,,mmlu:jurisprudence,test,99.0771128628403,llama2_7b,oe,oe,0.40740740299224854,0.42592594027519226,0.5308948863636364,0.23133139643404219
18,,,,,,mmlu:logical_fallacies,validation,19.099300859495997,llama2_7b,oe,oe,0.3888888955116272,0.5,0.5714285714285714,0.20347574022081164
163,,,,,,mmlu:logical_fallacies,test,142.31525048054755,llama2_7b,oe,oe,0.4171779155731201,0.46625766158103943,0.569814241486068,0.20365797522609216
11,,,,,,mmlu:machine_learning,validation,11.833540065214038,llama2_7b,oe,oe,0.3636363744735718,0.5454545617103577,0.14285714285714288,0.13735096021132034
112,,,,,,mmlu:machine_learning,test,103.16739562898874,llama2_7b,oe,oe,0.2946428656578064,0.4107142984867096,0.42903720751822016,0.29517874281321255
11,,,,,,mmlu:management,validation,10.971524212509394,llama2_7b,oe,oe,0.3636363744735718,0.5454545617103577,0.6428571428571429,0.13900644670833243
103,,,,,,mmlu:management,test,86.2737054489553,llama2_7b,oe,oe,0.42718446254730225,0.5145630836486816,0.5799306625577813,0.13532633515237605
25,,,,,,mmlu:marketing,validation,23.650612073019147,llama2_7b,oe,oe,0.2800000011920929,0.2800000011920929,0.6150793650793651,0.4132467031478882
234,,,,,,mmlu:marketing,test,207.0481785107404,llama2_7b,oe,oe,0.47435900568962097,0.5085470080375671,0.6025049439683587,0.17524385859823632
11,,,,,,mmlu:medical_genetics,validation,10.92423807643354,llama2_7b,oe,oe,0.6363636255264282,0.7272727489471436,0.5,0.1554148088801991
100,,,,,,mmlu:medical_genetics,test,85.91892991773784,llama2_7b,oe,oe,0.4599999785423279,0.550000011920929,0.5366344605475041,0.10491678535938262
38,,,,,,mmlu:moral_disputes,validation,35.03104500845075,llama2_7b,oe,oe,0.3947368562221527,0.44736841320991516,0.591304347826087,0.22859718140802882
346,,,,,,mmlu:moral_disputes,test,312.67307244054973,llama2_7b,oe,oe,0.39306357502937317,0.4595375657081604,0.6509803921568628,0.1814103958579157
33,,,,,,mmlu:nutrition,validation,30.391183376312256,llama2_7b,oe,oe,0.3636363744735718,0.5454545617103577,0.7420634920634921,0.1214705759828741
306,,,,,,mmlu:nutrition,test,272.1244533807039,llama2_7b,oe,oe,0.379084974527359,0.4542483687400818,0.6009981851179673,0.2144735077627344
34,,,,,,mmlu:philosophy,validation,31.770413191989064,llama2_7b,oe,oe,0.3235294222831726,0.29411765933036804,0.5098814229249011,0.37565587723956395
311,,,,,,mmlu:philosophy,test,269.79044774733484,llama2_7b,oe,oe,0.29903537034988403,0.3408360183238983,0.549398244056427,0.32184467802477035
35,,,,,,mmlu:prehistory,validation,32.08104143664241,llama2_7b,oe,oe,0.34285715222358704,0.6571428775787354,0.5923913043478262,0.042872766086033444
324,,,,,,mmlu:prehistory,test,373.7834030017257,llama2_7b,oe,oe,0.42283952236175537,0.5277777910232544,0.6154806979195128,0.07465894557075738
69,,,,,,mmlu:professional_psychology,validation,64.94832321070135,llama2_7b,oe,oe,0.3333333432674408,0.4057971239089966,0.5600189035916824,0.24181832783464074
612,,,,,,mmlu:professional_psychology,test,534.4875982962549,llama2_7b,oe,oe,0.30392158031463623,0.4526143968105316,0.5785501539704175,0.19595111244254643
12,,,,,,mmlu:public_relations,validation,11.370308600366116,llama2_7b,oe,oe,0.5,0.75,0.5277777777777778,0.1958058575789134
110,,,,,,mmlu:public_relations,test,98.77196754328907,llama2_7b,oe,oe,0.29999998211860657,0.4636363387107849,0.6103896103896104,0.1871763175184077
27,,,,,,mmlu:security_studies,validation,26.98827459104359,llama2_7b,oe,oe,0.48148149251937866,0.48148149251937866,0.6318681318681318,0.25363272870028464
245,,,,,,mmlu:security_studies,test,219.4576340597123,llama2_7b,oe,oe,0.5469387769699097,0.5755102038383484,0.554726368159204,0.12352153087148862
22,,,,,,mmlu:sociology,validation,21.86354702524841,llama2_7b,oe,oe,0.4545454680919647,0.5909091234207153,0.5333333333333333,0.1054915514859286
201,,,,,,mmlu:sociology,test,175.22157082892954,llama2_7b,oe,oe,0.3681592047214508,0.5522388219833374,0.5801234305171313,0.07800207179577194
11,,,,,,mmlu:us_foreign_policy,validation,11.541651068255305,llama2_7b,oe,oe,0.7272727489471436,0.9090909361839294,0.8333333333333334,0.2462416724725203
100,,,,,,mmlu:us_foreign_policy,test,91.21219585463405,llama2_7b,oe,oe,0.5799999833106995,0.550000011920929,0.4850164203612479,0.12304783463478088
18,,,,,,mmlu:virology,validation,18.57794937118888,llama2_7b,oe,oe,0.3333333432674408,0.6666666865348816,0.6944444444444444,0.22734544674555468
166,,,,,,mmlu:virology,test,150.1783258151263,llama2_7b,oe,oe,0.35542166233062744,0.6144577860832214,0.4878029463012831,0.10457998334643352
19,,,,,,mmlu:world_religions,validation,18.70290742814541,llama2_7b,oe,oe,0.7368420958518982,0.5789473652839661,0.2857142857142857,0.12163117057398747
171,,,,,,mmlu:world_religions,test,146.4212911259383,llama2_7b,oe,oe,0.5906432867050171,0.5497075915336609,0.5268033946251768,0.07787487799661202
14,,,,,,mmlu:anatomy,validation,9.346771571785212,llama2_13b_chat,oe,oe,0.2857142984867096,0.4285714626312256,0.65,0.21314443434987754
135,,,,,,mmlu:anatomy,test,48.63682257756591,llama2_13b_chat,oe,oe,0.4296296238899231,0.6592592597007751,0.5274294670846394,0.05143277910020617
16,,,,,,mmlu:astronomy,validation,9.598439764231443,llama2_13b_chat,oe,oe,0.4375,0.5625,0.30158730158730157,0.2517620883882046
152,,,,,,mmlu:astronomy,test,86.02602778747678,llama2_13b_chat,oe,oe,0.5131579041481018,0.6315789222717285,0.4398821898821898,0.08852528388562957
11,,,,,,mmlu:business_ethics,validation,6.603918232023716,llama2_13b_chat,oe,oe,0.4545454680919647,0.5454545617103577,0.33333333333333337,0.15643933144482697
100,,,,,,mmlu:business_ethics,test,63.204646557569504,llama2_13b_chat,oe,oe,0.3199999928474426,0.5699999928474426,0.603860294117647,0.10387740790843965
29,,,,,,mmlu:clinical_knowledge,validation,14.851285435259342,llama2_13b_chat,oe,oe,0.13793103396892548,0.8275861740112305,0.16999999999999998,0.19025907845332707
265,,,,,,mmlu:clinical_knowledge,test,134.93661437556148,llama2_13b_chat,oe,oe,0.28301888704299927,0.6641509532928467,0.46403508771929824,0.03913573611457391
16,,,,,,mmlu:college_biology,validation,12.142072107642889,llama2_13b_chat,oe,oe,0.125,0.4375,0.3214285714285714,0.21944239363074303
144,,,,,,mmlu:college_biology,test,95.3122498318553,llama2_13b_chat,oe,oe,0.375,0.5902777910232544,0.41697530864197535,0.08562589022848344
8,,,,,,mmlu:college_chemistry,validation,4.688519898802042,llama2_13b_chat,oe,oe,0.0,0.625,,0.14886174350976944
100,,,,,,mmlu:college_chemistry,test,59.60110875964165,llama2_13b_chat,oe,oe,0.1599999964237213,0.6399999856948853,0.45386904761904767,0.04491037487983703
11,,,,,,mmlu:college_computer_science,validation,11.872116573154926,llama2_13b_chat,oe,oe,0.3636363744735718,0.3636363744735718,0.32142857142857145,0.3067842505194924
100,,,,,,mmlu:college_computer_science,test,83.05371534079313,llama2_13b_chat,oe,oe,0.2199999988079071,0.6100000143051147,0.44959207459207456,0.13080257058143616
11,,,,,,mmlu:college_mathematics,validation,9.960905138403177,llama2_13b_chat,oe,oe,0.0,0.6363636255264282,,0.20317161625081842
100,,,,,,mmlu:college_mathematics,test,89.81481006368995,llama2_13b_chat,oe,oe,0.12999999523162842,0.7400000095367432,0.32714412024756856,0.07496235191822051
22,,,,,,mmlu:college_medicine,validation,11.847667418420315,llama2_13b_chat,oe,oe,0.40909093618392944,0.5909091234207153,0.405982905982906,0.09609734470194037
173,,,,,,mmlu:college_medicine,test,111.60708910226822,llama2_13b_chat,oe,oe,0.36994218826293945,0.676300585269928,0.36131020642201833,0.06449415883576938
11,,,,,,mmlu:college_physics,validation,6.687800962477922,llama2_13b_chat,oe,oe,0.27272728085517883,0.6363636255264282,0.5,0.22206744822588834
102,,,,,,mmlu:college_physics,test,65.14516574889421,llama2_13b_chat,oe,oe,0.1568627506494522,0.7254902124404907,0.6217296511627907,0.057344267765680974
11,,,,,,mmlu:computer_security,validation,5.871861536055803,llama2_13b_chat,oe,oe,0.4545454680919647,0.5454545617103577,0.33333333333333337,0.06169166890057651
100,,,,,,mmlu:computer_security,test,70.14285819232464,llama2_13b_chat,oe,oe,0.550000011920929,0.5199999809265137,0.5236363636363637,0.12561610221862793
26,,,,,,mmlu:conceptual_physics,validation,10.668303284794092,llama2_13b_chat,oe,oe,0.3076923191547394,0.6153846383094788,0.39583333333333337,0.11256681268031782
235,,,,,,mmlu:conceptual_physics,test,82.61950437352061,llama2_13b_chat,oe,oe,0.4510638117790222,0.5531914830207825,0.45410998976159134,0.15655530209236956
12,,,,,,mmlu:econometrics,validation,9.525247506797314,llama2_13b_chat,oe,oe,0.1666666716337204,0.6666666865348816,0.7,0.27335402369499207
114,,,,,,mmlu:econometrics,test,128.78751558437943,llama2_13b_chat,oe,oe,0.14035087823867798,0.5350877046585083,0.41390306122448983,0.10258416962205316
16,,,,,,mmlu:electrical_engineering,validation,14.993612565100193,llama2_13b_chat,oe,oe,0.25,0.75,0.25,0.05704084783792493
145,,,,,,mmlu:electrical_engineering,test,129.72123819217086,llama2_13b_chat,oe,oe,0.19310344755649567,0.7655172348022461,0.2774725274725275,0.07069503356670512
41,,,,,,mmlu:elementary_mathematics,validation,24.2366556301713,llama2_13b_chat,oe,oe,0.24390242993831635,0.707317054271698,0.5193548387096775,0.10662527636783878
378,,,,,,mmlu:elementary_mathematics,test,214.89493366330862,llama2_13b_chat,oe,oe,0.3095237910747528,0.6613756418228149,0.47060942463241306,0.055353813701205797
14,,,,,,mmlu:formal_logic,validation,14.576814036816359,llama2_13b_chat,oe,oe,0.3571428656578064,0.6428571939468384,0.6222222222222222,0.19179021886416844
126,,,,,,mmlu:formal_logic,test,99.04232515767217,llama2_13b_chat,oe,oe,0.2380952537059784,0.5793651342391968,0.5473958333333333,0.06991335276573424
10,,,,,,mmlu:global_facts,validation,5.2961199171841145,llama2_13b_chat,oe,oe,0.20000000298023224,0.800000011920929,0.53125,0.09281326532363894
100,,,,,,mmlu:global_facts,test,50.74883606284857,llama2_13b_chat,oe,oe,0.10999999940395355,0.7899999618530273,0.39427987742594484,0.09538091123104098
32,,,,,,mmlu:high_school_biology,validation,29.603133361786604,llama2_13b_chat,oe,oe,0.125,0.53125,0.5803571428571429,0.24796290509402752
310,,,,,,mmlu:high_school_biology,test,182.34017956256866,llama2_13b_chat,oe,oe,0.43870967626571655,0.5387096405029297,0.47027129817444224,0.13020846478400697
22,,,,,,mmlu:high_school_chemistry,validation,14.357538003474474,llama2_13b_chat,oe,oe,0.1818181872367859,0.6818181872367859,0.16666666666666669,0.1645716428756714
203,,,,,,mmlu:high_school_chemistry,test,129.88868774101138,llama2_13b_chat,oe,oe,0.17241379618644714,0.7142857313156128,0.4255952380952381,0.05977345452520059
9,,,,,,mmlu:high_school_computer_science,validation,11.153936952352524,llama2_13b_chat,oe,oe,0.7777777910232544,0.6666666865348816,0.3571428571428571,0.16370706425772769
100,,,,,,mmlu:high_school_computer_science,test,129.35715278238058,llama2_13b_chat,oe,oe,0.41999998688697815,0.550000011920929,0.4930213464696223,0.10899275183677673
22,,,,,,mmlu:high_school_geography,validation,22.944839511066675,llama2_13b_chat,oe,oe,0.5,0.40909093618392944,0.4380165289256199,0.24187139489433984
198,,,,,,mmlu:high_school_geography,test,140.12461967766285,llama2_13b_chat,oe,oe,0.3787878751754761,0.5858585834503174,0.41436314363143634,0.08959239450368016
21,,,,,,mmlu:high_school_government_and_politics,validation,9.165503703057766,llama2_13b_chat,oe,oe,0.380952388048172,0.6190476417541504,0.5384615384615384,0.1214601993560791
193,,,,,,mmlu:high_school_government_and_politics,test,90.11785550042987,llama2_13b_chat,oe,oe,0.43523314595222473,0.6165803074836731,0.4927916120576671,0.01723309625615727
43,,,,,,mmlu:high_school_macroeconomics,validation,29.139869581907988,llama2_13b_chat,oe,oe,0.44186046719551086,0.7674418687820435,0.23464912280701752,0.1282355868539145
390,,,,,,mmlu:high_school_macroeconomics,test,260.38934625312686,llama2_13b_chat,oe,oe,0.30512821674346924,0.6512820720672607,0.4083537474030202,0.05329037507375083
29,,,,,,mmlu:high_school_mathematics,validation,15.079372551292181,llama2_13b_chat,oe,oe,0.10344827175140381,0.7586206793785095,0.3974358974358974,0.0868283880167994
270,,,,,,mmlu:high_school_mathematics,test,154.70237043127418,llama2_13b_chat,oe,oe,0.0962962955236435,0.800000011920929,0.4782471626733921,0.08083013848022179
26,,,,,,mmlu:high_school_microeconomics,validation,22.141053535044193,llama2_13b_chat,oe,oe,0.23076924681663513,0.7307692766189575,0.41666666666666663,0.12315595837739801
238,,,,,,mmlu:high_school_microeconomics,test,162.1299982815981,llama2_13b_chat,oe,oe,0.34873950481414795,0.6638655662536621,0.3668869024485037,0.04527642471449716
17,,,,,,mmlu:high_school_physics,validation,13.085025455802679,llama2_13b_chat,oe,oe,0.11764705926179886,0.529411792755127,0.09999999999999998,0.18166014026193059
151,,,,,,mmlu:high_school_physics,test,95.55511238053441,llama2_13b_chat,oe,oe,0.16556291282176971,0.6754966974258423,0.4485714285714286,0.058813889295060075
60,,,,,,mmlu:high_school_psychology,validation,33.16212162747979,llama2_13b_chat,oe,oe,0.5,0.6000000238418579,0.3872222222222222,0.08091991146405537
545,,,,,,mmlu:high_school_psychology,test,298.5215934589505,llama2_13b_chat,oe,oe,0.5064220428466797,0.5596330165863037,0.3925367706481332,0.09981228670942673
23,,,,,,mmlu:high_school_statistics,validation,32.53145433217287,llama2_13b_chat,oe,oe,0.17391304671764374,0.6521739363670349,0.38157894736842113,0.1123761923416801
216,,,,,,mmlu:high_school_statistics,test,254.86841040104628,llama2_13b_chat,oe,oe,0.27314814925193787,0.5972222089767456,0.48418438950663933,0.065582482903092
22,,,,,,mmlu:high_school_us_history,validation,42.80662463977933,llama2_13b_chat,oe,oe,0.6363636255264282,0.5,0.39285714285714285,0.18676408312537454
204,,,,,,mmlu:high_school_us_history,test,409.1336831115186,llama2_13b_chat,oe,oe,0.6372549533843994,0.6029412150382996,0.41470893970893974,0.06814890807750179
23,,,,,,mmlu:human_aging,validation,22.490251436829567,llama2_13b_chat,oe,oe,0.3478260934352875,0.8695652484893799,0.2583333333333333,0.20309677590494568
223,,,,,,mmlu:human_aging,test,159.56206338107586,llama2_13b_chat,oe,oe,0.35874441266059875,0.6636771559715271,0.46319930069930065,0.020411624769458844
12,,,,,,mmlu:human_sexuality,validation,11.811525207012892,llama2_13b_chat,oe,oe,0.4166666865348816,0.6666666865348816,0.37142857142857144,0.18688828249772388
131,,,,,,mmlu:human_sexuality,test,81.03091282770038,llama2_13b_chat,oe,oe,0.49618321657180786,0.580152690410614,0.48846153846153845,0.09146179998193986
13,,,,,,mmlu:international_law,validation,14.666199069470167,llama2_13b_chat,oe,oe,0.1538461595773697,0.46153849363327026,0.5,0.24755189051994916
121,,,,,,mmlu:international_law,test,97.40366931632161,llama2_13b_chat,oe,oe,0.4876032769680023,0.5041322112083435,0.547840349917988,0.18315936169348473
11,,,,,,mmlu:jurisprudence,validation,8.73505587503314,llama2_13b_chat,oe,oe,0.27272728085517883,0.7272727489471436,0.41666666666666663,0.12884649363431067
108,,,,,,mmlu:jurisprudence,test,53.87186013907194,llama2_13b_chat,oe,oe,0.39814814925193787,0.6018518805503845,0.4270125223613596,0.058613109367865124
18,,,,,,mmlu:logical_fallacies,validation,8.046968653798103,llama2_13b_chat,oe,oe,0.3888888955116272,0.6111111044883728,0.6168831168831169,0.18137515584627786
163,,,,,,mmlu:logical_fallacies,test,97.14058249816298,llama2_13b_chat,oe,oe,0.460122674703598,0.5950919985771179,0.5220454545454546,0.02585290948306123
11,,,,,,mmlu:machine_learning,validation,6.999765735119581,llama2_13b_chat,oe,oe,0.4545454680919647,0.5454545617103577,0.39999999999999997,0.15980057824741709
112,,,,,,mmlu:machine_learning,test,66.01149332150817,llama2_13b_chat,oe,oe,0.2946428656578064,0.5089285969734192,0.3983505945531262,0.13042781821319036
11,,,,,,mmlu:management,validation,4.527193944901228,llama2_13b_chat,oe,oe,0.5454545617103577,0.4545454680919647,0.6,0.3144473000006242
103,,,,,,mmlu:management,test,48.94045666977763,llama2_13b_chat,oe,oe,0.3689320385456085,0.49514564871788025,0.41740890688259114,0.14472018167810535
25,,,,,,mmlu:marketing,validation,20.135156027972698,llama2_13b_chat,oe,oe,0.1599999964237213,0.8399999737739563,0.34523809523809523,0.2318857932090759
234,,,,,,mmlu:marketing,test,144.80305931344628,llama2_13b_chat,oe,oe,0.4529914855957031,0.6709402203559875,0.37533166273584906,0.08283719038351987
11,,,,,,mmlu:medical_genetics,validation,7.51011685281992,llama2_13b_chat,oe,oe,0.7272727489471436,0.3636363744735718,0.2916666666666667,0.38477708534760907
100,,,,,,mmlu:medical_genetics,test,63.12216270714998,llama2_13b_chat,oe,oe,0.4399999976158142,0.6100000143051147,0.4898538961038961,0.0353246307373047
38,,,,,,mmlu:moral_disputes,validation,25.995274133980274,llama2_13b_chat,oe,oe,0.4736842215061188,0.5526315569877625,0.5625,0.18578106478640907
346,,,,,,mmlu:moral_disputes,test,211.79492903873324,llama2_13b_chat,oe,oe,0.39017340540885925,0.6011560559272766,0.4627172195892575,0.025910551492878464
33,,,,,,mmlu:nutrition,validation,26.46353818103671,llama2_13b_chat,oe,oe,0.3333333432674408,0.5151515007019043,0.603305785123967,0.11535676862254288
306,,,,,,mmlu:nutrition,test,234.03912938013673,llama2_13b_chat,oe,oe,0.38235294818878174,0.49673202633857727,0.5024420024420024,0.14291573096724117
34,,,,,,mmlu:philosophy,validation,11.976518493145704,llama2_13b_chat,oe,oe,0.2647058963775635,0.7352941036224365,0.45333333333333337,0.08830076105454389
311,,,,,,mmlu:philosophy,test,155.0689558647573,llama2_13b_chat,oe,oe,0.2829582095146179,0.7266880869865417,0.41321850794944964,0.08087032860881647
35,,,,,,mmlu:prehistory,validation,18.603726234287024,llama2_13b_chat,oe,oe,0.3142857253551483,0.5428571701049805,0.5018939393939393,0.1646228824343
324,,,,,,mmlu:prehistory,test,155.91048012673855,llama2_13b_chat,oe,oe,0.395061731338501,0.5956790447235107,0.5288185586734695,0.0731483512086633
69,,,,,,mmlu:professional_psychology,validation,83.21384820342064,llama2_13b_chat,oe,oe,0.37681159377098083,0.6521739363670349,0.3152951699463327,0.051486733167067804
612,,,,,,mmlu:professional_psychology,test,706.3532844483852,llama2_13b_chat,oe,oe,0.3055555522441864,0.6895424723625183,0.39133689839572194,0.014502109460581381
12,,,,,,mmlu:public_relations,validation,4.083608590066433,llama2_13b_chat,oe,oe,0.25,0.6666666865348816,0.25925925925925924,0.16677892208099365
110,,,,,,mmlu:public_relations,test,55.274609703570604,llama2_13b_chat,oe,oe,0.2818181812763214,0.6454545259475708,0.4795835034708045,0.0658442025834864
27,,,,,,mmlu:security_studies,validation,23.547785498201847,llama2_13b_chat,oe,oe,0.7037037014961243,0.7407407760620117,0.48684210526315785,0.11137800084220038
245,,,,,,mmlu:security_studies,test,222.667185138911,llama2_13b_chat,oe,oe,0.6040816307067871,0.6897959113121033,0.45050849818891053,0.03961105541307096
22,,,,,,mmlu:sociology,validation,11.407257597893476,llama2_13b_chat,oe,oe,0.27272728085517883,0.5454545617103577,0.4166666666666667,0.13423918594013562
201,,,,,,mmlu:sociology,test,101.44568651914597,llama2_13b_chat,oe,oe,0.3980099558830261,0.5870646834373474,0.3742252066115702,0.0737480865189092
11,,,,,,mmlu:us_foreign_policy,validation,6.950090523809195,llama2_13b_chat,oe,oe,0.5454545617103577,0.4545454680919647,0.6,0.3071783239191229
100,,,,,,mmlu:us_foreign_policy,test,56.852686040103436,llama2_13b_chat,oe,oe,0.5399999618530273,0.4899999797344208,0.4223027375201288,0.18442989826202394
18,,,,,,mmlu:virology,validation,13.032894883304834,llama2_13b_chat,oe,oe,0.2222222238779068,0.6111111044883728,0.6607142857142857,0.31523551543553674
166,,,,,,mmlu:virology,test,98.6636722125113,llama2_13b_chat,oe,oe,0.2469879388809204,0.6024096012115479,0.4742439024390244,0.051425746406417276
19,,,,,,mmlu:world_religions,validation,10.948305413126945,llama2_13b_chat,oe,oe,0.6842105388641357,0.8421052694320679,0.8076923076923077,0.1551862076709145
171,,,,,,mmlu:world_religions,test,72.32156310603023,llama2_13b_chat,oe,oe,0.5789473652839661,0.6432748436927795,0.5988355780022449,0.057846089552717604
14,0.14360322271074571,0.785714328289032,0.785714328289032,0.30303030303030304,0.19389578700065613,mmlu:anatomy,validation,4.118735438212752,llama2_7b_chat,choice,choice,,,,
135,0.23289124921516133,0.4444444477558136,0.6370370388031006,0.5617777777777778,0.0964005298084683,mmlu:anatomy,test,16.602270148694515,llama2_7b_chat,choice,choice,,,,
16,0.267309220507741,0.3125,0.75,0.5454545454545454,0.0936405099928379,mmlu:astronomy,validation,3.085409911349416,llama2_7b_chat,choice,choice,,,,
152,0.25822553607194043,0.3552631735801697,0.7039473652839661,0.3208616780045352,0.05174609195244939,mmlu:astronomy,test,28.440432276576757,llama2_7b_chat,choice,choice,,,,
11,0.26610045541416516,0.5454545617103577,0.5454545617103577,0.5666666666666667,0.32824365117333154,mmlu:business_ethics,validation,2.128116613253951,llama2_7b_chat,choice,choice,,,,
100,0.21388616412878036,0.4699999988079071,0.7400000095367432,0.44620634283420313,0.06958860754966736,mmlu:business_ethics,test,18.665576154366136,llama2_7b_chat,choice,choice,,,,
29,0.30162716836764897,0.48275861144065857,0.517241358757019,0.5380952380952381,0.20440463773135478,mmlu:clinical_knowledge,validation,4.112291721627116,llama2_7b_chat,choice,choice,,,,
265,0.21002826533227595,0.498113214969635,0.5547170042991638,0.5812542720437457,0.11690893578079511,mmlu:clinical_knowledge,test,36.05550900101662,llama2_7b_chat,choice,choice,,,,
16,0.3395843356847763,0.25,0.625,0.3333333333333333,0.09226959943771361,mmlu:college_biology,validation,2.6532080862671137,llama2_7b_chat,choice,choice,,,,
144,0.16859111044969824,0.4930555522441864,0.5833333134651184,0.36002315261431606,0.09268397548132475,mmlu:college_biology,test,23.460526248440146,llama2_7b_chat,choice,choice,,,,
8,0.4093471057713032,0.25,0.75,0.0,0.1886584311723709,mmlu:college_chemistry,validation,1.5589264072477818,llama2_7b_chat,choice,choice,,,,
100,0.3730656743049621,0.17999999225139618,0.6299999952316284,0.3624661246612466,0.09764212965965272,mmlu:college_chemistry,test,17.585880510509014,llama2_7b_chat,choice,choice,,,,
11,0.3731845075433905,0.1818181872367859,0.8181818723678589,0.4444444444444444,0.20735435594211923,mmlu:college_computer_science,validation,2.8741409070789814,llama2_7b_chat,choice,choice,,,,
100,0.3637583175301552,0.1899999976158142,0.75,0.2891487979207278,0.049119127392768865,mmlu:college_computer_science,test,26.37706728465855,llama2_7b_chat,choice,choice,,,,
11,0.25741527297280054,0.4545454680919647,0.4545454680919647,0.4,0.17117816751653497,mmlu:college_mathematics,validation,2.0741273667663336,llama2_7b_chat,choice,choice,,,,
100,0.18979537755250933,0.25,0.6200000047683716,0.3728,0.07790983259677887,mmlu:college_mathematics,test,17.8265110719949,llama2_7b_chat,choice,choice,,,,
22,0.3422548323869705,0.3181818127632141,0.5909091234207153,0.6000000000000001,0.17297941717234525,mmlu:college_medicine,validation,3.8572600558400154,llama2_7b_chat,choice,choice,,,,
173,0.35140678303779205,0.3352600932121277,0.5664739608764648,0.4694902548725638,0.12393195091644461,mmlu:college_medicine,test,35.30765222385526,llama2_7b_chat,choice,choice,,,,
11,0.2650231583551927,0.4545454680919647,0.7272727489471436,0.0,0.3253258141604337,mmlu:college_physics,validation,1.8695785570889711,llama2_7b_chat,choice,choice,,,,
102,0.3296916137139002,0.2352941334247589,0.6960784792900085,0.4754273504273505,0.1335249513972039,mmlu:college_physics,test,16.232787128537893,llama2_7b_chat,choice,choice,,,,
11,0.35567068511789496,0.4545454680919647,0.8181818723678589,0.3,0.15661115537990222,mmlu:computer_security,validation,1.7222401946783066,llama2_7b_chat,choice,choice,,,,
100,0.28204764664173126,0.4899999797344208,0.7400000095367432,0.33833533413365346,0.044371231794357285,mmlu:computer_security,test,13.18780062161386,llama2_7b_chat,choice,choice,,,,
26,0.3915331902412268,0.3461538553237915,0.6538462042808533,0.5490196078431373,0.0952518674043509,mmlu:conceptual_physics,validation,2.9089292380958796,llama2_7b_chat,choice,choice,,,,
235,0.319086033993579,0.4170212745666504,0.4936169981956482,0.4873007597199463,0.10972718659867632,mmlu:conceptual_physics,test,25.04328791052103,llama2_7b_chat,choice,choice,,,,
12,0.5185929412643114,0.0833333358168602,0.5833333730697632,0.6363636363636364,0.1516757110754649,mmlu:econometrics,validation,2.3902687039226294,llama2_7b_chat,choice,choice,,,,
114,0.25804114420163005,0.3333333432674408,0.6578947305679321,0.5183518005540166,0.058493612105386325,mmlu:econometrics,test,22.02519355714321,llama2_7b_chat,choice,choice,,,,
16,0.3753856923431158,0.1875,0.875,0.15384615384615383,0.09596572816371919,mmlu:electrical_engineering,validation,2.2841920498758554,llama2_7b_chat,choice,choice,,,,
145,0.2949777732635367,0.29655173420906067,0.751724123954773,0.1711126310989512,0.038076581626102834,mmlu:electrical_engineering,test,19.769269248470664,llama2_7b_chat,choice,choice,,,,
41,0.26384771088274517,0.19512194395065308,0.7804877758026123,0.36363636363636365,0.05731626545510643,mmlu:elementary_mathematics,validation,7.238166626542807,llama2_7b_chat,choice,choice,,,,
378,0.3240992821082867,0.158730149269104,0.7037037014961243,0.22824947589098532,0.08494653178270531,mmlu:elementary_mathematics,test,64.56811826489866,llama2_7b_chat,choice,choice,,,,
14,0.39324057527950834,0.2142857313156128,0.3571428656578064,0.6969696969696969,0.28468274218695505,mmlu:formal_logic,validation,2.783314574509859,llama2_7b_chat,choice,choice,,,,
126,0.3519274436292194,0.1587301641702652,0.5873016119003296,0.4813679245283019,0.09799813372748238,mmlu:formal_logic,test,24.56047752685845,llama2_7b_chat,choice,choice,,,,
10,0.31881338357925415,0.5,0.5,0.52,0.30212517976760866,mmlu:global_facts,validation,1.4852888211607933,llama2_7b_chat,choice,choice,,,,
100,0.17295489966869354,0.3799999952316284,0.6200000047683716,0.44758064516129037,0.08168798863887791,mmlu:global_facts,test,13.663576012477279,llama2_7b_chat,choice,choice,,,,
32,0.2634980734437704,0.34375,0.71875,0.28571428571428575,0.0816500447690487,mmlu:high_school_biology,validation,5.58384171128273,llama2_7b_chat,choice,choice,,,,
310,0.19012936469047298,0.45483869314193726,0.6774193644523621,0.36266733811741997,0.02799821630600959,mmlu:high_school_biology,test,53.13619705103338,llama2_7b_chat,choice,choice,,,,
22,0.3071552284739234,0.3181818127632141,0.5909091234207153,0.39999999999999997,0.12958524985746903,mmlu:high_school_chemistry,validation,3.865226298570633,llama2_7b_chat,choice,choice,,,,
203,0.3276243413904031,0.2807881832122803,0.5123152732849121,0.41276135544340303,0.16596937355736796,mmlu:high_school_chemistry,test,33.59242624603212,llama2_7b_chat,choice,choice,,,,
9,0.3673994541168213,0.3333333432674408,0.5555555820465088,0.2222222222222222,0.18369745545917088,mmlu:high_school_computer_science,validation,2.783426582813263,llama2_7b_chat,choice,choice,,,,
100,0.3032753199338913,0.3199999928474426,0.75,0.3589154411764706,0.023388682603836072,mmlu:high_school_computer_science,test,29.62670422717929,llama2_7b_chat,choice,choice,,,,
22,0.09864844381809235,0.6818181872367859,0.9090909361839294,0.019047619047619053,0.1466825008392334,mmlu:high_school_geography,validation,2.901689512655139,llama2_7b_chat,choice,choice,,,,
198,0.2098702171234169,0.5252525210380554,0.7575757503509521,0.296133387888707,0.035506141005140344,mmlu:high_school_geography,test,25.459307607263327,llama2_7b_chat,choice,choice,,,,
21,0.49195078157243266,0.3333333432674408,0.6190476417541504,0.8367346938775511,0.2016411196617853,mmlu:high_school_government_and_politics,validation,3.2454927396029234,llama2_7b_chat,choice,choice,,,,
193,0.1237833309976548,0.6994818449020386,0.7202072143554688,0.5563218390804598,0.0543010154536351,mmlu:high_school_government_and_politics,test,29.56227895244956,llama2_7b_chat,choice,choice,,,,
43,0.24960815005524215,0.44186046719551086,0.5813953280448914,0.4956140350877193,0.09708169171976491,mmlu:high_school_macroeconomics,validation,5.744444169104099,llama2_7b_chat,choice,choice,,,,
390,0.23880436466290403,0.4128205180168152,0.656410276889801,0.5276383953999294,0.03900271103932308,mmlu:high_school_macroeconomics,test,51.14491607993841,llama2_7b_chat,choice,choice,,,,
29,0.252709082488356,0.20689654350280762,0.6896551847457886,0.32971014492753625,0.04043169268246356,mmlu:high_school_mathematics,validation,4.925605511292815,llama2_7b_chat,choice,choice,,,,
270,0.2743873725334804,0.2074074000120163,0.7259259223937988,0.31145694259012013,0.046043923386821055,mmlu:high_school_mathematics,test,44.452520191669464,llama2_7b_chat,choice,choice,,,,
26,0.3957244180716002,0.42307692766189575,0.5769230723381042,0.4363636363636364,0.1805904989059155,mmlu:high_school_microeconomics,validation,3.4696145225316286,llama2_7b_chat,choice,choice,,,,
238,0.29155009584266595,0.3571428656578064,0.6344538331031799,0.36908881199538635,0.06051302907847556,mmlu:high_school_microeconomics,test,31.493997862562537,llama2_7b_chat,choice,choice,,,,
17,0.31806064703885245,0.1764705926179886,0.7058823704719543,0.5476190476190477,0.10404726336984073,mmlu:high_school_physics,validation,3.14625833183527,llama2_7b_chat,choice,choice,,,,
151,0.25000007144662717,0.25827813148498535,0.6490066051483154,0.289720695970696,0.048093834065443625,mmlu:high_school_physics,test,26.769109558314085,llama2_7b_chat,choice,choice,,,,
60,0.1696029290556908,0.6833333969116211,0.7833333611488342,0.40436456996148906,0.11661041378974912,mmlu:high_school_psychology,validation,10.151768025010824,llama2_7b_chat,choice,choice,,,,
545,0.14540578876066648,0.5779816508293152,0.7467889785766602,0.40808143547273984,0.057723128686257445,mmlu:high_school_psychology,test,92.05262449197471,llama2_7b_chat,choice,choice,,,,
23,0.2577301147191421,0.260869562625885,0.5652173757553101,0.7058823529411764,0.1251652396243551,mmlu:high_school_statistics,validation,5.828251235187054,llama2_7b_chat,choice,choice,,,,
216,0.2981284598785418,0.25,0.5277777910232544,0.5236053955189757,0.12780642978571077,mmlu:high_school_statistics,test,56.897526152431965,llama2_7b_chat,choice,choice,,,,
22,0.281483838504011,0.40909093618392944,0.5454545617103577,0.23076923076923075,0.22400751439007846,mmlu:high_school_us_history,validation,20.788921063765883,llama2_7b_chat,choice,choice,,,,
204,0.16210081851949878,0.524509847164154,0.6813725829124451,0.3427112438577897,0.03826286424608792,mmlu:high_school_us_history,test,192.01531666889787,llama2_7b_chat,choice,choice,,,,
23,0.24964470837427222,0.695652186870575,0.6086956858634949,0.45535714285714285,0.07563048082849252,mmlu:human_aging,validation,2.66328701749444,llama2_7b_chat,choice,choice,,,,
223,0.1377078909510454,0.573991060256958,0.6278027296066284,0.4261513157894737,0.04877835672532497,mmlu:human_aging,test,24.700936146080494,llama2_7b_chat,choice,choice,,,,
12,0.2702306012312571,0.4166666865348816,0.5833333730697632,0.6857142857142858,0.04927903413772583,mmlu:human_sexuality,validation,1.5102562736719847,llama2_7b_chat,choice,choice,,,,
131,0.1873118843286092,0.5038167834281921,0.694656491279602,0.5223776223776223,0.11816028829749303,mmlu:human_sexuality,test,16.251984924077988,llama2_7b_chat,choice,choice,,,,
13,0.13474712005028358,0.9230769872665405,0.8461538553237915,0.4166666666666667,0.16390036161129293,mmlu:international_law,validation,2.869054038077593,llama2_7b_chat,choice,choice,,,,
121,0.16791189775979226,0.6198346614837646,0.7438015937805176,0.5049275362318841,0.05256364168214401,mmlu:international_law,test,24.29091559164226,llama2_7b_chat,choice,choice,,,,
11,0.2877437797459689,0.3636363744735718,0.6363636255264282,0.5714285714285714,0.031956282528963945,mmlu:jurisprudence,validation,1.5940435193479061,llama2_7b_chat,choice,choice,,,,
108,0.14624328193841157,0.5462962985038757,0.6851851940155029,0.4851262538913871,0.07054417332013446,mmlu:jurisprudence,test,14.400368673726916,llama2_7b_chat,choice,choice,,,,
18,0.31053988801108473,0.6111111044883728,0.7222222089767456,0.5584415584415585,0.07259846395916411,mmlu:logical_fallacies,validation,2.638576526194811,llama2_7b_chat,choice,choice,,,,
163,0.24466566732324702,0.460122674703598,0.6564416885375977,0.501439393939394,0.05248781545030562,mmlu:logical_fallacies,test,23.704849123954773,llama2_7b_chat,choice,choice,,,,
11,0.39697506211020733,0.09090909361839294,0.3636363744735718,0.6,0.3652745376933704,mmlu:machine_learning,validation,2.3045384641736746,llama2_7b_chat,choice,choice,,,,
112,0.3992476388812065,0.1875000149011612,0.6875000596046448,0.2749869178440607,0.11238408407994677,mmlu:machine_learning,test,22.636310828849673,llama2_7b_chat,choice,choice,,,,
11,0.2283242399042303,0.7272727489471436,0.6363636255264282,0.375,0.07210221615704623,mmlu:management,validation,1.1809717155992985,llama2_7b_chat,choice,choice,,,,
103,0.1447638672532387,0.6504854559898376,0.6310679912567139,0.5646766169154228,0.08782055134912141,mmlu:management,test,10.44941858574748,llama2_7b_chat,choice,choice,,,,
25,0.24346010208129887,0.7199999690055847,0.6399999856948853,0.7222222222222223,0.10456636190414428,mmlu:marketing,validation,3.505214100703597,llama2_7b_chat,choice,choice,,,,
234,0.07205178747829209,0.7264957427978516,0.7222222685813904,0.6947150735294118,0.07884243920318083,mmlu:marketing,test,31.271869329735637,llama2_7b_chat,choice,choice,,,,
11,0.24660130522467874,0.7272727489471436,0.8181818723678589,0.5833333333333334,0.19802021438425238,mmlu:medical_genetics,validation,1.4739660359919071,llama2_7b_chat,choice,choice,,,,
100,0.24506461858749393,0.4399999976158142,0.699999988079071,0.37073863636363635,0.062219975590705884,mmlu:medical_genetics,test,12.184572521597147,llama2_7b_chat,choice,choice,,,,
38,0.29730562787306936,0.4736842215061188,0.6315789222717285,0.5277777777777778,0.050327487682041365,mmlu:moral_disputes,validation,6.086258361116052,llama2_7b_chat,choice,choice,,,,
346,0.28996075689792633,0.4566473960876465,0.5664739608764648,0.5219162402370051,0.0537399119035357,mmlu:moral_disputes,test,54.54021058045328,llama2_7b_chat,choice,choice,,,,
33,0.2739083396665978,0.42424243688583374,0.8181818723678589,0.2518796992481203,0.06985763347510136,mmlu:nutrition,validation,6.39553133584559,llama2_7b_chat,choice,choice,,,,
306,0.28641536471500895,0.3464052379131317,0.7352941036224365,0.250872641509434,0.08246358508378071,mmlu:nutrition,test,59.19426644779742,llama2_7b_chat,choice,choice,,,,
34,0.3420334589831969,0.5,0.529411792755127,0.5501730103806228,0.11811707300298356,mmlu:philosophy,validation,4.125080885365605,llama2_7b_chat,choice,choice,,,,
311,0.2247296358994732,0.5723472833633423,0.6270096302032471,0.61844217284785,0.012932229655348598,mmlu:philosophy,test,36.218557162210345,llama2_7b_chat,choice,choice,,,,
35,0.3339710337775095,0.37142857909202576,0.6857143044471741,0.4475524475524476,0.04592495816094535,mmlu:prehistory,validation,6.280806129798293,llama2_7b_chat,choice,choice,,,,
324,0.22162122766912723,0.48765432834625244,0.645061731338501,0.39276727161811803,0.048621863862614585,mmlu:prehistory,test,56.51904157176614,llama2_7b_chat,choice,choice,,,,
69,0.32096975825834967,0.36231884360313416,0.52173912525177,0.5481818181818182,0.13626384216806162,mmlu:professional_psychology,validation,13.145668152719736,llama2_7b_chat,choice,choice,,,,
612,0.2966061641577802,0.37254902720451355,0.5539215803146362,0.4293105811403508,0.13423357494905883,mmlu:professional_psychology,test,111.83764244802296,llama2_7b_chat,choice,choice,,,,
12,0.3743753979603449,0.5,0.4166666865348816,0.5,0.27745831012725836,mmlu:public_relations,validation,1.867365501821041,llama2_7b_chat,choice,choice,,,,
110,0.18387245508757502,0.5454545021057129,0.663636326789856,0.5033333333333334,0.04754963625561107,mmlu:public_relations,test,15.41992754675448,llama2_7b_chat,choice,choice,,,,
27,0.31664352174158455,0.48148149251937866,0.5555555820465088,0.6263736263736264,0.2266520769507797,mmlu:security_studies,validation,11.528360521420836,llama2_7b_chat,choice,choice,,,,
245,0.3159258387526687,0.3632652759552002,0.5755102038383484,0.4612503601267647,0.16770110373594324,mmlu:security_studies,test,106.40334039367735,llama2_7b_chat,choice,choice,,,,
22,0.19736636091362347,0.7727273106575012,0.7272727489471436,0.5647058823529412,0.11989423903551973,mmlu:sociology,validation,3.1952253952622414,llama2_7b_chat,choice,choice,,,,
201,0.1510410602413007,0.6865671277046204,0.7263681292533875,0.5901196227283183,0.05318407276969644,mmlu:sociology,test,29.13541634194553,llama2_7b_chat,choice,choice,,,,
11,0.14652780240232297,0.7272727489471436,0.7272727489471436,0.7916666666666666,0.13516269488768143,mmlu:us_foreign_policy,validation,1.6316139977425337,llama2_7b_chat,choice,choice,,,,
100,0.1655122050642967,0.699999988079071,0.7299999594688416,0.48142857142857143,0.1039146590232849,mmlu:us_foreign_policy,test,13.605400130152702,llama2_7b_chat,choice,choice,,,,
18,0.270402921570672,0.4444444477558136,0.7222222089767456,0.49375,0.2538258234659831,mmlu:virology,validation,2.6773214992135763,llama2_7b_chat,choice,choice,,,,
166,0.324653073965785,0.41566264629364014,0.5301204919815063,0.45024652622142536,0.13751503466123557,mmlu:virology,test,20.431342033669353,llama2_7b_chat,choice,choice,,,,
19,0.08782861107274105,0.7894737124443054,0.8421052694320679,0.6833333333333333,0.19004975180876885,mmlu:world_religions,validation,1.8677252605557442,llama2_7b_chat,choice,choice,,,,
171,0.09528311180789566,0.6608186960220337,0.7953216433525085,0.30828501678364356,0.11050611629820703,mmlu:world_religions,test,16.132882328704,llama2_7b_chat,choice,choice,,,,
14,0.316505851490157,0.6428571939468384,0.5714285969734192,0.2666666666666666,0.11649784871510097,mmlu:anatomy,validation,5.237228916957974,llama2_7b,choice,choice,,,,
135,0.0471060276031494,0.4814814627170563,0.5925925970077515,0.5681318681318681,0.08002602435924389,mmlu:anatomy,test,16.978008553385735,llama2_7b,choice,choice,,,,
16,0.21303562633693218,0.4375,0.625,0.5714285714285714,0.05807682126760482,mmlu:astronomy,validation,3.164196787402034,llama2_7b,choice,choice,,,,
152,0.09957414159649294,0.42763158679008484,0.5460526347160339,0.6616268788682582,0.08319118579751571,mmlu:astronomy,test,28.966084260493517,llama2_7b,choice,choice,,,,
11,0.18482445044951004,0.5454545617103577,0.7272727489471436,0.6666666666666666,0.2512759783051231,mmlu:business_ethics,validation,2.200151836499572,llama2_7b,choice,choice,,,,
100,0.10293846011161806,0.5,0.5699999928474426,0.4638,0.038061020374298066,mmlu:business_ethics,test,19.010097939521074,llama2_7b,choice,choice,,,,
29,0.1997113207290913,0.41379308700561523,0.41379308700561523,0.43137254901960786,0.21219681460281897,mmlu:clinical_knowledge,validation,4.234895387664437,llama2_7b,choice,choice,,,,
265,0.04839907445997561,0.4867924451828003,0.5056604146957397,0.6025421796625627,0.12899280314175587,mmlu:clinical_knowledge,test,36.79688738286495,llama2_7b,choice,choice,,,,
16,0.1442484837025404,0.3125,0.3125,0.8545454545454545,0.41879595071077347,mmlu:college_biology,validation,2.7210098449140787,llama2_7b,choice,choice,,,,
144,0.05530282855033875,0.4444444477558136,0.4791666567325592,0.5686523437500001,0.15534918051626945,mmlu:college_biology,test,23.86754907295108,llama2_7b,choice,choice,,,,
8,0.2846439443528652,0.5,0.75,0.375,0.16635624319314957,mmlu:college_chemistry,validation,1.5981465820223093,llama2_7b,choice,choice,,,,
100,0.04396307885646821,0.3400000035762787,0.5399999618530273,0.6087344028520498,0.0647769057750702,mmlu:college_chemistry,test,17.860881593078375,llama2_7b,choice,choice,,,,
11,0.27867451310157776,0.6363636255264282,0.7272727489471436,0.6785714285714285,0.16192940148440274,mmlu:college_computer_science,validation,2.922214288264513,llama2_7b,choice,choice,,,,
100,0.12171100914478301,0.3499999940395355,0.47999998927116394,0.6408791208791208,0.0980769920349121,mmlu:college_computer_science,test,26.66997934691608,llama2_7b,choice,choice,,,,
11,0.03904929215257818,0.27272728085517883,0.6363636255264282,0.16666666666666666,0.13811013915322043,mmlu:college_mathematics,validation,2.1201714519411325,llama2_7b,choice,choice,,,,
100,0.06566793262958528,0.35999998450279236,0.5399999618530273,0.6508246527777778,0.012591388225555444,mmlu:college_mathematics,test,18.062085311859846,llama2_7b,choice,choice,,,,
22,0.23144665631380953,0.4545454680919647,0.40909093618392944,0.5333333333333333,0.24487499757246534,mmlu:college_medicine,validation,3.9751779194921255,llama2_7b,choice,choice,,,,
173,0.09870713173998572,0.3815028667449951,0.44508668780326843,0.6277258566978193,0.19673215171505262,mmlu:college_medicine,test,35.83789765648544,llama2_7b,choice,choice,,,,
11,0.21092458475719797,0.5454545617103577,0.5454545617103577,0.5333333333333333,0.14376018805937335,mmlu:college_physics,validation,1.912123166024685,llama2_7b,choice,choice,,,,
102,0.20560371379057563,0.2352941334247589,0.5882353186607361,0.4107905982905983,0.14945655067761737,mmlu:college_physics,test,16.476771902292967,llama2_7b,choice,choice,,,,
11,0.2262939594008706,0.5454545617103577,0.7272727489471436,0.7666666666666666,0.14545745741237293,mmlu:computer_security,validation,1.7669359873980284,llama2_7b,choice,choice,,,,
100,0.08229195713996887,0.5699999928474426,0.6200000047683716,0.5889432884536924,0.04297178506851198,mmlu:computer_security,test,13.451789932325482,llama2_7b,choice,choice,,,,
26,0.1780651154426428,0.38461539149284363,0.6153846383094788,0.30625,0.09215448452876167,mmlu:conceptual_physics,validation,3.0050630681216717,llama2_7b,choice,choice,,,,
235,0.0895193411948833,0.4382978677749634,0.5531914830207825,0.4875330979699912,0.05108721332347135,mmlu:conceptual_physics,test,25.590828832238913,llama2_7b,choice,choice,,,,
12,0.24002027014891306,0.25,0.5,0.40740740740740744,0.2536396086215973,mmlu:econometrics,validation,2.4367073588073254,llama2_7b,choice,choice,,,,
114,0.13919230406744434,0.28947368264198303,0.5175438523292542,0.6632996632996633,0.06371891707704774,mmlu:econometrics,test,22.304980332031846,llama2_7b,choice,choice,,,,
16,0.20740997791290283,0.5625,0.5625,0.5079365079365079,0.06343083083629608,mmlu:electrical_engineering,validation,2.3317400235682726,llama2_7b,choice,choice,,,,
145,0.07344877617112522,0.41379308700561523,0.4965517222881317,0.5070588235294118,0.11910434879105664,mmlu:electrical_engineering,test,20.102646818384528,llama2_7b,choice,choice,,,,
41,0.11478738377733928,0.2682926654815674,0.2926829159259796,0.23636363636363636,0.31048077344894415,mmlu:elementary_mathematics,validation,7.325057651847601,llama2_7b,choice,choice,,,,
378,0.08419816109238477,0.23280422389507294,0.35449734330177307,0.49847178683385573,0.23830196466395465,mmlu:elementary_mathematics,test,65.3096985630691,llama2_7b,choice,choice,,,,
14,0.1309523582458496,0.2142857313156128,0.5714285969734192,0.4848484848484848,0.019469712461744035,mmlu:formal_logic,validation,2.818988861516118,llama2_7b,choice,choice,,,,
126,0.0734056854058826,0.3968254327774048,0.5714285969734192,0.42723684210526314,0.03321427485299485,mmlu:formal_logic,test,24.765106216073036,llama2_7b,choice,choice,,,,
10,0.31112129986286163,0.0,0.699999988079071,,0.17404152154922486,mmlu:global_facts,validation,1.5166646633297205,llama2_7b,choice,choice,,,,
100,0.09453950107097625,0.29999998211860657,0.5399999618530273,0.575,0.03638427734375002,mmlu:global_facts,test,13.929199172183871,llama2_7b,choice,choice,,,,
32,0.15929202921688557,0.34375,0.53125,0.6883116883116883,0.10242722928524017,mmlu:high_school_biology,validation,5.637511946260929,llama2_7b,choice,choice,,,,
310,0.06557648556847727,0.4838709533214569,0.5354838371276855,0.6352916666666666,0.11037631765488656,mmlu:high_school_biology,test,53.75652096234262,llama2_7b,choice,choice,,,,
22,0.14563547616655179,0.3636363744735718,0.5909091234207153,0.75,0.028401613235473657,mmlu:high_school_chemistry,validation,3.91570982709527,llama2_7b,choice,choice,,,,
203,0.07429527751917911,0.37438422441482544,0.467980295419693,0.572057604641525,0.1288869025672011,mmlu:high_school_chemistry,test,34.00432981736958,llama2_7b,choice,choice,,,,
9,0.2763041125403509,0.6666666865348816,0.5555555820465088,0.44444444444444453,0.16296800639894274,mmlu:high_school_computer_science,validation,2.8140939939767122,llama2_7b,choice,choice,,,,
100,0.0944753623008728,0.3799999952316284,0.5399999618530273,0.5093378607809848,0.04723222017288211,mmlu:high_school_computer_science,test,29.839746069163084,llama2_7b,choice,choice,,,,
22,0.14493492787534543,0.7272727489471436,0.5909091234207153,0.71875,0.15312095121903854,mmlu:high_school_geography,validation,2.958738751709461,llama2_7b,choice,choice,,,,
198,0.1304760573789327,0.5,0.5404040217399597,0.6118253239465361,0.07624389968737208,mmlu:high_school_geography,test,25.896811408922076,llama2_7b,choice,choice,,,,
21,0.11912707345826284,0.5714285969734192,0.5714285969734192,0.7962962962962964,0.21196970485505606,mmlu:high_school_government_and_politics,validation,3.3030982799828053,llama2_7b,choice,choice,,,,
193,0.08869219598374835,0.6891191601753235,0.6994818449020386,0.6917293233082706,0.07432579067704591,mmlu:high_school_government_and_politics,test,29.972379161044955,llama2_7b,choice,choice,,,,
43,0.1393191038176071,0.3255814015865326,0.3255814015865326,0.4950738916256158,0.32322829684545823,mmlu:high_school_macroeconomics,validation,5.837242271751165,llama2_7b,choice,choice,,,,
390,0.039585466644702826,0.4435897469520569,0.4871794879436493,0.5960816174316081,0.15655254736924784,mmlu:high_school_macroeconomics,test,51.94055180065334,llama2_7b,choice,choice,,,,
29,0.1322748599381282,0.4482758641242981,0.5517241358757019,0.2764423076923077,0.10466700381246109,mmlu:high_school_mathematics,validation,4.992088476195931,llama2_7b,choice,choice,,,,
270,0.03766621925212718,0.277777761220932,0.5629629492759705,0.5290940170940172,0.03598802288373314,mmlu:high_school_mathematics,test,44.963910123333335,llama2_7b,choice,choice,,,,
26,0.20842720568180087,0.3461538553237915,0.46153849363327026,0.8104575163398693,0.1371720845882709,mmlu:high_school_microeconomics,validation,3.5309529714286327,llama2_7b,choice,choice,,,,
238,0.07028368027771217,0.4495798647403717,0.4621849060058594,0.60134122850824,0.15016937105595568,mmlu:high_school_microeconomics,test,32.00711353123188,llama2_7b,choice,choice,,,,
17,0.10082907361142777,0.29411765933036804,0.4117647111415863,0.6666666666666666,0.1405720815939062,mmlu:high_school_physics,validation,3.1955163329839706,llama2_7b,choice,choice,,,,
151,0.097967157103368,0.29139071702957153,0.3708609342575073,0.47249362786745963,0.19669370777559597,mmlu:high_school_physics,test,27.085375675931573,llama2_7b,choice,choice,,,,
60,0.1589977249503136,0.7000000476837158,0.7000000476837158,0.6223544973544973,0.05401192605495453,mmlu:high_school_psychology,validation,10.274143740534782,llama2_7b,choice,choice,,,,
545,0.07737777763550435,0.6366972327232361,0.6238532066345215,0.6080473321107327,0.03314379366166004,mmlu:high_school_psychology,test,93.17686454206705,llama2_7b,choice,choice,,,,
23,0.13274553677310116,0.43478262424468994,0.52173912525177,0.6615384615384615,0.11784571409225462,mmlu:high_school_statistics,validation,5.87848187610507,llama2_7b,choice,choice,,,,
216,0.10100761635435954,0.2638888955116272,0.47685185074806213,0.528246717422487,0.09004014840832465,mmlu:high_school_statistics,test,57.41032235696912,llama2_7b,choice,choice,,,,
22,0.28292583470994775,0.6818181872367859,0.6818181872367859,0.3047619047619048,0.11339545249938962,mmlu:high_school_us_history,validation,20.840260319411755,llama2_7b,choice,choice,,,,
204,0.11426834499134737,0.593137264251709,0.5882353186607361,0.5993726974011748,0.057781024014248554,mmlu:high_school_us_history,test,192.3648624792695,llama2_7b,choice,choice,,,,
23,0.28406256307726324,0.6521739363670349,0.6086956858634949,0.5625,0.12107882033223688,mmlu:human_aging,validation,2.7200655229389668,llama2_7b,choice,choice,,,,
223,0.07760624233382703,0.5426009297370911,0.5156950950622559,0.6002268676065468,0.11367552403377312,mmlu:human_aging,test,25.19706372730434,llama2_7b,choice,choice,,,,
12,0.25977308054765064,0.5833333730697632,0.75,0.8,0.14709811906019848,mmlu:human_sexuality,validation,1.5404964126646519,llama2_7b,choice,choice,,,,
131,0.08252456943497402,0.5496183037757874,0.5343511700630188,0.4835216572504708,0.06327606976487256,mmlu:human_sexuality,test,16.49324679747224,llama2_7b,choice,choice,,,,
13,0.20696626488979047,0.8461538553237915,0.692307710647583,0.5909090909090908,0.08014108584477349,mmlu:international_law,validation,2.9129910990595818,llama2_7b,choice,choice,,,,
121,0.06712943980516481,0.6280991435050964,0.6694214344024658,0.572953216374269,0.13723174845876773,mmlu:international_law,test,24.567989794537425,llama2_7b,choice,choice,,,,
11,0.2205446470867504,0.5454545617103577,0.6363636255264282,0.7333333333333333,0.07360533692620015,mmlu:jurisprudence,validation,1.6195929236710072,llama2_7b,choice,choice,,,,
108,0.11856746701178728,0.5092592835426331,0.5833333134651184,0.5396226415094341,0.015692012729468192,mmlu:jurisprudence,test,14.644767370074987,llama2_7b,choice,choice,,,,
18,0.170874469810062,0.7222222089767456,0.6111111044883728,0.4153846153846154,0.08513174785508051,mmlu:logical_fallacies,validation,2.6890346463769674,llama2_7b,choice,choice,,,,
163,0.10552868137330366,0.5521472096443176,0.5398772954940796,0.39299847792998477,0.056185433103994334,mmlu:logical_fallacies,test,24.066171804443,llama2_7b,choice,choice,,,,
11,0.16178627176718277,0.1818181872367859,0.8181818723678589,0.7777777777777779,0.24075741117650812,mmlu:machine_learning,validation,2.335583198815584,llama2_7b,choice,choice,,,,
112,0.06483048679573196,0.4017857313156128,0.6160714626312256,0.4409618573797678,0.03015659004449844,mmlu:machine_learning,test,22.897380851209164,llama2_7b,choice,choice,,,,
11,0.31467008048837836,0.27272728085517883,0.5454545617103577,0.625,0.32105164636265154,mmlu:management,validation,1.2088628131896257,llama2_7b,choice,choice,,,,
103,0.10779039836624293,0.6019417643547058,0.6116504669189453,0.6172305271439811,0.02771427619804458,mmlu:management,test,10.674634316936135,llama2_7b,choice,choice,,,,
25,0.21100118041038513,0.7999999523162842,0.7199999690055847,0.6799999999999999,0.12131827592849737,mmlu:marketing,validation,3.5633022896945477,llama2_7b,choice,choice,,,,
234,0.08511733282835057,0.6837607026100159,0.6452991962432861,0.6290962837837838,0.04110696249537998,mmlu:marketing,test,31.773401096463203,llama2_7b,choice,choice,,,,
11,0.2489505030892112,0.8181818723678589,0.7272727489471436,0.7777777777777778,0.09793613173744894,mmlu:medical_genetics,validation,1.5054234750568867,llama2_7b,choice,choice,,,,
100,0.08966358572244644,0.4699999988079071,0.6499999761581421,0.5660377358490566,0.0674854761362076,mmlu:medical_genetics,test,12.398951252922416,llama2_7b,choice,choice,,,,
38,0.21275872776382848,0.34210526943206787,0.6052631735801697,0.6230769230769231,0.03026136599088972,mmlu:moral_disputes,validation,6.173713486641645,llama2_7b,choice,choice,,,,
346,0.08811942276927087,0.48554912209510803,0.5404624342918396,0.5130584537185661,0.058494607492678416,mmlu:moral_disputes,test,55.22882004454732,llama2_7b,choice,choice,,,,
33,0.13644179250254776,0.6363636255264282,0.575757622718811,0.4722222222222222,0.12151374238910098,mmlu:nutrition,validation,6.487211646512151,llama2_7b,choice,choice,,,,
306,0.0441471742453918,0.5032680034637451,0.5686274766921997,0.5149521531100478,0.025430692371979285,mmlu:nutrition,test,59.77151466906071,llama2_7b,choice,choice,,,,
34,0.25040046783054576,0.38235294818878174,0.5882353186607361,0.6483516483516484,0.02026970596874463,mmlu:philosophy,validation,4.196507362648845,llama2_7b,choice,choice,,,,
311,0.06003534678860875,0.5787781476974487,0.5852090120315552,0.49715860899067,0.012713284162846415,mmlu:philosophy,test,36.91014058329165,llama2_7b,choice,choice,,,,
35,0.18100049325398032,0.4000000059604645,0.5428571701049805,0.7244897959183674,0.06101876667567659,mmlu:prehistory,validation,6.359579963609576,llama2_7b,choice,choice,,,,
324,0.0783309977915552,0.5154321193695068,0.540123462677002,0.5930813532171326,0.06326554034963065,mmlu:prehistory,test,57.12331681884825,llama2_7b,choice,choice,,,,
69,0.11339120933975,0.42028987407684326,0.52173912525177,0.5849137931034483,0.06577050167581311,mmlu:professional_psychology,validation,13.302802801132202,llama2_7b,choice,choice,,,,
612,0.03712628182827258,0.43627452850341797,0.5098039507865906,0.5829669434945448,0.07394345046258441,mmlu:professional_psychology,test,113.0986611135304,llama2_7b,choice,choice,,,,
12,0.18629899869362515,0.4166666865348816,0.4166666865348816,0.6857142857142857,0.21131008863449097,mmlu:public_relations,validation,1.8974136039614677,llama2_7b,choice,choice,,,,
110,0.10156022689559242,0.5363636016845703,0.5272727012634277,0.49551345962113663,0.06830546097321948,mmlu:public_relations,test,15.653393736109138,llama2_7b,choice,choice,,,,
27,0.08400083250469632,0.4444444477558136,0.7037037014961243,0.525,0.13732732666863334,mmlu:security_studies,validation,11.595628520473838,llama2_7b,choice,choice,,,,
245,0.06508886680311085,0.4734693765640259,0.5551019906997681,0.5990711039828922,0.04980817425007723,mmlu:security_studies,test,106.90027994848788,llama2_7b,choice,choice,,,,
22,0.1622227254238996,0.6363636255264282,0.7727273106575012,0.6428571428571429,0.1712795197963715,mmlu:sociology,validation,3.25053153000772,llama2_7b,choice,choice,,,,
201,0.08522436764109788,0.6368159055709839,0.641791045665741,0.5849208047945206,0.0427131089405041,mmlu:sociology,test,29.54241755604744,llama2_7b,choice,choice,,,,
11,0.22170420126481488,0.4545454680919647,0.7272727489471436,0.6666666666666667,0.3139891895380887,mmlu:us_foreign_policy,validation,1.6696903984993696,llama2_7b,choice,choice,,,,
100,0.06871068000793457,0.6499999761581421,0.6200000047683716,0.5323076923076924,0.03150077521800995,mmlu:us_foreign_policy,test,13.833071082830429,llama2_7b,choice,choice,,,,
18,0.2937471899721358,0.3888888955116272,0.3888888955116272,0.5454545454545454,0.22020974424150255,mmlu:virology,validation,2.727407243102789,llama2_7b,choice,choice,,,,
166,0.14781458370656855,0.40963852405548096,0.45783132314682007,0.48041716686674674,0.13984699780682483,mmlu:virology,test,20.783252565190196,llama2_7b,choice,choice,,,,
19,0.26303477193179886,0.7894737124443054,0.5789473652839661,0.33333333333333337,0.023280501365661604,mmlu:world_religions,validation,1.9121555592864752,llama2_7b,choice,choice,,,,
171,0.13904649681515163,0.7017543911933899,0.584795355796814,0.4673202614379085,0.047359796643954254,mmlu:world_religions,test,16.482988072559237,llama2_7b,choice,choice,,,,
14,0.12996737446103776,0.6428571939468384,0.6428571939468384,0.5111111111111111,0.09315825360161917,mmlu:anatomy,validation,6.900878330692649,mistral_7b,choice,choice,,,,
135,0.07770858980991223,0.5703703761100769,0.5925925970077515,0.5746753246753247,0.1369591412720857,mmlu:anatomy,test,18.573558688163757,mistral_7b,choice,choice,,,,
16,0.18127261102199554,0.6875,0.6875,0.6363636363636364,0.13738234713673592,mmlu:astronomy,validation,4.80920416675508,mistral_7b,choice,choice,,,,
152,0.1195880966751199,0.6578947305679321,0.6578947305679321,0.6236538461538461,0.030846629487840716,mmlu:astronomy,test,27.855041267350316,mistral_7b,choice,choice,,,,
11,0.31494476578452363,0.5454545617103577,0.5454545617103577,0.7666666666666666,0.2869887731292031,mmlu:business_ethics,validation,2.008247660472989,mistral_7b,choice,choice,,,,
100,0.10406364679336545,0.5899999737739563,0.6100000143051147,0.7618850764778834,0.11019589245319368,mmlu:business_ethics,test,18.359369644895196,mistral_7b,choice,choice,,,,
29,0.19262660474612794,0.6206896305084229,0.6206896305084229,0.5277777777777778,0.19972294774548766,mmlu:clinical_knowledge,validation,5.2810179609805346,mistral_7b,choice,choice,,,,
265,0.10500043967984758,0.6754717230796814,0.6679245233535767,0.6203066129660908,0.07683165770656658,mmlu:clinical_knowledge,test,35.642249673604965,mistral_7b,choice,choice,,,,
16,0.1876346506178379,0.625,0.625,0.525,0.1940699815750122,mmlu:college_biology,validation,2.5040186401456594,mistral_7b,choice,choice,,,,
144,0.04377846585379708,0.7291666865348816,0.7361111044883728,0.5881562881562881,0.07579029517041312,mmlu:college_biology,test,23.260797187685966,mistral_7b,choice,choice,,,,
8,0.32298047840595245,0.25,0.375,0.5,0.5149664357304573,mmlu:college_chemistry,validation,1.539071448147297,mistral_7b,choice,choice,,,,
100,0.0650123029947281,0.4699999988079071,0.5699999928474426,0.43115214773183463,0.16361966609954837,mmlu:college_chemistry,test,19.048842331394553,mistral_7b,choice,choice,,,,
11,0.09047955816442316,0.4545454680919647,0.6363636255264282,0.7,0.20047935030677105,mmlu:college_computer_science,validation,2.8671998139470816,mistral_7b,choice,choice,,,,
100,0.17411124080419543,0.5399999618530273,0.550000011920929,0.6340579710144928,0.11115193128585817,mmlu:college_computer_science,test,25.528169836848974,mistral_7b,choice,choice,,,,
11,0.09765914353457364,0.27272728085517883,0.3636363744735718,0.7916666666666666,0.29694473201578314,mmlu:college_mathematics,validation,2.0621987506747246,mistral_7b,choice,choice,,,,
100,0.06678379207849502,0.32999998331069946,0.5,0.57756671189507,0.111821004152298,mmlu:college_mathematics,test,17.138910908252,mistral_7b,choice,choice,,,,
22,0.20038289509036328,0.5454545617103577,0.5454545617103577,0.6,0.1706171360882846,mmlu:college_medicine,validation,3.5792223569005728,mistral_7b,choice,choice,,,,
173,0.057301384865204044,0.6300578117370605,0.5838150382041931,0.48193807339449546,0.0605462451890714,mmlu:college_medicine,test,32.257443871349096,mistral_7b,choice,choice,,,,
11,0.2806849073279988,0.3636363744735718,0.6363636255264282,1.0,0.28586170348254114,mmlu:college_physics,validation,1.80822647921741,mistral_7b,choice,choice,,,,
102,0.11120533592560713,0.4215686321258545,0.5196078419685364,0.6255419787150178,0.10728285826888741,mmlu:college_physics,test,15.057779336348176,mistral_7b,choice,choice,,,,
11,0.37076828154650604,0.8181818723678589,0.8181818723678589,0.5833333333333333,0.15744454210454767,mmlu:computer_security,validation,1.692227741703391,mistral_7b,choice,choice,,,,
100,0.06696448236703875,0.7699999809265137,0.7299999594688416,0.5115753811405985,0.1008183240890503,mmlu:computer_security,test,12.335902992635965,mistral_7b,choice,choice,,,,
26,0.25595321219701034,0.46153849363327026,0.5769230723381042,0.8809523809523809,0.09697652321595411,mmlu:conceptual_physics,validation,2.722386533394456,mistral_7b,choice,choice,,,,
235,0.05044980708588945,0.591489315032959,0.5999999642372131,0.575089928057554,0.050916964449781055,mmlu:conceptual_physics,test,22.86325116083026,mistral_7b,choice,choice,,,,
12,0.23041644444068274,0.6666666865348816,0.6666666865348816,0.59375,0.3563651293516159,mmlu:econometrics,validation,2.458368131890893,mistral_7b,choice,choice,,,,
114,0.08587186299917991,0.5087719559669495,0.5,0.5160098522167488,0.23589301893585607,mmlu:econometrics,test,20.99887770973146,mistral_7b,choice,choice,,,,
16,0.25773022696375847,0.625,0.625,0.7833333333333333,0.10830226168036461,mmlu:electrical_engineering,validation,2.2930477634072304,mistral_7b,choice,choice,,,,
145,0.08545136287294586,0.5793103575706482,0.5586206912994385,0.5971896955503513,0.16997714083770227,mmlu:electrical_engineering,test,18.871783209964633,mistral_7b,choice,choice,,,,
41,0.09747468407561138,0.4146341383457184,0.4878048598766327,0.4877450980392157,0.1592305229931343,mmlu:elementary_mathematics,validation,6.916900048032403,mistral_7b,choice,choice,,,,
378,0.06201344381564508,0.41534391045570374,0.4259259104728699,0.5342104504712224,0.19170564980733962,mmlu:elementary_mathematics,test,60.795031985268,mistral_7b,choice,choice,,,,
14,0.34706552752426695,0.2857142984867096,0.4285714626312256,0.55,0.2299527483327048,mmlu:formal_logic,validation,2.83414039388299,mistral_7b,choice,choice,,,,
126,0.08840034902095796,0.3888889253139496,0.4126984477043152,0.6679035250463822,0.24535601621582395,mmlu:formal_logic,test,24.30702757462859,mistral_7b,choice,choice,,,,
10,0.20264226198196417,0.6000000238418579,0.6000000238418579,0.5416666666666666,0.26713984012603764,mmlu:global_facts,validation,1.4833593219518661,mistral_7b,choice,choice,,,,
100,0.059538078308105466,0.32999998331069946,0.4099999964237213,0.5230664857530529,0.22681966066360473,mmlu:global_facts,test,12.823168417438865,mistral_7b,choice,choice,,,,
32,0.11322943214327094,0.6875,0.65625,0.5681818181818181,0.09114343114197254,mmlu:high_school_biology,validation,5.266344899311662,mistral_7b,choice,choice,,,,
310,0.04629246554067055,0.7645161151885986,0.7709677219390869,0.57230795907751,0.08074413807161396,mmlu:high_school_biology,test,51.24381942488253,mistral_7b,choice,choice,,,,
22,0.2628293985670263,0.40909093618392944,0.5,0.5982905982905983,0.17081747542728082,mmlu:high_school_chemistry,validation,3.714094990864396,mistral_7b,choice,choice,,,,
203,0.05231280015607186,0.5024630427360535,0.5665024518966675,0.6226946224034168,0.03569671790588079,mmlu:high_school_chemistry,test,32.676734644919634,mistral_7b,choice,choice,,,,
9,0.3007135225666894,0.6666666865348816,0.7777777910232544,0.6666666666666666,0.07208838727739121,mmlu:high_school_computer_science,validation,2.726333012804389,mistral_7b,choice,choice,,,,
100,0.13785880148410795,0.7299999594688416,0.6800000071525574,0.7295788939624556,0.067319170832634,mmlu:high_school_computer_science,test,28.579054525122046,mistral_7b,choice,choice,,,,
22,0.14824948256666012,0.8181818723678589,0.8181818723678589,0.4722222222222222,0.20919781381433658,mmlu:high_school_geography,validation,2.7114270869642496,mistral_7b,choice,choice,,,,
198,0.030429966220952065,0.7979797720909119,0.7676767706871033,0.4923259493670886,0.07984507294616311,mmlu:high_school_geography,test,23.248333239927888,mistral_7b,choice,choice,,,,
21,0.16606875402586804,0.8571428656578064,0.8095238208770752,0.5,0.17794033743086313,mmlu:high_school_government_and_politics,validation,4.29501742683351,mistral_7b,choice,choice,,,,
193,0.06839079792017766,0.8860103487968445,0.8704662919044495,0.5692450824029771,0.136548253538695,mmlu:high_school_government_and_politics,test,26.409594463184476,mistral_7b,choice,choice,,,,
43,0.07352438915607543,0.6511628031730652,0.6279069781303406,0.4880952380952381,0.18694384569345518,mmlu:high_school_macroeconomics,validation,5.155675815418363,mistral_7b,choice,choice,,,,
390,0.08413507013748853,0.656410276889801,0.6435897350311279,0.6325792910447761,0.06920108474217929,mmlu:high_school_macroeconomics,test,46.56537272967398,mistral_7b,choice,choice,,,,
29,0.09171333189668326,0.20689654350280762,0.517241358757019,0.3152173913043478,0.04430953387556406,mmlu:high_school_mathematics,validation,4.733928699046373,mistral_7b,choice,choice,,,,
270,0.052982342574331515,0.31111109256744385,0.5407407283782959,0.5313620071684587,0.033069910164232594,mmlu:high_school_mathematics,test,42.76439682021737,mistral_7b,choice,choice,,,,
26,0.16145830773390257,0.7692307829856873,0.7692307829856873,0.6291666666666667,0.14880162248244655,mmlu:high_school_microeconomics,validation,3.2668863218277693,mistral_7b,choice,choice,,,,
238,0.03960399868107643,0.6638655662536621,0.6512605547904968,0.5417325949367088,0.048546051778713226,mmlu:high_school_microeconomics,test,29.07836513593793,mistral_7b,choice,choice,,,,
17,0.21038203379687137,0.23529411852359772,0.29411765933036804,0.36538461538461536,0.30939796041039863,mmlu:high_school_physics,validation,3.0680196154862642,mistral_7b,choice,choice,,,,
151,0.05913235355686669,0.3509933650493622,0.42384105920791626,0.5569888332691568,0.19977649434512815,mmlu:high_school_physics,test,25.290863344445825,mistral_7b,choice,choice,,,,
60,0.06841527173916499,0.8833333849906921,0.8500000238418579,0.5606469002695419,0.13855856955051424,mmlu:high_school_psychology,validation,9.125818120315671,mistral_7b,choice,choice,,,,
545,0.029738220162347888,0.8183486461639404,0.8110091686248779,0.5781242922498528,0.07537773038269181,mmlu:high_school_psychology,test,99.40506782010198,mistral_7b,choice,choice,,,,
23,0.13216069729431817,0.52173912525177,0.5652173757553101,0.7651515151515151,0.1834845983463785,mmlu:high_school_statistics,validation,5.7802034467458725,mistral_7b,choice,choice,,,,
216,0.09823555347544176,0.5740740895271301,0.5787037014961243,0.5715287517531558,0.10346362739801407,mmlu:high_school_statistics,test,64.7016843110323,mistral_7b,choice,choice,,,,
22,0.17673563008958643,0.7727273106575012,0.4545454680919647,0.2588235294117647,0.14486358111554928,mmlu:high_school_us_history,validation,28.341008411720395,mistral_7b,choice,choice,,,,
204,0.04254282411991383,0.779411792755127,0.6715686321258545,0.490146750524109,0.07282461401294259,mmlu:high_school_us_history,test,212.34785528481007,mistral_7b,choice,choice,,,,
23,0.23292865960494333,0.739130437374115,0.739130437374115,0.6421568627450981,0.057085000950357186,mmlu:human_aging,validation,3.5626484230160713,mistral_7b,choice,choice,,,,
223,0.05373704019148788,0.6995515823364258,0.6995515823364258,0.6003635667814772,0.06588717666976655,mmlu:human_aging,test,40.193662099540234,mistral_7b,choice,choice,,,,
12,0.20912925402323407,0.5833333730697632,0.5,0.5714285714285714,0.22244475781917572,mmlu:human_sexuality,validation,5.124710857868195,mistral_7b,choice,choice,,,,
131,0.10510530135103764,0.8015267252922058,0.7786259651184082,0.543040293040293,0.06065978758207715,mmlu:human_sexuality,test,27.74469219148159,mistral_7b,choice,choice,,,,
13,0.1015930359180157,0.9230769872665405,0.9230769872665405,0.3333333333333333,0.1436073596660907,mmlu:international_law,validation,5.573058422654867,mistral_7b,choice,choice,,,,
121,0.03842827061976283,0.7933883666992188,0.7933883666992188,0.5447916666666667,0.0672643519630117,mmlu:international_law,test,30.586700968444347,mistral_7b,choice,choice,,,,
11,0.20057660612193018,0.6363636255264282,0.6363636255264282,0.3214285714285714,0.11449221589348535,mmlu:jurisprudence,validation,2.3397167213261127,mistral_7b,choice,choice,,,,
108,0.11406420226450321,0.8148148059844971,0.7777777910232544,0.6417613636363637,0.08062554178414522,mmlu:jurisprudence,test,19.95385342463851,mistral_7b,choice,choice,,,,
18,0.20586354533831278,0.7222222089767456,0.7222222089767456,0.4461538461538462,0.23967329661051429,mmlu:logical_fallacies,validation,4.614934302866459,mistral_7b,choice,choice,,,,
163,0.1014370464839818,0.8098159432411194,0.8098159432411194,0.6152248289345064,0.0761516233163377,mmlu:logical_fallacies,test,28.66947010718286,mistral_7b,choice,choice,,,,
11,0.19773347269405017,0.27272728085517883,0.3636363744735718,0.35416666666666663,0.4017841436646201,mmlu:machine_learning,validation,4.488347319886088,mistral_7b,choice,choice,,,,
112,0.13094645525727952,0.3750000298023224,0.6339285969734192,0.6273809523809524,0.13324221596121788,mmlu:machine_learning,test,28.655738012865186,mistral_7b,choice,choice,,,,
11,0.16335472735491666,0.9090909361839294,0.8181818723678589,0.3,0.17486622116782446,mmlu:management,validation,4.243023140355945,mistral_7b,choice,choice,,,,
103,0.0489254851364395,0.7961165308952332,0.7864077687263489,0.6652148664343787,0.11301341160987184,mmlu:management,test,21.73155884258449,mistral_7b,choice,choice,,,,
25,0.07497458100318907,0.8799999952316284,0.8399999737739563,0.7424242424242424,0.187140908241272,mmlu:marketing,validation,6.812600765377283,mistral_7b,choice,choice,,,,
234,0.04650758295996573,0.8632479310035706,0.8504273891448975,0.6409344059405941,0.16771709460478568,mmlu:marketing,test,41.49112240411341,mistral_7b,choice,choice,,,,
11,0.1311386904933236,1.0,1.0,,0.19026018272746695,mmlu:medical_genetics,validation,2.9402000587433577,mistral_7b,choice,choice,,,,
100,0.12973693013191223,0.7299999594688416,0.75,0.6481481481481481,0.08075582802295683,mmlu:medical_genetics,test,17.20483059808612,mistral_7b,choice,choice,,,,
38,0.18127680922809403,0.6315789222717285,0.6315789222717285,0.7366071428571429,0.13246995367501915,mmlu:moral_disputes,validation,7.603279395028949,mistral_7b,choice,choice,,,,
346,0.06783685002023773,0.7023121118545532,0.7023121118545532,0.5398537696272324,0.08296177152953395,mmlu:moral_disputes,test,65.27988085709512,mistral_7b,choice,choice,,,,
33,0.14350027387792413,0.7575757503509521,0.7878788113594055,0.7925,0.09150994546485669,mmlu:nutrition,validation,8.575847072526813,mistral_7b,choice,choice,,,,
306,0.09732476168987797,0.7450980544090271,0.7254902124404907,0.5869883040935673,0.04452595776981774,mmlu:nutrition,test,63.83650076575577,mistral_7b,choice,choice,,,,
34,0.1901066610041787,0.7352941036224365,0.7058823704719543,0.5311111111111111,0.10512023287660938,mmlu:philosophy,validation,8.988378496840596,mistral_7b,choice,choice,,,,
311,0.04866222610810946,0.7266880869865417,0.7234726548194885,0.5803227485684539,0.0492442698724017,mmlu:philosophy,test,52.98722603172064,mistral_7b,choice,choice,,,,
35,0.1596931661878313,0.5714285969734192,0.5714285969734192,0.5833333333333334,0.23782982655933926,mmlu:prehistory,validation,10.936006622388959,mistral_7b,choice,choice,,,,
324,0.031491318878568264,0.7407407760620117,0.7160493731498718,0.5706597222222223,0.056360313001974124,mmlu:prehistory,test,64.63484145887196,mistral_7b,choice,choice,,,,
69,0.07041500875915305,0.7101449370384216,0.7101449370384216,0.6326530612244898,0.061761108861453265,mmlu:professional_psychology,validation,15.259311582893133,mistral_7b,choice,choice,,,,
612,0.04561248324275796,0.6813725829124451,0.6813725829124451,0.5827891532927505,0.05648317514291773,mmlu:professional_psychology,test,105.03494582511485,mistral_7b,choice,choice,,,,
12,0.23054789006710052,0.5,0.5,0.36111111111111116,0.33846113085746765,mmlu:public_relations,validation,1.8115191739052534,mistral_7b,choice,choice,,,,
110,0.10268353657288982,0.663636326789856,0.6909090876579285,0.636986301369863,0.12546276504343204,mmlu:public_relations,test,14.138716652989388,mistral_7b,choice,choice,,,,
27,0.16775211581477412,0.7037037014961243,0.7037037014961243,0.5592105263157894,0.0684138536453247,mmlu:security_studies,validation,10.622693028301,mistral_7b,choice,choice,,,,
245,0.08090466029789982,0.7510203719139099,0.7387754917144775,0.6662954383464006,0.07566914461096941,mmlu:security_studies,test,97.30103533528745,mistral_7b,choice,choice,,,,
22,0.11629392071203752,0.8636363744735718,0.8636363744735718,0.4035087719298246,0.12854591824791645,mmlu:sociology,validation,2.998282764106989,mistral_7b,choice,choice,,,,
201,0.03207025984626502,0.8407959938049316,0.8358208537101746,0.5625,0.08051479959962383,mmlu:sociology,test,26.124248256906867,mistral_7b,choice,choice,,,,
11,0.1911940574645996,0.9090909361839294,0.9090909361839294,0.9,0.1970632401379672,mmlu:us_foreign_policy,validation,1.5881801005452871,mistral_7b,choice,choice,,,,
100,0.0888331925868988,0.8799999952316284,0.8499999642372131,0.6756628787878788,0.10755899012088777,mmlu:us_foreign_policy,test,12.682527573779225,mistral_7b,choice,choice,,,,
18,0.23083103365368313,0.6666666865348816,0.6111111044883728,0.638888888888889,0.12232045663727656,mmlu:virology,validation,2.533806962892413,mistral_7b,choice,choice,,,,
166,0.2130287745630885,0.5361445546150208,0.6024096012115479,0.6044797898730484,0.06456373470375333,mmlu:virology,test,18.65656554326415,mistral_7b,choice,choice,,,,
19,0.20412473772701462,0.8947368264198303,0.8421052694320679,0.8088235294117647,0.20481295648374054,mmlu:world_religions,validation,1.8385255206376314,mistral_7b,choice,choice,,,,
171,0.04494706475943848,0.8187134265899658,0.7719298601150513,0.599078341013825,0.11374991469913054,mmlu:world_religions,test,15.07921020500362,mistral_7b,choice,choice,,,,
14,,,,,,mmlu:anatomy,validation,11.237543472088873,llama2_7b_chat,oe,oe,0.2142857313156128,0.5,0.3636363636363636,0.32821279338427956
135,,,,,,mmlu:anatomy,test,56.95930426660925,llama2_7b_chat,oe,oe,0.3629629611968994,0.614814817905426,0.4315377313716184,0.19560847812228735
16,,,,,,mmlu:astronomy,validation,11.734121575020254,llama2_7b_chat,oe,oe,0.375,0.625,0.6,0.06633331626653673
152,,,,,,mmlu:astronomy,test,94.3704740870744,llama2_7b_chat,oe,oe,0.46052631735801697,0.5592105388641357,0.5126306620209059,0.11195094216811026
11,,,,,,mmlu:business_ethics,validation,6.210825441405177,llama2_7b_chat,oe,oe,0.4545454680919647,0.3636363744735718,0.49999999999999994,0.39868666367097333
100,,,,,,mmlu:business_ethics,test,52.425518192350864,llama2_7b_chat,oe,oe,0.26999998092651367,0.38999998569488525,0.6187214611872146,0.3311896270513535
29,,,,,,mmlu:clinical_knowledge,validation,14.773383183404803,llama2_7b_chat,oe,oe,0.20689654350280762,0.7931034564971924,0.2826086956521739,0.1574174843985459
265,,,,,,mmlu:clinical_knowledge,test,131.15651181340218,llama2_7b_chat,oe,oe,0.2792452871799469,0.6830188632011414,0.4169732559784916,0.11337394646878511
16,,,,,,mmlu:college_biology,validation,7.820461946539581,llama2_7b_chat,oe,oe,0.4375,0.8125,0.031746031746031744,0.08592739328742027
144,,,,,,mmlu:college_biology,test,68.9825572418049,llama2_7b_chat,oe,oe,0.3402777910232544,0.625,0.5055853920515574,0.11327426135540011
8,,,,,,mmlu:college_chemistry,validation,3.584254065528512,llama2_7b_chat,oe,oe,0.0,0.875,,0.2347179874777794
100,,,,,,mmlu:college_chemistry,test,50.28726133145392,llama2_7b_chat,oe,oe,0.10999999940395355,0.8199999928474426,0.2972420837589377,0.0936319571733475
11,,,,,,mmlu:college_computer_science,validation,7.076484886929393,llama2_7b_chat,oe,oe,0.3636363744735718,0.8181818723678589,0.6428571428571428,0.32679866118864576
100,,,,,,mmlu:college_computer_science,test,60.09079628251493,llama2_7b_chat,oe,oe,0.17999999225139618,0.699999988079071,0.34044715447154467,0.13957825779914856
11,,,,,,mmlu:college_mathematics,validation,6.622994020581245,llama2_7b_chat,oe,oe,0.0,1.0,,0.13936592232097278
100,,,,,,mmlu:college_mathematics,test,44.9029578268528,llama2_7b_chat,oe,oe,0.23999999463558197,0.75,0.4106359649122807,0.13769794702529903
22,,,,,,mmlu:college_medicine,validation,12.271146067418158,llama2_7b_chat,oe,oe,0.3181818127632141,0.6363636255264282,0.4095238095238095,0.19224813851443207
173,,,,,,mmlu:college_medicine,test,89.66782483831048,llama2_7b_chat,oe,oe,0.323699414730072,0.6820809245109558,0.4152167277167277,0.1209329583741337
11,,,,,,mmlu:college_physics,validation,6.439096259884536,llama2_7b_chat,oe,oe,0.09090909361839294,0.8181818723678589,0.30000000000000004,0.09043034098365091
102,,,,,,mmlu:college_physics,test,50.36318745277822,llama2_7b_chat,oe,oe,0.0882352963089943,0.8529412150382996,0.36798088410991636,0.09513293528089334
11,,,,,,mmlu:computer_security,validation,7.5414897901937366,llama2_7b_chat,oe,oe,0.5454545617103577,0.7272727489471436,0.8,0.17485579577359286
100,,,,,,mmlu:computer_security,test,60.56554326508194,llama2_7b_chat,oe,oe,0.5199999809265137,0.5,0.5783253205128205,0.21210724174976348
26,,,,,,mmlu:conceptual_physics,validation,22.268875368870795,llama2_7b_chat,oe,oe,0.3076923191547394,0.6153846383094788,0.638888888888889,0.13168038542454055
235,,,,,,mmlu:conceptual_physics,test,177.04156180098653,llama2_7b_chat,oe,oe,0.3787233829498291,0.6680850982666016,0.36209019547483456,0.0883844160019083
12,,,,,,mmlu:econometrics,validation,8.6081014405936,llama2_7b_chat,oe,oe,0.25,0.4166666865348816,0.7407407407407407,0.25752218564351403
114,,,,,,mmlu:econometrics,test,85.40038628038019,llama2_7b_chat,oe,oe,0.14035087823867798,0.5350877046585083,0.5025510204081632,0.18537332352839017
16,,,,,,mmlu:electrical_engineering,validation,6.253157310187817,llama2_7b_chat,oe,oe,0.1875,0.6875,0.3333333333333333,0.1514059454202652
145,,,,,,mmlu:electrical_engineering,test,69.86374331824481,llama2_7b_chat,oe,oe,0.22758620977401733,0.7103448510169983,0.45806277056277056,0.08946191976810322
41,,,,,,mmlu:elementary_mathematics,validation,15.930626411922276,llama2_7b_chat,oe,oe,0.39024388790130615,0.5609756112098694,0.32749999999999996,0.23257025858251063
378,,,,,,mmlu:elementary_mathematics,test,207.20734141487628,llama2_7b_chat,oe,oe,0.29629629850387573,0.6825396418571472,0.37226436627282494,0.10391012259892055
14,,,,,,mmlu:formal_logic,validation,9.857804765924811,llama2_7b_chat,oe,oe,0.4285714626312256,0.5,0.44791666666666663,0.283417067357472
126,,,,,,mmlu:formal_logic,test,84.10617134999484,llama2_7b_chat,oe,oe,0.222222238779068,0.785714328289032,0.3075801749271137,0.0703046511089991
10,,,,,,mmlu:global_facts,validation,6.076766397804022,llama2_7b_chat,oe,oe,0.4000000059604645,0.6000000238418579,0.6666666666666666,0.28593800663948066
100,,,,,,mmlu:global_facts,test,65.32548607792705,llama2_7b_chat,oe,oe,0.11999999731779099,0.7400000095367432,0.5478219696969697,0.04978570282459261
32,,,,,,mmlu:high_school_biology,validation,17.94094857852906,llama2_7b_chat,oe,oe,0.25,0.59375,0.27083333333333337,0.20964678935706615
310,,,,,,mmlu:high_school_biology,test,185.25730560161173,llama2_7b_chat,oe,oe,0.43225806951522827,0.5258064270019531,0.415641960651289,0.18950478453789987
22,,,,,,mmlu:high_school_chemistry,validation,12.537293049506843,llama2_7b_chat,oe,oe,0.04545454680919647,0.7727273106575012,0.6666666666666667,0.11582679098302667
203,,,,,,mmlu:high_school_chemistry,test,109.83610398508608,llama2_7b_chat,oe,oe,0.1625615805387497,0.7093595862388611,0.39491978609625666,0.04167554208210538
9,,,,,,mmlu:high_school_computer_science,validation,7.760875876992941,llama2_7b_chat,oe,oe,0.4444444477558136,0.5555555820465088,0.44999999999999996,0.31067235602272886
100,,,,,,mmlu:high_school_computer_science,test,84.46110304631293,llama2_7b_chat,oe,oe,0.3799999952316284,0.5899999737739563,0.4076825127334465,0.16062425374984743
22,,,,,,mmlu:high_school_geography,validation,13.70685120485723,llama2_7b_chat,oe,oe,0.4545454680919647,0.5454545617103577,0.5916666666666666,0.18214264512062073
198,,,,,,mmlu:high_school_geography,test,125.07749850675464,llama2_7b_chat,oe,oe,0.39393940567970276,0.5909090638160706,0.42313034188034193,0.11152726441922814
21,,,,,,mmlu:high_school_government_and_politics,validation,18.03367051575333,llama2_7b_chat,oe,oe,0.5714285969734192,0.523809552192688,0.3703703703703704,0.2518620263962519
193,,,,,,mmlu:high_school_government_and_politics,test,149.54483184870332,llama2_7b_chat,oe,oe,0.5284973978996277,0.5958548784255981,0.4114414996767938,0.12896713506372479
43,,,,,,mmlu:high_school_macroeconomics,validation,32.38020329270512,llama2_7b_chat,oe,oe,0.39534884691238403,0.604651153087616,0.5124434389140271,0.15312522233918657
390,,,,,,mmlu:high_school_macroeconomics,test,286.6038797767833,llama2_7b_chat,oe,oe,0.27435898780822754,0.692307710647583,0.3861662428585582,0.04587060503470594
29,,,,,,mmlu:high_school_mathematics,validation,9.540380595251918,llama2_7b_chat,oe,oe,0.0,0.8620689511299133,,0.1826577741524269
270,,,,,,mmlu:high_school_mathematics,test,92.77926107216626,llama2_7b_chat,oe,oe,0.0555555559694767,0.8888888955116272,0.5722875816993463,0.09797224579034026
26,,,,,,mmlu:high_school_microeconomics,validation,14.91179218608886,llama2_7b_chat,oe,oe,0.26923078298568726,0.6153846383094788,0.3308270676691729,0.1571124792098999
238,,,,,,mmlu:high_school_microeconomics,test,138.7910678545013,llama2_7b_chat,oe,oe,0.3403361439704895,0.6554622054100037,0.4551387905952662,0.05113685757172208
17,,,,,,mmlu:high_school_physics,validation,9.743773703463376,llama2_7b_chat,oe,oe,0.05882352963089943,0.7647058963775635,0.8125,0.13646546532126033
151,,,,,,mmlu:high_school_physics,test,82.5627620825544,llama2_7b_chat,oe,oe,0.17218543589115143,0.7814569473266602,0.384,0.10492416328152282
60,,,,,,mmlu:high_school_psychology,validation,31.329450765624642,llama2_7b_chat,oe,oe,0.4833333492279053,0.5666667222976685,0.41268075639599555,0.18533890346686044
545,,,,,,mmlu:high_school_psychology,test,322.39091499056667,llama2_7b_chat,oe,oe,0.49724769592285156,0.4935779869556427,0.44797586661998007,0.20983898825601704
23,,,,,,mmlu:high_school_statistics,validation,12.125610152259469,llama2_7b_chat,oe,oe,0.21739131212234497,0.739130437374115,0.18888888888888888,0.19306388367777286
216,,,,,,mmlu:high_school_statistics,test,144.6674083666876,llama2_7b_chat,oe,oe,0.21296297013759613,0.7731481790542603,0.3255754475703325,0.03917600876755181
22,,,,,,mmlu:high_school_us_history,validation,33.73522570449859,llama2_7b_chat,oe,oe,0.7272727489471436,0.5909091234207153,0.3541666666666667,0.11352731152014299
204,,,,,,mmlu:high_school_us_history,test,296.06505859456956,llama2_7b_chat,oe,oe,0.6176470518112183,0.5539215803146362,0.36996336996337,0.08820373053644219
23,,,,,,mmlu:human_aging,validation,12.245334039442241,llama2_7b_chat,oe,oe,0.30434784293174744,0.5652173757553101,0.4910714285714286,0.18974138861117157
223,,,,,,mmlu:human_aging,test,145.28434578049928,llama2_7b_chat,oe,oe,0.354260116815567,0.6322870254516602,0.5565664556962026,0.1061615569709128
12,,,,,,mmlu:human_sexuality,validation,9.188954031094909,llama2_7b_chat,oe,oe,0.3333333432674408,0.5833333730697632,0.625,0.3205708662668864
131,,,,,,mmlu:human_sexuality,test,91.60765136033297,llama2_7b_chat,oe,oe,0.4198473393917084,0.5114504098892212,0.4392344497607656,0.19416668624368333
13,,,,,,mmlu:international_law,validation,7.455705584958196,llama2_7b_chat,oe,oe,0.46153849363327026,0.46153849363327026,0.47619047619047616,0.24734270572662356
121,,,,,,mmlu:international_law,test,71.74990080483258,llama2_7b_chat,oe,oe,0.5950412750244141,0.586776852607727,0.5976473922902494,0.15003123657762513
11,,,,,,mmlu:jurisprudence,validation,9.623560244217515,llama2_7b_chat,oe,oe,0.4545454680919647,0.5454545617103577,0.5,0.17202622782100332
108,,,,,,mmlu:jurisprudence,test,72.45523746311665,llama2_7b_chat,oe,oe,0.5092592835426331,0.5277777910232544,0.4595197255574614,0.15982216541413904
18,,,,,,mmlu:logical_fallacies,validation,12.05109733901918,llama2_7b_chat,oe,oe,0.4444444477558136,0.6111111044883728,0.5875,0.1375311513741811
163,,,,,,mmlu:logical_fallacies,test,94.63736684340984,llama2_7b_chat,oe,oe,0.42331287264823914,0.5950919985771179,0.45189639222941713,0.14332199864592293
11,,,,,,mmlu:machine_learning,validation,9.577565046027303,llama2_7b_chat,oe,oe,0.5454545617103577,0.4545454680919647,0.2333333333333333,0.31328273903239856
112,,,,,,mmlu:machine_learning,test,65.19572022370994,llama2_7b_chat,oe,oe,0.2232142984867096,0.7321428656578064,0.4583908045977011,0.054703102580138635
11,,,,,,mmlu:management,validation,9.094095714390278,llama2_7b_chat,oe,oe,0.3636363744735718,0.4545454680919647,0.5357142857142857,0.29938398166136304
103,,,,,,mmlu:management,test,70.36606712639332,llama2_7b_chat,oe,oe,0.40776699781417847,0.49514564871788025,0.5152224824355971,0.19175489724261088
25,,,,,,mmlu:marketing,validation,17.92675507068634,llama2_7b_chat,oe,oe,0.19999998807907104,0.4399999976158142,0.62,0.21321965456008918
234,,,,,,mmlu:marketing,test,142.48004163522273,llama2_7b_chat,oe,oe,0.39316239953041077,0.5299145579338074,0.5030618493570116,0.11288536308158156
11,,,,,,mmlu:medical_genetics,validation,9.19711047410965,llama2_7b_chat,oe,oe,0.8181818723678589,0.4545454680919647,0.2777777777777778,0.32457888668233703
100,,,,,,mmlu:medical_genetics,test,75.08659688942134,llama2_7b_chat,oe,oe,0.3799999952316284,0.6599999666213989,0.4446095076400679,0.1560178476572037
38,,,,,,mmlu:moral_disputes,validation,25.816275847144425,llama2_7b_chat,oe,oe,0.3947368562221527,0.6315789222717285,0.31884057971014496,0.15552970610166855
346,,,,,,mmlu:moral_disputes,test,242.7482702350244,llama2_7b_chat,oe,oe,0.4161849617958069,0.6069363951683044,0.46512307480748066,0.08310932144953337
33,,,,,,mmlu:nutrition,validation,18.751133690588176,llama2_7b_chat,oe,oe,0.3030303120613098,0.5454545617103577,0.5739130434782609,0.17061188365473892
306,,,,,,mmlu:nutrition,test,190.46321008633822,llama2_7b_chat,oe,oe,0.41830065846443176,0.5915032625198364,0.48163184691011235,0.10814456982550281
34,,,,,,mmlu:philosophy,validation,22.92312696762383,llama2_7b_chat,oe,oe,0.3235294222831726,0.6470588445663452,0.4624505928853755,0.07813091488445505
311,,,,,,mmlu:philosophy,test,220.3264987654984,llama2_7b_chat,oe,oe,0.35691317915916443,0.6270096302032471,0.4619819819819819,0.05567596656333214
35,,,,,,mmlu:prehistory,validation,29.336429237388074,llama2_7b_chat,oe,oe,0.3142857253551483,0.6571428775787354,0.3522727272727273,0.1505171009472438
324,,,,,,mmlu:prehistory,test,252.4727497510612,llama2_7b_chat,oe,oe,0.35185185074806213,0.645061731338501,0.40676691729323305,0.13432169144536243
69,,,,,,mmlu:professional_psychology,validation,46.966557836160064,llama2_7b_chat,oe,oe,0.3333333432674408,0.7101449370384216,0.3799621928166351,0.1286698450212893
612,,,,,,mmlu:professional_psychology,test,394.01192815601826,llama2_7b_chat,oe,oe,0.30882352590560913,0.6470588445663452,0.43854053310318086,0.0921975228131986
12,,,,,,mmlu:public_relations,validation,7.372162224724889,llama2_7b_chat,oe,oe,0.3333333432674408,0.75,0.15625,0.41985374192396796
110,,,,,,mmlu:public_relations,test,43.44728759583086,llama2_7b_chat,oe,oe,0.3545454442501068,0.6090908646583557,0.44582881906825567,0.0733996716412631
27,,,,,,mmlu:security_studies,validation,18.983580925501883,llama2_7b_chat,oe,oe,0.6666666865348816,0.7037037014961243,0.48456790123456794,0.10250026870656898
245,,,,,,mmlu:security_studies,test,179.90874060988426,llama2_7b_chat,oe,oe,0.6489795446395874,0.6653060913085938,0.577592511335381,0.08313011879823645
22,,,,,,mmlu:sociology,validation,15.769816307350993,llama2_7b_chat,oe,oe,0.4545454680919647,0.5,0.5166666666666666,0.25291529568758875
201,,,,,,mmlu:sociology,test,148.84146983362734,llama2_7b_chat,oe,oe,0.46268656849861145,0.6119402647018433,0.43523496614894464,0.09489893142263689
11,,,,,,mmlu:us_foreign_policy,validation,6.915163807570934,llama2_7b_chat,oe,oe,0.6363636255264282,0.5454545617103577,0.7857142857142857,0.2096615758809176
100,,,,,,mmlu:us_foreign_policy,test,47.03764530364424,llama2_7b_chat,oe,oe,0.5600000023841858,0.47999998927116394,0.4855925324675324,0.16999868273735047
18,,,,,,mmlu:virology,validation,12.392192365601659,llama2_7b_chat,oe,oe,0.2777777910232544,0.6111111044883728,0.9384615384615385,0.26052125957277084
166,,,,,,mmlu:virology,test,121.4540971154347,llama2_7b_chat,oe,oe,0.3072288930416107,0.6626505851745605,0.4548167092924126,0.11147097183997373
19,,,,,,mmlu:world_religions,validation,7.653990489430726,llama2_7b_chat,oe,oe,0.5789473652839661,0.5789473652839661,0.6079545454545454,0.13314565545634224
171,,,,,,mmlu:world_religions,test,78.14846510719508,llama2_7b_chat,oe,oe,0.5146198868751526,0.5497075915336609,0.4991100766703176,0.12372837952005937
14,0.14716745274407525,0.4285714626312256,0.5714285969734192,0.5833333333333334,0.04717580335480823,mmlu:anatomy,validation,5.771870259195566,llama2_13b,choice,choice,,,,
135,0.09001349961316145,0.5111110806465149,0.6592592597007751,0.6478919631093544,0.07559558373910409,mmlu:anatomy,test,27.27532299607992,llama2_13b,choice,choice,,,,
16,0.2289632372558117,0.5625,0.625,0.6349206349206349,0.06169139593839644,mmlu:astronomy,validation,5.17000843398273,llama2_13b,choice,choice,,,,
152,0.1163935759349873,0.5131579041481018,0.5855263471603394,0.636001386001386,0.04258641718249575,mmlu:astronomy,test,46.827557649463415,llama2_13b,choice,choice,,,,
11,0.25074630975723267,0.3636363744735718,0.4545454680919647,0.75,0.3064108274199746,mmlu:business_ethics,validation,3.487208493053913,llama2_13b,choice,choice,,,,
100,0.08249628603458406,0.5299999713897705,0.5799999833106995,0.802488960256925,0.10730085372924807,mmlu:business_ethics,test,30.77938791550696,llama2_13b,choice,choice,,,,
29,0.13683780308427484,0.5862069129943848,0.517241358757019,0.5686274509803921,0.07751650234748579,mmlu:clinical_knowledge,validation,6.87673631682992,llama2_13b,choice,choice,,,,
265,0.03372989926698072,0.5886792540550232,0.6603773832321167,0.6329393083980239,0.06331373543109532,mmlu:clinical_knowledge,test,60.39995932392776,llama2_13b,choice,choice,,,,
16,0.1720481961965561,0.5625,0.5,0.746031746031746,0.12645522132515907,mmlu:college_biology,validation,4.203857701271772,llama2_13b,choice,choice,,,,
144,0.06489325004319352,0.5486111044883728,0.6041666865348816,0.6120740019474197,0.07193044573068616,mmlu:college_biology,test,38.3309107106179,llama2_13b,choice,choice,,,,
8,0.40915826708078384,0.625,0.5,0.8,0.4199231117963791,mmlu:college_chemistry,validation,2.5828898157924414,llama2_13b,choice,choice,,,,
100,0.12028073847293855,0.44999998807907104,0.5600000023841858,0.4329292929292929,0.06187456369400025,mmlu:college_chemistry,test,29.105753960087895,llama2_13b,choice,choice,,,,
11,0.23285808075558057,0.6363636255264282,0.3636363744735718,0.6785714285714286,0.2652019262313843,mmlu:college_computer_science,validation,4.664934882894158,llama2_13b,choice,choice,,,,
100,0.1002258676290512,0.4399999976158142,0.5600000023841858,0.5775162337662337,0.08001546025276182,mmlu:college_computer_science,test,42.98813243024051,llama2_13b,choice,choice,,,,
11,0.12380083853548224,0.1818181872367859,0.8181818723678589,0.36111111111111116,0.1463477882471952,mmlu:college_mathematics,validation,3.4405607264488935,llama2_13b,choice,choice,,,,
100,0.06589578837156294,0.29999998211860657,0.6899999976158142,0.5919047619047619,0.08787720263004306,mmlu:college_mathematics,test,29.623709743842483,llama2_13b,choice,choice,,,,
22,0.12571292438290338,0.5454545617103577,0.5,0.5708333333333333,0.15138406645167957,mmlu:college_medicine,validation,6.341721216216683,llama2_13b,choice,choice,,,,
173,0.058592356009290414,0.5549132823944092,0.6184970736503601,0.5831304112554112,0.06714233876652798,mmlu:college_medicine,test,57.4862193595618,llama2_13b,choice,choice,,,,
11,0.1288730718872764,0.5454545617103577,0.5454545617103577,0.6666666666666666,0.15476064790378916,mmlu:college_physics,validation,3.0075064431875944,llama2_13b,choice,choice,,,,
102,0.15867351404592106,0.2549019753932953,0.6764706373214722,0.5771761133603239,0.08726119878245335,mmlu:college_physics,test,26.240998348221183,llama2_13b,choice,choice,,,,
11,0.3201443932273171,0.8181818723678589,0.8181818723678589,0.6666666666666667,0.16600959409366955,mmlu:computer_security,validation,2.866928009316325,llama2_13b,choice,choice,,,,
100,0.07781153231859207,0.7099999785423279,0.7199999690055847,0.7294803302574064,0.038757953047752376,mmlu:computer_security,test,22.00610477104783,llama2_13b,choice,choice,,,,
26,0.15561166520302114,0.42307692766189575,0.5384615659713745,0.7303030303030302,0.13542358004129848,mmlu:conceptual_physics,validation,4.4954584408551455,llama2_13b,choice,choice,,,,
235,0.12013903146094464,0.3914893567562103,0.4765957295894623,0.5889708117968988,0.12888129898842346,mmlu:conceptual_physics,test,39.162537556141615,llama2_13b,choice,choice,,,,
12,0.17015917847553888,0.25,0.5833333730697632,0.33333333333333337,0.44436713059743244,mmlu:econometrics,validation,3.8942864425480366,llama2_13b,choice,choice,,,,
114,0.1632876720344811,0.24561403691768646,0.4736842215061188,0.5664451827242525,0.0966800080056776,mmlu:econometrics,test,36.34450303763151,llama2_13b,choice,choice,,,,
16,0.13311614841222763,0.375,0.75,0.7166666666666667,0.16033805534243584,mmlu:electrical_engineering,validation,3.887280683964491,llama2_13b,choice,choice,,,,
145,0.0973424523041166,0.4413793087005615,0.6413792967796326,0.42563657407407407,0.05491033710282427,mmlu:electrical_engineering,test,33.218321695923805,llama2_13b,choice,choice,,,,
41,0.09600169629585452,0.4146341383457184,0.5121951103210449,0.5367647058823529,0.0872542538293978,mmlu:elementary_mathematics,validation,12.006595754995942,llama2_13b,choice,choice,,,,
378,0.06784735217926996,0.31216931343078613,0.6190475821495056,0.5823989569752281,0.08490629391695456,mmlu:elementary_mathematics,test,106.90920747071505,llama2_13b,choice,choice,,,,
14,0.12916469999722072,0.2857142984867096,0.5714285969734192,0.6749999999999999,0.02214571407863072,mmlu:formal_logic,validation,4.535816717892885,llama2_13b,choice,choice,,,,
126,0.02843788242529311,0.3492063581943512,0.626984179019928,0.5735864745011086,0.04797968410310294,mmlu:formal_logic,test,40.537142124027014,llama2_13b,choice,choice,,,,
10,0.14060280919075013,0.5,0.6000000238418579,0.52,0.17501114010810853,mmlu:global_facts,validation,2.4877553079277277,llama2_13b,choice,choice,,,,
100,0.08612264096736909,0.3499999940395355,0.6899999976158142,0.38439560439560433,0.06213721513748169,mmlu:global_facts,test,23.00922866165638,llama2_13b,choice,choice,,,,
32,0.1209655273705721,0.53125,0.5,0.6392156862745098,0.2022896558046341,mmlu:high_school_biology,validation,9.116522438824177,llama2_13b,choice,choice,,,,
310,0.060094018520847454,0.6645160913467407,0.6580644845962524,0.6882468259895445,0.06987176652877564,mmlu:high_school_biology,test,87.52327483333647,llama2_13b,choice,choice,,,,
22,0.10005006465044892,0.3636363744735718,0.5454545617103577,0.6830357142857143,0.16883863373236224,mmlu:high_school_chemistry,validation,6.326627846807241,llama2_13b,choice,choice,,,,
203,0.05729783227291012,0.4729064106941223,0.5763546824455261,0.48481308411214963,0.024965690861781832,mmlu:high_school_chemistry,test,54.87086040712893,llama2_13b,choice,choice,,,,
9,0.17603182130389744,0.6666666865348816,0.6666666865348816,0.7222222222222223,0.21994173526763916,mmlu:high_school_computer_science,validation,4.460318140685558,llama2_13b,choice,choice,,,,
100,0.09345588743686677,0.5399999618530273,0.6899999976158142,0.7731481481481481,0.08069295406341556,mmlu:high_school_computer_science,test,48.77371855452657,llama2_13b,choice,choice,,,,
22,0.14594153247096323,0.7272727489471436,0.6818181872367859,0.734375,0.07560964335094801,mmlu:high_school_geography,validation,4.739987753331661,llama2_13b,choice,choice,,,,
198,0.06559802004785248,0.7222222089767456,0.6818181872367859,0.5079465988556897,0.07417922911017828,mmlu:high_school_geography,test,42.226996306329966,llama2_13b,choice,choice,,,,
21,0.1844906466347831,0.7142857313156128,0.7142857313156128,0.7055555555555555,0.13340742531276883,mmlu:high_school_government_and_politics,validation,5.239080751314759,llama2_13b,choice,choice,,,,
193,0.04912939513285542,0.8238341808319092,0.8134714961051941,0.6740658527561968,0.15828522653777366,mmlu:high_school_government_and_politics,test,47.5801553055644,llama2_13b,choice,choice,,,,
43,0.16379689199979913,0.5116279125213623,0.5116279125213623,0.7683982683982685,0.18551701307296756,mmlu:high_school_macroeconomics,validation,9.438034567981958,llama2_13b,choice,choice,,,,
390,0.07977168086247566,0.5333333611488342,0.5461538434028625,0.6294907016060862,0.13054886338038318,mmlu:high_school_macroeconomics,test,85.10681057721376,llama2_13b,choice,choice,,,,
29,0.11061135551025127,0.24137930572032928,0.7241379022598267,0.42857142857142855,0.030807106659330206,mmlu:high_school_mathematics,validation,8.149959959089756,llama2_13b,choice,choice,,,,
270,0.09013029590800958,0.23333333432674408,0.7111110687255859,0.48723257418909593,0.04244843103267526,mmlu:high_school_mathematics,test,73.1078862119466,llama2_13b,choice,choice,,,,
26,0.23534159706189087,0.692307710647583,0.6538462042808533,0.5,0.17651944435559785,mmlu:high_school_microeconomics,validation,5.863764643669128,llama2_13b,choice,choice,,,,
238,0.070158546086119,0.5756303071975708,0.542016863822937,0.567608585676086,0.09524548880192413,mmlu:high_school_microeconomics,test,52.247968507930636,llama2_13b,choice,choice,,,,
17,0.214115626671735,0.23529411852359772,0.5882353186607361,0.4423076923076923,0.1738830103593714,mmlu:high_school_physics,validation,5.167102301493287,llama2_13b,choice,choice,,,,
151,0.032332958172488685,0.3907284736633301,0.5960264801979065,0.5400700073691967,0.11882725614585625,mmlu:high_school_physics,test,44.33199250511825,llama2_13b,choice,choice,,,,
60,0.11067090133825937,0.8000000715255737,0.8166667222976685,0.8124999999999999,0.15230205257733662,mmlu:high_school_psychology,validation,16.704003458842635,llama2_13b,choice,choice,,,,
545,0.05436075614133011,0.7614678740501404,0.7651376128196716,0.6811399443929563,0.10574796188861953,mmlu:high_school_psychology,test,150.88572043552995,llama2_13b,choice,choice,,,,
23,0.1703792395799056,0.43478262424468994,0.43478262424468994,0.7769230769230769,0.2115651783735856,mmlu:high_school_statistics,validation,9.556927893310785,llama2_13b,choice,choice,,,,
216,0.04346492265661556,0.4490740895271301,0.4583333432674408,0.5349995668370441,0.13934088305190756,mmlu:high_school_statistics,test,93.10766254551709,llama2_13b,choice,choice,,,,
22,0.17520021985877646,0.7727273106575012,0.7727273106575012,0.5647058823529412,0.1191307793964039,mmlu:high_school_us_history,validation,34.5944495908916,llama2_13b,choice,choice,,,,
204,0.09055403050254372,0.7598039507865906,0.7598039507865906,0.6550362080315998,0.11612117495022564,mmlu:high_school_us_history,test,313.05046171694994,llama2_13b,choice,choice,,,,
23,0.29493607386298804,0.5652173757553101,0.6086956858634949,0.7538461538461538,0.06311381899792214,mmlu:human_aging,validation,4.190263815224171,llama2_13b,choice,choice,,,,
223,0.07797254281193688,0.5964125990867615,0.6233184337615967,0.7443191311612364,0.09329999749435972,mmlu:human_aging,test,38.86368442699313,llama2_13b,choice,choice,,,,
12,0.15332866211732227,0.5,0.5833333730697632,0.4722222222222222,0.1597592532634735,mmlu:human_sexuality,validation,2.4465537257492542,llama2_13b,choice,choice,,,,
131,0.09053917058551583,0.6106870174407959,0.7175572514533997,0.6705882352941176,0.08471606296437384,mmlu:human_sexuality,test,26.610182577744126,llama2_13b,choice,choice,,,,
13,0.18429349935971776,0.7692307829856873,0.7692307829856873,0.9666666666666668,0.22991162080031177,mmlu:international_law,validation,4.724399963393807,llama2_13b,choice,choice,,,,
121,0.0732406697982599,0.719008207321167,0.7355371713638306,0.7503380662609871,0.0831782803062565,mmlu:international_law,test,39.8285461794585,llama2_13b,choice,choice,,,,
11,0.22142491828311575,0.4545454680919647,0.4545454680919647,1.0,0.33980202674865717,mmlu:jurisprudence,validation,2.5484057292342186,llama2_13b,choice,choice,,,,
108,0.10479138874345355,0.7037037014961243,0.75,0.7117598684210525,0.12256977403605426,mmlu:jurisprudence,test,23.87943733856082,llama2_13b,choice,choice,,,,
18,0.2224999864896138,0.7777777910232544,0.7222222089767456,0.5714285714285714,0.13540524906582307,mmlu:logical_fallacies,validation,4.402441432699561,llama2_13b,choice,choice,,,,
163,0.06698918635128467,0.6380367875099182,0.7361962795257568,0.6082953063885268,0.12471585076279436,mmlu:logical_fallacies,test,38.71035126782954,llama2_13b,choice,choice,,,,
11,0.19108336080204355,0.4545454680919647,0.3636363744735718,0.6666666666666666,0.3538819605653936,mmlu:machine_learning,validation,3.687346164137125,llama2_13b,choice,choice,,,,
112,0.19081376971943037,0.2142857313156128,0.4285714626312256,0.6526988636363635,0.1879844468619143,mmlu:machine_learning,test,37.26725687272847,llama2_13b,choice,choice,,,,
11,0.23109854893250903,0.7272727489471436,0.9090909361839294,0.75,0.3130404840816151,mmlu:management,validation,1.9868266973644495,llama2_13b,choice,choice,,,,
103,0.10133581601300287,0.7766990661621094,0.7475728392601013,0.5817934782608696,0.1234796319193053,mmlu:management,test,16.78186441026628,llama2_13b,choice,choice,,,,
25,0.2459735798835755,0.8399999737739563,0.8399999737739563,0.6904761904761905,0.1388155198097229,mmlu:marketing,validation,5.903326196596026,llama2_13b,choice,choice,,,,
234,0.0601038861478496,0.7820513248443604,0.7777777910232544,0.7078109932497589,0.09158746452413054,mmlu:marketing,test,52.092541955411434,llama2_13b,choice,choice,,,,
11,0.17915785854512994,0.8181818723678589,0.9090909361839294,1.0,0.23356219313361426,mmlu:medical_genetics,validation,2.441466838121414,llama2_13b,choice,choice,,,,
100,0.1411105951666832,0.5799999833106995,0.6399999856948853,0.6832922824302133,0.07126536309719086,mmlu:medical_genetics,test,20.055859921500087,llama2_13b,choice,choice,,,,
38,0.18718513611115908,0.5263158082962036,0.5789473652839661,0.663888888888889,0.0855910981956281,mmlu:moral_disputes,validation,9.69021936878562,llama2_13b,choice,choice,,,,
346,0.055437243484348246,0.6098265647888184,0.6358381509780884,0.5985079866596454,0.048407291918131666,mmlu:moral_disputes,test,87.4577868245542,llama2_13b,choice,choice,,,,
33,0.1813181160074292,0.7575757503509521,0.7878788113594055,0.885,0.14899205258398343,mmlu:nutrition,validation,10.489177932962775,llama2_13b,choice,choice,,,,
306,0.07220801623428569,0.6241829991340637,0.6405228972434998,0.6721374914636922,0.025691327705881922,mmlu:nutrition,test,97.3520828075707,llama2_13b,choice,choice,,,,
34,0.20816840319072502,0.6470588445663452,0.6470588445663452,0.7196969696969697,0.07878993714556973,mmlu:philosophy,validation,6.665079241618514,llama2_13b,choice,choice,,,,
311,0.09089757631446005,0.6495176553726196,0.6655948162078857,0.6461985648106096,0.053354251614720856,mmlu:philosophy,test,57.71479261852801,llama2_13b,choice,choice,,,,
35,0.18569657632282802,0.6285714507102966,0.6000000238418579,0.673076923076923,0.12113654102597916,mmlu:prehistory,validation,10.430795194581151,llama2_13b,choice,choice,,,,
324,0.06019172900252873,0.6419752836227417,0.6759259104728699,0.6907327586206897,0.037480538458000014,mmlu:prehistory,test,93.07326193153858,llama2_13b,choice,choice,,,,
69,0.15859784207482272,0.5652173757553101,0.5652173757553101,0.7085470085470085,0.12546137882315594,mmlu:professional_psychology,validation,21.61121184565127,llama2_13b,choice,choice,,,,
612,0.0725067993199903,0.5555555820465088,0.5686274766921997,0.6671658737024222,0.10395246451976253,mmlu:professional_psychology,test,184.51635095104575,llama2_13b,choice,choice,,,,
12,0.49819476405779517,0.5833333730697632,0.5833333730697632,0.37142857142857144,0.351462776462237,mmlu:public_relations,validation,3.1405061036348343,llama2_13b,choice,choice,,,,
110,0.07987526167522778,0.6363636255264282,0.6363636255264282,0.79375,0.1442319783297452,mmlu:public_relations,test,25.510458743199706,llama2_13b,choice,choice,,,,
27,0.23700715546254758,0.5925925970077515,0.5925925970077515,0.5909090909090909,0.17417300188982926,mmlu:security_studies,validation,18.706184078007936,llama2_13b,choice,choice,,,,
245,0.047171321328805416,0.6326530575752258,0.6326530575752258,0.5753046594982079,0.11913227718703598,mmlu:security_studies,test,174.45209700614214,llama2_13b,choice,choice,,,,
22,0.160487486557527,0.8181818723678589,0.8181818723678589,0.8125,0.19257258827036075,mmlu:sociology,validation,5.360082965344191,llama2_13b,choice,choice,,,,
201,0.06170249207695916,0.7661691308021545,0.7910447716712952,0.6592981486598507,0.14147773014372264,mmlu:sociology,test,47.66604218818247,llama2_13b,choice,choice,,,,
11,0.13227141445333307,0.9090909361839294,0.9090909361839294,0.9,0.2205462401563471,mmlu:us_foreign_policy,validation,2.6985545083880424,llama2_13b,choice,choice,,,,
100,0.06834511309862137,0.8499999642372131,0.8499999642372131,0.5952941176470589,0.15116100609302519,mmlu:us_foreign_policy,test,22.84139282628894,llama2_13b,choice,choice,,,,
18,0.24425924155447218,0.5,0.6111111044883728,0.6296296296296297,0.15044105052948,mmlu:virology,validation,4.434607926756144,llama2_13b,choice,choice,,,,
166,0.17515957481171712,0.4457831084728241,0.48795178532600403,0.632270857814336,0.16597336961562373,mmlu:virology,test,33.010799307376146,llama2_13b,choice,choice,,,,
19,0.08429366820736936,0.7894737124443054,0.8421052694320679,0.6333333333333333,0.2420037012351187,mmlu:world_religions,validation,3.1391621828079224,llama2_13b,choice,choice,,,,
171,0.04342272372273675,0.7719298601150513,0.7602339386940002,0.6069347319347319,0.1489304122869034,mmlu:world_religions,test,26.704701896756887,llama2_13b,choice,choice,,,,
14,0.20662898250988554,0.5714285969734192,0.4285714626312256,0.47916666666666663,0.24957762445722312,mmlu:anatomy,validation,5.3378307446837425,llama2_13b_chat,choice,choice,,,,
135,0.19448365834024214,0.5111110806465149,0.5777777433395386,0.6052920509442249,0.14385256855576126,mmlu:anatomy,test,27.12192902341485,llama2_13b_chat,choice,choice,,,,
16,0.11424661241471767,0.625,0.75,0.5166666666666666,0.14552656933665276,mmlu:astronomy,validation,5.158888217061758,llama2_13b_chat,choice,choice,,,,
152,0.245416279097921,0.5657894611358643,0.5723684430122375,0.5525898520084567,0.10382301007446487,mmlu:astronomy,test,46.71482387557626,llama2_13b_chat,choice,choice,,,,
11,0.22440953959118237,0.5454545617103577,0.7272727489471436,0.7333333333333333,0.19926840608770197,mmlu:business_ethics,validation,3.461340054869652,llama2_13b_chat,choice,choice,,,,
100,0.24410267770290378,0.5299999713897705,0.6399999856948853,0.7310317141710156,0.1234950226545334,mmlu:business_ethics,test,30.622988387942314,llama2_13b_chat,choice,choice,,,,
29,0.3209612348984028,0.517241358757019,0.5517241358757019,0.5380952380952381,0.3350708875162848,mmlu:clinical_knowledge,validation,6.760913655161858,llama2_13b_chat,choice,choice,,,,
265,0.20924414148870502,0.5660377740859985,0.5849056839942932,0.6402898550724637,0.229740809044748,mmlu:clinical_knowledge,test,60.51991253718734,llama2_13b_chat,choice,choice,,,,
16,0.20605568774044514,0.5625,0.625,0.5714285714285714,0.282195046544075,mmlu:college_biology,validation,4.239350873976946,llama2_13b_chat,choice,choice,,,,
144,0.1936526567571693,0.5833333134651184,0.5902777910232544,0.557936507936508,0.12502663996484545,mmlu:college_biology,test,38.19021762162447,llama2_13b_chat,choice,choice,,,,
8,0.5105344615876675,0.125,0.375,0.8571428571428572,0.4007076695561409,mmlu:college_chemistry,validation,2.5600859001278877,llama2_13b_chat,choice,choice,,,,
100,0.2275681433081627,0.3700000047683716,0.47999998927116394,0.572930072930073,0.2718444365262985,mmlu:college_chemistry,test,29.134852070361376,llama2_13b_chat,choice,choice,,,,
11,0.15991395170038397,0.5454545617103577,0.4545454680919647,0.6,0.19875427267768167,mmlu:college_computer_science,validation,4.747863087803125,llama2_13b_chat,choice,choice,,,,
100,0.15642848163843157,0.5399999618530273,0.5,0.4472624798711755,0.15836596071720124,mmlu:college_computer_science,test,42.931144166737795,llama2_13b_chat,choice,choice,,,,
11,0.25650960748845886,0.27272728085517883,0.6363636255264282,0.41666666666666663,0.25392549146305426,mmlu:college_mathematics,validation,3.412310652434826,llama2_13b_chat,choice,choice,,,,
100,0.2351979598402977,0.3499999940395355,0.47999998927116394,0.56,0.1345799219608307,mmlu:college_mathematics,test,29.38781486451626,llama2_13b_chat,choice,choice,,,,
22,0.44382848387414764,0.3636363744735718,0.40909093618392944,0.6696428571428572,0.34289455413818365,mmlu:college_medicine,validation,6.417538654059172,llama2_13b_chat,choice,choice,,,,
173,0.2904427091165775,0.4624277353286743,0.5433526039123535,0.6513440860215054,0.17844306940288215,mmlu:college_medicine,test,57.37812551483512,llama2_13b_chat,choice,choice,,,,
11,0.3878866867585615,0.4545454680919647,0.5454545617103577,0.6000000000000001,0.11921183629469438,mmlu:college_physics,validation,2.98723828792572,llama2_13b_chat,choice,choice,,,,
102,0.370677268096045,0.2450980544090271,0.529411792755127,0.6174025974025974,0.12187772930837144,mmlu:college_physics,test,26.117781329900026,llama2_13b_chat,choice,choice,,,,
11,0.45247231830250134,0.6363636255264282,0.6363636255264282,0.6428571428571428,0.30191021073948254,mmlu:computer_security,validation,2.8341872580349445,llama2_13b_chat,choice,choice,,,,
100,0.2238504680991173,0.6499999761581421,0.699999988079071,0.7424175824175825,0.10804230153560639,mmlu:computer_security,test,21.7568541392684,llama2_13b_chat,choice,choice,,,,
26,0.31387063173147345,0.46153849363327026,0.692307710647583,0.6190476190476191,0.12722335182703465,mmlu:conceptual_physics,validation,4.665994707494974,llama2_13b_chat,choice,choice,,,,
235,0.3247843713202375,0.4127659499645233,0.5744680762290955,0.5729119976094427,0.09954150458599657,mmlu:conceptual_physics,test,39.052717965096235,llama2_13b_chat,choice,choice,,,,
12,0.49937231590350467,0.3333333432674408,0.3333333432674408,0.53125,0.4413627088069916,mmlu:econometrics,validation,4.003213848918676,llama2_13b_chat,choice,choice,,,,
114,0.30435455237564285,0.31578946113586426,0.3947368562221527,0.545405982905983,0.30276940579999956,mmlu:econometrics,test,36.27507935836911,llama2_13b_chat,choice,choice,,,,
16,0.39805904775857925,0.5,0.625,0.765625,0.0759813189506531,mmlu:electrical_engineering,validation,3.7837269715964794,llama2_13b_chat,choice,choice,,,,
145,0.2309398133179237,0.4965517222881317,0.5103448033332825,0.5018074581430746,0.1599609777845186,mmlu:electrical_engineering,test,33.209833931177855,llama2_13b_chat,choice,choice,,,,
41,0.25017098609994093,0.4146341383457184,0.4878048598766327,0.6397058823529412,0.2034703318665667,mmlu:elementary_mathematics,validation,11.938452571630478,llama2_13b_chat,choice,choice,,,,
378,0.31418251179198114,0.3253968060016632,0.5052909851074219,0.503012912482066,0.18933600439596426,mmlu:elementary_mathematics,test,106.59320718795061,llama2_13b_chat,choice,choice,,,,
14,0.5272892628397261,0.0714285746216774,0.2142857313156128,0.0,0.5222787175859723,mmlu:formal_logic,validation,4.497507467865944,llama2_13b_chat,choice,choice,,,,
126,0.32209860214165287,0.2857142984867096,0.3095238208770752,0.677932098765432,0.481920978379628,mmlu:formal_logic,test,40.32660010457039,llama2_13b_chat,choice,choice,,,,
10,0.47349956631660467,0.20000000298023224,0.5,1.0,0.22275915145874026,mmlu:global_facts,validation,2.437330510467291,llama2_13b_chat,choice,choice,,,,
100,0.3165890657901764,0.3100000023841858,0.47999998927116394,0.541841982234689,0.15538888335227968,mmlu:global_facts,test,22.98962890356779,llama2_13b_chat,choice,choice,,,,
32,0.2618219470605254,0.5625,0.59375,0.6111111111111112,0.2670989856123924,mmlu:high_school_biology,validation,9.352749779820442,llama2_13b_chat,choice,choice,,,,
310,0.1704712515877139,0.6774193644523621,0.6387096643447876,0.5910238095238095,0.06993062265457645,mmlu:high_school_biology,test,87.46518862992525,llama2_13b_chat,choice,choice,,,,
22,0.30064125359058386,0.40909093618392944,0.40909093618392944,0.6752136752136753,0.3349208262833683,mmlu:high_school_chemistry,validation,6.347121383994818,llama2_13b_chat,choice,choice,,,,
203,0.2409859713662434,0.41379308700561523,0.4088670015335083,0.4627851140456183,0.30228634127255144,mmlu:high_school_chemistry,test,54.68972832337022,llama2_13b_chat,choice,choice,,,,
9,0.2520365847481621,0.7777777910232544,0.5555555820465088,0.5714285714285714,0.2862005896038479,mmlu:high_school_computer_science,validation,4.58358084782958,llama2_13b_chat,choice,choice,,,,
100,0.1541334843635559,0.5999999642372131,0.6299999952316284,0.6410416666666667,0.08474038362503053,mmlu:high_school_computer_science,test,48.663552954792976,llama2_13b_chat,choice,choice,,,,
22,0.15720224651423365,0.7272727489471436,0.7727273106575012,0.5729166666666666,0.1220794753594832,mmlu:high_school_geography,validation,4.753551132977009,llama2_13b_chat,choice,choice,,,,
198,0.18159390278536866,0.7070707082748413,0.6262626051902771,0.4786330049261084,0.07524814027728456,mmlu:high_school_geography,test,42.12603009492159,llama2_13b_chat,choice,choice,,,,
21,0.22747943231037682,0.7142857313156128,0.7142857313156128,0.5777777777777777,0.2751367319197881,mmlu:high_school_government_and_politics,validation,5.251048248261213,llama2_13b_chat,choice,choice,,,,
193,0.1270896543801757,0.7927460670471191,0.7668393850326538,0.6172385620915033,0.07217719394308299,mmlu:high_school_government_and_politics,test,47.71326790377498,llama2_13b_chat,choice,choice,,,,
43,0.2938208836455678,0.4651162624359131,0.6744186282157898,0.5065217391304349,0.0824296419010606,mmlu:high_school_macroeconomics,validation,9.556913793087006,llama2_13b_chat,choice,choice,,,,
390,0.23552503035618708,0.535897433757782,0.6307692527770996,0.4958893970234476,0.08570192440962181,mmlu:high_school_macroeconomics,test,84.85189835354686,llama2_13b_chat,choice,choice,,,,
29,0.23744304940618322,0.27586206793785095,0.6206896305084229,0.5238095238095238,0.15914927268850396,mmlu:high_school_mathematics,validation,8.04154934734106,llama2_13b_chat,choice,choice,,,,
270,0.2369200842248069,0.28148147463798523,0.5629629492759705,0.45557514921323927,0.0765577581193712,mmlu:high_school_mathematics,test,72.96245137602091,llama2_13b_chat,choice,choice,,,,
26,0.21208596000304591,0.6153846383094788,0.5769230723381042,0.525,0.17620193041287938,mmlu:high_school_microeconomics,validation,5.814696043729782,llama2_13b_chat,choice,choice,,,,
238,0.1999973366741373,0.5840336680412292,0.6134454011917114,0.5370975946515516,0.0840729197033313,mmlu:high_school_microeconomics,test,52.17634695023298,llama2_13b_chat,choice,choice,,,,
17,0.5390769944471472,0.29411765933036804,0.5882353186607361,0.4666666666666667,0.275296127094942,mmlu:high_school_physics,validation,5.153254926204681,llama2_13b_chat,choice,choice,,,,
151,0.3287348271600458,0.33774834871292114,0.5827814340591431,0.48294117647058826,0.15139022331364105,mmlu:high_school_physics,test,44.00728094577789,llama2_13b_chat,choice,choice,,,,
60,0.11621293028195703,0.8000000715255737,0.7000000476837158,0.7291666666666666,0.06487637460231781,mmlu:high_school_psychology,validation,16.700353763997555,llama2_13b_chat,choice,choice,,,,
545,0.1283313002608238,0.752293586730957,0.721100926399231,0.6582475158084914,0.054132893107353,mmlu:high_school_psychology,test,150.92772955447435,llama2_13b_chat,choice,choice,,,,
23,0.31580342028452013,0.3478260934352875,0.739130437374115,0.7333333333333334,0.11245700069095776,mmlu:high_school_statistics,validation,9.470712374895811,llama2_13b_chat,choice,choice,,,,
216,0.24046254544346418,0.36574074625968933,0.6157407164573669,0.4382333918506883,0.05593373543686336,mmlu:high_school_statistics,test,92.97400664910674,llama2_13b_chat,choice,choice,,,,
22,0.2284643677147952,0.7272727489471436,0.5909091234207153,0.5520833333333334,0.08296556093476035,mmlu:high_school_us_history,validation,34.44204421713948,llama2_13b_chat,choice,choice,,,,
204,0.14268829118387372,0.75,0.6127451062202454,0.5077534281686531,0.07325488737985199,mmlu:high_school_us_history,test,313.89387713745236,llama2_13b_chat,choice,choice,,,,
23,0.23342548505119656,0.695652186870575,0.6086956858634949,0.7857142857142857,0.24314392649609112,mmlu:human_aging,validation,4.430761810392141,llama2_13b_chat,choice,choice,,,,
223,0.1750242027199322,0.6457399129867554,0.6457399129867554,0.6397679324894515,0.09710698464526188,mmlu:human_aging,test,39.43794944137335,llama2_13b_chat,choice,choice,,,,
12,0.23100995272397995,0.4166666865348816,0.5833333730697632,0.6000000000000001,0.10205398499965669,mmlu:human_sexuality,validation,2.450817007571459,llama2_13b_chat,choice,choice,,,,
131,0.20160232518465465,0.6106870174407959,0.6030534505844116,0.5840686274509803,0.0992433665362933,mmlu:human_sexuality,test,26.936359480023384,llama2_13b_chat,choice,choice,,,,
13,0.09920215606689457,0.8461538553237915,0.7692307829856873,0.0,0.30783037038949823,mmlu:international_law,validation,4.78561482578516,llama2_13b_chat,choice,choice,,,,
121,0.14776173135465825,0.7520660758018494,0.7685949802398682,0.7256410256410256,0.038057621352928735,mmlu:international_law,test,40.67048614472151,llama2_13b_chat,choice,choice,,,,
11,0.2845090708949349,0.4545454680919647,0.4545454680919647,0.6000000000000001,0.2008335915478793,mmlu:jurisprudence,validation,2.621569626033306,llama2_13b_chat,choice,choice,,,,
108,0.07530087784484582,0.7685185074806213,0.694444477558136,0.6520481927710844,0.06917355623510149,mmlu:jurisprudence,test,24.189975544810295,llama2_13b_chat,choice,choice,,,,
18,0.2260679933759901,0.7222222089767456,0.6666666865348816,0.49230769230769234,0.20784525076548258,mmlu:logical_fallacies,validation,4.5882200114429,llama2_13b_chat,choice,choice,,,,
163,0.18132933681727922,0.6748465895652771,0.7239263653755188,0.5821612349914237,0.07786623319965201,mmlu:logical_fallacies,test,39.64215485751629,llama2_13b_chat,choice,choice,,,,
11,0.3903419483791698,0.27272728085517883,0.4545454680919647,0.75,0.3337575630708174,mmlu:machine_learning,validation,3.7454406172037125,llama2_13b_chat,choice,choice,,,,
112,0.42653715983033186,0.2946428656578064,0.598214328289032,0.58036056770234,0.12610820734075137,mmlu:machine_learning,test,37.66421825811267,llama2_13b_chat,choice,choice,,,,
11,0.19820608875968238,0.8181818723678589,0.9090909361839294,0.8888888888888888,0.21212386001240124,mmlu:management,validation,1.9389570131897926,llama2_13b_chat,choice,choice,,,,
103,0.12850591685008078,0.7281553745269775,0.737864077091217,0.724047619047619,0.05063260932570524,mmlu:management,test,16.94216226786375,llama2_13b_chat,choice,choice,,,,
25,0.1604520511627197,0.7999999523162842,0.7599999904632568,0.52,0.07476258993148803,mmlu:marketing,validation,5.840049907565117,llama2_13b_chat,choice,choice,,,,
234,0.0556038345536615,0.811965823173523,0.811965823173523,0.6998803827751197,0.07100226379867293,mmlu:marketing,test,52.41762446239591,llama2_13b_chat,choice,choice,,,,
11,0.19195573980158026,0.7272727489471436,0.8181818723678589,0.5833333333333334,0.251137603412975,mmlu:medical_genetics,validation,2.4253049716353416,llama2_13b_chat,choice,choice,,,,
100,0.2222991907596588,0.5699999928474426,0.6800000071525574,0.7070583435332518,0.04949679076671604,mmlu:medical_genetics,test,20.05879395455122,llama2_13b_chat,choice,choice,,,,
38,0.274641951448039,0.4736842215061188,0.5263158082962036,0.6555555555555556,0.16782742738723755,mmlu:moral_disputes,validation,9.907305028289557,llama2_13b_chat,choice,choice,,,,
346,0.2104136041134079,0.6011560559272766,0.5924855470657349,0.6091833890746935,0.11431268236540647,mmlu:moral_disputes,test,87.6162296384573,llama2_13b_chat,choice,choice,,,,
33,0.12391907067009898,0.7272727489471436,0.7272727489471436,0.5555555555555556,0.11544569514014506,mmlu:nutrition,validation,10.678037010133266,llama2_13b_chat,choice,choice,,,,
306,0.20404470599944294,0.5947712659835815,0.5816993713378906,0.5987681673165544,0.12294670471958086,mmlu:nutrition,test,97.19623854011297,llama2_13b_chat,choice,choice,,,,
34,0.3614660878391827,0.5588235259056091,0.7352941036224365,0.7192982456140351,0.07333432751543381,mmlu:philosophy,validation,6.529500417411327,llama2_13b_chat,choice,choice,,,,
311,0.2685818516939783,0.6141479015350342,0.668810248374939,0.5988438045375218,0.07617322003343098,mmlu:philosophy,test,57.90451952442527,llama2_13b_chat,choice,choice,,,,
35,0.24310854503086635,0.6285714507102966,0.5714285969734192,0.6433566433566433,0.13924996682575772,mmlu:prehistory,validation,10.26455569639802,llama2_13b_chat,choice,choice,,,,
324,0.2470247510958601,0.5956790447235107,0.6327160596847534,0.5843452121979196,0.07224838325270898,mmlu:prehistory,test,92.75047141313553,llama2_13b_chat,choice,choice,,,,
69,0.20283278304597607,0.6086956858634949,0.6376811861991882,0.6979717813051147,0.12379762919052786,mmlu:professional_psychology,validation,21.59806225821376,llama2_13b_chat,choice,choice,,,,
612,0.23851665124004962,0.5522875785827637,0.5735294222831726,0.5942588433464346,0.149790331331733,mmlu:professional_psychology,test,184.19121516123414,llama2_13b_chat,choice,choice,,,,
12,0.4481361309687297,0.5,0.4166666865348816,0.24999999999999997,0.3530834019184112,mmlu:public_relations,validation,3.0523817017674446,llama2_13b_chat,choice,choice,,,,
110,0.16180461211638014,0.6363636255264282,0.6727272272109985,0.74375,0.0861614308573983,mmlu:public_relations,test,25.46165281906724,llama2_13b_chat,choice,choice,,,,
27,0.34522028322573056,0.5555555820465088,0.5925925970077515,0.7611111111111112,0.19914027938136347,mmlu:security_studies,validation,18.58129921555519,llama2_13b_chat,choice,choice,,,,
245,0.22966081475724975,0.6408162713050842,0.6612244844436646,0.5945280833815866,0.13215216617194975,mmlu:security_studies,test,173.72284388169646,llama2_13b_chat,choice,choice,,,,
22,0.11438660730015147,0.8181818723678589,0.8181818723678589,0.6388888888888888,0.13603986393321643,mmlu:sociology,validation,5.429453428834677,llama2_13b_chat,choice,choice,,,,
201,0.1654659453316114,0.7661691308021545,0.7960199117660522,0.6930781983973473,0.049040088309577456,mmlu:sociology,test,47.4985146522522,llama2_13b_chat,choice,choice,,,,
11,0.09280334277586508,0.9090909361839294,0.8181818723678589,1.0,0.16415297443216495,mmlu:us_foreign_policy,validation,2.655646651983261,llama2_13b_chat,choice,choice,,,,
100,0.12127714633941647,0.7899999618530273,0.7799999713897705,0.5575647980711272,0.04622912764549255,mmlu:us_foreign_policy,test,22.880583371967077,llama2_13b_chat,choice,choice,,,,
18,0.4539293646812439,0.4444444477558136,0.6111111044883728,0.675,0.2287131349245707,mmlu:virology,validation,4.346238948404789,llama2_13b_chat,choice,choice,,,,
166,0.32515772369252627,0.48192769289016724,0.5301204919815063,0.5337936046511628,0.2603011540619724,mmlu:virology,test,33.183667194098234,llama2_13b_chat,choice,choice,,,,
19,0.18241700686906515,0.7894737124443054,0.7368420958518982,0.7666666666666666,0.10624183479108307,mmlu:world_religions,validation,3.1828414537012577,llama2_13b_chat,choice,choice,,,,
171,0.08028784359407706,0.7836257219314575,0.7953216433525085,0.740520371117386,0.0411348109356841,mmlu:world_religions,test,26.698248475790024,llama2_13b_chat,choice,choice,,,,
14,,,,,,mmlu:anatomy,validation,17.115460896864533,llama2_13b,oe,oe,0.2142857313156128,0.4285714626312256,0.8484848484848484,0.2652313198362078
135,,,,,,mmlu:anatomy,test,132.32082254253328,llama2_13b,oe,oe,0.4888888895511627,0.614814817905426,0.7613087395696092,0.13129409507468892
16,,,,,,mmlu:astronomy,validation,17.681127302348614,llama2_13b,oe,oe,0.3125,0.5625,0.7454545454545455,0.3070392906665802
152,,,,,,mmlu:astronomy,test,157.25184367690235,llama2_13b,oe,oe,0.4868420958518982,0.5460526347160339,0.5817740817740819,0.11985959308712102
11,,,,,,mmlu:business_ethics,validation,12.862000616267323,llama2_13b,oe,oe,0.3636363744735718,0.4545454680919647,0.8928571428571428,0.2496701641516252
100,,,,,,mmlu:business_ethics,test,110.58389258384705,llama2_13b,oe,oe,0.32999998331069946,0.38999998569488525,0.6610131162369968,0.296505931019783
29,,,,,,mmlu:clinical_knowledge,validation,31.186681465245783,llama2_13b,oe,oe,0.24137930572032928,0.48275861144065857,0.8571428571428571,0.13669872695002064
265,,,,,,mmlu:clinical_knowledge,test,265.56159982737154,llama2_13b,oe,oe,0.324528306722641,0.5584905743598938,0.6238794335455373,0.08513725073832386
16,,,,,,mmlu:college_biology,validation,16.861517381854355,llama2_13b,oe,oe,0.1875,0.3125,0.43589743589743585,0.32770654186606407
144,,,,,,mmlu:college_biology,test,151.92203810624778,llama2_13b,oe,oe,0.4166666567325592,0.5347222089767456,0.6427579365079366,0.14801182225346565
8,,,,,,mmlu:college_chemistry,validation,8.750268903560936,llama2_13b,oe,oe,0.125,0.375,0.8571428571428572,0.42902178317308426
100,,,,,,mmlu:college_chemistry,test,111.31805418804288,llama2_13b,oe,oe,0.14999999105930328,0.5299999713897705,0.5776470588235294,0.1813646346330643
11,,,,,,mmlu:college_computer_science,validation,15.514657764695585,llama2_13b,oe,oe,0.1818181872367859,0.5454545617103577,0.11111111111111116,0.27476258169520984
100,,,,,,mmlu:college_computer_science,test,138.64659145381302,llama2_13b,oe,oe,0.1899999976158142,0.5299999713897705,0.5055230669265758,0.2201805996894836
11,,,,,,mmlu:college_mathematics,validation,14.136321465484798,llama2_13b,oe,oe,0.09090909361839294,1.0,0.09999999999999998,0.15812581235712225
100,,,,,,mmlu:college_mathematics,test,118.99830443225801,llama2_13b,oe,oe,0.10999999940395355,0.7299999594688416,0.432073544433095,0.07131722629070283
22,,,,,,mmlu:college_medicine,validation,25.259619225747883,llama2_13b,oe,oe,0.4545454680919647,0.5909091234207153,0.6000000000000001,0.1404870396310633
173,,,,,,mmlu:college_medicine,test,201.90882442798465,llama2_13b,oe,oe,0.32947975397109985,0.5086705088615417,0.624395039322444,0.17899268555503356
11,,,,,,mmlu:college_physics,validation,13.290868381038308,llama2_13b,oe,oe,0.27272728085517883,0.7272727489471436,0.5416666666666666,0.1296012889255177
102,,,,,,mmlu:college_physics,test,116.41284372936934,llama2_13b,oe,oe,0.18627451360225677,0.774509847164154,0.3021559923906151,0.0716192219771591
11,,,,,,mmlu:computer_security,validation,12.729469197802246,llama2_13b,oe,oe,0.5454545617103577,0.3636363744735718,0.5,0.21488294818184595
100,,,,,,mmlu:computer_security,test,99.92594889272004,llama2_13b,oe,oe,0.47999998927116394,0.5899999737739563,0.6344150641025641,0.0735680294036865
26,,,,,,mmlu:conceptual_physics,validation,26.795793215744197,llama2_13b,oe,oe,0.3461538553237915,0.5,0.33986928104575165,0.25553708580824047
235,,,,,,mmlu:conceptual_physics,test,233.75458555389196,llama2_13b,oe,oe,0.4553191363811493,0.5531914830207825,0.591632593457944,0.11341879925829298
12,,,,,,mmlu:econometrics,validation,19.414790622889996,llama2_13b,oe,oe,0.0,0.4166666865348816,,0.19456036885579428
114,,,,,,mmlu:econometrics,test,137.92241627536714,llama2_13b,oe,oe,0.14912280440330505,0.6140350699424744,0.5263796240145543,0.04858826545246861
16,,,,,,mmlu:electrical_engineering,validation,16.994447208940983,llama2_13b,oe,oe,0.3125,0.6875,0.29090909090909095,0.12036427110433578
145,,,,,,mmlu:electrical_engineering,test,158.31519889924675,llama2_13b,oe,oe,0.22068965435028076,0.5793103575706482,0.4177267699115044,0.10349320995396581
41,,,,,,mmlu:elementary_mathematics,validation,46.37483483366668,llama2_13b,oe,oe,0.31707316637039185,0.7804877758026123,0.42582417582417587,0.11952333770147183
378,,,,,,mmlu:elementary_mathematics,test,412.6089876899496,llama2_13b,oe,oe,0.3888888657093048,0.6560846567153931,0.3506935241629119,0.05977755816525251
14,,,,,,mmlu:formal_logic,validation,17.10604457370937,llama2_13b,oe,oe,0.3571428656578064,0.3571428656578064,0.6222222222222223,0.2961145554270063
126,,,,,,mmlu:formal_logic,test,141.35569594893605,llama2_13b,oe,oe,0.2380952537059784,0.341269850730896,0.49600694444444443,0.29849909316925777
10,,,,,,mmlu:global_facts,validation,11.980523167178035,llama2_13b,oe,oe,0.20000000298023224,0.800000011920929,0.3125,0.3376645863056183
100,,,,,,mmlu:global_facts,test,102.26650099083781,llama2_13b,oe,oe,0.19999998807907104,0.6200000047683716,0.566875,0.03205434322357181
32,,,,,,mmlu:high_school_biology,validation,33.732169398106635,llama2_13b,oe,oe,0.40625,0.34375,0.5465587044534413,0.36844938062131405
310,,,,,,mmlu:high_school_biology,test,329.7744591170922,llama2_13b,oe,oe,0.45483869314193726,0.5032258033752441,0.6017247891224978,0.23410912233014264
22,,,,,,mmlu:high_school_chemistry,validation,25.981486012227833,llama2_13b,oe,oe,0.09090909361839294,0.5454545617103577,0.35,0.3306463333693418
203,,,,,,mmlu:high_school_chemistry,test,222.5634490372613,llama2_13b,oe,oe,0.17733989655971527,0.45320194959640503,0.5429973386560213,0.22033617473000966
9,,,,,,mmlu:high_school_computer_science,validation,13.575130176730454,llama2_13b,oe,oe,0.2222222238779068,0.4444444477558136,0.5,0.24542109833823306
100,,,,,,mmlu:high_school_computer_science,test,131.67580560501665,llama2_13b,oe,oe,0.41999998688697815,0.5600000023841858,0.597495894909688,0.12587193310260772
22,,,,,,mmlu:high_school_geography,validation,23.37186543084681,llama2_13b,oe,oe,0.40909093618392944,0.5909091234207153,0.547008547008547,0.2583243955265392
198,,,,,,mmlu:high_school_geography,test,198.40663911495358,llama2_13b,oe,oe,0.3787878751754761,0.5757575631141663,0.6117073170731707,0.11060503064984023
21,,,,,,mmlu:high_school_government_and_politics,validation,23.539938633330166,llama2_13b,oe,oe,0.523809552192688,0.523809552192688,0.6636363636363636,0.18318939492816017
193,,,,,,mmlu:high_school_government_and_politics,test,198.22967546619475,llama2_13b,oe,oe,0.5492227673530579,0.5958548784255981,0.6412383430926046,0.07289483695450225
43,,,,,,mmlu:high_school_macroeconomics,validation,43.1460765292868,llama2_13b,oe,oe,0.41860464215278625,0.5581395626068115,0.5266666666666666,0.09982603372529497
390,,,,,,mmlu:high_school_macroeconomics,test,395.22958453558385,llama2_13b,oe,oe,0.3512820601463318,0.4948718249797821,0.5256484232999625,0.13948853428547198
29,,,,,,mmlu:high_school_mathematics,validation,35.27318172901869,llama2_13b,oe,oe,0.10344827175140381,0.8965517282485962,0.3846153846153846,0.09809147489481962
270,,,,,,mmlu:high_school_mathematics,test,310.0987851237878,llama2_13b,oe,oe,0.08518518507480621,0.8740740418434143,0.3076923076923077,0.041716330801999095
26,,,,,,mmlu:high_school_microeconomics,validation,27.600192212499678,llama2_13b,oe,oe,0.38461539149284363,0.38461539149284363,0.41875,0.2563480070004096
238,,,,,,mmlu:high_school_microeconomics,test,238.22763283830136,llama2_13b,oe,oe,0.3739495873451233,0.5168067216873169,0.6140185506372067,0.12652614862978964
17,,,,,,mmlu:high_school_physics,validation,21.216582529246807,llama2_13b,oe,oe,0.11764705926179886,0.7647058963775635,0.36666666666666664,0.27520207447164197
151,,,,,,mmlu:high_school_physics,test,169.53298885840923,llama2_13b,oe,oe,0.21192052960395813,0.6026490330696106,0.5070903361344538,0.10593733684906109
60,,,,,,mmlu:high_school_psychology,validation,63.79513290524483,llama2_13b,oe,oe,0.6000000238418579,0.5333333611488342,0.6655092592592592,0.14578992426395418
545,,,,,,mmlu:high_school_psychology,test,586.6254035355523,llama2_13b,oe,oe,0.5504587292671204,0.5908256769180298,0.6283945578231293,0.10201763734904995
23,,,,,,mmlu:high_school_statistics,validation,29.052940348163247,llama2_13b,oe,oe,0.21739131212234497,0.6521739363670349,0.3888888888888889,0.19022461383239084
216,,,,,,mmlu:high_school_statistics,test,268.32308614905924,llama2_13b,oe,oe,0.24074074625968933,0.5879629850387573,0.4451219512195122,0.0952191921295943
22,,,,,,mmlu:high_school_us_history,validation,66.136932390742,llama2_13b,oe,oe,0.5909091234207153,0.5909091234207153,0.37606837606837606,0.1894719058817083
204,,,,,,mmlu:high_school_us_history,test,594.08603780251,llama2_13b,oe,oe,0.6274510025978088,0.6666666865348816,0.7016858552631579,0.03758423965351257
23,,,,,,mmlu:human_aging,validation,23.0160394012928,llama2_13b,oe,oe,0.260869562625885,0.260869562625885,0.33333333333333337,0.4092715227085612
223,,,,,,mmlu:human_aging,test,222.5857910886407,llama2_13b,oe,oe,0.3901345431804657,0.5201793909072876,0.6645960108181204,0.2107846873223514
12,,,,,,mmlu:human_sexuality,validation,11.84761056303978,llama2_13b,oe,oe,0.3333333432674408,0.5,0.53125,0.21235038836797077
131,,,,,,mmlu:human_sexuality,test,132.31891477387398,llama2_13b,oe,oe,0.3893129825592041,0.5954198241233826,0.6432598039215687,0.07054802798132863
13,,,,,,mmlu:international_law,validation,15.80418396834284,llama2_13b,oe,oe,0.3076923191547394,0.38461539149284363,0.41666666666666663,0.3435014027815599
121,,,,,,mmlu:international_law,test,129.10281133651733,llama2_13b,oe,oe,0.5454545021057129,0.586776852607727,0.6670798898071625,0.08925726886623163
11,,,,,,mmlu:jurisprudence,validation,11.85389194637537,llama2_13b,oe,oe,0.4545454680919647,0.3636363744735718,0.2666666666666667,0.2613157359036532
108,,,,,,mmlu:jurisprudence,test,109.79542230349034,llama2_13b,oe,oe,0.43518519401550293,0.5555555820465088,0.5381932333449599,0.14149652090337542
18,,,,,,mmlu:logical_fallacies,validation,20.043755665421486,llama2_13b,oe,oe,0.5,0.3888888955116272,0.7407407407407407,0.3200362920761109
163,,,,,,mmlu:logical_fallacies,test,168.0605282112956,llama2_13b,oe,oe,0.4417177736759186,0.6073619723320007,0.6016483516483517,0.10192053559367642
11,,,,,,mmlu:machine_learning,validation,13.461237638257444,llama2_13b,oe,oe,0.3636363744735718,0.4545454680919647,0.2142857142857143,0.2494002309712497
112,,,,,,mmlu:machine_learning,test,128.8246174287051,llama2_13b,oe,oe,0.2053571492433548,0.4732142984867096,0.4648265754763068,0.16718443429895807
11,,,,,,mmlu:management,validation,11.179990236647427,llama2_13b,oe,oe,0.6363636255264282,0.5454545617103577,0.5,0.22096439925107086
103,,,,,,mmlu:management,test,100.36059011053294,llama2_13b,oe,oe,0.3203883469104767,0.48543688654899597,0.6692640692640693,0.16945056313449897
25,,,,,,mmlu:marketing,validation,28.012809433974326,llama2_13b,oe,oe,0.3199999928474426,0.35999998450279236,0.6801470588235294,0.3463210821151734
234,,,,,,mmlu:marketing,test,236.2839031042531,llama2_13b,oe,oe,0.49145302176475525,0.5341880321502686,0.6164413591523566,0.1622427847140875
11,,,,,,mmlu:medical_genetics,validation,11.513252078555524,llama2_13b,oe,oe,0.7272727489471436,0.8181818723678589,0.875,0.20922239802100437
100,,,,,,mmlu:medical_genetics,test,96.72731148544699,llama2_13b,oe,oe,0.5199999809265137,0.6200000047683716,0.600761217948718,0.0957836401462555
38,,,,,,mmlu:moral_disputes,validation,41.01048196014017,llama2_13b,oe,oe,0.42105263471603394,0.5,0.5710227272727273,0.2095493799761722
346,,,,,,mmlu:moral_disputes,test,356.55451095756143,llama2_13b,oe,oe,0.42485547065734863,0.5086705088615417,0.6222609646873825,0.13929289613845033
33,,,,,,mmlu:nutrition,validation,37.9044123403728,llama2_13b,oe,oe,0.3636363744735718,0.39393940567970276,0.5793650793650793,0.3580849929289384
306,,,,,,mmlu:nutrition,test,330.9081149324775,llama2_13b,oe,oe,0.36274510622024536,0.516339898109436,0.6582582582582583,0.1758616934804355
34,,,,,,mmlu:philosophy,validation,36.58061888162047,llama2_13b,oe,oe,0.2647058963775635,0.4117647111415863,0.5377777777777778,0.277452570550582
311,,,,,,mmlu:philosophy,test,308.0666701979935,llama2_13b,oe,oe,0.34405145049095154,0.3633440434932709,0.5708264614256917,0.3293712831003489
35,,,,,,mmlu:prehistory,validation,36.56368085183203,llama2_13b,oe,oe,0.34285715222358704,0.6571428775787354,0.6231884057971014,0.16466785328728814
324,,,,,,mmlu:prehistory,test,329.94560254830867,llama2_13b,oe,oe,0.48456791043281555,0.6358024477958679,0.5941874213356726,0.025070298785044836
69,,,,,,mmlu:professional_psychology,validation,77.6105171861127,llama2_13b,oe,oe,0.3913043439388275,0.47826087474823,0.5260141093474426,0.1772398793179056
612,,,,,,mmlu:professional_psychology,test,659.7058958858252,llama2_13b,oe,oe,0.3251633942127228,0.46405228972435,0.5800491561925851,0.19728069250879723
12,,,,,,mmlu:public_relations,validation,12.522391702979803,llama2_13b,oe,oe,0.25,0.5,0.0740740740740741,0.21060681839783985
110,,,,,,mmlu:public_relations,test,116.94859328959137,llama2_13b,oe,oe,0.3272727131843567,0.5909090638160706,0.6441441441441441,0.17008084600622003
27,,,,,,mmlu:security_studies,validation,31.000828673131764,llama2_13b,oe,oe,0.6296296119689941,0.5555555820465088,0.6764705882352942,0.1275293098555671
245,,,,,,mmlu:security_studies,test,276.24302360229194,llama2_13b,oe,oe,0.5551019906997681,0.59183669090271,0.608708850512682,0.055680705819811126
22,,,,,,mmlu:sociology,validation,23.0127316955477,llama2_13b,oe,oe,0.5454545617103577,0.5454545617103577,0.6166666666666666,0.20644626834175803
201,,,,,,mmlu:sociology,test,203.0721461130306,llama2_13b,oe,oe,0.4179104268550873,0.5820895433425903,0.5601851851851852,0.0998141632151248
11,,,,,,mmlu:us_foreign_policy,validation,11.889828217215836,llama2_13b,oe,oe,0.6363636255264282,0.7272727489471436,0.6785714285714286,0.18288230354135687
100,,,,,,mmlu:us_foreign_policy,test,99.49071232229471,llama2_13b,oe,oe,0.5899999737739563,0.6599999666213989,0.7077304671351798,0.038278355002403286
18,,,,,,mmlu:virology,validation,21.237419851124287,llama2_13b,oe,oe,0.3888888955116272,0.5,0.5064935064935066,0.26257675886154175
166,,,,,,mmlu:virology,test,167.1048363810405,llama2_13b,oe,oe,0.3313252925872803,0.47590360045433044,0.5877968877968877,0.16266824107572259
19,,,,,,mmlu:world_religions,validation,19.249009359627962,llama2_13b,oe,oe,0.6842105388641357,0.7368420958518982,0.5897435897435896,0.13404965086987145
171,,,,,,mmlu:world_religions,test,163.34489207621664,llama2_13b,oe,oe,0.6432748436927795,0.6257309913635254,0.5666915052160955,0.08206159991827625
