N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.8181818127632141,0.33333333333333337,0.2812500054186041,mmlu:abstract_algebra,validation,2.041275614872575
100,0.2199999988079071,0.7799999713897705,0.6101398601398602,0.24925783157348635,mmlu:abstract_algebra,test,1.5723008618224412
14,0.2857142984867096,0.2857142984867096,0.7375,0.29771203654153006,mmlu:anatomy,validation,0.4620484139304608
135,0.4148148000240326,0.4148148000240326,0.5782097649186256,0.17005208907303984,mmlu:anatomy,test,2.0841293309349567
16,0.4375,0.4375,0.5793650793650793,0.1520995944738388,mmlu:astronomy,validation,0.4063842981122434
152,0.5065789222717285,0.5065789222717285,0.567012987012987,0.08210835331364683,mmlu:astronomy,test,2.3762363269925117
11,0.6363636255264282,0.6363636255264282,0.33928571428571425,0.16157672080126678,mmlu:business_ethics,validation,0.3507027740124613
100,0.30000001192092896,0.30000001192092896,0.5333333333333333,0.2993749845027924,mmlu:business_ethics,test,1.6015225949231535
29,0.24137930572032928,0.24137930572032928,0.6363636363636364,0.3675915948275862,mmlu:clinical_knowledge,validation,0.5561149590648711
265,0.35849055647850037,0.35849055647850037,0.605108359133127,0.24786259498236313,mmlu:clinical_knowledge,test,3.9519597131293267
16,0.3125,0.3125,0.4727272727272728,0.239990234375,mmlu:college_biology,validation,0.4318051200825721
144,0.2986111044883728,0.2916666567325592,0.5546857011282524,0.2731119758552975,mmlu:college_biology,test,2.1532634620089084
8,0.125,0.125,0.4285714285714286,0.43603515625,mmlu:college_chemistry,validation,0.26708968891762197
100,0.14000000059604645,0.1599999964237213,0.5261627906976745,0.40499998092651374,mmlu:college_chemistry,test,1.611854705028236
11,0.0,0.7272727489471436,,0.19247160174629907,mmlu:college_computer_science,validation,0.40305249486118555
100,0.17000000178813934,0.5799999833106995,0.5109851169383416,0.04652340888977047,mmlu:college_computer_science,test,1.6119309479836375
11,0.0,1.0,,0.38423297621987085,mmlu:college_mathematics,validation,0.4272862400393933
100,0.1599999964237213,0.8299999833106995,0.609747023809524,0.22843751072883606,mmlu:college_mathematics,test,1.6206703239586204
22,0.3636363744735718,0.3636363744735718,0.7723214285714286,0.22549714825370093,mmlu:college_medicine,validation,0.6975875699426979
173,0.36994218826293945,0.36994218826293945,0.5321100917431194,0.22852690888278057,mmlu:college_medicine,test,2.6272964510135353
11,0.27272728085517883,0.27272728085517883,0.7083333333333333,0.34481534632769495,mmlu:college_physics,validation,0.38115858915261924
102,0.14705882966518402,0.14705882966518402,0.475095785440613,0.4731157983050628,mmlu:college_physics,test,1.5992872170172632
11,0.7272727489471436,0.8181818127632141,0.8541666666666666,0.2585227110169151,mmlu:computer_security,validation,0.40205312287434936
100,0.4300000071525574,0.46000000834465027,0.5926152590779273,0.11695310592651366,mmlu:computer_security,test,1.5607486530207098
26,0.3076923191547394,0.692307710647583,0.4965277777777778,0.16376201464579654,mmlu:conceptual_physics,validation,0.6389900271315128
235,0.4127659499645233,0.5914893746376038,0.6097041685342897,0.06351398128144281,mmlu:conceptual_physics,test,3.417066377121955
12,0.0833333358168602,0.0833333358168602,1.0,0.4563802282015483,mmlu:econometrics,validation,0.47234735800884664
114,0.14912280440330505,0.15789473056793213,0.5239539114614918,0.38325797884087814,mmlu:econometrics,test,1.801214040024206
16,0.125,0.125,0.5892857142857143,0.52099609375,mmlu:electrical_engineering,validation,0.4112837100401521
145,0.1862068921327591,0.1862068921327591,0.486660389202762,0.459590536972572,mmlu:electrical_engineering,test,2.359248585999012
41,0.26829269528388977,0.7317073345184326,0.6015151515151514,0.15339179155303206,mmlu:elementary_mathematics,validation,0.8497720770537853
378,0.32275131344795227,0.6772486567497253,0.48339843749999994,0.10101482146000737,mmlu:elementary_mathematics,test,5.677499359939247
14,0.5,0.5,0.5816326530612245,0.035435259342193604,mmlu:formal_logic,validation,0.42821600497700274
126,0.30158731341362,0.6984127163887024,0.5287081339712919,0.16542659392432557,mmlu:formal_logic,test,1.9973368181381375
10,0.30000001192092896,0.30000001192092896,0.5238095238095238,0.25390626192092897,mmlu:global_facts,validation,0.4344910951331258
100,0.17000000178813934,0.17000000178813934,0.49326718639262934,0.3862890768051147,mmlu:global_facts,test,1.6632186030037701
32,0.15625,0.21875,0.5666666666666667,0.31726073287427425,mmlu:high_school_biology,validation,0.7368426700122654
310,0.41290321946144104,0.4161290228366852,0.5440204326923075,0.1265750931155297,mmlu:high_school_biology,test,4.729502980131656
22,0.13636364042758942,0.13636364042758942,0.6228070175438597,0.43288351730866864,mmlu:high_school_chemistry,validation,0.4229963559191674
203,0.16748768091201782,0.16748768091201782,0.581447963800905,0.3993226421877668,mmlu:high_school_chemistry,test,3.061806119978428
9,0.2222222238779068,0.2222222238779068,0.39285714285714285,0.2990451322661506,mmlu:high_school_computer_science,validation,0.38531027804128826
100,0.3700000047683716,0.47999998927116394,0.5420420420420421,0.0493749797344208,mmlu:high_school_computer_science,test,1.736637915018946
18,0.7222222089767456,0.2777777910232544,0.6692307692307693,0.2819010615348816,mmlu:high_school_european_history,validation,0.6428158350754529
165,0.6727272868156433,0.34545454382896423,0.5922589255922588,0.21782668576096045,mmlu:high_school_european_history,test,2.5527187138795853
22,0.4545454680919647,0.4545454680919647,0.7791666666666667,0.0898437337441878,mmlu:high_school_geography,validation,0.5817435330245644
198,0.3636363744735718,0.3636363744735718,0.5440917107583774,0.18006236444820056,mmlu:high_school_geography,test,3.002040575025603
21,0.4285714328289032,0.4285714328289032,0.3472222222222222,0.09207591840199064,mmlu:high_school_government_and_politics,validation,0.4957964960485697
193,0.48704662919044495,0.4715026021003723,0.46400171932086826,0.049485933286538386,mmlu:high_school_government_and_politics,test,3.067615264095366
43,0.41860464215278625,0.44186046719551086,0.4966666666666667,0.08884445040724998,mmlu:high_school_macroeconomics,validation,0.9272365760989487
390,0.34358975291252136,0.36153846979141235,0.5612902285447762,0.1701522552050077,mmlu:high_school_macroeconomics,test,5.757258640835062
29,0.03448275849223137,0.9655172228813171,0.9642857142857143,0.3720366317650367,mmlu:high_school_mathematics,validation,0.6873836249578744
270,0.08148147910833359,0.9185185432434082,0.5611253665689149,0.3232783666363468,mmlu:high_school_mathematics,test,3.8944726260378957
26,0.3076923191547394,0.692307710647583,0.5069444444444445,0.18554685666010928,mmlu:high_school_microeconomics,validation,0.6596871069632471
238,0.32773110270500183,0.5882353186607361,0.5447115384615384,0.07940522362204161,mmlu:high_school_microeconomics,test,3.447604770073667
17,0.23529411852359772,0.23529411852359772,0.47115384615384615,0.2968749859753777,mmlu:high_school_physics,validation,0.5308244668412954
151,0.17880794405937195,0.26490065455436707,0.599910394265233,0.2675134760654525,mmlu:high_school_physics,test,2.304264218779281
60,0.5,0.6166666746139526,0.5700000000000001,0.10735677878061933,mmlu:high_school_psychology,validation,1.1969696481246501
545,0.5064220428466797,0.5174311995506287,0.5106607941382468,0.00877296235583247,mmlu:high_school_psychology,test,8.1834660328459
23,0.1304347813129425,0.8260869383811951,0.6916666666666667,0.2936480822770492,mmlu:high_school_statistics,validation,0.57601392804645
216,0.24074074625968933,0.7037037014961243,0.48780487804878053,0.17053675872308238,mmlu:high_school_statistics,test,3.2966860269661993
22,0.5909090638160706,0.3181818127632141,0.3547008547008548,0.21857243234461005,mmlu:high_school_us_history,validation,0.5700482039246708
204,0.5980392098426819,0.4264705777168274,0.5089464214314274,0.11148132997400621,mmlu:high_school_us_history,test,3.04701182898134
26,0.5384615659713745,0.42307692766189575,0.449404761904762,0.11718750458497268,mmlu:high_school_world_history,validation,0.6408098370302469
237,0.4345991611480713,0.5654008388519287,0.504492102593827,0.022794728540669995,mmlu:high_school_world_history,test,3.5664239719044417
23,0.21739129722118378,0.21739129722118378,0.5555555555555556,0.38383154765419336,mmlu:human_aging,validation,0.514188343891874
223,0.340807169675827,0.340807169675827,0.5645810955961331,0.22356714421858162,mmlu:human_aging,test,3.3604397799354047
12,0.4166666567325592,0.5,0.6857142857142857,0.0517578125,mmlu:human_sexuality,validation,0.38605402782559395
131,0.47328245639801025,0.47328245639801025,0.48901355773726035,0.08614622045109291,mmlu:human_sexuality,test,2.139974426012486
13,0.23076923191547394,0.1538461595773697,0.31666666666666665,0.3753004578443674,mmlu:international_law,validation,0.4628086171578616
121,0.4876033067703247,0.4958677589893341,0.5396391470749043,0.0414837204720363,mmlu:international_law,test,1.9508252490777522
11,0.4545454680919647,0.4545454680919647,0.6166666666666667,0.05610798163847491,mmlu:jurisprudence,validation,0.3615786312147975
108,0.37037035822868347,0.4166666567325592,0.534375,0.09360529979070026,mmlu:jurisprudence,test,1.7145109449047595
18,0.4444444477558136,0.3888888955116272,0.40625,0.1156684226459927,mmlu:logical_fallacies,validation,0.5676703047938645
163,0.42944785952568054,0.4969325065612793,0.5403993855606759,0.006949773595376962,mmlu:logical_fallacies,test,2.5638766470365226
11,0.27272728085517883,0.7272727489471436,0.7916666666666666,0.20738635279915552,mmlu:machine_learning,validation,0.4439215899910778
112,0.2857142984867096,0.4732142984867096,0.6294921875,0.0416434236935207,mmlu:machine_learning,test,1.733663705876097
11,0.4545454680919647,0.6363636255264282,0.7166666666666667,0.12073863636363635,mmlu:management,validation,0.4036377379670739
103,0.4563106894493103,0.49514561891555786,0.617211246200608,0.024082231290132095,mmlu:management,test,1.6220919359475374
25,0.2800000011920929,0.2800000011920929,0.5357142857142857,0.2890625095367432,mmlu:marketing,validation,0.6113121409434825
234,0.4572649598121643,0.4572649598121643,0.6134373390242107,0.13171076061379197,mmlu:marketing,test,3.493334769969806
11,0.7272727489471436,0.7272727489471436,0.33333333333333337,0.0767045400359414,mmlu:medical_genetics,validation,0.41460936795920134
100,0.4699999988079071,0.4699999988079071,0.6991168205539943,0.17519533991813663,mmlu:medical_genetics,test,1.6419942558277398
86,0.5465116500854492,0.45348837971687317,0.5324604473540644,0.07553599047106369,mmlu:miscellaneous,validation,1.398151980014518
783,0.5874840617179871,0.4636015295982361,0.525121146856912,0.06468510330865207,mmlu:miscellaneous,test,11.261562573956326
38,0.42105263471603394,0.42105263471603394,0.5411931818181819,0.13312089756915446,mmlu:moral_disputes,validation,0.7878842640202492
346,0.41040462255477905,0.41329479217529297,0.5634320629660315,0.1448360573005125,mmlu:moral_disputes,test,5.198916955851018
100,0.3499999940395355,0.5299999713897705,0.4778021978021978,0.02042969942092898,mmlu:moral_scenarios,validation,1.5717341511044651
895,0.3173184394836426,0.5977653861045837,0.49465779949747585,0.08858678427488442,mmlu:moral_scenarios,test,13.002537983004004
33,0.3636363744735718,0.3636363744735718,0.5793650793650793,0.18667138706554065,mmlu:nutrition,validation,0.7812737578060478
306,0.38235294818878174,0.38235294818878174,0.5803599692488581,0.16844108057957072,mmlu:nutrition,test,4.631750338012353
34,0.29411765933036804,0.29411765933036804,0.49374999999999997,0.2543657842804404,mmlu:philosophy,validation,0.7484185539651662
311,0.3247588276863098,0.3279742896556854,0.4985148514851485,0.2226688079895314,mmlu:philosophy,test,4.635820596013218
35,0.3142857253551483,0.2857142984867096,0.5984848484848484,0.2660714217594692,mmlu:prehistory,validation,0.8275439930148423
324,0.4166666567325592,0.4444444477558136,0.5732510288065845,0.10665024725007424,mmlu:prehistory,test,4.668425654992461
31,0.12903225421905518,0.16129031777381897,0.35185185185185186,0.3883568298432135,mmlu:professional_accounting,validation,0.6730209430679679
282,0.152482271194458,0.1631205677986145,0.546219713924297,0.3865386847908615,mmlu:professional_accounting,test,4.352938955882564
170,0.3117647171020508,0.6882352828979492,0.528785679729076,0.12853861977072323,mmlu:professional_law,validation,2.768143097870052
1534,0.2777053415775299,0.721642792224884,0.5259455348214438,0.1625600827097737,mmlu:professional_law,test,22.53899979405105
31,0.4193548262119293,0.4193548262119293,0.4850427350427351,0.10609878839985015,mmlu:professional_medicine,validation,0.7287000128999352
272,0.27941176295280457,0.5477941036224365,0.5440051020408163,0.020737602430231483,mmlu:professional_medicine,test,4.058425041846931
69,0.3913043439388275,0.3913043439388275,0.5806878306878306,0.14362546412841132,mmlu:professional_psychology,validation,1.3512817339506
612,0.30882352590560913,0.3611111044883728,0.49807372384204535,0.17114733987384373,mmlu:professional_psychology,test,8.495416412129998
12,0.4166666567325592,0.3333333432674408,0.5571428571428572,0.1914062301317851,mmlu:public_relations,validation,0.3715975577943027
110,0.3181818127632141,0.3181818127632141,0.5264761904761904,0.2028053944761103,mmlu:public_relations,test,1.6344141939189285
27,0.5925925970077515,0.5925925970077515,0.5965909090909092,0.017216413109390774,mmlu:security_studies,validation,0.6379778790287673
245,0.5306122303009033,0.5265306234359741,0.5770903010033445,0.050462392641573525,mmlu:security_studies,test,3.3909246081020683
22,0.3181818127632141,0.7272727489471436,0.6666666666666666,0.21004972674629907,mmlu:sociology,validation,0.5092572241555899
201,0.3781094551086426,0.6318408250808716,0.6104736842105263,0.11048272326217956,mmlu:sociology,test,2.9243760388344526
11,0.6363636255264282,0.6363636255264282,0.5714285714285714,0.19176137447357175,mmlu:us_foreign_policy,validation,0.36305223288945854
100,0.5799999833106995,0.5799999833106995,0.5264778325123153,0.014687484502792328,mmlu:us_foreign_policy,test,1.542570326011628
18,0.5,0.5,0.4506172839506173,0.13324652777777776,mmlu:virology,validation,0.49450443987734616
166,0.3313252925872803,0.3313252925872803,0.5324324324324323,0.2783791279218283,mmlu:virology,test,2.4108745420817286
19,0.7368420958518982,0.5263158082962036,0.5642857142857143,0.013980250609548439,mmlu:world_religions,validation,0.4892449378967285
171,0.5847952961921692,0.5029239654541016,0.4919014084507042,0.012769568733304593,mmlu:world_religions,test,2.4388919218908995
