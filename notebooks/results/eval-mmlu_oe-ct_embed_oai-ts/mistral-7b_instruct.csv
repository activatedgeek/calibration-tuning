N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.7272727489471436,0.6666666666666667,0.16299716992811722,mmlu:abstract_algebra,validation,1.9480207820888609
100,0.30000001192092896,0.6399999856948853,0.4633333333333333,0.06683594286441805,mmlu:abstract_algebra,test,1.4419669460039586
14,0.3571428656578064,0.3571428656578064,0.6222222222222222,0.3155691964285714,mmlu:anatomy,validation,0.49914346099831164
135,0.5185185074806213,0.5111111402511597,0.592967032967033,0.15162035977398908,mmlu:anatomy,test,1.9083501570858061
16,0.5,0.5,0.7578125,0.3647460713982582,mmlu:astronomy,validation,0.5806057429872453
152,0.6907894611358643,0.6907894611358643,0.6519756838905775,0.16493625664397288,mmlu:astronomy,test,2.0440223871264607
11,0.5454545617103577,0.7272727489471436,0.8166666666666667,0.17613635279915552,mmlu:business_ethics,validation,0.5092895200941712
100,0.4300000071525574,0.699999988079071,0.7435740514075888,0.1504687690734863,mmlu:business_ethics,test,1.5797448970843107
29,0.4137931168079376,0.6206896305084229,0.7941176470588236,0.08984374383400227,mmlu:clinical_knowledge,validation,0.7555177689064294
265,0.4226415157318115,0.5622641444206238,0.6486636321195145,0.01832250761535937,mmlu:clinical_knowledge,test,3.5110444761812687
16,0.375,0.375,0.55,0.2109375074505806,mmlu:college_biology,validation,0.4318594478536397
144,0.4791666567325592,0.5763888955116272,0.6615458937198069,0.00670028602083526,mmlu:college_biology,test,1.984825620893389
8,0.0,0.0,,0.6279296800494194,mmlu:college_chemistry,validation,0.3831918879877776
100,0.25999999046325684,0.25999999046325684,0.6483887733887734,0.3786328208446503,mmlu:college_chemistry,test,1.5179713438265026
11,0.1818181872367859,0.9090909361839294,0.8333333333333334,0.26278410174629907,mmlu:college_computer_science,validation,0.46531990612857044
100,0.3100000023841858,0.6600000262260437,0.6498363721365125,0.06718750536441805,mmlu:college_computer_science,test,1.5503045439254493
11,0.09090909361839294,0.9090909361839294,0.7,0.05326702378012914,mmlu:college_mathematics,validation,0.47339380509220064
100,0.14000000059604645,0.8500000238418579,0.6623754152823921,0.06406250000000001,mmlu:college_mathematics,test,1.4963603159412742
22,0.40909090638160706,0.3181818127632141,0.41025641025641024,0.35298294912685046,mmlu:college_medicine,validation,0.5954595122020692
173,0.4624277353286743,0.4624277353286743,0.6206989247311827,0.21610820431240726,mmlu:college_medicine,test,2.2413522659335285
11,0.1818181872367859,0.3636363744735718,0.6666666666666667,0.22940341992811725,mmlu:college_physics,validation,0.463222524151206
102,0.19607843458652496,0.3529411852359772,0.5542682926829269,0.2620251225490196,mmlu:college_physics,test,1.4855047648306936
11,0.8181818127632141,0.4545454680919647,0.7222222222222223,0.1257102435285395,mmlu:computer_security,validation,0.4911708799190819
100,0.6800000071525574,0.4699999988079071,0.5700827205882353,0.10953125953674318,mmlu:computer_security,test,1.4107987550087273
26,0.38461539149284363,0.42307692766189575,0.70625,0.21499398809212908,mmlu:conceptual_physics,validation,0.7599274360109121
235,0.46382978558540344,0.5063830018043518,0.585590505315276,0.09630983865007439,mmlu:conceptual_physics,test,3.0466007629875094
12,0.4166666567325592,0.5,0.5857142857142857,0.09830730656782788,mmlu:econometrics,validation,0.46867707115598023
114,0.31578946113586426,0.4912280738353729,0.593482905982906,0.08374451597531637,mmlu:econometrics,test,1.5981699079275131
16,0.3125,0.6875,0.4727272727272728,0.05566405504941936,mmlu:electrical_engineering,validation,0.46683895983733237
145,0.43448275327682495,0.565517246723175,0.6319202477739063,0.07790949467954966,mmlu:electrical_engineering,test,1.9613470190670341
41,0.3658536672592163,0.6341463327407837,0.6743589743589744,0.05706936702495665,mmlu:elementary_mathematics,validation,0.8885214398615062
378,0.45502644777297974,0.49735450744628906,0.5071686610973132,0.06954776121195029,mmlu:elementary_mathematics,test,4.5856600070837885
14,0.2857142984867096,0.7142857313156128,0.6124999999999999,0.1420200892857143,mmlu:formal_logic,validation,0.3019475981127471
126,0.380952388048172,0.6190476417541504,0.5797275641025641,0.06783232802436465,mmlu:formal_logic,test,1.5023284810595214
10,0.5,0.4000000059604645,0.48,0.17421875,mmlu:global_facts,validation,0.3032372030429542
100,0.20999999344348907,0.25999999046325684,0.5527426160337553,0.3214452916383743,mmlu:global_facts,test,1.2394518840592355
32,0.40625,0.40625,0.6761133603238867,0.28625488840043545,mmlu:high_school_biology,validation,0.5254422959405929
310,0.57419353723526,0.57419353723526,0.6454502894109635,0.14121723251958046,mmlu:high_school_biology,test,3.516580011928454
22,0.22727273404598236,0.22727273404598236,0.6411764705882353,0.5850497267462991,mmlu:high_school_chemistry,validation,0.3876915709115565
203,0.2807881832122803,0.2807881832122803,0.5266762797404471,0.514682114711536,mmlu:high_school_chemistry,test,2.3723165311384946
9,0.4444444477558136,0.6666666865348816,0.725,0.125,mmlu:high_school_computer_science,validation,0.31021680496633053
100,0.5099999904632568,0.5799999833106995,0.6596638655462186,0.08585939407348633,mmlu:high_school_computer_science,test,1.2053842681925744
18,0.8333333134651184,0.7222222089767456,0.34444444444444444,0.08919269177648755,mmlu:high_school_european_history,validation,0.4043264559004456
165,0.8060606122016907,0.7272727489471436,0.4910714285714285,0.0945549285773075,mmlu:high_school_european_history,test,2.0220155380666256
22,0.3636363744735718,0.3636363744735718,0.8214285714285714,0.316406252709302,mmlu:high_school_geography,validation,0.38909005699679255
198,0.4595959484577179,0.4595959484577179,0.5947930574098798,0.22589174936516118,mmlu:high_school_geography,test,2.2274975168984383
21,0.761904776096344,0.9047619104385376,0.9500000000000001,0.32049851474307833,mmlu:high_school_government_and_politics,validation,0.3777794069610536
193,0.6269429922103882,0.6269429922103882,0.6109389348025711,0.05622572478852737,mmlu:high_school_government_and_politics,test,2.3257849840447307
43,0.5116279125213623,0.5116279125213623,0.528138528138528,0.16124635518983352,mmlu:high_school_macroeconomics,validation,0.6306334708351642
390,0.5102564096450806,0.5076923370361328,0.5408324344234261,0.1476863063298739,mmlu:high_school_macroeconomics,test,4.3279680360574275
29,0.13793103396892548,0.8620689511299133,0.43999999999999995,0.045797417903768595,mmlu:high_school_mathematics,validation,0.5055998938623816
270,0.11481481790542603,0.885185182094574,0.508098258874342,0.015060760798277673,mmlu:high_school_mathematics,test,2.9782064938917756
26,0.38461539149284363,0.38461539149284363,0.6093750000000001,0.3463041094633249,mmlu:high_school_microeconomics,validation,0.47326343785971403
238,0.45798319578170776,0.45798319578170776,0.5948012232415902,0.27348671941196223,mmlu:high_school_microeconomics,test,2.6676602319348603
17,0.1764705926179886,0.7647058963775635,0.8333333333333334,0.18267463936525236,mmlu:high_school_physics,validation,0.4132074050139636
151,0.38410595059394836,0.5761589407920837,0.6038190582128291,0.05528249922177651,mmlu:high_school_physics,test,1.757429325953126
60,0.6333333253860474,0.4333333373069763,0.5777511961722488,0.15657551685969034,mmlu:high_school_psychology,validation,0.8741680111270398
545,0.6091743111610413,0.42385321855545044,0.5251004016064258,0.1606723247318093,mmlu:high_school_psychology,test,5.941282409941778
23,0.30434781312942505,0.6521739363670349,0.3883928571428571,0.07625679347826084,mmlu:high_school_statistics,validation,0.39141219900920987
216,0.40740740299224854,0.6157407164573669,0.5846946022727272,0.04568142029974198,mmlu:high_school_statistics,test,2.4868554410059005
22,0.8181818127632141,0.8181818127632141,0.5625,0.24875711310993542,mmlu:high_school_us_history,validation,0.39633029396645725
204,0.7352941036224365,0.6813725233078003,0.6024691358024692,0.10880054153648076,mmlu:high_school_us_history,test,2.359963078983128
26,0.692307710647583,0.7307692170143127,0.6701388888888888,0.176832921229876,mmlu:high_school_world_history,validation,0.5010371669195592
237,0.7257384061813354,0.5569620132446289,0.4935599284436494,0.02183874900833969,mmlu:high_school_world_history,test,2.661255342885852
23,0.43478259444236755,0.43478259444236755,0.6153846153846154,0.27751356622447143,mmlu:human_aging,validation,0.40118123800493777
223,0.46188339591026306,0.46188339591026306,0.6398058252427186,0.19839547140181335,mmlu:human_aging,test,2.4861229727976024
12,0.5,0.5,0.1111111111111111,0.3203125099341074,mmlu:human_sexuality,validation,0.31109908618964255
131,0.6030534505844116,0.6030534505844116,0.4870983446932814,0.11184994819510076,mmlu:human_sexuality,test,1.5826120870187879
13,0.6153846383094788,0.6153846383094788,0.5125,0.2815504807692307,mmlu:international_law,validation,0.30212865490466356
121,0.7851239442825317,0.7851239442825317,0.5406882591093117,0.05911026365500834,mmlu:international_law,test,1.4794893101789057
11,0.7272727489471436,0.7272727489471436,0.6458333333333333,0.13778409632769498,mmlu:jurisprudence,validation,0.3108059191145003
108,0.7407407164573669,0.7222222089767456,0.5412946428571429,0.1414568943006021,mmlu:jurisprudence,test,1.338100312044844
18,0.6666666865348816,0.5555555820465088,0.4305555555555555,0.02690972222222222,mmlu:logical_fallacies,validation,0.3772695008665323
163,0.5889570713043213,0.6441717743873596,0.6326958955223881,0.09147334098815918,mmlu:logical_fallacies,test,1.9206287830602378
11,0.4545454680919647,0.3636363744735718,0.5,0.23366477272727273,mmlu:machine_learning,validation,0.30657715001143515
112,0.4642857015132904,0.4732142984867096,0.5625,0.1456124463251659,mmlu:machine_learning,test,1.3088142059277743
11,0.6363636255264282,0.5454545617103577,0.6785714285714286,0.006036920980973637,mmlu:management,validation,0.31768173817545176
103,0.49514561891555786,0.6699029207229614,0.7601809954751132,0.122648641322423,mmlu:management,test,1.2389635920990258
25,0.36000001430511475,0.4399999976158142,0.8090277777777778,0.09671872615814209,mmlu:marketing,validation,0.4782275138422847
234,0.4444444477558136,0.5170940160751343,0.5600591715976332,0.022702974131983515,mmlu:marketing,test,2.62205038103275
11,0.7272727489471436,0.7272727489471436,0.35416666666666663,0.18075284090909094,mmlu:medical_genetics,validation,0.32556980405934155
100,0.5600000023841858,0.5600000023841858,0.6475243506493507,0.1827734398841858,mmlu:medical_genetics,test,1.2436784219462425
86,0.6744186282157898,0.6860465407371521,0.6708743842364532,0.1380359475002732,mmlu:miscellaneous,validation,1.085051042959094
783,0.6666666865348816,0.6768837571144104,0.6243742751868,0.12815792517948277,mmlu:miscellaneous,test,8.403450710931793
38,0.6315789222717285,0.6052631735801697,0.44642857142857145,0.08120890040146679,mmlu:moral_disputes,validation,0.599675073986873
346,0.5780346989631653,0.5664739608764648,0.5355650684931507,0.023787476768383428,mmlu:moral_disputes,test,3.864754581125453
100,0.5,0.5,0.5884,0.08042968571186065,mmlu:moral_scenarios,validation,1.2361483110580593
895,0.5307262539863586,0.46927374601364136,0.5466942355889725,0.1116358136331569,mmlu:moral_scenarios,test,9.513180769048631
33,0.5454545617103577,0.5454545617103577,0.7407407407407407,0.22419505588936084,mmlu:nutrition,validation,0.6019220950547606
306,0.5522875785827637,0.5522875785827637,0.5821059905843735,0.20893329596207805,mmlu:nutrition,test,3.4136994290165603
34,0.47058823704719543,0.5,0.5364583333333334,0.039292279411764705,mmlu:philosophy,validation,0.5910979679320008
311,0.4308681786060333,0.5755627155303955,0.5670166118559743,0.025911903458009596,mmlu:philosophy,test,3.4264366740826517
35,0.4571428596973419,0.4285714328289032,0.37500000000000006,0.1752232074737549,mmlu:prehistory,validation,0.5463083339855075
324,0.5555555820465088,0.5586419701576233,0.5826581790123456,0.06649066636591787,mmlu:prehistory,test,3.6740922720637172
31,0.25806450843811035,0.7419354915618896,0.625,0.08228325074718842,mmlu:professional_accounting,validation,0.49037855491042137
282,0.20921985805034637,0.7907801270484924,0.7004636315269438,0.10811445793361531,mmlu:professional_accounting,test,3.160264411009848
170,0.4647058844566345,0.5529412031173706,0.5849214077062178,0.010248142480850183,mmlu:professional_law,validation,2.116692296927795
1534,0.36245110630989075,0.47588005661964417,0.5252800826823203,0.0716901183750048,mmlu:professional_law,test,16.641421914100647
31,0.4193548262119293,0.4193548262119293,0.4551282051282051,0.18901211792422878,mmlu:professional_medicine,validation,0.48761594598181546
272,0.375,0.38235294818878174,0.5059688581314878,0.22588752385448005,mmlu:professional_medicine,test,3.0183344727847725
69,0.5362318754196167,0.47826087474823,0.45228040540540543,0.0800497911978459,mmlu:professional_psychology,validation,0.8907803280744702
612,0.4395424723625183,0.5784313678741455,0.5506790076625445,0.018561085065205856,mmlu:professional_psychology,test,6.705159951001406
12,0.4166666567325592,0.5,0.5,0.06510416169961289,mmlu:public_relations,validation,0.3024745690636337
110,0.37272727489471436,0.5454545617103577,0.5966772711205374,0.034943159060044734,mmlu:public_relations,test,1.303256592946127
27,0.6666666865348816,0.6296296119689941,0.6049382716049383,0.06423613097932607,mmlu:security_studies,validation,0.48026837198995054
245,0.7877551317214966,0.7102040648460388,0.6951474691111997,0.15188139677047727,mmlu:security_studies,test,2.770948362071067
22,0.6818181872367859,0.6818181872367859,0.6619047619047619,0.08220881765539,mmlu:sociology,validation,0.39112775097601116
201,0.5671641826629639,0.572139322757721,0.5349364791288566,0.024933933618649925,mmlu:sociology,test,2.364818047033623
11,0.9090909361839294,0.7272727489471436,0.7,0.18217329545454541,mmlu:us_foreign_policy,validation,0.30171699402853847
100,0.7900000214576721,0.5400000214576721,0.6675708257986739,0.0015234565734862926,mmlu:us_foreign_policy,test,1.2152822010684758
18,0.6666666865348816,0.6666666865348816,0.5625,0.10308161377906803,mmlu:virology,validation,0.3836569811683148
166,0.6867470145225525,0.6867470145225525,0.6439777327935222,0.09174979523003823,mmlu:virology,test,1.8648167359642684
19,0.6315789222717285,0.6315789222717285,0.6488095238095238,0.1829769830954702,mmlu:world_religions,validation,0.400368379894644
171,0.6900584697723389,0.6900584697723389,0.5731531819635434,0.10037465332544342,mmlu:world_religions,test,1.9371916290838271
