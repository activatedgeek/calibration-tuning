N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.5454545617103577,0.9,0.15269887989217587,mmlu:abstract_algebra,validation,1.9563855400774628
100,0.23000000417232513,0.550000011920929,0.6880293619424056,0.02886717259883883,mmlu:abstract_algebra,test,1.6813816060312092
14,0.2142857164144516,0.2142857164144516,0.24242424242424238,0.3278460076877049,mmlu:anatomy,validation,0.3885707769077271
135,0.45185184478759766,0.46666666865348816,0.588059370846256,0.07462386996657763,mmlu:anatomy,test,2.0773302339948714
16,0.25,0.4375,0.6770833333333334,0.12011719495058057,mmlu:astronomy,validation,0.42802309710532427
152,0.5131579041481018,0.5526315569877625,0.5550935550935551,0.013337776849144424,mmlu:astronomy,test,2.370552538894117
11,0.4545454680919647,0.4545454680919647,0.5666666666666667,0.06889204545454547,mmlu:business_ethics,validation,0.4032614850439131
100,0.3199999928474426,0.5,0.5615808823529411,0.033554673194885254,mmlu:business_ethics,test,1.6611004720907658
29,0.24137930572032928,0.27586206793785095,0.6428571428571429,0.2530980397915018,mmlu:clinical_knowledge,validation,0.5730948599521071
265,0.3207547068595886,0.4528301954269409,0.6197712418300654,0.0857458609455037,mmlu:clinical_knowledge,test,4.060157031985
16,0.25,0.25,0.9375,0.416015625,mmlu:college_biology,validation,0.4331455370411277
144,0.3958333432674408,0.3958333432674408,0.5667473280903408,0.24970159803827605,mmlu:college_biology,test,2.20117356791161
8,0.125,0.125,0.8571428571428572,0.5390625,mmlu:college_chemistry,validation,0.2697276941034943
100,0.15000000596046448,0.15000000596046448,0.580392156862745,0.5181640481948853,mmlu:college_chemistry,test,1.6880488200113177
11,0.1818181872367859,0.8181818127632141,0.7777777777777778,0.18963069265538993,mmlu:college_computer_science,validation,0.3932120380923152
100,0.2199999988079071,0.7099999785423279,0.49446386946386944,0.08917968273162843,mmlu:college_computer_science,test,1.6083298311568797
11,0.1818181872367859,0.8181818127632141,0.9444444444444444,0.22017045454545453,mmlu:college_mathematics,validation,0.3396270149387419
100,0.10000000149011612,0.8899999856948853,0.5438888888888889,0.11519530534744263,mmlu:college_mathematics,test,1.6828415649943054
22,0.5,0.4545454680919647,0.5702479338842976,0.2936789799820293,mmlu:college_medicine,validation,0.5310188899748027
173,0.3583815097808838,0.3815028965473175,0.5211421098517872,0.2122019574132269,mmlu:college_medicine,test,2.7405962799675763
11,0.3636363744735718,0.27272728085517883,0.23214285714285715,0.2826704653826627,mmlu:college_physics,validation,0.36397896287962794
102,0.21568627655506134,0.30392158031463623,0.4715909090909091,0.24329811217738131,mmlu:college_physics,test,1.6829515530262142
11,0.3636363744735718,0.6363636255264282,0.7321428571428571,0.11150569807399402,mmlu:computer_security,validation,0.4098199491854757
100,0.46000000834465027,0.5099999904632568,0.48329307568438,0.020234359502792378,mmlu:computer_security,test,1.5543475721497089
26,0.3461538553237915,0.5,0.5,0.026141822338104248,mmlu:conceptual_physics,validation,0.6506704660132527
235,0.44255319237709045,0.5659574270248413,0.5869054609512624,0.040857692475014584,mmlu:conceptual_physics,test,3.549326080130413
12,0.0833333358168602,0.9166666865348816,0.8181818181818181,0.314453125,mmlu:econometrics,validation,0.3906946210190654
114,0.19298245012760162,0.8070175647735596,0.6178359683794467,0.20459839701652527,mmlu:econometrics,test,1.8953466478269547
16,0.375,0.375,0.24166666666666664,0.2001953274011612,mmlu:electrical_engineering,validation,0.40392616810277104
145,0.2344827651977539,0.2620689570903778,0.5549814520402756,0.3107489166588619,mmlu:electrical_engineering,test,2.357584276003763
41,0.2926829159259796,0.6829268336296082,0.4885057471264367,0.06869283100453816,mmlu:elementary_mathematics,validation,0.9196339449845254
378,0.4021163880825043,0.5925925970077515,0.4768717978574756,0.08360200237344811,mmlu:elementary_mathematics,test,5.625231716083363
14,0.3571428656578064,0.6428571343421936,0.2777777777777778,0.1093750085149493,mmlu:formal_logic,validation,0.42557226098142564
126,0.190476194024086,0.7698412537574768,0.4736519607843137,0.2450086635256571,mmlu:formal_logic,test,2.060011673020199
10,0.30000001192092896,0.5,0.5714285714285714,0.033984363079071045,mmlu:global_facts,validation,0.38185556302778423
100,0.23999999463558197,0.6100000143051147,0.5095942982456141,0.08011716127395631,mmlu:global_facts,test,1.6947589938063174
32,0.34375,0.34375,0.538961038961039,0.3470458947122097,mmlu:high_school_biology,validation,0.6999597270041704
310,0.47096773982048035,0.4741935431957245,0.5418894086201136,0.19838709081372907,mmlu:high_school_biology,test,4.829884400125593
22,0.04545454680919647,0.04545454680919647,0.04761904761904767,0.634765630418604,mmlu:high_school_chemistry,validation,0.5043812550138682
203,0.19704432785511017,0.19704432785511017,0.48389570552147243,0.47881388605521824,mmlu:high_school_chemistry,test,3.1515067748259753
9,0.2222222238779068,0.6666666865348816,0.4285714285714286,0.12326389551162723,mmlu:high_school_computer_science,validation,0.4504961599595845
100,0.41999998688697815,0.6000000238418579,0.5004105090311987,0.10874999880790712,mmlu:high_school_computer_science,test,1.5839928579516709
18,0.7222222089767456,0.2777777910232544,0.14615384615384613,0.2814670337571038,mmlu:high_school_european_history,validation,0.5463350228965282
165,0.6000000238418579,0.46666666865348816,0.5692531374349556,0.10643940008047856,mmlu:high_school_european_history,test,2.581321839010343
22,0.40909090638160706,0.6363636255264282,0.6581196581196581,0.1157670725475658,mmlu:high_school_geography,validation,0.5556158779654652
198,0.3787878751754761,0.6161616444587708,0.5812466124661247,0.0906526163370922,mmlu:high_school_geography,test,2.902355433208868
21,0.4761904776096344,0.4761904776096344,0.48636363636363633,0.06956842683610465,mmlu:high_school_government_and_politics,validation,0.514885175973177
193,0.5544041395187378,0.4455958604812622,0.5173875244512062,0.08923656304265554,mmlu:high_school_government_and_politics,test,3.0920200750697404
43,0.41860464215278625,0.5116279125213623,0.5700000000000001,0.05804871819740119,mmlu:high_school_macroeconomics,validation,0.8517981339246035
390,0.34358975291252136,0.571794867515564,0.6252040578358209,0.03397435897435899,mmlu:high_school_macroeconomics,test,5.880525284912437
29,0.13793103396892548,0.8620689511299133,0.585,0.14964980914674955,mmlu:high_school_mathematics,validation,0.7123379439581186
270,0.10000000149011612,0.8999999761581421,0.5643956713915561,0.14474826918707956,mmlu:high_school_mathematics,test,4.084867052035406
26,0.38461539149284363,0.38461539149284363,0.46875,0.16195914837030262,mmlu:high_school_microeconomics,validation,0.65907265804708
238,0.3781512677669525,0.39915966987609863,0.5009009009009009,0.1510471523809834,mmlu:high_school_microeconomics,test,3.769038455095142
17,0.11764705926179886,0.11764705926179886,0.6,0.4595588410601896,mmlu:high_school_physics,validation,0.5359695069491863
151,0.20529800653457642,0.2384105920791626,0.533467741935484,0.3427411049407049,mmlu:high_school_physics,test,2.3817965160124004
60,0.6000000238418579,0.5666666626930237,0.5810185185185184,0.0527994672457377,mmlu:high_school_psychology,validation,1.122700918931514
545,0.5357798337936401,0.5211009383201599,0.5437422166874222,0.006436327072458559,mmlu:high_school_psychology,test,7.982381250010803
23,0.043478261679410934,0.95652174949646,0.2272727272727273,0.36345110768857214,mmlu:high_school_statistics,validation,0.4882108080200851
216,0.25925925374031067,0.7268518805503845,0.5853236607142857,0.13541665342119005,mmlu:high_school_statistics,test,3.3736132530029863
22,0.5909090638160706,0.3636363744735718,0.2692307692307693,0.1663707603107799,mmlu:high_school_us_history,validation,0.5335156889632344
204,0.6225489974021912,0.5784313678741455,0.5556294099601186,0.03760722922343837,mmlu:high_school_us_history,test,3.152976268902421
26,0.6153846383094788,0.3076923191547394,0.5,0.25270430858318627,mmlu:high_school_world_history,validation,0.6668423190712929
237,0.5274261832237244,0.49789029359817505,0.58775,0.06896097046413499,mmlu:high_school_world_history,test,3.5367475219536573
23,0.3478260934352875,0.3913043439388275,0.4291666666666667,0.17832880175631982,mmlu:human_aging,validation,0.5600270188879222
223,0.3497757911682129,0.37219730019569397,0.5523430592396111,0.1968714961022005,mmlu:human_aging,test,3.5011061548721045
12,0.25,0.5,0.42592592592592593,0.08430991073449454,mmlu:human_sexuality,validation,0.38698570989072323
131,0.442748099565506,0.5267175436019897,0.5831365139348134,0.02576337834350939,mmlu:human_sexuality,test,2.0510301920585334
13,0.3076923191547394,0.3076923191547394,0.4444444444444444,0.24639423076923078,mmlu:international_law,validation,0.3733378481119871
121,0.5206611752510071,0.5702479481697083,0.5519978106185003,0.013591157503364483,mmlu:international_law,test,2.027401812141761
11,0.3636363744735718,0.3636363744735718,0.5892857142857142,0.25745738636363635,mmlu:jurisprudence,validation,0.40466038091108203
108,0.39814814925193787,0.39814814925193787,0.5651162790697674,0.1944806112183465,mmlu:jurisprudence,test,1.8481161259114742
18,0.5555555820465088,0.5555555820465088,0.40625,0.06966147489017908,mmlu:logical_fallacies,validation,0.5213328530080616
163,0.4601227045059204,0.4601227045059204,0.5963636363636365,0.15819113642160149,mmlu:logical_fallacies,test,2.6588323910254985
11,0.4545454680919647,0.7272727489471436,0.9333333333333333,0.16583804650740186,mmlu:machine_learning,validation,0.430495219072327
112,0.2232142835855484,0.5625,0.45816091954022986,0.038434701838663626,mmlu:machine_learning,test,1.76941779977642
11,0.8181818127632141,0.4545454680919647,0.0,0.07350854440168902,mmlu:management,validation,0.4009156269021332
103,0.43689319491386414,0.5631067752838135,0.6770114942528735,0.02264105926439605,mmlu:management,test,1.681636261055246
25,0.36000001430511475,0.36000001430511475,0.5659722222222222,0.20578124761581423,mmlu:marketing,validation,0.6352445450611413
234,0.5170940160751343,0.5299145579338074,0.579280333503986,0.034054495839991136,mmlu:marketing,test,3.5711681391112506
11,0.7272727489471436,0.7272727489471436,0.4375,0.03267044370824641,mmlu:medical_genetics,validation,0.3618281539529562
100,0.4699999988079071,0.4699999988079071,0.5389401846647932,0.20781249761581422,mmlu:medical_genetics,test,1.646340447012335
86,0.604651153087616,0.5581395626068115,0.6948529411764707,0.005359749461329231,mmlu:miscellaneous,validation,1.5147780559491366
783,0.6168582439422607,0.5517241358757019,0.6074672187715665,0.009937766639665675,mmlu:miscellaneous,test,11.427781648002565
38,0.3947368562221527,0.3947368562221527,0.4478260869565217,0.21175986528396606,mmlu:moral_disputes,validation,0.7900805480312556
346,0.424855500459671,0.424855500459671,0.5354493556216458,0.1784682282478134,mmlu:moral_disputes,test,5.291883175959811
100,0.47999998927116394,0.5199999809265137,0.4905849358974359,0.03832028388977049,mmlu:moral_scenarios,validation,1.6503492719493806
895,0.44134077429771423,0.5586591958999634,0.4998025316455697,0.0023873735406545298,mmlu:moral_scenarios,test,13.15419560088776
33,0.3030303120613098,0.3636363744735718,0.5826086956521739,0.21034564393939395,mmlu:nutrition,validation,0.7759995460510254
306,0.36274510622024536,0.3921568691730499,0.5057288057288057,0.1715175774362352,mmlu:nutrition,test,4.630212754011154
34,0.3235294222831726,0.3235294222831726,0.43478260869565216,0.2187500105184667,mmlu:philosophy,validation,0.777598086046055
311,0.34405145049095154,0.34405145049095154,0.5412085394905625,0.20024869200501028,mmlu:philosophy,test,4.669565701857209
35,0.3142857253551483,0.3142857253551483,0.5833333333333333,0.36328127554484774,mmlu:prehistory,validation,0.80475670308806
324,0.48148149251937866,0.48148149251937866,0.5471802503052503,0.18150800963242852,mmlu:prehistory,test,4.870469225104898
31,0.09677419066429138,0.5161290168762207,0.3333333333333333,0.07673889590847874,mmlu:professional_accounting,validation,0.685732290847227
282,0.14539006352424622,0.5921986103057861,0.5534864892217387,0.049035917782614465,mmlu:professional_accounting,test,4.3307724869810045
170,0.364705890417099,0.6176470518112183,0.47334229390681004,0.04965530914418837,mmlu:professional_law,validation,2.6194642880000174
1534,0.29400262236595154,0.6994785070419312,0.5019798007096162,0.13004197325980024,mmlu:professional_law,test,22.44217632804066
31,0.35483869910240173,0.6451612710952759,0.5272727272727273,0.06426412636233918,mmlu:professional_medicine,validation,0.7055507481563836
272,0.3345588147640228,0.6617646813392639,0.554337927266104,0.07693303332609291,mmlu:professional_medicine,test,4.070883438922465
69,0.3913043439388275,0.5652173757553101,0.4779541446208113,0.044780325198519044,mmlu:professional_psychology,validation,1.2629249319434166
612,0.3006536066532135,0.6944444179534912,0.5307166802112964,0.10814312840598865,mmlu:professional_psychology,test,9.143299642018974
12,0.25,0.5,0.25925925925925924,0.024739563465118408,mmlu:public_relations,validation,0.39237650111317635
110,0.30909091234207153,0.6000000238418579,0.5499226006191951,0.07794741392135618,mmlu:public_relations,test,1.8133612610399723
27,0.48148149251937866,0.48148149251937866,0.7362637362637363,0.15422451496124268,mmlu:security_studies,validation,0.5855546130333096
245,0.5265306234359741,0.5306122303009033,0.6135057471264368,0.07330992976013496,mmlu:security_studies,test,3.783918537897989
22,0.5909090638160706,0.5909090638160706,0.670940170940171,0.05149146643551916,mmlu:sociology,validation,0.5298752109520137
201,0.4129353165626526,0.5920398235321045,0.6239534408821727,0.040500618332061,mmlu:sociology,test,3.3005915379617363
11,0.6363636255264282,0.5454545617103577,0.6607142857142857,0.062499989162791855,mmlu:us_foreign_policy,validation,0.41442032414488494
100,0.5699999928474426,0.5199999809265137,0.5469196246430029,0.011406223773956281,mmlu:us_foreign_policy,test,1.68241560109891
18,0.3333333432674408,0.3333333432674408,0.5972222222222222,0.2619357804457347,mmlu:virology,validation,0.48020749911665916
166,0.33734938502311707,0.34337350726127625,0.41915584415584417,0.2472232569413013,mmlu:virology,test,2.6370711559429765
19,0.6315789222717285,0.4736842215061188,0.5357142857142858,0.05777136589351456,mmlu:world_religions,validation,0.5260287020355463
171,0.6432748436927795,0.39181286096572876,0.527645305514158,0.13811220481381778,mmlu:world_religions,test,2.668061346048489
