N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.4545454680919647,0.4545454680919647,0.8333333333333334,0.1946022835644809,mmlu:abstract_algebra,validation,2.1149675329215825
100,0.28999999165534973,0.28999999165534973,0.5274405050995629,0.36699217736721035,mmlu:abstract_algebra,test,1.4272428990807384
14,0.4285714328289032,0.4285714328289032,0.6979166666666666,0.25083703654153006,mmlu:anatomy,validation,0.5017326171509922
135,0.5703703761100769,0.5703703761100769,0.5461262875055979,0.11542244487338593,mmlu:anatomy,test,1.8919080540072173
16,0.375,0.375,0.8083333333333333,0.4013672098517418,mmlu:astronomy,validation,0.46906497492454946
152,0.41447368264198303,0.41447368264198303,0.6358123773854111,0.3691663169547131,mmlu:astronomy,test,2.0104714080225676
11,0.6363636255264282,0.6363636255264282,0.6964285714285714,0.08380681276321414,mmlu:business_ethics,validation,0.4754347871057689
100,0.3499999940395355,0.41999998688697815,0.47120879120879117,0.1362109589576721,mmlu:business_ethics,test,1.520334147149697
29,0.24137930572032928,0.7586206793785095,0.7207792207792209,0.16945043514514788,mmlu:clinical_knowledge,validation,0.6945860278792679
265,0.35849055647850037,0.6113207340240479,0.5472136222910217,0.041804263276873914,mmlu:clinical_knowledge,test,3.3927904861047864
16,0.25,0.3125,0.6770833333333334,0.3488769493997097,mmlu:college_biology,validation,0.46811777306720614
144,0.3958333432674408,0.4097222089767456,0.5594877999596692,0.2484809027777778,mmlu:college_biology,test,1.9658579661045223
8,0.125,0.125,0.35714285714285715,0.6567382887005806,mmlu:college_chemistry,validation,0.3721785661764443
100,0.23000000417232513,0.23000000417232513,0.6784302653867871,0.5417187595367431,mmlu:college_chemistry,test,1.5378181650303304
11,0.09090909361839294,0.5454545617103577,0.6,0.23011364178224045,mmlu:college_computer_science,validation,0.4205469018779695
100,0.20999999344348907,0.5699999928474426,0.4960819770946353,0.08660156905651092,mmlu:college_computer_science,test,1.5071448299568146
11,0.09090909361839294,0.9090909361839294,0.19999999999999996,0.2166193127632141,mmlu:college_mathematics,validation,0.46389845316298306
100,0.20000000298023224,0.7300000190734863,0.5809375,0.053867198228836066,mmlu:college_mathematics,test,1.5487461490556598
22,0.5,0.5,0.7520661157024794,0.23401989178224045,mmlu:college_medicine,validation,0.5953299179673195
173,0.39306357502937317,0.4046242833137512,0.6121848739495799,0.30696801953233044,mmlu:college_medicine,test,2.359476726036519
11,0.4545454680919647,0.4545454680919647,0.5,0.2748579437082464,mmlu:college_physics,validation,0.46613341383636
102,0.23529411852359772,0.2450980395078659,0.5817307692307693,0.4828431518638835,mmlu:college_physics,test,1.5414665250573307
11,0.6363636255264282,0.6363636255264282,0.21428571428571427,0.5156249891627919,mmlu:computer_security,validation,0.47556958300992846
100,0.49000000953674316,0.44999998807907104,0.4723889555822328,0.12050780713558198,mmlu:computer_security,test,1.4572259651031345
26,0.3076923191547394,0.5,0.6944444444444444,0.03620791435241699,mmlu:conceptual_physics,validation,0.6360375450458378
235,0.48085105419158936,0.5702127814292908,0.6208835050050775,0.02283910360742126,mmlu:conceptual_physics,test,3.042158274911344
12,0.5,0.5,0.4027777777777778,0.1946614384651184,mmlu:econometrics,validation,0.48384739900939167
114,0.21929824352264404,0.21929824352264404,0.5382022471910113,0.4754660181831895,mmlu:econometrics,test,1.5415142648853362
16,0.3125,0.375,0.2545454545454545,0.3039550669491291,mmlu:electrical_engineering,validation,0.5064269250724465
145,0.2896551787853241,0.37931033968925476,0.5951225150254277,0.23079202586206898,mmlu:electrical_engineering,test,2.047288642032072
41,0.3658536672592163,0.6341463327407837,0.608974358974359,0.02943979094668129,mmlu:elementary_mathematics,validation,0.7836834131740034
378,0.44708994030952454,0.5476190447807312,0.4522946688938591,0.10308159753759069,mmlu:elementary_mathematics,test,4.5996221150271595
14,0.4285714328289032,0.4285714328289032,0.40625,0.15485492774418422,mmlu:formal_logic,validation,0.3898113491013646
126,0.3095238208770752,0.3492063581943512,0.5004420866489832,0.23328991352565706,mmlu:formal_logic,test,1.618908426957205
10,0.20000000298023224,0.30000001192092896,0.15625,0.25468747615814213,mmlu:global_facts,validation,0.3190639181993902
100,0.1899999976158142,0.4399999976158142,0.6185834957764783,0.1142578113079071,mmlu:global_facts,test,1.297485986026004
32,0.46875,0.46875,0.5588235294117647,0.32263183034956455,mmlu:high_school_biology,validation,0.4684312450699508
310,0.5064516067504883,0.5064516067504883,0.5705840722700971,0.29453125423000714,mmlu:high_school_biology,test,3.7708431179635227
22,0.13636364042758942,0.13636364042758942,0.7456140350877193,0.7077414962378417,mmlu:high_school_chemistry,validation,0.3913151731248945
203,0.2019704431295395,0.2019704431295395,0.5494579945799457,0.6356219332206426,mmlu:high_school_chemistry,test,2.3588154930621386
9,0.4444444477558136,0.3333333432674408,0.2,0.2717013955116272,mmlu:high_school_computer_science,validation,0.3198976879939437
100,0.5699999928474426,0.49000000953674316,0.5371277029783761,0.10300781428813936,mmlu:high_school_computer_science,test,1.3206245040055364
18,0.7222222089767456,0.4444444477558136,0.6,0.1738281117545234,mmlu:high_school_european_history,validation,0.411458658054471
165,0.678787887096405,0.4727272689342499,0.5487702156334232,0.1502604213627902,mmlu:high_school_european_history,test,1.9964831830002367
22,0.3636363744735718,0.40909090638160706,0.8928571428571429,0.22194601189006458,mmlu:high_school_geography,validation,0.4745577990543097
198,0.4444444477558136,0.43939393758773804,0.60625,0.18921635668687148,mmlu:high_school_geography,test,2.3657550590578467
21,0.5714285969734192,0.6666666865348816,0.5,0.23251488095238093,mmlu:high_school_government_and_politics,validation,0.37846900103613734
193,0.5544041395187378,0.5181347131729126,0.5019017604868506,0.06432156241619526,mmlu:high_school_government_and_politics,test,2.2543024490587413
43,0.44186046719551086,0.5581395626068115,0.6732456140350878,0.0039062278215274814,mmlu:high_school_macroeconomics,validation,0.6654232589062303
390,0.3692307770252228,0.5230769515037537,0.5911952348690154,0.027153435120215764,mmlu:high_school_macroeconomics,test,4.488738590152934
29,0.06896551698446274,0.931034505367279,0.5462962962962963,0.1833243411162804,mmlu:high_school_mathematics,validation,0.48517811903730035
270,0.12962962687015533,0.8703703880310059,0.5782370820668693,0.1180410873006891,mmlu:high_school_mathematics,test,3.0802190869580954
26,0.42307692766189575,0.42307692766189575,0.7,0.22956732603219843,mmlu:high_school_microeconomics,validation,0.5534648159518838
238,0.3781512677669525,0.38235294818878174,0.5578453453453454,0.24888390352746018,mmlu:high_school_microeconomics,test,2.7343438020907342
17,0.1764705926179886,0.1764705926179886,0.619047619047619,0.5760569993187399,mmlu:high_school_physics,validation,0.3851012249942869
151,0.20529800653457642,0.20529800653457642,0.6404569892473119,0.5344060513357454,mmlu:high_school_physics,test,1.7659986719954759
60,0.6333333253860474,0.6333333253860474,0.6644736842105263,0.05123695731163022,mmlu:high_school_psychology,validation,0.805524623952806
545,0.5596330165863037,0.5596330165863037,0.4721926229508197,0.05774800416526443,mmlu:high_school_psychology,test,6.17396771395579
23,0.30434781312942505,0.52173912525177,0.5982142857142858,0.08729620601819911,mmlu:high_school_statistics,validation,0.4302617711946368
216,0.32870370149612427,0.5833333134651184,0.65726080621661,0.07331453594896525,mmlu:high_school_statistics,test,2.4463259228505194
22,0.5909090638160706,0.3636363744735718,0.5256410256410257,0.22762782465327872,mmlu:high_school_us_history,validation,0.3878167720977217
204,0.6421568393707275,0.36764705181121826,0.5422984419115341,0.21444164362608215,mmlu:high_school_us_history,test,2.429947178112343
26,0.5769230723381042,0.4615384638309479,0.5181818181818182,0.14903848217083857,mmlu:high_school_world_history,validation,0.49558220407925546
237,0.4388185739517212,0.5738396644592285,0.5242914979757085,0.04085902926288074,mmlu:high_school_world_history,test,2.740038039861247
23,0.30434781312942505,0.3478260934352875,0.5580357142857142,0.2235054321911024,mmlu:human_aging,validation,0.3835427740123123
223,0.34529146552085876,0.4439461827278137,0.5650240170788116,0.11620655161382909,mmlu:human_aging,test,2.594620643882081
12,0.3333333432674408,0.75,0.71875,0.1708984375,mmlu:human_sexuality,validation,0.3029799440409988
131,0.49618321657180786,0.572519063949585,0.6016317016317017,0.019829442482868217,mmlu:human_sexuality,test,1.635654408019036
13,0.4615384638309479,0.4615384638309479,0.6190476190476191,0.3677884569534889,mmlu:international_law,validation,0.3065178159158677
121,0.5619834661483765,0.5619834661483765,0.6284683684794672,0.23954029418220205,mmlu:international_law,test,1.5430118769872934
11,0.4545454680919647,0.4545454680919647,0.33333333333333337,0.3426846699281172,mmlu:jurisprudence,validation,0.30249356501735747
108,0.49074074625968933,0.49074074625968933,0.4847341337907376,0.24016206407988513,mmlu:jurisprudence,test,1.3031783469486982
18,0.5,0.5,0.48148148148148145,0.1629774570465088,mmlu:logical_fallacies,validation,0.3868921019602567
163,0.47852760553359985,0.47852760553359985,0.6036199095022624,0.17151552073063292,mmlu:logical_fallacies,test,1.9840740009676665
11,0.1818181872367859,0.1818181872367859,0.5555555555555556,0.4438920400359414,mmlu:machine_learning,validation,0.30782051803544164
112,0.2767857015132904,0.2946428656578064,0.47710075667064916,0.3512834789497512,mmlu:machine_learning,test,1.3341944778803736
11,0.6363636255264282,0.4545454680919647,0.7499999999999999,0.0937499837441878,mmlu:management,validation,0.32239773380570114
103,0.3980582654476166,0.6310679316520691,0.6876475216365067,0.07292932040483044,mmlu:management,test,1.2615664510522038
25,0.2800000011920929,0.5199999809265137,0.5555555555555556,0.006562511920928937,mmlu:marketing,validation,0.46843860810622573
234,0.47863247990608215,0.5256410241127014,0.5805766978922717,0.009832382202148453,mmlu:marketing,test,2.7441653199493885
11,0.7272727489471436,0.7272727489471436,0.7916666666666667,0.09268466992811722,mmlu:medical_genetics,validation,0.3145678439177573
100,0.550000011920929,0.550000011920929,0.6991919191919191,0.25265625953674314,mmlu:medical_genetics,test,1.2895647250115871
86,0.5930232405662537,0.5581395626068115,0.5750700280112045,0.074763800515685,mmlu:miscellaneous,validation,1.1106117609888315
783,0.6245210766792297,0.6513410210609436,0.6203657332053477,0.026061635592888134,mmlu:miscellaneous,test,8.528006321983412
38,0.3684210479259491,0.3684210479259491,0.5818452380952381,0.3533100219149339,mmlu:moral_disputes,validation,0.5558786841575056
346,0.40751445293426514,0.40751445293426514,0.5628092025601107,0.3059858297336997,mmlu:moral_disputes,test,3.8741795369423926
100,0.5899999737739563,0.41999998688697815,0.4975196362133113,0.10359372377395631,mmlu:moral_scenarios,validation,1.24436509096995
895,0.5329608917236328,0.48491621017456055,0.5155452238371802,0.040790864941794125,mmlu:moral_scenarios,test,9.872877268120646
33,0.39393940567970276,0.39393940567970276,0.7173076923076924,0.3908617514552492,mmlu:nutrition,validation,0.569699757033959
306,0.4346405267715454,0.4313725531101227,0.5428745273588595,0.27946281997986083,mmlu:nutrition,test,3.4747536960057914
34,0.38235294818878174,0.38235294818878174,0.44505494505494503,0.3192785049186033,mmlu:philosophy,validation,0.6086505618877709
311,0.34405145049095154,0.34405145049095154,0.5347489463074948,0.35227843036222306,mmlu:philosophy,test,3.4953775089234114
35,0.37142857909202576,0.4285714328289032,0.7762237762237763,0.22555803401129584,mmlu:prehistory,validation,0.5512767089530826
324,0.45987653732299805,0.4783950746059418,0.5639884947267498,0.13023243090252815,mmlu:prehistory,test,3.7195278368890285
31,0.19354838132858276,0.8064516186714172,0.58,0.12663811637509256,mmlu:professional_accounting,validation,0.4942465089261532
282,0.173758864402771,0.826241135597229,0.6355872821231496,0.14576405033152154,mmlu:professional_accounting,test,3.185342424083501
170,0.4000000059604645,0.5764706134796143,0.4510524798154556,0.06128215333994696,mmlu:professional_law,validation,2.0876886430196464
1534,0.35071706771850586,0.6362451314926147,0.4463560561950404,0.05733070667284253,mmlu:professional_law,test,17.07636122708209
31,0.4516128897666931,0.6129032373428345,0.6092436974789915,0.10874494621830602,mmlu:professional_medicine,validation,0.5229481749702245
272,0.35661765933036804,0.6286764740943909,0.5640058910162004,0.020780655391076056,mmlu:professional_medicine,test,3.0294403668958694
69,0.43478259444236755,0.4637681245803833,0.41794871794871796,0.11565899071486103,mmlu:professional_psychology,validation,0.9085909409914166
612,0.3660130798816681,0.42810457944869995,0.5001093059646539,0.14197814747009402,mmlu:professional_psychology,test,6.789995525032282
12,0.3333333432674408,0.5833333134651184,0.9375,0.08138020833333333,mmlu:public_relations,validation,0.3033699160441756
110,0.30909091234207153,0.38181817531585693,0.6151315789473684,0.18373578136617486,mmlu:public_relations,test,1.3238296899944544
27,0.5925925970077515,0.5925925970077515,0.6136363636363636,0.1587095084013762,mmlu:security_studies,validation,0.5133489051368088
245,0.5469387769699097,0.5510203838348389,0.6161422616646497,0.1764189929378276,mmlu:security_studies,test,2.812286507105455
22,0.5,0.40909090638160706,0.4132231404958678,0.16867895830761304,mmlu:sociology,validation,0.4207294180523604
201,0.45771142840385437,0.5671641826629639,0.5901974471479856,0.016868775163716945,mmlu:sociology,test,2.386794034857303
11,0.7272727489471436,0.5454545617103577,0.5,0.12428976730866867,mmlu:us_foreign_policy,validation,0.327932066982612
100,0.6100000143051147,0.5899999737739563,0.5420344682639765,0.026640638709068305,mmlu:us_foreign_policy,test,1.2612959491088986
18,0.3888888955116272,0.3888888955116272,0.35714285714285715,0.42426216271188527,mmlu:virology,validation,0.38485570903867483
166,0.34939759969711304,0.34939759969711304,0.5403895274584929,0.3897778650364244,mmlu:virology,test,1.8990206150338054
19,0.6842105388641357,0.5263158082962036,0.5,0.07791942985434279,mmlu:world_religions,validation,0.3893383229151368
171,0.6725146174430847,0.5906432867050171,0.5915372670807453,0.10010052563851339,mmlu:world_religions,test,2.07482063700445
