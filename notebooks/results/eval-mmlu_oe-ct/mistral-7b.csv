N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.4545454680919647,0.3636363744735718,0.75,0.37711386788975104,mmlu:abstract_algebra,validation,36.323694198043086
100,0.3199999928474426,0.5899999737739563,0.44094669117647056,0.1453243339061737,mmlu:abstract_algebra,test,313.5140758799389
22,0.09090909361839294,0.5909091234207153,0.6,0.187888194214214,mmlu:high_school_chemistry,validation,64.67407422093675
203,0.21182265877723694,0.743842363357544,0.5190406976744186,0.0548225277163125,mmlu:high_school_chemistry,test,587.9267990463413
86,0.604651153087616,0.7209302186965942,0.7392533936651583,0.1294401918732843,mmlu:miscellaneous,validation,254.6980074737221
783,0.6309067606925964,0.7637292146682739,0.771391647871342,0.09660521869001715,mmlu:miscellaneous,test,2304.8097400991246
35,0.34285715222358704,0.5428571701049805,0.7427536231884058,0.23429503100258964,mmlu:prehistory,validation,129.60741047933698
324,0.4660493731498718,0.6512345671653748,0.6910385484056196,0.15132627718978459,mmlu:prehistory,test,1195.4209937937558
38,0.3947368562221527,0.6052631735801697,0.7999999999999999,0.1335512368302596,mmlu:moral_disputes,validation,168.35021752101602
346,0.4046242833137512,0.6445086598396301,0.6705617198335645,0.11908013162585353,mmlu:moral_disputes,test,1084.2599730280053
11,0.0,0.4545454680919647,,0.42367265441200946,mmlu:college_computer_science,validation,49.41189084947109
100,0.23999999463558197,0.6299999952316284,0.600328947368421,0.1760387271642685,mmlu:college_computer_science,test,445.20793398469687
23,0.260869562625885,0.695652186870575,0.7156862745098039,0.13644927999247675,mmlu:high_school_statistics,validation,74.72110931575298
216,0.31481480598449707,0.5879629850387573,0.620081478537361,0.20577104996751858,mmlu:high_school_statistics,test,684.6006812928244
60,0.6166666746139526,0.7333333492279053,0.737367802585194,0.14552348057428993,mmlu:high_school_psychology,validation,248.4168534949422
545,0.5651376247406006,0.6532109975814819,0.7525686338977479,0.17999526306029853,mmlu:high_school_psychology,test,2282.623675312847
18,0.3333333432674408,0.7222222089767456,0.3888888888888889,0.1492113239235348,mmlu:virology,validation,100.86949726752937
166,0.35542166233062744,0.668674647808075,0.5389672105179787,0.15648393386817838,mmlu:virology,test,520.2042811773717
29,0.03448275849223137,0.8965517282485962,0.9107142857142858,0.19817314271269174,mmlu:high_school_mathematics,validation,85.13452933402732
270,0.11481481045484543,0.8333333134651184,0.3466054798218383,0.07077441215515137,mmlu:high_school_mathematics,test,780.7739383419976
25,0.3199999928474426,0.4399999976158142,0.7499999999999999,0.4147714328765869,mmlu:marketing,validation,80.12788816727698
234,0.46581199765205383,0.636752188205719,0.8238532110091743,0.23644360365011755,mmlu:marketing,test,767.2593729048967
13,0.5384615659713745,0.692307710647583,0.7261904761904762,0.2527629366287818,mmlu:international_law,validation,42.89428647235036
121,0.5950412750244141,0.6611570119857788,0.7426303854875285,0.12499680794960213,mmlu:international_law,test,353.84572007879615
26,0.26923078298568726,0.5,0.7744360902255639,0.2673415404099685,mmlu:conceptual_physics,validation,79.69668262265623
235,0.48085105419158936,0.6042553186416626,0.6353184389960829,0.17991946580562185,mmlu:conceptual_physics,test,712.0055852979422
11,0.4545454680919647,0.7272727489471436,1.0,0.14360488544810907,mmlu:college_physics,validation,36.91316758503672
102,0.22549019753932953,0.686274528503418,0.6263070996147496,0.10434618124774857,mmlu:college_physics,test,324.3763845160138
31,0.19354838132858276,0.5161290168762207,0.5433333333333333,0.24376138756352086,mmlu:professional_accounting,validation,100.53743893094361
282,0.1843971610069275,0.631205677986145,0.5969063545150503,0.09457594663538832,mmlu:professional_accounting,test,886.2424745336175
27,0.6296296119689941,0.6296296119689941,0.6,0.17824587777808862,mmlu:security_studies,validation,114.46469297632575
245,0.5306122303009033,0.6448979377746582,0.6635785953177258,0.12139463886922719,mmlu:security_studies,test,1021.8712225668132
19,0.7368420958518982,0.7894737124443054,0.8071428571428572,0.11149968285309642,mmlu:world_religions,validation,60.724910102784634
171,0.6842105388641357,0.7251461744308472,0.8026274137385249,0.13948742234916017,mmlu:world_religions,test,535.7768515106291
22,0.5,0.7727273106575012,0.9421487603305785,0.19213973392139783,mmlu:high_school_us_history,validation,74.04811173863709
204,0.6519607901573181,0.7598039507865906,0.6181298316213067,0.05902766275639628,mmlu:high_school_us_history,test,665.0513432957232
41,0.4146341383457184,0.5121951103210449,0.5833333333333334,0.2008269051226174,mmlu:elementary_mathematics,validation,131.68497223220766
378,0.4682539403438568,0.5714285373687744,0.5198583354414369,0.1592373956763555,mmlu:elementary_mathematics,test,1193.3211261313409
16,0.3125,0.6875,0.37272727272727274,0.23802025243639952,mmlu:college_biology,validation,50.169864343479276
144,0.375,0.6180555820465088,0.6959876543209876,0.16957835232218108,mmlu:college_biology,test,442.1963527854532
43,0.44186046719551086,0.604651153087616,0.7335526315789473,0.3020893931388855,mmlu:high_school_macroeconomics,validation,178.3102718628943
390,0.37948718667030334,0.5948718190193176,0.6979422604422605,0.18628280040545342,mmlu:high_school_macroeconomics,test,1623.861854787916
11,0.1818181872367859,0.6363636255264282,0.5555555555555556,0.2570770653811368,mmlu:college_mathematics,validation,48.441200975328684
100,0.14000000059604645,0.8199999928474426,0.3949335548172757,0.1302193874120712,mmlu:college_mathematics,test,431.27895836904645
12,0.5,0.5833333730697632,0.8472222222222223,0.29789169629414874,mmlu:econometrics,validation,39.16310238093138
114,0.21929824352264404,0.41228070855140686,0.5795505617977528,0.35300250273001826,mmlu:econometrics,test,354.28804458491504
14,0.4285714626312256,0.4285714626312256,0.4479166666666667,0.23182415536471776,mmlu:formal_logic,validation,47.92951973155141
126,0.3333333432674408,0.4365079700946808,0.5433673469387755,0.26193051631488495,mmlu:formal_logic,test,597.1370597593486
11,0.6363636255264282,0.7272727489471436,0.9285714285714286,0.16863338513807818,mmlu:medical_genetics,validation,34.457128901034594
100,0.550000011920929,0.6800000071525574,0.8381818181818183,0.11678198397159578,mmlu:medical_genetics,test,281.3505090000108
22,0.5909091234207153,0.6363636255264282,0.4700854700854702,0.19581850279461255,mmlu:college_medicine,validation,71.05527631752193
173,0.3641618490219116,0.6589595079421997,0.7004329004329003,0.15274977615113894,mmlu:college_medicine,test,540.2222714759409
11,0.6363636255264282,0.5454545617103577,0.9107142857142857,0.2736334042115645,mmlu:computer_security,validation,40.518611456267536
100,0.4699999988079071,0.5,0.6192292252107587,0.2705861115455628,mmlu:computer_security,test,328.8908140109852
16,0.1875,0.4375,0.8974358974358975,0.3567986339330673,mmlu:astronomy,validation,53.709464279934764
152,0.45394736528396606,0.6644737124443054,0.8713113322856645,0.1069982530255067,mmlu:astronomy,test,488.40301068127155
11,0.5454545617103577,0.8181818723678589,0.6166666666666667,0.2203663695942272,mmlu:jurisprudence,validation,36.97749650699552
108,0.5092592835426331,0.7129629850387573,0.7207547169811319,0.06661679236977189,mmlu:jurisprudence,test,344.48278554400895
26,0.42307692766189575,0.692307710647583,0.7121212121212122,0.1276929080486298,mmlu:high_school_microeconomics,validation,72.78886233642697
238,0.3403361439704895,0.605042040348053,0.7308720610206809,0.1663700259533249,mmlu:high_school_microeconomics,test,662.3105186745524
16,0.1875,0.4375,0.33333333333333337,0.25111907720565796,mmlu:electrical_engineering,validation,50.36949226260185
145,0.2620689570903778,0.6965517401695251,0.6548204623708804,0.09174661882992445,mmlu:electrical_engineering,test,454.44253784045577
32,0.375,0.53125,0.50625,0.21491948142647743,mmlu:high_school_biology,validation,99.316471029073
310,0.5,0.7322580814361572,0.6564412070759624,0.08787900843927936,mmlu:high_school_biology,test,918.7176562212408
12,0.25,0.8333333730697632,0.4444444444444444,0.31402339537938445,mmlu:human_sexuality,validation,41.89737421646714
131,0.5038167834281921,0.7251908183097839,0.7076923076923077,0.14042160529216738,mmlu:human_sexuality,test,422.0100971609354
31,0.4838709533214569,0.5806451439857483,0.7250000000000001,0.25160761225608086,mmlu:professional_medicine,validation,99.79631887376308
272,0.40441176295280457,0.6397058963775635,0.5738776655443322,0.14875167126164715,mmlu:professional_medicine,test,861.1811460610479
9,0.5555555820465088,0.7777777910232544,0.85,0.16499722666210598,mmlu:high_school_computer_science,validation,32.650256872177124
100,0.5699999928474426,0.6699999570846558,0.620563035495716,0.1455572140216827,mmlu:high_school_computer_science,test,319.1443306542933
11,0.6363636255264282,0.7272727489471436,0.6428571428571428,0.2123763669620861,mmlu:us_foreign_policy,validation,35.9655730612576
100,0.6399999856948853,0.6499999761581421,0.7085503472222223,0.2032756197452545,mmlu:us_foreign_policy,test,316.4716987721622
26,0.5384615659713745,0.6538462042808533,0.5029761904761905,0.2545338158424084,mmlu:high_school_world_history,validation,90.09052176401019
237,0.4514767825603485,0.6202531456947327,0.7705607476635513,0.20497633711698185,mmlu:high_school_world_history,test,728.2468842044473
69,0.42028987407684326,0.6811594367027283,0.6599137931034483,0.19327858392743097,mmlu:professional_psychology,validation,204.13796989666298
612,0.3807189464569092,0.5980392098426819,0.675371148380083,0.19169402083540274,mmlu:professional_psychology,test,1815.7436645049602
12,0.3333333432674408,0.4166666865348816,0.625,0.45019377271334327,mmlu:public_relations,validation,36.81704888306558
110,0.2818181812763214,0.5454545021057129,0.8031849734585546,0.27004167220809244,mmlu:public_relations,test,310.9723033355549
11,0.27272728085517883,0.5454545617103577,0.47916666666666663,0.28128481994975696,mmlu:machine_learning,validation,37.959238920360804
112,0.2142857313156128,0.4464285969734192,0.5059185606060606,0.26849761818136486,mmlu:machine_learning,test,335.7782888188958
23,0.30434784293174744,0.5652173757553101,0.7008928571428572,0.22973646288332733,mmlu:human_aging,validation,73.54044527187943
223,0.3632287085056305,0.605381190776825,0.7424795687706486,0.15579944902471365,mmlu:human_aging,test,698.7455367408693
10,0.30000001192092896,0.800000011920929,0.5238095238095237,0.2500945925712586,mmlu:global_facts,validation,32.946906896308064
100,0.2199999988079071,0.5099999904632568,0.6622960372960373,0.18057842493057252,mmlu:global_facts,test,308.6752138584852
22,0.4545454680919647,0.6818181872367859,0.7041666666666666,0.22753523154692218,mmlu:high_school_geography,validation,63.75769902486354
198,0.4292929172515869,0.6515151262283325,0.7672566371681416,0.16192202044255805,mmlu:high_school_geography,test,569.1856357268989
11,0.5454545617103577,0.4545454680919647,0.75,0.3410696874965321,mmlu:management,validation,36.105645168572664
103,0.40776699781417847,0.582524299621582,0.7898126463700235,0.22873832704951463,mmlu:management,test,299.8938819207251
18,0.5555555820465088,0.8888888955116272,0.85,0.25305674804581535,mmlu:logical_fallacies,validation,54.47143912315369
163,0.5092024207115173,0.6380367875099182,0.6642319277108434,0.17371444175579795,mmlu:logical_fallacies,test,492.60316192917526
170,0.4176470637321472,0.5588235259056091,0.6462512448427942,0.1867260817219229,mmlu:professional_law,validation,481.67844755295664
1534,0.428943932056427,0.5423728823661804,0.6380645306796575,0.2004015164782513,mmlu:professional_law,test,4706.985966403969
18,0.7222222089767456,0.8333333134651184,0.7307692307692308,0.15611984994676378,mmlu:high_school_european_history,validation,66.7562445756048
165,0.6545454263687134,0.7333332896232605,0.6972059779077323,0.0939368298559478,mmlu:high_school_european_history,test,605.1379654631019
34,0.3235294222831726,0.6470588445663452,0.8379446640316206,0.17961323962492104,mmlu:philosophy,validation,109.26248356886208
311,0.33118969202041626,0.5916398763656616,0.6868932038834951,0.15384464421072958,mmlu:philosophy,test,985.7684040050954
14,0.2142857313156128,0.6428571939468384,0.7575757575757576,0.3855438913617815,mmlu:anatomy,validation,45.9002565164119
135,0.5703703761100769,0.6888888478279114,0.7635467980295567,0.13318004254941584,mmlu:anatomy,test,420.585049783811
17,0.29411765933036804,0.47058823704719543,0.7416666666666666,0.28198932198917165,mmlu:high_school_physics,validation,50.16979334503412
151,0.19205297529697418,0.3642384111881256,0.6531938948558509,0.3737945015856762,mmlu:high_school_physics,test,433.80545671097934
22,0.5,0.5454545617103577,0.6363636363636364,0.2279109873554923,mmlu:sociology,validation,72.0061556249857
201,0.42786067724227905,0.641791045665741,0.6614762386248736,0.189419749364331,mmlu:sociology,test,615.8622098434716
100,0.28999999165534973,0.7099999785423279,0.47013113161729,0.11385742902755737,mmlu:moral_scenarios,validation,296.0288853868842
895,0.3005586564540863,0.6994413137435913,0.4288068458496146,0.11856710184885805,mmlu:moral_scenarios,test,2659.6840383522213
11,0.4545454680919647,0.5454545617103577,0.6333333333333333,0.34839459982785315,mmlu:business_ethics,validation,36.77424135804176
100,0.28999999165534973,0.429999977350235,0.7396794560466246,0.3600882816314697,mmlu:business_ethics,test,309.2645864915103
21,0.6190476417541504,0.7142857313156128,0.514423076923077,0.25756182273228967,mmlu:high_school_government_and_politics,validation,70.46644293889403
193,0.559585452079773,0.7098445296287537,0.7905228758169934,0.11001451707256887,mmlu:high_school_government_and_politics,test,704.2897468283772
33,0.42424243688583374,0.4848484992980957,0.5864661654135339,0.3494172367182645,mmlu:nutrition,validation,109.83078959956765
306,0.4346405267715454,0.5588235259056091,0.6761919248989526,0.23606121734856,mmlu:nutrition,test,1022.6968164518476
8,0.25,0.625,0.45833333333333337,0.26721832156181335,mmlu:college_chemistry,validation,26.86129116266966
100,0.2199999988079071,0.6299999952316284,0.7421328671328671,0.11352141797542568,mmlu:college_chemistry,test,312.1480611525476
29,0.37931033968925476,0.5517241358757019,0.6388888888888888,0.23019310112657218,mmlu:clinical_knowledge,validation,93.37099547870457
265,0.324528306722641,0.6037735939025879,0.7233987267766662,0.18454273264363127,mmlu:clinical_knowledge,test,820.5207506716251
