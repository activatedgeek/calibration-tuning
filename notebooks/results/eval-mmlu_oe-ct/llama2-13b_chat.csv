N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
60,0.5333333611488342,0.7833333611488342,0.6417410714285714,0.12523329854011536,mmlu:high_school_psychology,validation,67.875309439376
545,0.526605486869812,0.6770642399787903,0.5705507387299786,0.05992495105900897,mmlu:high_school_psychology,test,612.1685673911124
13,0.5384615659713745,0.7692307829856873,0.5357142857142857,0.2524439875896161,mmlu:international_law,validation,22.485511319711804
121,0.6198346614837646,0.6694214344024658,0.5130434782608696,0.050403406304761415,mmlu:international_law,test,191.61567127890885
29,0.13793103396892548,0.7241379022598267,0.5599999999999999,0.17227385578484372,mmlu:clinical_knowledge,validation,34.64355795271695
265,0.27547168731689453,0.7094339728355408,0.4567280251141552,0.0406864119025896,mmlu:clinical_knowledge,test,274.6721625458449
26,0.42307692766189575,0.5384615659713745,0.6,0.3922808720515324,mmlu:conceptual_physics,validation,27.740292228758335
235,0.4553191363811493,0.612765908241272,0.3659462616822429,0.16205314600721316,mmlu:conceptual_physics,test,185.61049970053136
11,0.3636363744735718,0.6363636255264282,0.75,0.08798529343171553,mmlu:business_ethics,validation,17.004137594252825
100,0.29999998211860657,0.5399999618530273,0.6185714285714285,0.11255445122718813,mmlu:business_ethics,test,183.9291843622923
69,0.3333333432674408,0.6811594367027283,0.6517013232514178,0.10501809137454929,mmlu:professional_psychology,validation,162.2466878965497
612,0.3284313678741455,0.6601307392120361,0.5363692486472746,0.06163494347357284,mmlu:professional_psychology,test,1381.6503499522805
17,0.29411765933036804,0.7058823704719543,0.4666666666666667,0.16352128982543945,mmlu:high_school_physics,validation,27.80545648559928
151,0.19205297529697418,0.7947019934654236,0.43682871678914637,0.032803252043313566,mmlu:high_school_physics,test,204.77032824978232
11,0.09090909361839294,0.9090909361839294,1.0,0.09041729298504912,mmlu:abstract_algebra,validation,26.758144548162818
100,0.3499999940395355,0.6200000047683716,0.4142857142857143,0.13700422704219817,mmlu:abstract_algebra,test,223.96560909599066
22,0.5454545617103577,0.6363636255264282,0.5083333333333333,0.04966823892159899,mmlu:sociology,validation,36.233272191137075
201,0.4776119291782379,0.6865671277046204,0.554513888888889,0.042945438060001354,mmlu:sociology,test,330.5778924897313
16,0.375,0.6875,0.5083333333333333,0.2000751718878746,mmlu:college_biology,validation,26.626092461985536
144,0.3819444477558136,0.7361111044883728,0.4866189989785495,0.08969591971900727,mmlu:college_biology,test,166.64339949400164
14,0.2857142984867096,0.7142857313156128,0.26249999999999996,0.06284951737948828,mmlu:formal_logic,validation,19.723664718214422
126,0.3095238208770752,0.6746032238006592,0.4358974358974359,0.043133628273767176,mmlu:formal_logic,test,193.3021364067681
25,0.19999998807907104,0.7199999690055847,0.44000000000000006,0.18737202405929562,mmlu:marketing,validation,51.66286853607744
234,0.4316239655017853,0.7478632926940918,0.4932628601205986,0.061186938968479106,mmlu:marketing,test,421.07301661511883
38,0.42105263471603394,0.7105263471603394,0.5127840909090908,0.10955211990757995,mmlu:moral_disputes,validation,36.01891838526353
346,0.4219653010368347,0.6387283205986023,0.4989041095890411,0.04131756318097862,mmlu:moral_disputes,test,318.6926715602167
18,0.6111111044883728,0.4444444477558136,0.36363636363636365,0.30484045876397026,mmlu:virology,validation,21.317871920764446
166,0.34939756989479065,0.7048192620277405,0.5015166028097062,0.06542126708720104,mmlu:virology,test,227.14629098027945
43,0.44186046719551086,0.6511628031730652,0.3596491228070175,0.09496578089026517,mmlu:high_school_macroeconomics,validation,64.75732832401991
390,0.34871795773506165,0.7153846621513367,0.364491662806855,0.0279046416282654,mmlu:high_school_macroeconomics,test,576.6822576709092
12,0.25,0.5833333730697632,0.4444444444444445,0.19273840884367627,mmlu:public_relations,validation,10.357989591080695
110,0.3545454442501068,0.7181817889213562,0.45413506681112314,0.03627610098231922,mmlu:public_relations,test,87.23160711722448
29,0.06896551698446274,0.9655172228813171,0.2592592592592593,0.12453207887452221,mmlu:high_school_mathematics,validation,45.675778448581696
270,0.10000000149011612,0.8999999761581421,0.36625514403292186,0.07496074129033968,mmlu:high_school_mathematics,test,512.4938685931265
18,0.6111111044883728,0.7777777910232544,0.7662337662337663,0.149553034040663,mmlu:logical_fallacies,validation,29.2726745121181
163,0.47239261865615845,0.699386477470398,0.6428571428571428,0.031699330894493616,mmlu:logical_fallacies,test,277.9487167932093
11,0.7272727489471436,0.8181818723678589,0.5833333333333333,0.10123386708172886,mmlu:us_foreign_policy,validation,19.90487975999713
100,0.5799999833106995,0.6599999666213989,0.6366995073891626,0.10747959733009342,mmlu:us_foreign_policy,test,184.97164805233479
23,0.260869562625885,0.739130437374115,0.6911764705882354,0.24226545250934103,mmlu:high_school_statistics,validation,61.93521798029542
216,0.2638888955116272,0.694444477558136,0.5531832726470264,0.07135280939163986,mmlu:high_school_statistics,test,616.4564347490668
34,0.3235294222831726,0.7941176295280457,0.7391304347826088,0.1349628515103284,mmlu:philosophy,validation,30.95434724201914
311,0.3536977469921112,0.6334404945373535,0.5784034373586611,0.05302448652181594,mmlu:philosophy,test,273.4738208600029
21,0.5714285969734192,1.0,0.6481481481481481,0.23631378014882407,mmlu:high_school_government_and_politics,validation,31.758113633841276
193,0.5699481964111328,0.6683937907218933,0.6519167579408544,0.0936318938596261,mmlu:high_school_government_and_politics,test,290.3937860392034
11,0.3636363744735718,0.6363636255264282,0.4285714285714286,0.1938610456206582,mmlu:machine_learning,validation,21.28546961955726
112,0.2321428656578064,0.7589285969734192,0.4771914132379249,0.09022328417216027,mmlu:machine_learning,test,169.18666383996606
11,0.27272728085517883,0.8181818723678589,0.0,0.15702565149827435,mmlu:college_physics,validation,11.721307680010796
102,0.14705882966518402,0.843137264251709,0.34942528735632183,0.11260108445204942,mmlu:college_physics,test,127.54840882495046
31,0.16129031777381897,0.774193525314331,0.4807692307692308,0.08650624944317728,mmlu:professional_accounting,validation,41.65325593948364
282,0.1914893537759781,0.7801418304443359,0.429540285899935,0.08479830960855415,mmlu:professional_accounting,test,359.98916617035866
8,0.0,1.0,,0.28076303005218506,mmlu:college_chemistry,validation,17.230900581926107
100,0.17000000178813934,0.8299999833106995,0.5180722891566265,0.060443802475929266,mmlu:college_chemistry,test,250.1670878380537
35,0.48571428656578064,0.5428571701049805,0.5065359477124183,0.18653248037610737,mmlu:prehistory,validation,40.36306503880769
324,0.45370370149612427,0.6512345671653748,0.45685844959452715,0.08010712781070188,mmlu:prehistory,test,313.6371800787747
11,0.6363636255264282,0.4545454680919647,0.6964285714285714,0.40963349017229944,mmlu:medical_genetics,validation,22.686896685510874
100,0.5099999904632568,0.7099999785423279,0.5844337735094038,0.06348746180534366,mmlu:medical_genetics,test,164.33800694532692
31,0.3870967626571655,0.6451612710952759,0.605263157894737,0.07846842273589104,mmlu:professional_medicine,validation,55.99454467743635
272,0.2977941334247589,0.6397058963775635,0.4342964255704221,0.05455587848144419,mmlu:professional_medicine,test,433.43791142478585
14,0.2142857313156128,0.785714328289032,0.7272727272727273,0.12826842069625854,mmlu:anatomy,validation,12.223941408097744
135,0.43703702092170715,0.7185184955596924,0.4063336306868867,0.04509765925230802,mmlu:anatomy,test,103.12067137286067
33,0.3636363744735718,0.575757622718811,0.4246031746031746,0.17042774323261145,mmlu:nutrition,validation,71.38154622912407
306,0.44117647409439087,0.6764705777168274,0.5553606237816764,0.03657832137899463,mmlu:nutrition,test,667.0590019598603
11,0.1818181872367859,0.7272727489471436,0.888888888888889,0.1802382848479531,mmlu:jurisprudence,validation,11.18727377615869
108,0.37962964177131653,0.694444477558136,0.5058245358572988,0.03570158006968323,mmlu:jurisprudence,test,111.5006313174963
41,0.2926829159259796,0.7317072749137878,0.5502873563218391,0.1689579239705714,mmlu:elementary_mathematics,validation,58.3773609418422
378,0.31481480598449707,0.738095223903656,0.44579994159826086,0.0417040914454788,mmlu:elementary_mathematics,test,415.36853820830584
16,0.25,0.8125,0.3958333333333333,0.1424916908144951,mmlu:electrical_engineering,validation,59.405265567824244
145,0.20689654350280762,0.7724137902259827,0.4028985507246377,0.05708438116928628,mmlu:electrical_engineering,test,381.17117678560317
22,0.13636364042758942,0.9090909361839294,0.0,0.15024405175989322,mmlu:high_school_chemistry,validation,33.30395949445665
203,0.19211822748184204,0.8226600885391235,0.4155722326454034,0.06619392034455475,mmlu:high_school_chemistry,test,247.11195122171193
11,0.5454545617103577,0.6363636255264282,0.7166666666666667,0.052887488495219834,mmlu:management,validation,11.260448198765516
103,0.3883495330810547,0.7669903039932251,0.4724206349206349,0.09290427721819829,mmlu:management,test,96.2285394333303
32,0.28125,0.71875,0.5169082125603864,0.17460367269814014,mmlu:high_school_biology,validation,37.06523817544803
310,0.4000000059604645,0.699999988079071,0.4520681581685744,0.04142691992944286,mmlu:high_school_biology,test,343.4055882380344
11,0.7272727489471436,0.6363636255264282,0.47916666666666674,0.1729172413999384,mmlu:computer_security,validation,12.756766680628061
100,0.4699999988079071,0.6399999856948853,0.5503813729425934,0.05449821710586547,mmlu:computer_security,test,111.60911894217134
100,0.3100000023841858,0.6699999570846558,0.3534361851332398,0.08526534557342527,mmlu:moral_scenarios,validation,249.43402348831296
895,0.2648044526576996,0.6703910231590271,0.4865818937324458,0.03653816251115424,mmlu:moral_scenarios,test,2112.756120402366
170,0.5,0.5647059082984924,0.43785467128027683,0.12929601739434635,mmlu:professional_law,validation,584.6740708351135
1534,0.5013037919998169,0.6173402667045593,0.4530227695759708,0.09622203281836529,mmlu:professional_law,test,5141.142808992416
22,0.5,0.8181818723678589,0.7520661157024794,0.13034641200845895,mmlu:high_school_geography,validation,26.41931016743183
198,0.38383838534355164,0.752525269985199,0.5142364106988783,0.04140800327965709,mmlu:high_school_geography,test,220.59037457685918
9,0.5555555820465088,0.6666666865348816,1.0,0.2411343190405104,mmlu:high_school_computer_science,validation,14.449436208233237
100,0.44999998807907104,0.6800000071525574,0.4892929292929293,0.08471543550491333,mmlu:high_school_computer_science,test,143.162356602028
10,0.20000000298023224,0.800000011920929,0.5625,0.17521265149116516,mmlu:global_facts,validation,12.341839610598981
100,0.14000000059604645,0.7899999618530273,0.4759136212624585,0.08034188985824586,mmlu:global_facts,test,98.68096083123237
19,0.6315789222717285,0.8421052694320679,0.8392857142857143,0.12742408325797633,mmlu:world_religions,validation,19.210024695843458
171,0.5906432867050171,0.707602322101593,0.7489391796322489,0.04511062199609322,mmlu:world_religions,test,145.4655669592321
12,0.3333333432674408,0.5,0.53125,0.29020917912324273,mmlu:econometrics,validation,15.777654280886054
114,0.1666666716337204,0.6754385828971863,0.6412742382271468,0.08697633628259624,mmlu:econometrics,test,205.08439145004377
23,0.43478262424468994,0.6521739363670349,0.3192307692307692,0.08116459846496583,mmlu:human_aging,validation,21.160812648944557
223,0.37219732999801636,0.6681614518165588,0.4626075731497419,0.05910282231232512,mmlu:human_aging,test,214.51399619691074
16,0.375,0.8125,0.35,0.07920062169432639,mmlu:astronomy,validation,22.340037636458874
152,0.4802631735801697,0.6776315569877625,0.45812380787237733,0.06705747544765474,mmlu:astronomy,test,188.93709509260952
11,0.0,1.0,,0.1556954112919894,mmlu:college_mathematics,validation,31.062265577726066
100,0.10999999940395355,0.8799999952316284,0.26710929519918286,0.04830705225467684,mmlu:college_mathematics,test,189.10833147121593
12,0.3333333432674408,0.5,0.46875,0.34876251220703125,mmlu:human_sexuality,validation,18.6957538574934
131,0.5190839767456055,0.5877862572669983,0.45121381886087775,0.13505752350537834,mmlu:human_sexuality,test,152.83956374786794
26,0.6538462042808533,0.5769230723381042,0.6013071895424837,0.23639281896444467,mmlu:high_school_world_history,validation,50.29857946373522
237,0.5991560816764832,0.6962025165557861,0.7073387694588585,0.08246455212685629,mmlu:high_school_world_history,test,443.1750456634909
26,0.3461538553237915,0.7692307829856873,0.5326797385620915,0.17960080045920154,mmlu:high_school_microeconomics,validation,37.28656352683902
238,0.38235294818878174,0.6638655662536621,0.5835762876579202,0.06155047346563902,mmlu:high_school_microeconomics,test,313.49372144881636
22,0.40909093618392944,0.7272727489471436,0.2649572649572649,0.25309823047031055,mmlu:college_medicine,validation,25.048515687696636
173,0.3815028667449951,0.6589595079421997,0.518833191730388,0.0910533129135308,mmlu:college_medicine,test,186.14646009076387
11,0.27272728085517883,0.8181818723678589,0.16666666666666666,0.19354466958479447,mmlu:college_computer_science,validation,20.226272262632847
100,0.23999999463558197,0.7699999809265137,0.5268640350877193,0.10027420341968536,mmlu:college_computer_science,test,142.47245048731565
27,0.7037037014961243,0.7407407760620117,0.4934210526315789,0.11936659503866125,mmlu:security_studies,validation,41.75887288572267
245,0.669387698173523,0.6163265109062195,0.44508431195423065,0.08025290966033938,mmlu:security_studies,test,418.56283105770126
86,0.5348837375640869,0.7209302186965942,0.5182065217391304,0.08093805784402892,mmlu:miscellaneous,validation,78.21223918348551
783,0.6028096675872803,0.7241379022598267,0.6112560630007084,0.03079755568108495,mmlu:miscellaneous,test,707.9785927310586
