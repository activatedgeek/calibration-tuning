N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.5454545617103577,0.5454545617103577,0.8500000000000001,0.2835712432861328,mmlu:business_ethics,validation,33.973410729988245
100,0.35999998450279236,0.4599999785423279,0.6718749999999999,0.24156483530998227,mmlu:business_ethics,test,288.38238079697476
11,0.3636363744735718,0.7272727489471436,0.08928571428571429,0.2847485704855485,mmlu:jurisprudence,validation,37.275100007653236
108,0.43518519401550293,0.6759259104728699,0.4358214161144053,0.056930780962661465,mmlu:jurisprudence,test,319.9139903243631
11,0.0,1.0,,0.17553822018883442,mmlu:college_mathematics,validation,33.753335929999594
100,0.1599999964237213,0.8399999737739563,0.28199404761904767,0.05471303105354309,mmlu:college_mathematics,test,294.01762222201796
29,0.27586206793785095,0.7586206793785095,0.3511904761904762,0.10107195171816596,mmlu:clinical_knowledge,validation,80.91310188733041
265,0.34339624643325806,0.7245283126831055,0.47306429202980926,0.07630133606352894,mmlu:clinical_knowledge,test,717.711964353919
22,0.3181818127632141,0.6363636255264282,0.5523809523809524,0.15510879050601611,mmlu:sociology,validation,68.13631364237517
201,0.4079601764678955,0.6368159055709839,0.48293707726993235,0.045830982241464494,mmlu:sociology,test,601.3809938039631
14,0.3571428656578064,0.7142857313156128,0.20000000000000004,0.12078590478215895,mmlu:formal_logic,validation,44.375206066062674
126,0.2936508059501648,0.7460317611694336,0.5692377771029457,0.08413593068955436,mmlu:formal_logic,test,403.59969948395155
21,0.4285714328289032,0.6666666865348816,0.3611111111111111,0.15304959955669584,mmlu:high_school_government_and_politics,validation,57.243655283004045
193,0.47668391466140747,0.6528497338294983,0.6230628497632371,0.04593877347639807,mmlu:high_school_government_and_politics,test,644.1258094385266
11,0.7272727489471436,0.7272727489471436,0.875,0.30331549319353973,mmlu:medical_genetics,validation,36.840387078002095
100,0.4399999976158142,0.6399999856948853,0.5594561688311689,0.04307632625102996,mmlu:medical_genetics,test,303.5477021113038
23,0.1304347813129425,0.739130437374115,0.22499999999999998,0.13788983355397763,mmlu:high_school_statistics,validation,70.81413382699247
216,0.23148147761821747,0.7268518805503845,0.4063253012048193,0.05536472990556997,mmlu:high_school_statistics,test,634.0394416250056
60,0.5166667103767395,0.7500000596046448,0.7263626251390434,0.17091195682684576,mmlu:high_school_psychology,validation,195.0928341979161
545,0.5100917220115662,0.631192684173584,0.6549457063562634,0.06164309672259409,mmlu:high_school_psychology,test,1649.0244074808434
41,0.24390242993831635,0.7317072749137878,0.32419354838709674,0.04569741429352178,mmlu:elementary_mathematics,validation,126.04147319123149
378,0.32010582089424133,0.6719576716423035,0.417258899572306,0.019277733627450565,mmlu:elementary_mathematics,test,1094.7675515338778
11,0.4545454680919647,0.9090909361839294,0.06666666666666668,0.2692721540277654,mmlu:management,validation,31.050981303676963
103,0.4563106894493103,0.6893203854560852,0.3529635258358662,0.07303405733941827,mmlu:management,test,272.5460078138858
16,0.4375,0.75,0.4841269841269842,0.10065831989049911,mmlu:astronomy,validation,47.09254963201238
152,0.4802631735801697,0.7236841917037964,0.5556615224553494,0.07559489733294437,mmlu:astronomy,test,437.808377037989
18,0.3888888955116272,0.6111111044883728,0.6038961038961038,0.11299107472101849,mmlu:logical_fallacies,validation,54.96246573328972
163,0.43558281660079956,0.6932514905929565,0.5849663196570729,0.07288821672369368,mmlu:logical_fallacies,test,466.69491443410516
19,0.6842105388641357,0.8421052694320679,0.7243589743589743,0.1581429713650754,mmlu:world_religions,validation,54.92375906999223
171,0.5906432867050171,0.6725146174430847,0.7463932107496464,0.030842256476307464,mmlu:world_religions,test,496.3540683360188
22,0.4545454680919647,0.6818181872367859,0.23750000000000002,0.09630248221484096,mmlu:high_school_geography,validation,64.53165314998478
198,0.36868685483932495,0.7222222089767456,0.34071232876712326,0.05725016377188945,mmlu:high_school_geography,test,569.9126331309963
17,0.1764705926179886,0.7058823704719543,0.7976190476190476,0.10827324320288267,mmlu:high_school_physics,validation,159.1289937272668
151,0.16556291282176971,0.7814569473266602,0.3790476190476191,0.12553698179737627,mmlu:high_school_physics,test,432.2480743601918
11,0.1818181872367859,0.7272727489471436,0.02777777777777779,0.19728745655580004,mmlu:machine_learning,validation,34.6267974358052
112,0.2142857313156128,0.7410714626312256,0.39015151515151514,0.09228222497871946,mmlu:machine_learning,test,331.72974652051926
26,0.26923078298568726,0.7692307829856873,0.48120300751879697,0.14147681227097142,mmlu:high_school_microeconomics,validation,72.718330912292
238,0.31512606143951416,0.6554622054100037,0.3282208588957055,0.060506078625927474,mmlu:high_school_microeconomics,test,668.2218537852168
35,0.3142857253551483,0.6285714507102966,0.4090909090909091,0.05413636139460975,mmlu:prehistory,validation,105.28177860751748
324,0.4135802388191223,0.6666666865348816,0.4710919088766693,0.04190825441001372,mmlu:prehistory,test,872.404989104718
12,0.25,0.6666666865348816,0.4444444444444444,0.16617188851038614,mmlu:human_sexuality,validation,39.53658866509795
131,0.4656488597393036,0.6259542107582092,0.5737704918032787,0.10052299818009822,mmlu:human_sexuality,test,392.07975317910314
10,0.20000000298023224,0.5,0.375,0.14718205332756049,mmlu:global_facts,validation,29.89129850640893
100,0.14999999105930328,0.7299999594688416,0.5858823529411765,0.14679530620574952,mmlu:global_facts,test,271.8231064118445
26,0.42307692766189575,0.6153846383094788,0.2727272727272727,0.11337590676087603,mmlu:conceptual_physics,validation,79.96777953591663
235,0.4127659499645233,0.5787233710289001,0.4087852980726131,0.11831009185060541,mmlu:conceptual_physics,test,725.6504642160144
18,0.5555555820465088,0.6666666865348816,0.7437499999999999,0.08542912205060323,mmlu:high_school_european_history,validation,62.05084380879998
165,0.6666666269302368,0.7212120890617371,0.5940495867768595,0.06826979572122746,mmlu:high_school_european_history,test,549.4953017048538
22,0.6363636255264282,0.7272727489471436,0.7232142857142857,0.11929689754139294,mmlu:high_school_us_history,validation,72.18972460925579
204,0.6323529481887817,0.7254902124404907,0.7328165374677003,0.06735811835410548,mmlu:high_school_us_history,test,655.8869936913252
23,0.260869562625885,0.739130437374115,0.4215686274509804,0.11403278164241624,mmlu:human_aging,validation,66.25696455998695
223,0.3228699564933777,0.7219731211662292,0.43975349521707136,0.06673391009660043,mmlu:human_aging,test,636.1484976120119
31,0.4193548262119293,0.6451612710952759,0.4786324786324786,0.09058981364773162,mmlu:professional_medicine,validation,93.16414365544915
272,0.29411765933036804,0.625,0.38053385416666663,0.06547951742130166,mmlu:professional_medicine,test,804.4755762368441
22,0.40909093618392944,0.6818181872367859,0.48290598290598286,0.07628534056923608,mmlu:college_medicine,validation,67.5591106399661
173,0.3352600932121277,0.7225433588027954,0.44565217391304346,0.06882882945110341,mmlu:college_medicine,test,545.5455541589763
11,0.7272727489471436,0.5454545617103577,0.3541666666666667,0.37019570849158545,mmlu:us_foreign_policy,validation,31.555532034486532
100,0.5799999833106995,0.5600000023841858,0.551518883415435,0.0950106132030487,mmlu:us_foreign_policy,test,279.3667780421674
26,0.5384615659713745,0.5384615659713745,0.5327380952380952,0.3108160220659696,mmlu:high_school_world_history,validation,78.02719008177519
237,0.47257381677627563,0.5063290596008301,0.7018571428571428,0.32498629309457067,mmlu:high_school_world_history,test,721.027367155999
27,0.48148149251937866,0.6296296119689941,0.7637362637362637,0.15119432961499252,mmlu:security_studies,validation,77.23758406564593
245,0.5632652640342712,0.6857142448425293,0.6365975890559392,0.059838369184610794,mmlu:security_studies,test,680.0631381887943
69,0.42028987407684326,0.5362318754196167,0.6724137931034482,0.10790823162465854,mmlu:professional_psychology,validation,202.99811707399203
612,0.2875817120075226,0.5343137383460999,0.596115252293578,0.12739686716615764,mmlu:professional_psychology,test,1896.3360361589876
9,0.2222222238779068,0.7777777910232544,0.5,0.16154666741689044,mmlu:high_school_computer_science,validation,32.65979504596908
100,0.35999998450279236,0.6599999666213989,0.5082465277777778,0.07112033247947691,mmlu:high_school_computer_science,test,322.8812105950201
12,0.4166666865348816,0.5833333730697632,0.5285714285714286,0.10418698191642763,mmlu:public_relations,validation,40.363007448613644
110,0.29999998211860657,0.7090908885002136,0.39905548996458085,0.07103342847390606,mmlu:public_relations,test,341.27156615257263
25,0.23999999463558197,0.47999998927116394,0.6315789473684211,0.329165735244751,mmlu:marketing,validation,73.46533323451877
234,0.4572649896144867,0.6282051801681519,0.7653616896018839,0.0824159462737222,mmlu:marketing,test,708.8868006784469
11,0.0,0.9090909361839294,,0.2572005499492992,mmlu:college_computer_science,validation,33.49077993602259
100,0.17999999225139618,0.85999995470047,0.4640921409214092,0.1719572585821152,mmlu:college_computer_science,test,294.4172184659983
32,0.15625,0.84375,0.3962962962962963,0.11843208596110343,mmlu:high_school_biology,validation,95.30558380298316
310,0.4419354796409607,0.6354838609695435,0.37937217838909754,0.07579250547193714,mmlu:high_school_biology,test,905.5046216007322
16,0.3125,0.8125,0.0,0.1784740947186947,mmlu:college_biology,validation,47.356541560962796
144,0.3055555522441864,0.6597222089767456,0.3471590909090909,0.07003173852960272,mmlu:college_biology,test,416.02732437849045
12,0.0833333358168602,0.8333333730697632,0.8181818181818182,0.2967009643713633,mmlu:econometrics,validation,37.3546276849811
114,0.1315789520740509,0.8333333134651184,0.5414141414141415,0.16822217274130435,mmlu:econometrics,test,338.86042738400283
29,0.10344827175140381,0.8965517282485962,0.7692307692307692,0.21334901349297886,mmlu:high_school_mathematics,validation,86.15171855999506
270,0.07777777314186096,0.9111111164093018,0.48345764008414605,0.14616591599252488,mmlu:high_school_mathematics,test,788.6655655959912
33,0.39393940567970276,0.6666666865348816,0.7461538461538462,0.08770309614412715,mmlu:nutrition,validation,103.4868159800244
306,0.36274510622024536,0.6274510025978088,0.5889581889581889,0.043931048679975125,mmlu:nutrition,test,911.7236119559966
11,0.4545454680919647,0.6363636255264282,0.6000000000000001,0.16171599518169055,mmlu:computer_security,validation,34.74134964123368
100,0.4399999976158142,0.5699999928474426,0.5602678571428572,0.09933251202106474,mmlu:computer_security,test,301.03746915608644
31,0.22580644488334656,0.774193525314331,0.28273809523809523,0.17325351122886906,mmlu:professional_accounting,validation,90.20522750541568
282,0.152482271194458,0.8297871947288513,0.39967889461905226,0.1448134978612264,mmlu:professional_accounting,test,783.9946469906718
14,0.3571428656578064,0.6428571939468384,0.36666666666666675,0.176128591809954,mmlu:anatomy,validation,45.61599052324891
135,0.4296296238899231,0.6370370388031006,0.3306090461262875,0.10815567661214755,mmlu:anatomy,test,400.0491247139871
43,0.5116279125213623,0.7209302186965942,0.5227272727272727,0.1507029685863229,mmlu:high_school_macroeconomics,validation,133.2289729807526
390,0.3384615480899811,0.7179487347602844,0.4902953958186516,0.05283717283835777,mmlu:high_school_macroeconomics,test,1170.872532935813
16,0.1875,0.875,0.2564102564102564,0.2467500902712345,mmlu:electrical_engineering,validation,48.292828457430005
145,0.22758620977401733,0.7310344576835632,0.4107142857142857,0.03337186574935912,mmlu:electrical_engineering,test,436.6765384133905
8,0.25,0.75,0.16666666666666663,0.2173186019062996,mmlu:college_chemistry,validation,25.610213169828057
100,0.11999999731779099,0.8499999642372131,0.19602272727272724,0.11739440619945522,mmlu:college_chemistry,test,300.16044250689447
34,0.29411765933036804,0.3529411852359772,0.7479166666666667,0.390852845766965,mmlu:philosophy,validation,102.25833635218441
311,0.31832796335220337,0.36012861132621765,0.6438441013912714,0.37886115209082694,mmlu:philosophy,test,939.209958942607
22,0.13636364042758942,0.7727273106575012,0.4649122807017544,0.1646452627398751,mmlu:high_school_chemistry,validation,73.20694016478956
203,0.2019704431295395,0.7980295419692993,0.2835742246311352,0.10056181229981294,mmlu:high_school_chemistry,test,606.3762840908021
18,0.4444444477558136,0.5,0.675,0.19022012088033885,mmlu:virology,validation,63.93756768107414
166,0.35542166233062744,0.6445782780647278,0.31641058134009187,0.09240668653005576,mmlu:virology,test,555.0020745061338
11,0.27272728085517883,0.9090909361839294,0.3125,0.24671542644500732,mmlu:college_physics,validation,36.365337615832686
102,0.14705882966518402,0.8235294222831726,0.30766283524904214,0.14755408202900608,mmlu:college_physics,test,279.48727823235095
11,0.1818181872367859,0.8181818723678589,0.6944444444444444,0.15527085282585837,mmlu:abstract_algebra,validation,34.749003352597356
100,0.2199999988079071,0.7400000095367432,0.3884032634032634,0.09481012284755708,mmlu:abstract_algebra,test,301.6433098204434
38,0.42105263471603394,0.6052631735801697,0.5880681818181819,0.0453491587387888,mmlu:moral_disputes,validation,119.98385518789291
346,0.398843914270401,0.6300578117370605,0.4350961538461538,0.0646063483863897,mmlu:moral_disputes,test,1070.788845071569
13,0.3076923191547394,0.46153849363327026,0.6805555555555556,0.252256269638355,mmlu:international_law,validation,48.81410039961338
121,0.4793388247489929,0.6033057570457458,0.6538040503557745,0.10471972453692727,mmlu:international_law,test,373.6597556360066
