N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.3636363744735718,0.7777777777777778,0.15980113636363635,mmlu:abstract_algebra,validation,4.422439154936001
100,0.30000001192092896,0.33000001311302185,0.5342857142857143,0.2056640815734863,mmlu:abstract_algebra,test,1.6263776931446046
14,0.3571428656578064,0.3571428656578064,0.7666666666666668,0.3805803614003318,mmlu:anatomy,validation,0.506972418166697
135,0.5185185074806213,0.5111111402511597,0.5921978021978022,0.18851270984720306,mmlu:anatomy,test,2.0395466098561883
16,0.5,0.5,0.625,0.2373046837747097,mmlu:astronomy,validation,0.5118576539680362
152,0.6907894611358643,0.6907894611358643,0.6873353596757852,0.03428248825826144,mmlu:astronomy,test,2.3795015709474683
11,0.5454545617103577,0.7272727489471436,0.8833333333333333,0.21413353898308496,mmlu:business_ethics,validation,0.49942949297837913
100,0.4300000071525574,0.6800000071525574,0.6952264381884945,0.16558594167232518,mmlu:business_ethics,test,1.7293584258295596
29,0.4137931168079376,0.4137931168079376,0.4877450980392156,0.24030171591660066,mmlu:clinical_knowledge,validation,0.6919811428524554
265,0.4226415157318115,0.4226415157318115,0.5626458916900093,0.23469930414883597,mmlu:clinical_knowledge,test,4.096117286011577
16,0.375,0.375,0.3833333333333333,0.3591308556497097,mmlu:college_biology,validation,0.4891878208145499
144,0.4791666567325592,0.4791666567325592,0.6907246376811594,0.19344075520833334,mmlu:college_biology,test,2.2350874429102987
8,0.0,0.25,,0.28759765625,mmlu:college_chemistry,validation,0.5039053049404174
100,0.25999999046325684,0.550000011920929,0.7125779625779626,0.02476562738418583,mmlu:college_chemistry,test,1.799128806218505
11,0.1818181872367859,0.8181818127632141,0.5,0.18146306818181823,mmlu:college_computer_science,validation,0.5216511799953878
100,0.3100000023841858,0.6899999976158142,0.5,0.05328124999999995,mmlu:college_computer_science,test,1.8323499951511621
11,0.09090909361839294,0.09090909361839294,0.0,0.4833096645095132,mmlu:college_mathematics,validation,0.5107245510444045
100,0.14000000059604645,0.20999999344348907,0.43895348837209297,0.3735937595367431,mmlu:college_mathematics,test,1.8501561000011861
22,0.40909090638160706,0.40909090638160706,0.49572649572649574,0.3140980249101466,mmlu:college_medicine,validation,0.5937924620229751
173,0.4624277353286743,0.4624277353286743,0.6139784946236561,0.28353051746511737,mmlu:college_medicine,test,3.064414589898661
11,0.1818181872367859,0.27272728085517883,0.861111111111111,0.3022017153826627,mmlu:college_physics,validation,0.5138405910693109
102,0.19607843458652496,0.3137255012989044,0.6527439024390245,0.25988052989922317,mmlu:college_physics,test,1.8125439051073045
11,0.8181818127632141,0.5454545617103577,0.8611111111111112,0.11576702378012918,mmlu:computer_security,validation,0.4916416350752115
100,0.6800000071525574,0.49000000953674316,0.6318933823529411,0.09609372615814209,mmlu:computer_security,test,1.6691971011459827
26,0.38461539149284363,0.38461539149284363,0.575,0.22070312958497268,mmlu:conceptual_physics,validation,0.6839563499670476
235,0.46382978558540344,0.45957446098327637,0.5583588175331295,0.13716753467600395,mmlu:conceptual_physics,test,3.5167523690033704
12,0.4166666567325592,0.4166666567325592,0.2857142857142857,0.12141927083333331,mmlu:econometrics,validation,0.3763972909655422
114,0.31578946113586426,0.3684210479259491,0.5763888888888888,0.19236570230701516,mmlu:econometrics,test,1.7865793181117624
16,0.3125,0.5625,0.0,0.1865234300494194,mmlu:electrical_engineering,validation,0.4690115209668875
145,0.43448275327682495,0.6206896305084229,0.6361788617886179,0.03596444294370454,mmlu:electrical_engineering,test,2.284625965869054
41,0.3658536672592163,0.6341463327407837,0.5012820512820513,0.14576980398922434,mmlu:elementary_mathematics,validation,0.7986606699414551
378,0.45502644777297974,0.5449735522270203,0.4726941747572816,0.2306237611821089,mmlu:elementary_mathematics,test,5.231709589017555
14,0.2857142984867096,0.2857142984867096,0.675,0.338169664144516,mmlu:formal_logic,validation,0.4175406580325216
126,0.380952388048172,0.380952388048172,0.45219017094017094,0.24206346557253883,mmlu:formal_logic,test,1.927571804029867
10,0.5,0.5,0.48000000000000004,0.2519531071186066,mmlu:global_facts,validation,0.3428687748964876
100,0.20999999344348907,0.20999999344348907,0.5009041591320073,0.4669140636920929,mmlu:global_facts,test,1.5958392480388284
32,0.40625,0.40625,0.680161943319838,0.3304443508386612,mmlu:high_school_biology,validation,0.6057557968888432
310,0.57419353723526,0.57419353723526,0.558158835546476,0.18971775597141638,mmlu:high_school_biology,test,4.4498861350584775
22,0.22727273404598236,0.22727273404598236,0.676470588235294,0.3991477245634252,mmlu:high_school_chemistry,validation,0.5047548310831189
203,0.2807881832122803,0.29064038395881653,0.5680725787070415,0.3421143945214784,mmlu:high_school_chemistry,test,2.948978873901069
9,0.4444444477558136,0.5555555820465088,0.7,0.10199652777777776,mmlu:high_school_computer_science,validation,0.40467552887275815
100,0.5099999904632568,0.49000000953674316,0.5592236894757903,0.08468751668930054,mmlu:high_school_computer_science,test,1.6294455109164119
18,0.8333333134651184,0.8333333134651184,0.5,0.29817708333333337,mmlu:high_school_european_history,validation,0.5957610511686653
165,0.8060606122016907,0.8060606122016907,0.5,0.27090435606060603,mmlu:high_school_european_history,test,3.373280053026974
22,0.3636363744735718,0.3636363744735718,0.7410714285714286,0.2876420319080353,mmlu:high_school_geography,validation,0.47528602089732885
198,0.4595959484577179,0.4595959484577179,0.5236725890931498,0.16852114778576474,mmlu:high_school_geography,test,2.890360871097073
21,0.761904776096344,0.2380952388048172,0.8,0.29203866493134273,mmlu:high_school_government_and_politics,validation,0.5091834310442209
193,0.6269429922103882,0.40414509177207947,0.5799471992653812,0.12884555672116849,mmlu:high_school_government_and_politics,test,2.844303260790184
43,0.5116279125213623,0.5116279125213623,0.38311688311688313,0.1540697577387787,mmlu:high_school_macroeconomics,validation,0.8013847761321813
390,0.5102564096450806,0.5128205418586731,0.5214949091004762,0.08564702104299497,mmlu:high_school_macroeconomics,test,5.335435923188925
29,0.13793103396892548,0.8620689511299133,0.44,0.11045256359823817,mmlu:high_school_mathematics,validation,0.6164507830981165
270,0.11481481790542603,0.885185182094574,0.5355648535564853,0.13368057387846483,mmlu:high_school_mathematics,test,4.011436698958278
26,0.38461539149284363,0.38461539149284363,0.40625,0.2797476053237915,mmlu:high_school_microeconomics,validation,0.5911642869468778
238,0.45798319578170776,0.45798319578170776,0.5298342934357443,0.20028556344889792,mmlu:high_school_microeconomics,test,3.3378003530669957
17,0.1764705926179886,0.529411792755127,0.45238095238095233,0.006663592422709752,mmlu:high_school_physics,validation,0.49515063501894474
151,0.38410595059394836,0.503311276435852,0.5413422321097516,0.035130394215615375,mmlu:high_school_physics,test,2.2790198009461164
60,0.6333333253860474,0.36666667461395264,0.5245215311004785,0.2056640823682149,mmlu:high_school_psychology,validation,1.1065788140986115
545,0.6091743111610413,0.39266055822372437,0.5731376209061598,0.1649727899000185,mmlu:high_school_psychology,test,7.722254525870085
23,0.30434781312942505,0.695652186870575,0.6339285714285714,0.16983698502830835,mmlu:high_school_statistics,validation,0.5427077240310609
216,0.40740740299224854,0.5462962985038757,0.5642311789772728,0.017541958226098,mmlu:high_school_statistics,test,3.2614053240977228
22,0.8181818127632141,0.8181818127632141,0.5,0.30646306818181823,mmlu:high_school_us_history,validation,0.5681292060762644
204,0.7352941036224365,0.7352941036224365,0.5,0.22357536764705888,mmlu:high_school_us_history,test,3.9727910081855953
26,0.692307710647583,0.692307710647583,0.5,0.1766826923076923,mmlu:high_school_world_history,validation,0.7100658260751516
237,0.7257384061813354,0.7257384061813354,0.5,0.2101133966244726,mmlu:high_school_world_history,test,4.048411143943667
23,0.43478259444236755,0.43478259444236755,0.48076923076923084,0.23335595493731293,mmlu:human_aging,validation,0.49132165987975895
223,0.46188339591026306,0.46188339591026306,0.6307443365695793,0.19492711881885616,mmlu:human_aging,test,3.0859575842041522
12,0.5,0.5,0.40277777777777785,0.20052082339922586,mmlu:human_sexuality,validation,0.37020464800298214
131,0.6030534505844116,0.5954198241233826,0.5073028237585199,0.0485448268533663,mmlu:human_sexuality,test,2.005299505079165
13,0.6153846383094788,0.5384615659713745,0.475,0.01923074630590582,mmlu:international_law,validation,0.41566887591034174
121,0.7851239442825317,0.7768595218658447,0.5202429149797572,0.19615183930751703,mmlu:international_law,test,1.9130000281147659
11,0.7272727489471436,0.7272727489471436,0.41666666666666663,0.10688921538266269,mmlu:jurisprudence,validation,0.3751965679693967
108,0.7407407164573669,0.7314814925193787,0.41316964285714286,0.1109302673074934,mmlu:jurisprudence,test,1.6726445280946791
18,0.6666666865348816,0.6666666865348816,0.5069444444444444,0.24631074733204314,mmlu:logical_fallacies,validation,0.4976196999195963
163,0.5889570713043213,0.5889570713043213,0.560556592039801,0.03518022350007042,mmlu:logical_fallacies,test,2.4407867479603738
11,0.4545454680919647,0.5454545617103577,0.3,0.011008544401688969,mmlu:machine_learning,validation,0.3692780761048198
112,0.4642857015132904,0.5267857313156128,0.4969551282051282,0.0037318638392856984,mmlu:machine_learning,test,1.752175227040425
11,0.6363636255264282,0.5454545617103577,0.7857142857142857,0.2634943290190263,mmlu:management,validation,0.3501151232048869
103,0.49514561891555786,0.5242718458175659,0.7897812971342384,0.16732405400970607,mmlu:management,test,1.5656925460789353
25,0.36000001430511475,0.6399999856948853,0.4166666666666667,0.12234373331069948,mmlu:marketing,validation,0.6512323620263487
234,0.4444444477558136,0.5811966061592102,0.5586908284023667,0.06173208839872968,mmlu:marketing,test,3.3757970419246703
11,0.7272727489471436,0.7272727489471436,0.7083333333333334,0.09374999458139593,mmlu:medical_genetics,validation,0.37149130017496645
100,0.5600000023841858,0.5600000023841858,0.6174918831168831,0.2123437559604645,mmlu:medical_genetics,test,1.518673158949241
86,0.6744186282157898,0.4883720874786377,0.540948275862069,0.033521094987558765,mmlu:miscellaneous,validation,1.3585157108027488
783,0.6666666865348816,0.5389527678489685,0.5680627119390496,0.017136619617808085,mmlu:miscellaneous,test,10.581734081031755
38,0.6315789222717285,0.6315789222717285,0.48809523809523814,0.0754523057686655,mmlu:moral_disputes,validation,0.7215380759444088
346,0.5780346989631653,0.5635837912559509,0.49611301369863015,0.008512466629116545,mmlu:moral_disputes,test,4.905718524008989
100,0.5,0.5,0.48700000000000004,0.10222655534744265,mmlu:moral_scenarios,validation,1.6476049371995032
895,0.5307262539863586,0.529608964920044,0.5112556390977445,0.07333713157216931,mmlu:moral_scenarios,test,13.004959444049746
33,0.5454545617103577,0.5454545617103577,0.661111111111111,0.09114581346511844,mmlu:nutrition,validation,0.735371275106445
306,0.5522875785827637,0.5555555820465088,0.5716537813674254,0.0555683054955177,mmlu:nutrition,test,4.403325903927907
34,0.47058823704719543,0.47058823704719543,0.7256944444444445,0.14751837008139668,mmlu:philosophy,validation,0.7576720190700144
311,0.4308681786060333,0.4565916359424591,0.5298296652331562,0.13821343018694324,mmlu:philosophy,test,4.328166858991608
35,0.4571428596973419,0.48571428656578064,0.569078947368421,0.11004464796611244,mmlu:prehistory,validation,0.755280327051878
324,0.5555555820465088,0.5555555820465088,0.6066550925925926,0.07401380623564306,mmlu:prehistory,test,4.581768303876743
31,0.25806450843811035,0.6774193644523621,0.4429347826086956,0.1628024481957958,mmlu:professional_accounting,validation,0.6734048610087484
282,0.20921985805034637,0.741134762763977,0.5965645663905146,0.22689496371762974,mmlu:professional_accounting,test,4.370073433034122
170,0.4647058844566345,0.5352941155433655,0.5,0.01576286764705881,mmlu:professional_law,validation,2.97316428902559
1534,0.36245110630989075,0.6375488638877869,0.5,0.1180176417861799,mmlu:professional_law,test,25.333077137824148
31,0.4193548262119293,0.4193548262119293,0.5,0.10017641129032256,mmlu:professional_medicine,validation,0.7158213800285012
272,0.375,0.375,0.5,0.14453125,mmlu:professional_medicine,test,4.4339944559615105
69,0.5362318754196167,0.5072463750839233,0.48902027027027034,0.014153061569600833,mmlu:professional_psychology,validation,1.1599304222036153
612,0.4395424723625183,0.46568626165390015,0.5151950318098562,0.0568065512803645,mmlu:professional_psychology,test,8.576849702978507
12,0.4166666567325592,0.5,0.6428571428571428,0.04654949903488159,mmlu:public_relations,validation,0.40110881091095507
110,0.37272727489471436,0.40909090638160706,0.49045599151643693,0.12947443073446102,mmlu:public_relations,test,1.646218289854005
27,0.6666666865348816,0.6666666865348816,0.7407407407407407,0.12196182100861162,mmlu:security_studies,validation,0.6595169450156391
245,0.7877551317214966,0.7755101919174194,0.6141889198884017,0.20448022034703467,mmlu:security_studies,test,3.659964662976563
22,0.6818181872367859,0.6818181872367859,0.5476190476190476,0.06285512176426979,mmlu:sociology,validation,0.5119422599673271
201,0.5671641826629639,0.5621890425682068,0.5998689251865296,0.05414337186671015,mmlu:sociology,test,2.9716574831400067
11,0.9090909361839294,0.9090909361839294,0.8500000000000001,0.28302557901902625,mmlu:us_foreign_policy,validation,0.39268002402968705
100,0.7900000214576721,0.7900000214576721,0.647377938517179,0.1633984261751175,mmlu:us_foreign_policy,test,1.5783809290733188
18,0.6666666865348816,0.6666666865348816,0.6041666666666667,0.2213541832235124,mmlu:virology,validation,0.46398799889720976
166,0.6867470145225525,0.6867470145225525,0.6931511470985156,0.20368978057999212,mmlu:virology,test,2.3853218590375036
19,0.6315789222717285,0.6315789222717285,0.44047619047619047,0.0890213753047742,mmlu:world_religions,validation,0.45488760503940284
171,0.6900584697723389,0.6959064602851868,0.627758234729773,0.0790159203852826,mmlu:world_religions,test,2.458679657196626
