N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.8181818127632141,0.45,0.31463069265539,mmlu:abstract_algebra,validation,2.9333271400246304
100,0.20999999344348907,0.6899999976158142,0.6238698010849909,0.1869921708106994,mmlu:abstract_algebra,test,1.881258760986384
14,0.2142857164144516,0.4285714328289032,0.7727272727272727,0.08677456208637785,mmlu:anatomy,validation,0.3887173520051874
135,0.385185182094574,0.4962962865829468,0.5373030583873957,0.013396968664946385,mmlu:anatomy,test,2.649414451996563
16,0.5625,0.5625,0.5238095238095238,0.015380859375,mmlu:astronomy,validation,0.377365443011513
152,0.42763158679008484,0.42763158679008484,0.5767462422634837,0.12510279605263158,mmlu:astronomy,test,2.5591754830093123
11,0.4545454680919647,0.7272727489471436,0.7833333333333333,0.21306816556236963,mmlu:business_ethics,validation,0.404918476997409
100,0.33000001311302185,0.4099999964237213,0.5345997286295794,0.10632809638977053,mmlu:business_ethics,test,2.07461634799256
29,0.17241379618644714,0.17241379618644714,0.3416666666666667,0.34563580463672505,mmlu:clinical_knowledge,validation,0.7560337739996612
265,0.2792452871799469,0.2981131970882416,0.5304230932503184,0.21844043281843079,mmlu:clinical_knowledge,test,4.806640340015292
16,0.375,0.3125,0.3416666666666667,0.202880859375,mmlu:college_biology,validation,0.4693783289985731
144,0.3402777910232544,0.375,0.4721804511278196,0.1415473222732544,mmlu:college_biology,test,2.5451026060036384
8,0.0,0.875,,0.36376953125,mmlu:college_chemistry,validation,0.36254215199733153
100,0.14000000059604645,0.7900000214576721,0.6623754152823921,0.2763671660423279,mmlu:college_chemistry,test,1.9761953459819779
11,0.27272728085517883,0.7272727489471436,0.5,0.1882102272727273,mmlu:college_computer_science,validation,0.484944688010728
100,0.17000000178813934,0.8299999833106995,0.5,0.29093749999999996,mmlu:college_computer_science,test,1.972262605006108
11,0.0,0.9090909361839294,,0.3863636580380526,mmlu:college_mathematics,validation,0.46661294699879363
100,0.2199999988079071,0.7300000190734863,0.5842074592074592,0.20925782203674315,mmlu:college_mathematics,test,1.961169707996305
22,0.3181818127632141,0.3181818127632141,0.6238095238095238,0.19620030576532538,mmlu:college_medicine,validation,0.5845298890199047
173,0.2947976887226105,0.30635836720466614,0.6665059466409514,0.20989884496424238,mmlu:college_medicine,test,3.151041537988931
11,0.09090909361839294,0.9090909361839294,0.8,0.3980824080380526,mmlu:college_physics,validation,0.42090408300282434
102,0.0882352963089943,0.8725489974021912,0.6583034647550776,0.35527726248198865,mmlu:college_physics,test,1.849828194011934
11,0.6363636255264282,0.6363636255264282,0.5178571428571428,0.1083096374164928,mmlu:computer_security,validation,0.48910044800140895
100,0.5,0.5199999809265137,0.5873999999999999,0.005468766689300519,mmlu:computer_security,test,1.9304922820010688
26,0.1538461595773697,0.3461538553237915,0.6534090909090909,0.15925479852236235,mmlu:conceptual_physics,validation,0.7040123080078047
235,0.3787234127521515,0.47659575939178467,0.5319378174542096,0.029604390073329823,mmlu:conceptual_physics,test,3.991081946005579
12,0.3333333432674408,0.4166666567325592,0.71875,0.09505208333333331,mmlu:econometrics,validation,0.37997385900234804
114,0.17543859779834747,0.19298245012760162,0.6340425531914894,0.32206002766625924,mmlu:econometrics,test,2.172107654012507
16,0.1875,0.8125,0.20512820512820507,0.26708984375,mmlu:electrical_engineering,validation,0.38075001901597716
145,0.2137930989265442,0.7862069010734558,0.5093378607809846,0.2412984922014434,mmlu:electrical_engineering,test,2.5809363790031057
41,0.3658536672592163,0.6341463327407837,0.7153846153846154,0.061737784525243256,mmlu:elementary_mathematics,validation,0.9290380860038567
378,0.28042328357696533,0.7195767164230347,0.5635231687014428,0.14945024567306353,mmlu:elementary_mathematics,test,6.624962469999446
14,0.4285714328289032,0.4285714328289032,0.5625,0.08482143708637785,mmlu:formal_logic,validation,0.39416972201433964
126,0.2539682686328888,0.2539682686328888,0.6697140957446808,0.25781248486231245,mmlu:formal_logic,test,2.219305434002308
10,0.20000000298023224,0.20000000298023224,0.3125,0.3355468988418579,mmlu:global_facts,validation,0.37603522001882084
100,0.07999999821186066,0.07000000029802322,0.34035326086956524,0.46453123569488525,mmlu:global_facts,test,1.7934242229966912
32,0.3125,0.5,0.55,0.00830078125,mmlu:high_school_biology,validation,0.6290487759979442
310,0.3838709592819214,0.46451613306999207,0.5376171410972765,0.043636594280119845,mmlu:high_school_biology,test,5.251631296996493
22,0.1818181872367859,0.7272727489471436,0.8125,0.21874997832558374,mmlu:high_school_chemistry,validation,0.5445019269827753
203,0.1428571492433548,0.6600984930992126,0.5673801030519223,0.15103527830152086,mmlu:high_school_chemistry,test,3.5624428390001412
9,0.4444444477558136,0.5555555820465088,0.12499999999999999,0.03689238760206437,mmlu:high_school_computer_science,validation,0.399466915987432
100,0.4099999964237213,0.6000000238418579,0.4607275733774287,0.08031252622604368,mmlu:high_school_computer_science,test,1.8596193099801894
18,0.8333333134651184,0.8333333134651184,0.5,0.32161458333333337,mmlu:high_school_european_history,validation,0.6293346689781174
165,0.7090908885002136,0.7090908885002136,0.5,0.1973721590909091,mmlu:high_school_european_history,test,3.752357908990234
22,0.4545454680919647,0.5454545617103577,0.5708333333333333,0.03835229440168897,mmlu:high_school_geography,validation,0.5144091820111498
198,0.3737373650074005,0.469696968793869,0.5320401046207498,0.036754279425649905,mmlu:high_school_geography,test,3.355329458019696
21,0.523809552192688,0.761904776096344,0.6681818181818182,0.2568824149313427,mmlu:high_school_government_and_politics,validation,0.5131386619759724
193,0.5233160853385925,0.5699481964111328,0.6204799827808868,0.06531332935076306,mmlu:high_school_government_and_politics,test,3.331406232988229
43,0.39534884691238403,0.5116279125213623,0.47398190045248867,0.005995625673338445,mmlu:high_school_macroeconomics,validation,0.9336948049895
390,0.2897436022758484,0.6153846383094788,0.5784479729082138,0.10908452364114618,mmlu:high_school_macroeconomics,test,6.343607513990719
29,0.0,1.0,,0.41608297619326357,mmlu:high_school_mathematics,validation,0.695579010003712
270,0.0555555559694767,0.9444444179534912,0.6270588235294118,0.35934607717725964,mmlu:high_school_mathematics,test,4.656398223014548
26,0.26923078298568726,0.42307692766189575,0.706766917293233,0.08353364926118118,mmlu:high_school_microeconomics,validation,0.6415259779896587
238,0.3403361439704895,0.4453781545162201,0.5403790202091688,0.06126901832949211,mmlu:high_school_microeconomics,test,3.9373278899875004
17,0.0,1.0,,0.47265625,mmlu:high_school_physics,validation,0.5009513669938315
151,0.18543046712875366,0.8145695328712463,0.6411149825783973,0.28743273375050127,mmlu:high_school_physics,test,2.552295291010523
60,0.5666666626930237,0.4333333373069763,0.5712669683257919,0.08691406647364297,mmlu:high_school_psychology,validation,1.1825432140030898
545,0.5009174346923828,0.4990825653076172,0.5337952488687784,0.02176034100558777,mmlu:high_school_psychology,test,9.067176520999055
23,0.17391304671764374,0.782608687877655,0.5855263157894737,0.2695312577745189,mmlu:high_school_statistics,validation,0.5361254159943201
216,0.19907407462596893,0.7870370149612427,0.5454362145449657,0.27226199927153416,mmlu:high_school_statistics,test,3.9137015599990264
22,0.6363636255264282,0.6363636255264282,0.5,0.12464488636363635,mmlu:high_school_us_history,validation,0.6286247939860914
204,0.5784313678741455,0.5784313678741455,0.5,0.06671262254901966,mmlu:high_school_us_history,test,4.367615419003414
26,0.7307692170143127,0.26923078298568726,0.5,0.23858173076923078,mmlu:high_school_world_history,validation,0.7392929390189238
237,0.552742600440979,0.4472573697566986,0.5,0.060555116033755296,mmlu:high_school_world_history,test,4.615146908996394
23,0.30434781312942505,0.30434781312942505,0.3080357142857143,0.2243546117906985,mmlu:human_aging,validation,0.510609495016979
223,0.33183857798576355,0.33183857798576355,0.5984944676219844,0.1993238757544034,mmlu:human_aging,test,3.6142566909838933
12,0.25,0.3333333432674408,0.8518518518518519,0.18229166666666669,mmlu:human_sexuality,validation,0.38623112699133344
131,0.4198473393917084,0.47328245639801025,0.5527511961722489,0.03965885812089642,mmlu:human_sexuality,test,2.2751139869797044
13,0.4615384638309479,0.4615384638309479,0.47619047619047616,0.06460336079964268,mmlu:international_law,validation,0.37938836799003184
121,0.6115702390670776,0.6198347210884094,0.5309085681426107,0.09281377949990521,mmlu:international_law,test,2.163478684000438
11,0.5454545617103577,0.5454545617103577,0.2833333333333333,0.006036920980973637,mmlu:jurisprudence,validation,0.3773826730030123
108,0.5185185074806213,0.5185185074806213,0.5221497252747253,0.025028932977605778,mmlu:jurisprudence,test,1.9525005289760884
18,0.4444444477558136,0.4444444477558136,0.2,0.10568574402067399,mmlu:logical_fallacies,validation,0.5032821710046846
163,0.42944785952568054,0.42944785952568054,0.46313364055299544,0.11891297182422472,mmlu:logical_fallacies,test,2.8404172669979744
11,0.3636363744735718,0.6363636255264282,0.3392857142857143,0.11257101189006458,mmlu:machine_learning,validation,0.4062192050041631
112,0.1964285671710968,0.8035714030265808,0.6022727272727273,0.2806919472558158,mmlu:machine_learning,test,2.0487919739971403
11,0.27272728085517883,0.7272727489471436,0.5,0.21803978898308496,mmlu:management,validation,0.3721621730073821
103,0.3689320385456085,0.6310679316520691,0.608502024291498,0.12196603388462257,mmlu:management,test,1.763357204006752
25,0.20000000298023224,0.5199999809265137,0.53,0.01250000715255739,mmlu:marketing,validation,0.6369459510024171
234,0.39743590354919434,0.44871795177459717,0.49336536261725006,0.05866051025879687,mmlu:marketing,test,3.9494345790008083
11,0.7272727489471436,0.6363636255264282,0.6458333333333334,0.12500001083720813,mmlu:medical_genetics,validation,0.3953766050108243
100,0.4099999964237213,0.47999998927116394,0.5791649441918147,0.02808596611022951,mmlu:medical_genetics,test,1.7068122389900964
86,0.41860464215278625,0.5232558250427246,0.5627777777777778,0.015261638996213023,mmlu:miscellaneous,validation,1.501396203006152
783,0.4533844292163849,0.5568326711654663,0.5945307358167697,0.04875078176934444,mmlu:miscellaneous,test,12.33770566500607
38,0.4736842215061188,0.4736842215061188,0.7611111111111112,0.0525287797576503,mmlu:moral_disputes,validation,0.7605393929989077
346,0.41040462255477905,0.41040462255477905,0.4615955537144435,0.11590045518268738,mmlu:moral_disputes,test,5.68166754298727
100,0.5099999904632568,0.5099999904632568,0.5034013605442176,0.03769533872604369,mmlu:moral_scenarios,validation,1.9248488509911112
895,0.46145251393318176,0.46145251393318176,0.49145258356524973,0.08629104491718653,mmlu:moral_scenarios,test,15.164661729009822
33,0.3636363744735718,0.3636363744735718,0.5476190476190477,0.1616950739513744,mmlu:nutrition,validation,0.7897598039999139
306,0.4084967374801636,0.4117647111415863,0.5289723756906077,0.11229828525992003,mmlu:nutrition,test,5.134519371000351
34,0.3529411852359772,0.3529411852359772,0.5511363636363636,0.17153034490697522,mmlu:philosophy,validation,0.7667089249880519
311,0.3376205861568451,0.3536977469921112,0.5073046694405918,0.1707194723500316,mmlu:philosophy,test,5.025500107993139
35,0.2857142984867096,0.6571428775787354,0.43999999999999995,0.1412946377481733,mmlu:prehistory,validation,0.7608915739983786
324,0.34259259700775146,0.6481481194496155,0.5837668654570063,0.13430747279414423,mmlu:prehistory,test,5.281841688993154
31,0.06451612710952759,0.8709677457809448,0.5431034482758621,0.3550907334973735,mmlu:professional_accounting,validation,0.6721438840031624
282,0.1560283750295639,0.7659574747085571,0.6003628724216958,0.2517314870306786,mmlu:professional_accounting,test,4.983147689985344
170,0.30588236451148987,0.30588236451148987,0.5,0.2136488970588235,mmlu:professional_law,validation,3.4153783390065655
1534,0.3200782239437103,0.3200782239437103,0.5,0.1994530231421121,mmlu:professional_law,test,28.85287769700517
31,0.25806450843811035,0.7419354915618896,0.5,0.23412298387096775,mmlu:professional_medicine,validation,0.697511905018473
272,0.23529411852359772,0.7647058963775635,0.5,0.2568933823529411,mmlu:professional_medicine,test,5.076985157007584
69,0.37681159377098083,0.5797101259231567,0.48434704830053665,0.07252039425614953,mmlu:professional_psychology,validation,1.3007320439792238
612,0.32189542055130005,0.5996732115745544,0.5241086172099566,0.09292023477990641,mmlu:professional_psychology,test,10.05025951800053
12,0.3333333432674408,0.4166666567325592,0.640625,0.0898437698682149,mmlu:public_relations,validation,0.3760601649992168
110,0.3272727131843567,0.4909090995788574,0.5966591591591591,0.017578133669766516,mmlu:public_relations,test,1.92971789999865
27,0.7407407164573669,0.7777777910232544,0.7892857142857144,0.26229743825064766,mmlu:security_studies,validation,0.6703427350148559
245,0.6816326379776001,0.7020407915115356,0.6267848917549517,0.18397637702980818,mmlu:security_studies,test,4.276813967007911
22,0.5,0.5,0.6735537190082644,0.024502813816070557,mmlu:sociology,validation,0.536634611984482
201,0.45771142840385437,0.45771142840385437,0.5672616673314719,0.06646455876269741,mmlu:sociology,test,3.353280368988635
11,0.5454545617103577,0.5454545617103577,0.6333333333333333,0.01846591992811719,mmlu:us_foreign_policy,validation,0.37824815401108935
100,0.550000011920929,0.550000011920929,0.49090909090909096,0.01941405534744267,mmlu:us_foreign_policy,test,1.8928586300171446
18,0.2777777910232544,0.2777777910232544,0.7,0.2810329927338494,mmlu:virology,validation,0.5036202129849698
166,0.34337350726127625,0.34337350726127625,0.536697247706422,0.22392693126058005,mmlu:virology,test,2.7767841419845354
19,0.6315789222717285,0.5263158082962036,0.6190476190476191,0.0228207519179896,mmlu:world_religions,validation,0.49340118799591437
171,0.5380116701126099,0.5204678177833557,0.5650798018712162,0.016538757678360994,mmlu:world_religions,test,2.8190548949933145
