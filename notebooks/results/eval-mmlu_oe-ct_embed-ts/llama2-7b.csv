N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.8181818127632141,0.3055555555555556,0.30255681818181823,mmlu:abstract_algebra,validation,2.8882655180059373
100,0.2199999988079071,0.7799999713897705,0.6025641025641026,0.2683202910423279,mmlu:abstract_algebra,test,1.8198958321008831
14,0.2857142984867096,0.3571428656578064,0.75,0.16517854588372366,mmlu:anatomy,validation,0.4278001228813082
135,0.4148148000240326,0.4888888895511627,0.5325497287522604,0.02734372085995146,mmlu:anatomy,test,2.4669378171674907
16,0.4375,0.375,0.5,0.139404296875,mmlu:astronomy,validation,0.46973836701363325
152,0.5065789222717285,0.5526315569877625,0.6187878787878788,0.03824015667563996,mmlu:astronomy,test,2.7286080659832805
11,0.6363636255264282,0.4545454680919647,0.8035714285714286,0.05504260821775958,mmlu:business_ethics,validation,0.6279830951243639
100,0.30000001192092896,0.7099999785423279,0.5645238095238095,0.20070310592651364,mmlu:business_ethics,test,1.8927242448553443
29,0.24137930572032928,0.3448275923728943,0.5941558441558441,0.16082972904731485,mmlu:clinical_knowledge,validation,0.7092440789565444
265,0.35849055647850037,0.4000000059604645,0.5285448916408669,0.1052034258842468,mmlu:clinical_knowledge,test,4.6358372459653765
16,0.3125,0.5625,0.6727272727272728,0.053955078125,mmlu:college_biology,validation,0.41756912996061146
144,0.2986111044883728,0.4722222089767456,0.4974671885793231,0.03634981976615059,mmlu:college_biology,test,2.4668208118528128
8,0.125,0.875,0.5714285714285714,0.34716796875,mmlu:college_chemistry,validation,0.29331293888390064
100,0.14000000059604645,0.8600000143051147,0.7404485049833887,0.3292968726158142,mmlu:college_chemistry,test,1.8827329620253295
11,0.0,1.0,,0.44921875,mmlu:college_computer_science,validation,0.4890848759096116
100,0.17000000178813934,0.8299999833106995,0.5,0.27921874999999996,mmlu:college_computer_science,test,2.017541283974424
11,0.0,1.0,,0.4747869372367859,mmlu:college_mathematics,validation,0.4135179079603404
100,0.1599999964237213,0.8399999737739563,0.6127232142857142,0.31464841604232785,mmlu:college_mathematics,test,2.024424222065136
22,0.3636363744735718,0.5454545617103577,0.8035714285714286,0.027876420454545414,mmlu:college_medicine,validation,0.5576967550441623
173,0.36994218826293945,0.42774567008018494,0.5650802752293578,0.09183076558085534,mmlu:college_medicine,test,2.958559924038127
11,0.27272728085517883,0.7272727489471436,0.47916666666666663,0.1899857900359414,mmlu:college_physics,validation,0.4277247751597315
102,0.14705882966518402,0.8529411554336548,0.567816091954023,0.31334253269083356,mmlu:college_physics,test,1.812888143118471
11,0.7272727489471436,0.6363636255264282,0.7916666666666667,0.11434657465327869,mmlu:computer_security,validation,0.42114366800524294
100,0.4300000071525574,0.5899999737739563,0.6124031007751938,0.07359376192092892,mmlu:computer_security,test,1.73524514795281
26,0.3076923191547394,0.6153846383094788,0.5555555555555556,0.09960935207513666,mmlu:conceptual_physics,validation,0.6254151000175625
235,0.4127659499645233,0.5234042406082153,0.517929179740027,0.009341731477291004,mmlu:conceptual_physics,test,3.921103836968541
12,0.0833333358168602,0.9166666865348816,0.9545454545454546,0.39062498013178504,mmlu:econometrics,validation,0.4054047940298915
114,0.14912280440330505,0.8508771657943726,0.5864160097028502,0.32627466059567634,mmlu:econometrics,test,2.1113679530099034
16,0.125,0.875,0.6964285714285714,0.334716796875,mmlu:electrical_engineering,validation,0.40349951293319464
145,0.1862068921327591,0.800000011920929,0.5940050219711237,0.2590786695480347,mmlu:electrical_engineering,test,2.56620874395594
41,0.26829269528388977,0.7317073345184326,0.6121212121212122,0.20360134287578302,mmlu:elementary_mathematics,validation,0.9207403159234673
378,0.32275131344795227,0.6772486567497253,0.47406506147540983,0.14925386571379562,mmlu:elementary_mathematics,test,6.293599408818409
14,0.5,0.5,0.5510204081632653,0.0050223469734191895,mmlu:formal_logic,validation,0.411726756952703
126,0.30158731341362,0.6984127163887024,0.4494617224880383,0.19298736443595277,mmlu:formal_logic,test,2.2075689940247685
10,0.30000001192092896,0.699999988079071,0.7857142857142857,0.1933593869209289,mmlu:global_facts,validation,0.38303018012084067
100,0.17000000178813934,0.699999988079071,0.569454287739192,0.1953125119209289,mmlu:global_facts,test,1.7717096421401948
32,0.15625,0.3125,0.7074074074074075,0.20458984375,mmlu:high_school_biology,validation,0.7142976289615035
310,0.41290321946144104,0.41290321946144104,0.5128992101648352,0.10512855014493389,mmlu:high_school_biology,test,5.213093027938157
22,0.13636364042758942,0.6818181872367859,0.5789473684210527,0.17418324405496766,mmlu:high_school_chemistry,validation,0.5419712599832565
203,0.16748768091201782,0.5073891878128052,0.6060737904629308,0.0032134904650044094,mmlu:high_school_chemistry,test,3.42462537297979
9,0.2222222238779068,0.7777777910232544,0.2142857142857143,0.257378445731269,mmlu:high_school_computer_science,validation,0.4111288539133966
100,0.3700000047683716,0.6299999952316284,0.43264693264693277,0.10882813215255738,mmlu:high_school_computer_science,test,1.9032164299860597
18,0.7222222089767456,0.2777777910232544,0.5,0.2573784722222222,mmlu:high_school_european_history,validation,0.67452112887986
165,0.6727272868156433,0.3272727131843567,0.5,0.20788352272727273,mmlu:high_school_european_history,test,3.787921280832961
22,0.4545454680919647,0.5454545617103577,0.7041666666666666,0.033735795454545414,mmlu:high_school_geography,validation,0.5432360311970115
198,0.3636363744735718,0.46464645862579346,0.4729387125220459,0.04407357567488546,mmlu:high_school_geography,test,3.2168395170010626
21,0.4285714328289032,0.523809552192688,0.638888888888889,0.011904747713179842,mmlu:high_school_government_and_politics,validation,0.5226424529682845
193,0.48704662919044495,0.5025906562805176,0.45508274231678486,0.008986396184239354,mmlu:high_school_government_and_politics,test,3.3007264079060405
43,0.41860464215278625,0.5116279125213623,0.43999999999999995,0.001362616239592107,mmlu:high_school_macroeconomics,validation,0.924778135959059
390,0.34358975291252136,0.5897436141967773,0.5623979710820896,0.07879606424233854,mmlu:high_school_macroeconomics,test,6.2930255110841244
29,0.03448275849223137,0.9655172228813171,0.9642857142857143,0.43076511087088754,mmlu:high_school_mathematics,validation,0.6882959171198308
270,0.08148147910833359,0.9185185432434082,0.4594941348973607,0.3848813524952641,mmlu:high_school_mathematics,test,4.652915107784793
26,0.3076923191547394,0.6153846383094788,0.4930555555555556,0.11072716804651117,mmlu:high_school_microeconomics,validation,0.6763887270353734
238,0.32773110270500183,0.5924369692802429,0.5290464743589743,0.08746392085772603,mmlu:high_school_microeconomics,test,3.9185088970698416
17,0.23529411852359772,0.7647058963775635,0.7019230769230769,0.2481617787305046,mmlu:high_school_physics,validation,0.5282783929724246
151,0.17880794405937195,0.7947019934654236,0.6197729988052568,0.27881830259664164,mmlu:high_school_physics,test,2.650681568076834
60,0.5,0.5,0.6283333333333334,0.013736963272094727,mmlu:high_school_psychology,validation,1.148821352981031
545,0.5064220428466797,0.4935779869556427,0.5339825440439632,0.02034119301979692,mmlu:high_school_psychology,test,8.954788270173594
23,0.1304347813129425,0.8695651888847351,0.5916666666666667,0.3527513431466144,mmlu:high_school_statistics,validation,0.5876861899159849
216,0.24074074625968933,0.7314814925193787,0.5266768292682926,0.21251087277023883,mmlu:high_school_statistics,test,3.853263321798295
22,0.5909090638160706,0.40909090638160706,0.5,0.10653409090909088,mmlu:high_school_us_history,validation,0.6440188440028578
204,0.5980392098426819,0.4019607901573181,0.5,0.1136642156862745,mmlu:high_school_us_history,test,4.429874676978216
26,0.5384615659713745,0.4615384638309479,0.5,0.06580528846153844,mmlu:high_school_world_history,validation,0.750229770084843
237,0.4345991611480713,0.5654008388519287,0.5,0.03805709388185652,mmlu:high_school_world_history,test,4.651545656844974
23,0.21739129722118378,0.21739129722118378,0.41666666666666663,0.30230975928513903,mmlu:human_aging,validation,0.5192839610390365
223,0.340807169675827,0.340807169675827,0.5768886501969208,0.17812850550151194,mmlu:human_aging,test,3.63796088215895
12,0.4166666567325592,0.4166666567325592,0.18571428571428572,0.09537758429845172,mmlu:human_sexuality,validation,0.3987384829670191
131,0.47328245639801025,0.4351145029067993,0.501986909770921,0.07576930431919243,mmlu:human_sexuality,test,2.247896166983992
13,0.23076923191547394,0.4615384638309479,0.45,0.04356971612343419,mmlu:international_law,validation,0.408009713049978
121,0.4876033067703247,0.5206611752510071,0.536085292509568,0.014269095314435765,mmlu:international_law,test,2.191402297001332
11,0.4545454680919647,0.4545454680919647,0.2,0.07705966992811725,mmlu:jurisprudence,validation,0.4208294420968741
108,0.37037035822868347,0.37037035822868347,0.5277573529411764,0.16044558860637526,mmlu:jurisprudence,test,1.8894365408923477
18,0.4444444477558136,0.4444444477558136,0.42500000000000004,0.07443574402067399,mmlu:logical_fallacies,validation,0.5227750290650874
163,0.42944785952568054,0.43558281660079956,0.5262672811059909,0.08083301234099033,mmlu:logical_fallacies,test,2.9004088449291885
11,0.27272728085517883,0.7272727489471436,0.7708333333333333,0.2095170400359414,mmlu:machine_learning,validation,0.40241678385064006
112,0.2857142984867096,0.7142857313156128,0.5499999999999999,0.1978585549763271,mmlu:machine_learning,test,2.1072207449469715
11,0.4545454680919647,0.5454545617103577,0.3666666666666667,0.031249983744187748,mmlu:management,validation,0.41114802099764347
103,0.4563106894493103,0.553398072719574,0.4998100303951368,0.03709040625581461,mmlu:management,test,1.7559909941628575
25,0.2800000011920929,0.6399999856948853,0.4603174603174603,0.12515623807907106,mmlu:marketing,validation,0.6841044567991048
234,0.4572649598121643,0.5384615659713745,0.5068069762307749,0.024823042062612655,mmlu:marketing,test,3.9095145580358803
11,0.7272727489471436,0.7272727489471436,0.45833333333333337,0.20099429108879785,mmlu:medical_genetics,validation,0.3989557269960642
100,0.4699999988079071,0.5,0.5475712565234846,0.02542966604232788,mmlu:medical_genetics,test,1.761043946025893
86,0.5465116500854492,0.45348837971687317,0.36033824331696673,0.07994184660357101,mmlu:miscellaneous,validation,1.5136196301318705
783,0.5874840617179871,0.4137931168079376,0.4683066361556064,0.11889366651403493,mmlu:miscellaneous,test,12.32889237999916
38,0.42105263471603394,0.5789473652839661,0.6704545454545454,0.06250000313708659,mmlu:moral_disputes,validation,0.8036765549331903
346,0.41040462255477905,0.586705207824707,0.506282794808064,0.07052701160397834,mmlu:moral_disputes,test,5.728682758053765
100,0.3499999940395355,0.6600000262260437,0.49362637362637357,0.15996095895767215,mmlu:moral_scenarios,validation,1.9081466461066157
895,0.3173184394836426,0.6446927189826965,0.49286554021345746,0.14461417850835367,mmlu:moral_scenarios,test,15.161049152957276
33,0.3636363744735718,0.3636363744735718,0.7658730158730159,0.14678032289851795,mmlu:nutrition,validation,0.816028029890731
306,0.38235294818878174,0.3888888955116272,0.5472120472120472,0.12111926741070217,mmlu:nutrition,test,5.229537328938022
34,0.29411765933036804,0.6176470518112183,0.6145833333333334,0.10776651606840248,mmlu:philosophy,validation,0.7682104439008981
311,0.3247588276863098,0.6173633337020874,0.5107967939651108,0.10555667720040329,mmlu:philosophy,test,5.03257634700276
35,0.3142857253551483,0.6857143044471741,0.48106060606060613,0.17243305955614363,mmlu:prehistory,validation,0.7845308508258313
324,0.4166666567325592,0.5833333134651184,0.49135802469135803,0.0704451402028402,mmlu:prehistory,test,5.338421545922756
31,0.12903225421905518,0.8709677457809448,0.6481481481481481,0.3654233774831218,mmlu:professional_accounting,validation,0.698173503857106
282,0.152482271194458,0.8333333134651184,0.5310401868249489,0.32863750060399377,mmlu:professional_accounting,test,4.970196710899472
170,0.3117647171020508,0.6882352828979492,0.5,0.17261029411764706,mmlu:professional_law,validation,3.496228361967951
1534,0.2777053415775299,0.7222946286201477,0.5,0.2066696544980443,mmlu:professional_law,test,28.687567326938733
31,0.4193548262119293,0.5806451439857483,0.5,0.07283266129032262,mmlu:professional_medicine,validation,0.7488292520865798
272,0.27941176295280457,0.720588207244873,0.5,0.21277573529411764,mmlu:professional_medicine,test,5.031852002022788
69,0.3913043439388275,0.6231883764266968,0.541005291005291,0.11560234384260315,mmlu:professional_psychology,validation,1.3165394528768957
612,0.30882352590560913,0.686274528503418,0.4747582773587502,0.17903010167327582,mmlu:professional_psychology,test,10.146569765172899
12,0.4166666567325592,0.6666666865348816,0.6142857142857143,0.15234373013178504,mmlu:public_relations,validation,0.39115255884826183
110,0.3181818127632141,0.6636363863945007,0.488952380952381,0.14683947671543474,mmlu:public_relations,test,1.9221467329189181
27,0.5925925970077515,0.5925925970077515,0.6193181818181819,0.08318864857708963,mmlu:security_studies,validation,0.7119778178166598
245,0.5306122303009033,0.5020408034324646,0.5690301003344481,0.008466171245185672,mmlu:security_studies,test,4.272034341003746
22,0.3181818127632141,0.6363636255264282,0.6571428571428571,0.12517757307399402,mmlu:sociology,validation,0.5452476528007537
201,0.3781094551086426,0.6218905448913574,0.4972105263157895,0.11141556738620961,mmlu:sociology,test,3.416752361925319
11,0.6363636255264282,0.3636363744735718,0.4107142857142857,0.14985794912685046,mmlu:us_foreign_policy,validation,0.39545051101595163
100,0.5799999833106995,0.550000011920929,0.5123152709359606,0.03589843511581425,mmlu:us_foreign_policy,test,1.8086934860330075
18,0.5,0.5555555820465088,0.30246913580246915,0.030815992090437172,mmlu:virology,validation,0.552091202000156
166,0.3313252925872803,0.3253012001514435,0.48894348894348894,0.2047721994928567,mmlu:virology,test,2.8400058920960873
19,0.7368420958518982,0.2631579041481018,0.4285714285714285,0.26336348997919184,mmlu:world_religions,validation,0.5295373159460723
171,0.5847952961921692,0.4093567132949829,0.49676056338028174,0.11536000973997063,mmlu:world_religions,test,2.8974655671045184
