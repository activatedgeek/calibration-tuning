N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.09090909361839294,0.09999999999999998,0.4865056601437655,mmlu:abstract_algebra,validation,2.247706182010006
100,0.3499999940395355,0.3499999940395355,0.6382417582417582,0.23191408812999725,mmlu:abstract_algebra,test,1.7677460489794612
14,0.2857142984867096,0.2857142984867096,0.7,0.452845994915281,mmlu:anatomy,validation,0.3774148460070137
135,0.42222222685813904,0.42222222685813904,0.5901934322986954,0.2427372557145578,mmlu:anatomy,test,2.2887567650177516
16,0.5,0.5,0.609375,0.1682129018008709,mmlu:astronomy,validation,0.3865565209998749
152,0.5263158082962036,0.5263158082962036,0.5958333333333333,0.12564248866156533,mmlu:astronomy,test,2.607866908016149
11,0.5454545617103577,0.5454545617103577,0.55,0.1047585173086687,mmlu:business_ethics,validation,0.3890367319982033
100,0.3199999928474426,0.3199999928474426,0.46139705882352944,0.32460937619209296,mmlu:business_ethics,test,1.8442542189732194
29,0.24137930572032928,0.24137930572032928,0.5974025974025974,0.36126076764073867,mmlu:clinical_knowledge,validation,0.6520404879993293
265,0.2981131970882416,0.2981131970882416,0.5839118007349938,0.3128243081974534,mmlu:clinical_knowledge,test,4.436160951008787
16,0.25,0.25,0.5208333333333334,0.5075683631002903,mmlu:college_biology,validation,0.3875888879992999
144,0.3958333432674408,0.3958333432674408,0.5098810244000808,0.37209743426905734,mmlu:college_biology,test,2.4451301989902277
8,0.0,0.0,,0.6284179836511612,mmlu:college_chemistry,validation,0.28794907600968145
100,0.17000000178813934,0.17000000178813934,0.7345854004252304,0.4463281399011612,mmlu:college_chemistry,test,1.8208869969821535
11,0.27272728085517883,0.27272728085517883,0.5,0.2819602272727273,mmlu:college_computer_science,validation,0.39599439399898984
100,0.23999999463558197,0.23999999463558197,0.5,0.3146875,mmlu:college_computer_science,test,1.914415236999048
11,0.0,0.0,,0.5717329382896423,mmlu:college_mathematics,validation,0.40034599698265083
100,0.09000000357627869,0.09000000357627869,0.5744810744810744,0.4774218535423279,mmlu:college_mathematics,test,1.8650167279993184
22,0.5,0.5,0.5495867768595042,0.20809659903699707,mmlu:college_medicine,validation,0.5273267009761184
173,0.3988439440727234,0.3988439440727234,0.6133639910813824,0.32013185761567486,mmlu:college_medicine,test,2.945500883011846
11,0.27272728085517883,0.27272728085517883,0.75,0.43501419912685046,mmlu:college_physics,validation,0.393206305016065
102,0.1568627506494522,0.1568627506494522,0.5105377906976744,0.5395986472859102,mmlu:college_physics,test,1.823798564990284
11,0.5454545617103577,0.5454545617103577,0.5333333333333332,0.04687500000000001,mmlu:computer_security,validation,0.377463220997015
100,0.550000011920929,0.550000011920929,0.554141414141414,0.03222657322883606,mmlu:computer_security,test,1.7921860839996953
26,0.3461538553237915,0.4615384638309479,0.6111111111111112,0.09990985576923078,mmlu:conceptual_physics,validation,0.6555645709740929
235,0.4553191363811493,0.48510637879371643,0.5370911214953271,0.0673038327947576,mmlu:conceptual_physics,test,3.9529048800177407
12,0.25,0.25,0.7777777777777777,0.3909505258003871,mmlu:econometrics,validation,0.4045031540154014
114,0.1315789520740509,0.1315789520740509,0.6414141414141414,0.45391311561852166,mmlu:econometrics,test,2.163448014005553
16,0.25,0.5,0.20833333333333334,0.05981445312500002,mmlu:electrical_engineering,validation,0.37483149298350327
145,0.24827586114406586,0.6965517401695251,0.5485474006116209,0.13817348767971172,mmlu:electrical_engineering,test,2.5338331870152615
41,0.26829269528388977,0.7317073345184326,0.4257575757575757,0.10851751013499936,mmlu:elementary_mathematics,validation,0.8912701150111388
378,0.3174603283405304,0.682539701461792,0.5347222222222222,0.058542073088348266,mmlu:elementary_mathematics,test,6.403902738005854
14,0.2142857164144516,0.2142857164144516,0.6969696969696969,0.3666294813156128,mmlu:formal_logic,validation,0.3758000899979379
126,0.261904776096344,0.261904776096344,0.6168132942326492,0.31504215323735796,mmlu:formal_logic,test,2.235177702998044
10,0.20000000298023224,0.20000000298023224,0.875,0.4199218571186066,mmlu:global_facts,validation,0.3937694859923795
100,0.12999999523162842,0.12999999523162842,0.3859416445623342,0.4904687774181366,mmlu:global_facts,test,1.8423259969858918
32,0.3125,0.3125,0.4545454545454545,0.5093993991613388,mmlu:high_school_biology,validation,0.6363622180069797
310,0.42258065938949585,0.42258065938949585,0.49940295961448256,0.4005418177573912,mmlu:high_school_biology,test,5.241679283004487
22,0.1818181872367859,0.1818181872367859,0.375,0.48828125,mmlu:high_school_chemistry,validation,0.5122350220044609
203,0.1822660118341446,0.1822660118341446,0.41696515792901334,0.4978063455943404,mmlu:high_school_chemistry,test,3.536783841002034
9,0.6666666865348816,0.7777777910232544,0.6666666666666667,0.2361110912428962,mmlu:high_school_computer_science,validation,0.389434798998991
100,0.4300000071525574,0.4699999988079071,0.5752753977968176,0.07390627145767215,mmlu:high_school_computer_science,test,1.8648925730085466
18,0.7777777910232544,0.7777777910232544,0.5,0.04340277777777779,mmlu:high_school_european_history,validation,0.6277338479994796
165,0.7575757503509521,0.7575757503509521,0.5,0.02320075757575757,mmlu:high_school_european_history,test,3.7896940869977698
22,0.5,0.5,0.5206611570247934,0.07741478898308495,mmlu:high_school_geography,validation,0.5003771579940803
198,0.39393940567970276,0.39393940567970276,0.5001602564102564,0.18438288870483938,mmlu:high_school_geography,test,3.3260078210150823
21,0.523809552192688,0.523809552192688,0.509090909090909,0.09858628965559457,mmlu:high_school_government_and_politics,validation,0.5009320440003648
193,0.6321243643760681,0.6321243643760681,0.5490648810898175,0.02574482081467622,mmlu:high_school_government_and_politics,test,3.3527422309853137
43,0.4883720874786377,0.4883720874786377,0.5508658008658008,0.12590842052947643,mmlu:high_school_macroeconomics,validation,0.8968113079899922
390,0.3692307770252228,0.36666667461395264,0.5458163956639567,0.24587340920399395,mmlu:high_school_macroeconomics,test,6.399366300000111
29,0.06896551698446274,0.9655172228813171,0.7777777777777778,0.3628771777810721,mmlu:high_school_mathematics,validation,0.6363881959987339
270,0.10000000149011612,0.9037036895751953,0.4434537418076513,0.2968460422975046,mmlu:high_school_mathematics,test,4.67190199898323
26,0.3076923191547394,0.7692307829856873,0.5173611111111112,0.24068509615384615,mmlu:high_school_microeconomics,validation,0.6258866790158208
238,0.36554622650146484,0.6386554837226868,0.5496688741721855,0.08940057919806796,mmlu:high_school_microeconomics,test,3.9294695910066366
17,0.29411765933036804,0.29411765933036804,0.6833333333333333,0.30147056719836063,mmlu:high_school_physics,validation,0.5204117280081846
151,0.17218543589115143,0.17218543589115143,0.46799999999999997,0.40731062202264146,mmlu:high_school_physics,test,2.616042768000625
60,0.6000000238418579,0.6000000238418579,0.546875,0.05546877384185789,mmlu:high_school_psychology,validation,1.1796255579974968
545,0.5064220428466797,0.5064220428466797,0.4831972954043424,0.03873994416053139,mmlu:high_school_psychology,test,9.04191926101339
23,0.17391304671764374,0.17391304671764374,0.5394736842105263,0.4181385817735092,mmlu:high_school_statistics,validation,0.5456204160000198
216,0.25925925374031067,0.25462964177131653,0.5474888392857143,0.3041087808432402,mmlu:high_school_statistics,test,3.775264091003919
22,0.7727272510528564,0.7727272510528564,0.5,0.1360085227272727,mmlu:high_school_us_history,validation,0.6104647769825533
204,0.6764705777168274,0.6764705777168274,0.5,0.03975183823529416,mmlu:high_school_us_history,test,4.390875448996667
26,0.6538461446762085,0.6538461446762085,0.5,0.006310096153846145,mmlu:high_school_world_history,validation,0.7046881620190106
237,0.6033755540847778,0.6033755540847778,0.5,0.056780722573839704,mmlu:high_school_world_history,test,4.632979729009094
23,0.3913043439388275,0.3913043439388275,0.4880952380952381,0.2150135999140532,mmlu:human_aging,validation,0.5118956549849827
223,0.3901345431804657,0.3901345431804657,0.5370182555780934,0.20995653905141515,mmlu:human_aging,test,3.646073661977425
12,0.3333333432674408,0.3333333432674408,0.65625,0.3037109176317851,mmlu:human_sexuality,validation,0.37042210597428493
131,0.5114504098892212,0.5114504098892212,0.5209888059701493,0.13812020443778003,mmlu:human_sexuality,test,2.2530500150169246
13,0.6153846383094788,0.6153846383094788,0.625,0.09224757781395543,mmlu:international_law,validation,0.3987518189824186
121,0.6280992031097412,0.6280992031097412,0.4776315789473684,0.031249975369981545,mmlu:international_law,test,2.2205199600139167
11,0.1818181872367859,0.1818181872367859,0.25,0.4616477543657476,mmlu:jurisprudence,validation,0.3643007919890806
108,0.3611111044883728,0.3611111044883728,0.4065403195837979,0.2901113833542223,mmlu:jurisprudence,test,2.0352127380028833
18,0.6666666865348816,0.6666666865348816,0.2986111111111111,0.07638887564341232,mmlu:logical_fallacies,validation,0.5294576100131962
163,0.48466256260871887,0.48466256260871887,0.6287673297166969,0.1749424901476667,mmlu:logical_fallacies,test,2.825239991012495
11,0.27272728085517883,0.27272728085517883,0.5625,0.25355116345665674,mmlu:machine_learning,validation,0.39443318397388794
112,0.2946428656578064,0.3125,0.4466820099731492,0.2183663249015808,mmlu:machine_learning,test,2.0184598530177027
11,0.6363636255264282,0.6363636255264282,0.3928571428571428,0.056107943708246386,mmlu:management,validation,0.3948721830092836
103,0.42718446254730225,0.41747573018074036,0.4522342064714946,0.16884099742741263,mmlu:management,test,1.7580510880216025
25,0.23999999463558197,0.2800000011920929,0.3728070175438597,0.24375000715255735,mmlu:marketing,validation,0.6170476160186809
234,0.44871795177459717,0.44871795177459717,0.43362864525655226,0.07333398170960254,mmlu:marketing,test,3.9504103229846805
11,0.9090909361839294,0.9090909361839294,1.0,0.1953125162558122,mmlu:medical_genetics,validation,0.39253082999493927
100,0.44999998807907104,0.44999998807907104,0.6032323232323232,0.2427734577655792,mmlu:medical_genetics,test,1.739119972975459
86,0.5581395626068115,0.5581395626068115,0.5699013157894737,0.030795784883720922,mmlu:miscellaneous,validation,1.5419081299914978
783,0.618135392665863,0.6206896305084229,0.5944677851792476,0.09140028967254465,mmlu:miscellaneous,test,12.636907542997506
38,0.42105263471603394,0.42105263471603394,0.53125,0.250308367766832,mmlu:moral_disputes,validation,0.7793507410096936
346,0.43063583970069885,0.43063583970069885,0.49817735836200727,0.2441406084622951,mmlu:moral_disputes,test,5.705262758012395
100,0.4300000071525574,0.4300000071525574,0.40799673602611186,0.15062499761581422,mmlu:moral_scenarios,validation,1.8720479870098643
895,0.38100558519363403,0.38100558519363403,0.5182305175900145,0.20073757691090333,mmlu:moral_scenarios,test,15.414859226992121
33,0.3333333432674408,0.3333333432674408,0.6983471074380165,0.3365293379985925,mmlu:nutrition,validation,0.7674435699882451
306,0.4542483687400818,0.4542483687400818,0.5680868478869598,0.2152394743916256,mmlu:nutrition,test,5.31759906699881
34,0.3235294222831726,0.3235294222831726,0.47430830039525695,0.29469210610670205,mmlu:philosophy,validation,0.7830330510041676
311,0.3633440434932709,0.3633440434932709,0.4369357289711272,0.2576366705143183,mmlu:philosophy,test,5.0615858910023235
35,0.37142857909202576,0.37142857909202576,0.36888111888111885,0.23805803741727555,mmlu:prehistory,validation,0.7662105250055902
324,0.4413580298423767,0.4413580298423767,0.5557508789552988,0.17400895224677193,mmlu:prehistory,test,5.381557646993315
31,0.16129031777381897,0.16129031777381897,0.5692307692307692,0.46963205452888246,mmlu:professional_accounting,validation,0.694375224004034
282,0.1879432648420334,0.1879432648420334,0.5858943725797149,0.44678080842850054,mmlu:professional_accounting,test,5.025314040016383
170,0.38235294818878174,0.38235294818878174,0.5,0.13717830882352944,mmlu:professional_law,validation,3.446581622993108
1534,0.34810951352119446,0.34810951352119446,0.5,0.17142173239895697,mmlu:professional_law,test,29.667695662996266
31,0.35483869910240173,0.35483869910240173,0.5,0.2545362903225806,mmlu:professional_medicine,validation,0.760668162984075
272,0.2904411852359772,0.2904411852359772,0.5,0.31893382352941174,mmlu:professional_medicine,test,5.0912208759982605
69,0.37681159377098083,0.37681159377098083,0.5805008944543829,0.19978487491607666,mmlu:professional_psychology,validation,1.3486461749998853
612,0.3464052379131317,0.3464052379131317,0.555247641509434,0.22974749678879783,mmlu:professional_psychology,test,10.53758073199424
12,0.1666666716337204,0.1666666716337204,0.3,0.44303385416666663,mmlu:public_relations,validation,0.44373708599596284
110,0.30909091234207153,0.30909091234207153,0.46749226006191946,0.28707387013868846,mmlu:public_relations,test,2.009955717017874
27,0.5555555820465088,0.5555555820465088,0.7361111111111112,0.09447338845994735,mmlu:security_studies,validation,0.7381638280057814
245,0.6612244844436646,0.6612244844436646,0.5008924587237841,0.012244896986046576,mmlu:security_studies,test,4.546851773979142
22,0.5909090638160706,0.5909090638160706,0.4102564102564103,0.05095879056236965,mmlu:sociology,validation,0.5455020969966426
201,0.447761207818985,0.447761207818985,0.6093593593593594,0.1314715416870307,mmlu:sociology,test,3.5262537469970994
11,0.7272727489471436,0.7272727489471436,0.3125,0.10511364720084448,mmlu:us_foreign_policy,validation,0.41720343299675733
100,0.5899999737739563,0.5899999737739563,0.5248036378668872,0.03890623331069941,mmlu:us_foreign_policy,test,1.8737066829926334
18,0.5555555820465088,0.5555555820465088,0.59375,0.1835937367545234,mmlu:virology,validation,0.5426503850030713
166,0.34939759969711304,0.34939759969711304,0.44875478927203066,0.41027389987405527,mmlu:virology,test,2.9196585830068216
19,0.6315789222717285,0.6315789222717285,0.5595238095238095,0.08532072995838369,mmlu:world_religions,validation,0.5191281459992751
171,0.6081871390342712,0.6081871390342712,0.4778272101033295,0.02432837646607071,mmlu:world_religions,test,3.1145386669959407
