N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.27272728085517883,0.85,0.24715910174629907,mmlu:abstract_algebra,validation,2.476329892175272
100,0.23000000417232513,0.3100000023841858,0.6696781479390176,0.211484375,mmlu:abstract_algebra,test,1.65628915396519
14,0.2142857164144516,0.2142857164144516,0.7727272727272727,0.3295200637408665,mmlu:anatomy,validation,0.4174770228564739
135,0.45185184478759766,0.46666666865348816,0.5890562693841382,0.07337961373505768,mmlu:anatomy,test,2.1497114880476147
16,0.25,0.25,0.6666666666666666,0.4160156287252903,mmlu:astronomy,validation,0.421441227896139
152,0.5131579041481018,0.5131579041481018,0.5824670824670826,0.1688682048728591,mmlu:astronomy,test,2.3756018760614097
11,0.4545454680919647,0.6363636255264282,0.9500000000000001,0.1157670725475658,mmlu:business_ethics,validation,0.3995878091081977
100,0.3199999928474426,0.49000000953674316,0.5710018382352942,0.02742190122604371,mmlu:business_ethics,test,1.7739350418560207
29,0.24137930572032928,0.27586206793785095,0.25649350649350644,0.2714170505260599,mmlu:clinical_knowledge,validation,0.6476227960083634
265,0.3207547068595886,0.3207547068595886,0.5326797385620915,0.22463147820166823,mmlu:clinical_knowledge,test,4.084773798938841
16,0.25,0.25,0.7916666666666666,0.2841796875,mmlu:college_biology,validation,0.395235886098817
144,0.3958333432674408,0.3888888955116272,0.4637023593466425,0.1443684763378567,mmlu:college_biology,test,2.2795803679618984
8,0.125,0.875,0.7142857142857143,0.30371095240116114,mmlu:college_chemistry,validation,0.29995484999381006
100,0.15000000596046448,0.8500000238418579,0.7607843137254903,0.2666406142711639,mmlu:college_chemistry,test,1.7271265790332109
11,0.1818181872367859,0.8181818127632141,0.5,0.22833806818181823,mmlu:college_computer_science,validation,0.3940345118753612
100,0.2199999988079071,0.7799999713897705,0.5,0.19015625000000003,mmlu:college_computer_science,test,1.8715131809003651
11,0.1818181872367859,0.7272727489471436,0.9444444444444445,0.21484372832558374,mmlu:college_mathematics,validation,0.3851702599786222
100,0.10000000149011612,0.4399999976158142,0.5883333333333333,0.07132810115814209,mmlu:college_mathematics,test,1.8029137211851776
22,0.5,0.5,0.5578512396694215,0.061079561710357666,mmlu:college_medicine,validation,0.532667163060978
173,0.3583815097808838,0.3583815097808838,0.5276809067131647,0.19894777005807512,mmlu:college_medicine,test,2.857740269973874
11,0.3636363744735718,0.6363636255264282,0.625,0.0845170725475658,mmlu:college_physics,validation,0.42730587301775813
102,0.21568627655506134,0.7843137383460999,0.6198863636363636,0.2252604242633371,mmlu:college_physics,test,1.774258237099275
11,0.3636363744735718,0.6363636255264282,0.5178571428571429,0.09765626083720813,mmlu:computer_security,validation,0.39873388316482306
100,0.46000000834465027,0.47999998927116394,0.4154589371980676,0.050507820844650275,mmlu:computer_security,test,1.6680343050975353
26,0.3461538553237915,0.3461538553237915,0.5359477124183006,0.21138823949373686,mmlu:conceptual_physics,validation,0.5950983020011336
235,0.44255319237709045,0.4382978677749634,0.5703904873752202,0.1163065073337961,mmlu:conceptual_physics,test,3.5958796120248735
12,0.0833333358168602,1.0,1.0,0.4762369990348816,mmlu:econometrics,validation,0.41090959892608225
114,0.19298245012760162,0.6929824352264404,0.5980731225296442,0.1634800047205206,mmlu:econometrics,test,2.0266339480876923
16,0.375,0.4375,0.3833333333333333,0.08447265625,mmlu:electrical_engineering,validation,0.4023854569531977
145,0.2344827651977539,0.6413792967796326,0.5563063063063063,0.1239493797565329,mmlu:electrical_engineering,test,2.334638918051496
41,0.2926829159259796,0.6585366129875183,0.67816091954023,0.1366234741559843,mmlu:elementary_mathematics,validation,0.9657424599863589
378,0.4021163880825043,0.5978835821151733,0.4881084070796461,0.07747395423354297,mmlu:elementary_mathematics,test,5.9160218317992985
14,0.3571428656578064,0.4285714328289032,0.38888888888888895,0.08872768708637785,mmlu:formal_logic,validation,0.378120148088783
126,0.190476194024086,0.30158731341362,0.6580882352941176,0.21509174695090644,mmlu:formal_logic,test,2.1077588219195604
10,0.30000001192092896,0.30000001192092896,0.6428571428571428,0.241015625,mmlu:global_facts,validation,0.377119927899912
100,0.23999999463558197,0.3100000023841858,0.5427631578947368,0.2266796851158142,mmlu:global_facts,test,1.6899672660510987
32,0.34375,0.34375,0.5606060606060607,0.24853513203561306,mmlu:high_school_biology,validation,0.6227732850238681
310,0.47096773982048035,0.47096773982048035,0.5014199799532241,0.11930443625296315,mmlu:high_school_biology,test,4.828093752032146
22,0.04545454680919647,0.04545454680919647,0.7142857142857143,0.5102982764894313,mmlu:high_school_chemistry,validation,0.5271646738983691
203,0.19704432785511017,0.2068965584039688,0.49302147239263805,0.3536599357727126,mmlu:high_school_chemistry,test,3.2383870370686054
9,0.2222222238779068,0.6666666865348816,0.32142857142857145,0.14105902115503943,mmlu:high_school_computer_science,validation,0.4361729118973017
100,0.41999998688697815,0.6000000238418579,0.6063218390804598,0.06910154819488523,mmlu:high_school_computer_science,test,1.77744174702093
18,0.7222222089767456,0.2777777910232544,0.5,0.2456597222222222,mmlu:high_school_european_history,validation,0.605792178073898
165,0.6000000238418579,0.4000000059604645,0.5,0.12343749999999998,mmlu:high_school_european_history,test,3.609059819020331
22,0.40909090638160706,0.40909090638160706,0.6068376068376068,0.13316759196194733,mmlu:high_school_geography,validation,0.5266287690028548
198,0.3787878751754761,0.3737373650074005,0.5994579945799458,0.16451623162837942,mmlu:high_school_geography,test,2.9999490089248866
21,0.4761904776096344,0.4285714328289032,0.4181818181818182,0.08537945577076506,mmlu:high_school_government_and_politics,validation,0.5303754629567266
193,0.5544041395187378,0.43523314595222473,0.4703868724190393,0.07891435944354597,mmlu:high_school_government_and_politics,test,3.073911043116823
43,0.41860464215278625,0.3488371968269348,0.3322222222222222,0.16506175939426865,mmlu:high_school_macroeconomics,validation,0.8940568270627409
390,0.34358975291252136,0.4564102590084076,0.5447906949626866,0.060967537378653514,mmlu:high_school_macroeconomics,test,5.81750016589649
29,0.13793103396892548,0.8620689511299133,0.895,0.29256465517241376,mmlu:high_school_mathematics,validation,0.6956649920903146
270,0.10000000149011612,0.8925926089286804,0.63404968754763,0.32740161838354886,mmlu:high_school_mathematics,test,4.360101864207536
26,0.38461539149284363,0.38461539149284363,0.3875,0.23167065473703236,mmlu:high_school_microeconomics,validation,0.6322732621338218
238,0.3781512677669525,0.3781512677669525,0.4891891891891892,0.2389377821393374,mmlu:high_school_microeconomics,test,3.608303969958797
17,0.11764705926179886,0.8235294222831726,0.9333333333333333,0.3060662045198328,mmlu:high_school_physics,validation,0.4855870120227337
151,0.20529800653457642,0.695364236831665,0.5977150537634408,0.17666077771723665,mmlu:high_school_physics,test,2.4468453240115196
60,0.6000000238418579,0.4000000059604645,0.6134259259259259,0.1254557132720947,mmlu:high_school_psychology,validation,1.1076698319520801
545,0.5357798337936401,0.46422019600868225,0.5158711895608858,0.061174017792447966,mmlu:high_school_psychology,test,8.416159733897075
23,0.043478261679410934,0.52173912525177,0.8409090909090908,0.001528555932252318,mmlu:high_school_statistics,validation,0.5740925439167768
216,0.25925925374031067,0.6018518805503845,0.5934709821428571,0.09027778108914697,mmlu:high_school_statistics,test,3.6649807281792164
22,0.5909090638160706,0.40909090638160706,0.5,0.11825284090909088,mmlu:high_school_us_history,validation,0.6437805951572955
204,0.6225489974021912,0.37745097279548645,0.5,0.14989276960784315,mmlu:high_school_us_history,test,4.174250659998506
26,0.6153846383094788,0.6153846383094788,0.5,0.09975961538461542,mmlu:high_school_world_history,validation,0.730580607894808
237,0.5274261832237244,0.5274261832237244,0.5,0.01180116033755274,mmlu:high_school_world_history,test,4.4631098890677094
23,0.3478260934352875,0.30434781312942505,0.5916666666666667,0.268682044485341,mmlu:human_aging,validation,0.4811442489735782
223,0.3497757911682129,0.3497757911682129,0.6091954022988505,0.1873073307922603,mmlu:human_aging,test,3.573185652960092
12,0.25,0.4166666567325592,0.7592592592592593,0.1074218948682149,mmlu:human_sexuality,validation,0.4063021708279848
131,0.442748099565506,0.442748099565506,0.6343882853094001,0.08387998542712843,mmlu:human_sexuality,test,2.1517413889523596
13,0.3076923191547394,0.5384615659713745,0.5138888888888888,0.013221176771017196,mmlu:international_law,validation,0.4343245350755751
121,0.5206611752510071,0.4710743725299835,0.490831964969896,0.05049069952373664,mmlu:international_law,test,2.048852124949917
11,0.3636363744735718,0.3636363744735718,0.2857142857142857,0.2297585064714605,mmlu:jurisprudence,validation,0.3964427609462291
108,0.39814814925193787,0.39814814925193787,0.3658318425760287,0.24699797564082673,mmlu:jurisprudence,test,1.7977406580466777
18,0.5555555820465088,0.5555555820465088,0.5625,0.05750868055555555,mmlu:logical_fallacies,validation,0.5364026159513742
163,0.4601227045059204,0.4601227045059204,0.49143939393939395,0.15296681709816123,mmlu:logical_fallacies,test,2.657170513877645
11,0.4545454680919647,0.5454545617103577,0.5833333333333334,0.005326704545454586,mmlu:machine_learning,validation,0.41615911200642586
112,0.2232142835855484,0.7678571343421936,0.4526436781609195,0.22321426655564985,mmlu:machine_learning,test,1.893540217075497
11,0.8181818127632141,0.7272727489471436,0.41666666666666663,0.20454547621987085,mmlu:management,validation,0.38619817793369293
103,0.43689319491386414,0.4563106894493103,0.47107279693486587,0.06291718274644276,mmlu:management,test,1.64700399315916
25,0.36000001430511475,0.4399999976158142,0.3923611111111111,0.08296876907348633,mmlu:marketing,validation,0.6350373509339988
234,0.5170940160751343,0.5128205418586731,0.493198273970599,0.008346705864637372,mmlu:marketing,test,3.741450211033225
11,0.7272727489471436,0.7272727489471436,0.6041666666666667,0.11896305734461005,mmlu:medical_genetics,validation,0.3675124729052186
100,0.4699999988079071,0.4699999988079071,0.490766760337214,0.13300781786441804,mmlu:medical_genetics,test,1.634165283991024
86,0.604651153087616,0.45348837971687317,0.4601244343891403,0.060092665428339076,mmlu:miscellaneous,validation,1.423441655933857
783,0.6168582439422607,0.5185185074806213,0.5483022774327122,0.003397384365856394,mmlu:miscellaneous,test,11.467461084015667
38,0.3947368562221527,0.44736841320991516,0.5246376811594202,0.07750823309547022,mmlu:moral_disputes,validation,0.7790302678477019
346,0.424855500459671,0.45375722646713257,0.5388336239018221,0.07089954717999936,mmlu:moral_disputes,test,5.405237129889429
100,0.47999998927116394,0.47999998927116394,0.5190304487179487,0.13921876668930055,mmlu:moral_scenarios,validation,1.8049748297780752
895,0.44134077429771423,0.44134077429771423,0.5124430379746835,0.17794168748003145,mmlu:moral_scenarios,test,14.412398495944217
33,0.3030303120613098,0.3030303120613098,0.43695652173913047,0.2896543560606061,mmlu:nutrition,validation,0.7821806771680713
306,0.36274510622024536,0.36274510622024536,0.5514206514206514,0.2033164633644952,mmlu:nutrition,test,4.8834560450632125
34,0.3235294222831726,0.3529411852359772,0.4802371541501977,0.187040413127226,mmlu:philosophy,validation,0.7872334301937371
311,0.34405145049095154,0.3954983949661255,0.48753894080996885,0.14438051847782932,mmlu:philosophy,test,4.7582673211582005
35,0.3142857253551483,0.6285714507102966,0.6609848484848485,0.10312499659402033,mmlu:prehistory,validation,0.7629233100451529
324,0.48148149251937866,0.5524691343307495,0.5526747557997558,0.028513185955859974,mmlu:prehistory,test,4.962795820087194
31,0.09677419066429138,0.7419354915618896,0.5238095238095237,0.21862398809002292,mmlu:professional_accounting,validation,0.7066303270403296
282,0.14539006352424622,0.7021276354789734,0.530209492966299,0.1813636067065787,mmlu:professional_accounting,test,4.6708598281256855
170,0.364705890417099,0.6352941393852234,0.5,0.03373161764705879,mmlu:professional_law,validation,3.335026567103341
1534,0.29400262236595154,0.7059974074363708,0.5,0.10443489243807036,mmlu:professional_law,test,27.67496139695868
31,0.35483869910240173,0.6451612710952759,0.5,0.11000504032258063,mmlu:professional_medicine,validation,0.7654532920569181
272,0.3345588147640228,0.6654411554336548,0.5,0.1302849264705882,mmlu:professional_medicine,test,4.884068678831682
69,0.3913043439388275,0.6086956262588501,0.41313932980599644,0.07942708938018139,mmlu:professional_psychology,validation,1.3040508378762752
612,0.3006536066532135,0.6781045794487,0.5232311560341325,0.1517757134499893,mmlu:professional_psychology,test,9.533899018075317
12,0.25,0.4166666567325592,0.3333333333333333,0.10481770833333331,mmlu:public_relations,validation,0.3859173250384629
110,0.30909091234207153,0.5090909004211426,0.4467879256965944,0.011363616856661762,mmlu:public_relations,test,1.8128427669871598
27,0.48148149251937866,0.5185185074806213,0.5054945054945055,0.00028933198363689794,mmlu:security_studies,validation,0.6988926471676677
245,0.5265306234359741,0.5551020503044128,0.5769847634322373,0.03765945677854576,mmlu:security_studies,test,3.978263281052932
22,0.5909090638160706,0.5909090638160706,0.6452991452991453,0.0763494047251615,mmlu:sociology,validation,0.5208123070187867
201,0.4129353165626526,0.43283581733703613,0.5162344292423933,0.08030163885942149,mmlu:sociology,test,3.2084824841003865
11,0.6363636255264282,0.6363636255264282,0.6428571428571428,0.10475851189006458,mmlu:us_foreign_policy,validation,0.3842521570622921
100,0.5699999928474426,0.550000011920929,0.5571195430436555,0.014218767881393443,mmlu:us_foreign_policy,test,1.6400959980674088
18,0.3333333432674408,0.3333333432674408,0.5486111111111112,0.2554253538449605,mmlu:virology,validation,0.5447626269888133
166,0.33734938502311707,0.34337350726127625,0.4955357142857143,0.2566829754645566,mmlu:virology,test,2.6103310759644955
19,0.6315789222717285,0.4736842215061188,0.2380952380952381,0.04255757833781998,mmlu:world_religions,validation,0.5218107500113547
171,0.6432748436927795,0.6549707651138306,0.4739195230998509,0.1374725650625619,mmlu:world_religions,test,2.660151637159288
