N,fuzzy_gpt-3.5-turbo-1106_acc,fuzzy_gpt-3.5-turbo-1106_unc_acc,fuzzy_gpt-3.5-turbo-1106_unc_auroc,fuzzy_gpt-3.5-turbo-1106_unc_ece,dataset,split,ts
11,0.4545454680919647,0.3636363744735718,0.33333333333333337,0.6261751435019753,mmlu:abstract_algebra,validation,3.9018454649485648
100,0.28999999165534973,0.6399999856948853,0.5886352598348713,0.3337508547306062,mmlu:abstract_algebra,test,6.831400010967627
14,0.4285714328289032,0.6428571343421936,0.6666666666666666,0.3446236763681684,mmlu:anatomy,validation,1.2667985609732568
135,0.5703703761100769,0.6740740537643433,0.7525750111957008,0.31523337452499955,mmlu:anatomy,test,7.309369888855144
16,0.375,0.875,0.9666666666666667,0.09954864159226415,mmlu:astronomy,validation,1.3807280100882053
152,0.41447368264198303,0.8157894611358643,0.8796147672552166,0.16653342976381905,mmlu:astronomy,test,9.620433727977797
11,0.6363636255264282,0.8181818127632141,0.8928571428571428,0.14538702639666476,mmlu:business_ethics,validation,1.3434950429946184
100,0.3499999940395355,0.6000000238418579,0.7336263736263737,0.3576958382129669,mmlu:business_ethics,test,7.455199507065117
29,0.24137930572032928,0.6896551847457886,0.827922077922078,0.2915914161451932,mmlu:clinical_knowledge,validation,2.126478830119595
265,0.35849055647850037,0.6679245233535767,0.7468730650154799,0.318810328672517,mmlu:clinical_knowledge,test,15.28422402497381
16,0.25,0.875,0.9687499999999999,0.11384212970733643,mmlu:college_biology,validation,1.3489196980372071
144,0.3958333432674408,0.625,0.7250453720508166,0.3596265866524644,mmlu:college_biology,test,9.393217463046312
8,0.125,1.0,1.0,0.0119096040725708,mmlu:college_chemistry,validation,0.9980479748919606
100,0.23000000417232513,0.75,0.7094861660079052,0.2351046764850617,mmlu:college_chemistry,test,7.882195087848231
11,0.09090909361839294,0.7272727489471436,0.19999999999999996,0.23316025733947748,mmlu:college_computer_science,validation,1.7081046770326793
100,0.20999999344348907,0.7200000286102295,0.6787221217600964,0.25993865847587583,mmlu:college_computer_science,test,10.996316452976316
11,0.09090909361839294,0.8181818127632141,0.9,0.17081754857843567,mmlu:college_mathematics,validation,1.4919292121194303
100,0.20000000298023224,0.7599999904632568,0.6890625000000001,0.22481053292751318,mmlu:college_mathematics,test,8.52350556710735
22,0.5,0.5909090638160706,0.7272727272727273,0.40559682520953094,mmlu:college_medicine,validation,1.9202471589669585
173,0.39306357502937317,0.7052023410797119,0.7688375350140056,0.27104990158466935,mmlu:college_medicine,test,14.972022980917245
11,0.4545454680919647,0.6363636255264282,0.6333333333333333,0.3529691587794911,mmlu:college_physics,validation,1.4772756190504879
102,0.23529411852359772,0.7647058963775635,0.641826923076923,0.22739834119291866,mmlu:college_physics,test,7.774443970993161
11,0.6363636255264282,0.9090909361839294,0.8928571428571428,0.09549988399852403,mmlu:computer_security,validation,1.21380595699884
100,0.49000000953674316,0.6299999952316284,0.655062024809924,0.3551108545064926,mmlu:computer_security,test,6.146003192989156
26,0.3076923191547394,0.6153846383094788,0.7222222222222222,0.3605355551609627,mmlu:conceptual_physics,validation,1.7622480308637023
235,0.48085105419158936,0.672340452671051,0.7179747569998549,0.3113446867212336,mmlu:conceptual_physics,test,12.24278258997947
12,0.5,0.6666666865348816,0.6944444444444445,0.3205810387929281,mmlu:econometrics,validation,1.3472992479801178
114,0.21929824352264404,0.5263158082962036,0.6366292134831462,0.4232520853218279,mmlu:econometrics,test,9.51823853305541
16,0.3125,0.625,0.4090909090909091,0.3707277737557888,mmlu:electrical_engineering,validation,1.329531269846484
145,0.2896551787853241,0.6758620738983154,0.7020342117429497,0.3017536845700494,mmlu:electrical_engineering,test,9.808796068886295
41,0.3658536672592163,0.5853658318519592,0.6,0.4022295852986778,mmlu:elementary_mathematics,validation,3.2705659749917686
378,0.44708994030952454,0.5555555820465088,0.5335494465049121,0.42641141537636046,mmlu:elementary_mathematics,test,24.791414983803406
14,0.4285714328289032,0.5714285969734192,0.5,0.4153382437569755,mmlu:formal_logic,validation,1.3848605400417
126,0.3095238208770752,0.6269841194152832,0.6715296198054819,0.35114828367081896,mmlu:formal_logic,test,9.568600906059146
10,0.20000000298023224,0.6000000238418579,0.625,0.3579716324806214,mmlu:global_facts,validation,1.0870295939967036
100,0.1899999976158142,0.6399999856948853,0.3973359324236517,0.30921440660953525,mmlu:global_facts,test,6.4458908890374005
32,0.46875,0.75,0.7607843137254903,0.2070312760770321,mmlu:high_school_biology,validation,2.1641713650897145
310,0.5064516067504883,0.7193548679351807,0.805982265517672,0.2617002158395706,mmlu:high_school_biology,test,19.605859519913793
22,0.13636364042758942,0.9090909361839294,1.0,0.07853933897885412,mmlu:high_school_chemistry,validation,1.8889851870480925
203,0.2019704431295395,0.8177340030670166,0.7592592592592592,0.16956711901819763,mmlu:high_school_chemistry,test,15.133486592909321
9,0.4444444477558136,0.5555555820465088,0.65,0.42936017778184676,mmlu:high_school_computer_science,validation,1.36909656599164
100,0.5699999928474426,0.699999988079071,0.7133822929416566,0.28378004074096685,mmlu:high_school_computer_science,test,9.889362924033776
18,0.7222222089767456,0.7777777910232544,0.7230769230769231,0.2163616551293267,mmlu:high_school_european_history,validation,6.097866004100069
165,0.678787887096405,0.7575757503509521,0.8331367924528301,0.22488848548946966,mmlu:high_school_european_history,test,52.95416425191797
22,0.3636363744735718,0.8181818127632141,0.9107142857142857,0.17230396920984437,mmlu:high_school_geography,validation,1.5617527409922332
198,0.4444444477558136,0.691919207572937,0.790702479338843,0.2850660495083741,mmlu:high_school_geography,test,10.899946213932708
21,0.5714285969734192,0.7142857313156128,0.8240740740740741,0.2632267077763875,mmlu:high_school_government_and_politics,validation,1.5879806180018932
193,0.5544041395187378,0.7150259017944336,0.8072158226472506,0.27320099154902244,mmlu:high_school_government_and_politics,test,11.276210590964183
43,0.44186046719551086,0.6279069781303406,0.6535087719298246,0.3580289510793464,mmlu:high_school_macroeconomics,validation,2.699212821898982
390,0.3692307770252228,0.6461538672447205,0.7464007452574526,0.3290188398116674,mmlu:high_school_macroeconomics,test,21.35026050894521
29,0.06896551698446274,0.931034505367279,0.37037037037037035,0.060386084277054386,mmlu:high_school_mathematics,validation,2.5849333468358964
270,0.12962962687015533,0.8666666746139526,0.61580547112462,0.1244219621022542,mmlu:high_school_mathematics,test,20.73767298902385
26,0.42307692766189575,0.7692307829856873,0.8242424242424243,0.2205360783980443,mmlu:high_school_microeconomics,validation,1.882261408958584
238,0.3781512677669525,0.651260495185852,0.7232357357357357,0.32960943790043096,mmlu:high_school_microeconomics,test,13.2981996901799
17,0.1764705926179886,0.7647058963775635,0.761904761904762,0.22139681788051835,mmlu:high_school_physics,validation,1.761984903132543
151,0.20529800653457642,0.7350993156433105,0.7279569892473118,0.24269194002972533,mmlu:high_school_physics,test,11.2011590260081
60,0.6333333253860474,0.75,0.6991626794258373,0.23222244083881374,mmlu:high_school_psychology,validation,4.216554010985419
545,0.5596330165863037,0.6917431354522705,0.7683333333333333,0.2936875226300791,mmlu:high_school_psychology,test,34.61651128693484
23,0.30434781312942505,0.739130437374115,0.7232142857142857,0.23996549067289935,mmlu:high_school_statistics,validation,2.4174521800596267
216,0.32870370149612427,0.6574074029922485,0.7219524040796503,0.317723945611053,mmlu:high_school_statistics,test,19.480661830166355
22,0.5909090638160706,0.7727272510528564,0.9230769230769231,0.19519514658234338,mmlu:high_school_us_history,validation,5.895267511019483
204,0.6421568393707275,0.7107843160629272,0.8008470145351876,0.2773954357002296,mmlu:high_school_us_history,test,51.19791524903849
26,0.5769230723381042,0.6153846383094788,0.6696969696969697,0.3879283666610718,mmlu:high_school_world_history,validation,5.321459308033809
237,0.4388185739517212,0.6877636909484863,0.7698814343551185,0.28931087607572853,mmlu:high_school_world_history,test,41.94631641590968
23,0.30434781312942505,0.6521739363670349,0.7142857142857143,0.37442101862119587,mmlu:human_aging,validation,1.6411918317899108
223,0.34529146552085876,0.6547085046768188,0.7864703789361323,0.33481555054540585,mmlu:human_aging,test,12.047125168843195
12,0.3333333432674408,0.6666666865348816,0.71875,0.35098767777283985,mmlu:human_sexuality,validation,1.2752905839588493
131,0.49618321657180786,0.7022900581359863,0.7754079254079255,0.28114828308120027,mmlu:human_sexuality,test,7.870267479913309
13,0.4615384638309479,0.692307710647583,0.6190476190476191,0.2858955447490399,mmlu:international_law,validation,1.3396596619859338
121,0.5619834661483765,0.6776859760284424,0.7605438401775804,0.3143761571773813,mmlu:international_law,test,8.065884859999642
11,0.4545454680919647,0.7272727489471436,0.6333333333333333,0.26033731482245703,mmlu:jurisprudence,validation,1.1308438119012862
108,0.49074074625968933,0.6111111044883728,0.7307032590051458,0.3634925131444577,mmlu:jurisprudence,test,6.617057238938287
18,0.5,0.8333333134651184,0.9444444444444444,0.15683237711588538,mmlu:logical_fallacies,validation,1.6044563550967723
163,0.47852760553359985,0.6871165633201599,0.7759426847662142,0.2963730714803825,mmlu:logical_fallacies,test,10.259658404160291
11,0.1818181872367859,0.7272727489471436,0.8888888888888888,0.23910747874866833,mmlu:machine_learning,validation,1.320503557100892
112,0.2767857015132904,0.6785714030265808,0.7483074472321783,0.2754852553563459,mmlu:machine_learning,test,9.060225591994822
11,0.6363636255264282,0.8181818127632141,0.8571428571428572,0.1823552630164406,mmlu:management,validation,1.0643329450394958
103,0.3980582654476166,0.7184466123580933,0.8149095200629426,0.26835750954822435,mmlu:management,test,5.5067781480029225
25,0.2800000011920929,0.4000000059604645,0.7738095238095238,0.5602316999435426,mmlu:marketing,validation,2.043481588130817
234,0.47863247990608215,0.692307710647583,0.8222701990632317,0.29828210111357206,mmlu:marketing,test,13.552864953875542
11,0.7272727489471436,0.9090909361839294,0.9583333333333334,0.07394125786694616,mmlu:medical_genetics,validation,1.0917237210087478
100,0.550000011920929,0.7300000190734863,0.8143434343434343,0.2514984107017517,mmlu:medical_genetics,test,5.571409608935937
86,0.5930232405662537,0.7790697813034058,0.8425770308123249,0.20197840693385097,mmlu:miscellaneous,validation,4.86272430093959
783,0.6245210766792297,0.7432950139045715,0.7917310073313579,0.24207776586975938,mmlu:miscellaneous,test,41.88753101299517
38,0.3684210479259491,0.6578947305679321,0.7946428571428571,0.3257314123605427,mmlu:moral_disputes,validation,2.8412570969667286
346,0.40751445293426514,0.6560693383216858,0.7192873205327799,0.31874976061672144,mmlu:moral_disputes,test,21.442362995119765
100,0.5899999737739563,0.44999998807907104,0.6808598594460521,0.5413770049810409,mmlu:moral_scenarios,validation,8.984182479092851
895,0.5329608917236328,0.4893854856491089,0.6350997562516927,0.49347488067669576,mmlu:moral_scenarios,test,74.66440875199623
33,0.39393940567970276,0.5757575631141663,0.6865384615384615,0.38383059068159625,mmlu:nutrition,validation,2.757618715055287
306,0.4346405267715454,0.5915032625198364,0.7102655482637229,0.3808895402094896,mmlu:nutrition,test,20.591224895091727
34,0.38235294818878174,0.5588235259056091,0.673992673992674,0.42105633371016554,mmlu:philosophy,validation,2.5119290549773723
311,0.34405145049095154,0.6045016050338745,0.7102803738317757,0.36301895391519423,mmlu:philosophy,test,17.538378102937713
35,0.37142857909202576,0.7714285850524902,0.7692307692307692,0.20416679041726252,mmlu:prehistory,validation,2.739209735998884
324,0.45987653732299805,0.709876537322998,0.7544391179290508,0.2717210488554872,mmlu:prehistory,test,19.41909650200978
31,0.19354838132858276,0.7419354915618896,0.73,0.24271316105319607,mmlu:professional_accounting,validation,3.203345838934183
282,0.173758864402771,0.7553191781044006,0.6368573180345098,0.22428655920299234,mmlu:professional_accounting,test,25.850988746853545
170,0.4000000059604645,0.4941176474094391,0.5064158016147635,0.4855694861973033,mmlu:professional_law,validation,29.19813550915569
1534,0.35071706771850586,0.5423728823661804,0.5830478046013048,0.41547222569526565,mmlu:professional_law,test,263.0661068079062
31,0.4516128897666931,0.7096773982048035,0.7457983193277311,0.2571086825863008,mmlu:professional_medicine,validation,4.78686523810029
272,0.35661765933036804,0.6360294222831726,0.6934315169366716,0.3416097861002473,mmlu:professional_medicine,test,38.396801229100674
69,0.43478259444236755,0.6376811861991882,0.7452991452991453,0.32880861603695416,mmlu:professional_psychology,validation,5.282690128078684
612,0.3660130798816681,0.6160130500793457,0.7125713365243005,0.3552274216039508,mmlu:professional_psychology,test,40.74675483093597
12,0.3333333432674408,0.6666666865348816,0.859375,0.32351883252461755,mmlu:public_relations,validation,1.220661684172228
110,0.30909091234207153,0.6636363863945007,0.7925696594427244,0.3274486102841117,mmlu:public_relations,test,6.859839281998575
27,0.5925925970077515,0.6666666865348816,0.8096590909090909,0.2959177957640754,mmlu:security_studies,validation,2.598186078015715
245,0.5469387769699097,0.6734693646430969,0.7357469409708215,0.29124186720166884,mmlu:security_studies,test,18.67871855199337
22,0.5,0.6818181872367859,0.6942148760330579,0.2920297248796983,mmlu:sociology,validation,1.6960745379328728
201,0.45771142840385437,0.6815920472145081,0.7402273633825289,0.2924325854624089,mmlu:sociology,test,11.174079991877079
11,0.7272727489471436,0.7272727489471436,0.5416666666666667,0.22684541073712433,mmlu:us_foreign_policy,validation,1.0566576009150594
100,0.6100000143051147,0.6800000071525574,0.7099621689785625,0.286415508389473,mmlu:us_foreign_policy,test,5.660335055086762
18,0.3888888955116272,0.5,0.5714285714285714,0.480255126953125,mmlu:virology,validation,1.5492098189424723
166,0.34939759969711304,0.650602400302887,0.7622924648786716,0.32556304443313416,mmlu:virology,test,9.037222960032523
19,0.6842105388641357,0.7894737124443054,0.7820512820512822,0.2132026113961872,mmlu:world_religions,validation,1.4563669438939542
171,0.6725146174430847,0.7309941649436951,0.8028726708074535,0.2423357754422907,mmlu:world_religions,test,8.440428070025519
