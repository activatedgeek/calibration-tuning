N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.09090909361839294,0.09999999999999998,0.4608546224507418,mmlu:abstract_algebra,validation,8.71551963686943
100,0.2199999988079071,0.22999998927116394,0.38286713286713286,0.3226688098907471,mmlu:abstract_algebra,test,74.02497700694948
14,0.2142857313156128,0.2142857313156128,0.8333333333333334,0.35501153979982647,mmlu:anatomy,validation,14.17676954017952
135,0.4000000059604645,0.4000000059604645,0.6667809785093737,0.16785136461257932,mmlu:anatomy,test,128.78141784714535
16,0.4375,0.4375,0.31746031746031744,0.12233912944793701,mmlu:astronomy,validation,24.11677928781137
152,0.46710526943206787,0.44736841320991516,0.611111111111111,0.1113072257292898,mmlu:astronomy,test,178.7536953939125
11,0.5454545617103577,0.5454545617103577,0.4666666666666666,0.21782158179716635,mmlu:business_ethics,validation,10.678780253976583
100,0.32999998331069946,0.32999998331069946,0.6768430574400723,0.28696952581405644,mmlu:business_ethics,test,108.4886453198269
29,0.06896551698446274,0.06896551698446274,0.75,0.49948491310251175,mmlu:clinical_knowledge,validation,31.170895459596068
265,0.29056602716445923,0.2943396270275116,0.5298079579994474,0.2736145003786627,mmlu:clinical_knowledge,test,298.5887469719164
16,0.375,0.375,0.55,0.22764014080166817,mmlu:college_biology,validation,16.77227134304121
144,0.3611111044883728,0.3611111044883728,0.6374372909698997,0.21432651744948494,mmlu:college_biology,test,755.3958708602004
8,0.0,0.0,,0.5734535455703735,mmlu:college_chemistry,validation,9.093894965946674
100,0.14000000059604645,0.14000000059604645,0.5253322259136213,0.43672594308853147,mmlu:college_chemistry,test,94.84551555197686
11,0.1818181872367859,0.27272728085517883,0.6666666666666666,0.29495570876381616,mmlu:college_computer_science,validation,12.747871608939022
100,0.17000000178813934,0.1899999976158142,0.4727143869596031,0.37638617515563966,mmlu:college_computer_science,test,102.16938663227484
11,0.0,0.0,,0.5876397653059526,mmlu:college_mathematics,validation,9.130371103063226
100,0.17000000178813934,0.1899999976158142,0.6651311126860383,0.39605227172374724,mmlu:college_mathematics,test,76.72612624615431
22,0.3181818127632141,0.3181818127632141,0.2571428571428571,0.23880314285104925,mmlu:college_medicine,validation,23.13490491686389
173,0.3179190754890442,0.3179190754890442,0.6313559322033897,0.23263958837255577,mmlu:college_medicine,test,190.08824675763026
11,0.09090909361839294,0.1818181872367859,0.95,0.38173497265035455,mmlu:college_physics,validation,12.114307662006468
102,0.09803921729326248,0.09803921729326248,0.5690217391304347,0.4725624860501757,mmlu:college_physics,test,114.64570352109149
11,0.6363636255264282,0.6363636255264282,0.5,0.0950810367410833,mmlu:computer_security,validation,15.089654156938195
100,0.47999998927116394,0.47999998927116394,0.5592948717948718,0.10993376731872559,mmlu:computer_security,test,125.50573567813262
26,0.3461538553237915,0.3461538553237915,0.5326797385620915,0.2306047769693228,mmlu:conceptual_physics,validation,46.32235619798303
235,0.37021276354789734,0.37021276354789734,0.519726623174899,0.20393923825406016,mmlu:conceptual_physics,test,455.36140209203586
12,0.1666666716337204,0.4166666865348816,0.6,0.13285984595616657,mmlu:econometrics,validation,13.236608545295894
114,0.12280701845884323,0.41228070855140686,0.6392857142857143,0.12522820317954347,mmlu:econometrics,test,170.37715775612742
16,0.25,0.3125,0.4375,0.23703473806381226,mmlu:electrical_engineering,validation,15.892473737243563
145,0.22068965435028076,0.22758620977401733,0.453954646017699,0.32948440601085793,mmlu:electrical_engineering,test,151.48813018528745
41,0.3414633870124817,0.3414633870124817,0.4920634920634921,0.23415414298452983,mmlu:elementary_mathematics,validation,31.687600730918348
378,0.30423280596733093,0.30423280596733093,0.5595635642254918,0.27333547529720126,mmlu:elementary_mathematics,test,369.7055584057234
14,0.4285714626312256,0.4285714626312256,0.5,0.12099859544209074,mmlu:formal_logic,validation,21.263577167876065
126,0.261904776096344,0.261904776096344,0.3545128706419029,0.28234507072539555,mmlu:formal_logic,test,163.96348817180842
10,0.10000000149011612,0.10000000149011612,0.2222222222222222,0.46238323450088503,mmlu:global_facts,validation,11.827574048191309
100,0.09999999403953552,0.09999999403953552,0.5461111111111112,0.46566411256790163,mmlu:global_facts,test,126.81062160898
32,0.3125,0.3125,0.5181818181818182,0.2634657472372055,mmlu:high_school_biology,validation,36.37143980572
310,0.4193548262119293,0.4258064329624176,0.5191239316239316,0.150556718918585,mmlu:high_school_biology,test,408.2427205448039
22,0.09090909361839294,0.09090909361839294,0.47500000000000003,0.47906652363863855,mmlu:high_school_chemistry,validation,22.027499228250235
203,0.14778324961662292,0.14778324961662292,0.6016377649325626,0.41845133739151974,mmlu:high_school_chemistry,test,205.63438588473946
9,0.4444444477558136,0.4444444477558136,0.75,0.12175169918272233,mmlu:high_school_computer_science,validation,12.578645166009665
100,0.4099999964237213,0.4099999964237213,0.4834642414220753,0.15626166820526122,mmlu:high_school_computer_science,test,171.00364856002852
22,0.5454545617103577,0.5454545617103577,0.6041666666666667,0.022546367211775387,mmlu:high_school_geography,validation,29.318234323058277
198,0.3787878751754761,0.3787878751754761,0.6492682926829267,0.18830138083660242,mmlu:high_school_geography,test,245.15638325735927
21,0.4761904776096344,0.4761904776096344,0.3545454545454545,0.11165907269432432,mmlu:high_school_government_and_politics,validation,44.77525755111128
193,0.5388600826263428,0.5388600826263428,0.5738439930855661,0.0674691984690533,mmlu:high_school_government_and_politics,test,413.1208958067
43,0.3720930218696594,0.3720930218696594,0.46180555555555547,0.18835747103358425,mmlu:high_school_macroeconomics,validation,67.98159292386845
390,0.3102564215660095,0.3102564215660095,0.48903192110356697,0.2506250003973643,mmlu:high_school_macroeconomics,test,677.533880060073
29,0.03448275849223137,0.03448275849223137,0.8571428571428572,0.5328139847722547,mmlu:high_school_mathematics,validation,18.483218398876488
270,0.051851850003004074,0.051851850003004074,0.40848214285714285,0.5187281590920907,mmlu:high_school_mathematics,test,167.7581677371636
26,0.26923078298568726,0.26923078298568726,0.4511278195488722,0.3080648183822632,mmlu:high_school_microeconomics,validation,30.280736646149307
238,0.3949579894542694,0.3949579894542694,0.5656767139479905,0.18541261929423872,mmlu:high_school_microeconomics,test,307.5388293392025
17,0.0,0.0,,0.6089690573075238,mmlu:high_school_physics,validation,16.518188206013292
151,0.15231788158416748,0.15231788158416748,0.634171195652174,0.45309085482793143,mmlu:high_school_physics,test,156.4930644170381
60,0.5333333611488342,0.5333333611488342,0.5212053571428572,0.11572038431962331,mmlu:high_school_psychology,validation,65.84262970695272
545,0.49724769592285156,0.49724769592285156,0.5067875131306057,0.08630528406265682,mmlu:high_school_psychology,test,647.1534619410522
23,0.21739131212234497,0.21739131212234497,0.3166666666666667,0.36612132839534595,mmlu:high_school_statistics,validation,22.474868267774582
216,0.2222222238779068,0.22685185074806213,0.4982638888888889,0.3559984713792801,mmlu:high_school_statistics,test,254.09483069181442
22,0.8636363744735718,0.8636363744735718,0.7192982456140351,0.2516916800629009,mmlu:high_school_us_history,validation,30.191347822081298
204,0.6078431606292725,0.6078431606292725,0.565171370967742,0.01583789961010802,mmlu:high_school_us_history,test,304.0158716822043
23,0.30434784293174744,0.30434784293174744,0.5178571428571428,0.2867798105530117,mmlu:human_aging,validation,22.803932783193886
223,0.3363228738307953,0.3363228738307953,0.5177927927927928,0.2533430213885457,mmlu:human_aging,test,303.05097265308723
12,0.25,0.25,0.3333333333333333,0.319976270198822,mmlu:human_sexuality,validation,18.958592276088893
131,0.42748090624809265,0.4351145029067993,0.5107142857142857,0.1412797765877411,mmlu:human_sexuality,test,196.6660599000752
13,0.5384615659713745,0.5384615659713745,0.45238095238095233,0.017419008108285783,mmlu:international_law,validation,17.854404516983777
121,0.6115702390670776,0.6033057570457458,0.5687176538240368,0.05477529813435447,mmlu:international_law,test,167.7305229427293
11,0.5454545617103577,0.5454545617103577,0.6,0.015971259637312496,mmlu:jurisprudence,validation,17.64184322580695
108,0.5185185074806213,0.5185185074806213,0.4175824175824176,0.049555290628362614,mmlu:jurisprudence,test,151.01095321495086
18,0.4444444477558136,0.4444444477558136,0.8000000000000002,0.2750907176070743,mmlu:logical_fallacies,validation,22.238334517925978
163,0.4417177736759186,0.4417177736759186,0.5293803418803419,0.14660928329807119,mmlu:logical_fallacies,test,193.05746969301254
11,0.4545454680919647,0.4545454680919647,0.41666666666666663,0.09295837445692584,mmlu:machine_learning,validation,14.373028670903295
112,0.2232142984867096,0.2142857313156128,0.4914942528735632,0.33069826875414166,mmlu:machine_learning,test,130.7816733228974
11,0.27272728085517883,0.27272728085517883,0.5208333333333333,0.30618713118813257,mmlu:management,validation,22.005036489106715
103,0.35922330617904663,0.35922330617904663,0.5098280098280099,0.22609303240637177,mmlu:management,test,160.31702067889273
25,0.19999998807907104,0.19999998807907104,0.45000000000000007,0.4073674345016479,mmlu:marketing,validation,28.175581973977387
234,0.38034188747406006,0.38034188747406006,0.5615652847733437,0.22647793807535094,mmlu:marketing,test,258.2436801609583
11,0.8181818723678589,0.8181818723678589,0.1111111111111111,0.23200834339315246,mmlu:medical_genetics,validation,27.047358518932015
100,0.38999998569488525,0.38999998569488525,0.6584699453551913,0.19271242678165434,mmlu:medical_genetics,test,227.35226261010394
38,0.44736841320991516,0.44736841320991516,0.4215686274509804,0.10934510042792872,mmlu:moral_disputes,validation,62.224298138171434
346,0.4017340838909149,0.4017340838909149,0.5636360476835921,0.15648908387718863,mmlu:moral_disputes,test,512.3239451032132
33,0.39393940567970276,0.3636363744735718,0.4980769230769231,0.17559392343867908,mmlu:nutrition,validation,39.0971835530363
306,0.4215686321258545,0.4215686321258545,0.5799500722638288,0.11445588340946272,mmlu:nutrition,test,379.89532505488023
34,0.38235294818878174,0.38235294818878174,0.49267399267399276,0.2084294277078965,mmlu:philosophy,validation,46.47694568103179
311,0.36012861132621765,0.35691317915916443,0.5114860014357502,0.23523208891847125,mmlu:philosophy,test,463.45439851190895
35,0.34285715222358704,0.34285715222358704,0.6594202898550724,0.2531492693083627,mmlu:prehistory,validation,74.15478729596362
324,0.40123456716537476,0.40123456716537476,0.5243259318001586,0.19810992736875274,mmlu:prehistory,test,678.2625907082111
69,0.36231884360313416,0.36231884360313416,0.4340909090909091,0.20512211495551508,mmlu:professional_psychology,validation,85.01348214969039
612,0.3202614486217499,0.3202614486217499,0.4926658163265305,0.24766753857431847,mmlu:professional_psychology,test,759.8498232318088
12,0.25,0.25,0.25925925925925924,0.32861120502154034,mmlu:public_relations,validation,11.86088125500828
110,0.33636361360549927,0.3545454442501068,0.5344316919659386,0.23253083554181184,mmlu:public_relations,test,88.02485698834062
27,0.7407407760620117,0.7407407760620117,0.5178571428571429,0.16709752877553297,mmlu:security_studies,validation,43.48229667684063
245,0.6775509715080261,0.6775509715080261,0.6415281378679274,0.10471174206052511,mmlu:security_studies,test,407.9288525939919
22,0.5454545617103577,0.5454545617103577,0.42916666666666664,0.043827764012596804,mmlu:sociology,validation,42.514980043284595
201,0.4726368188858032,0.4726368188858032,0.5981132075471699,0.11871502767154826,mmlu:sociology,test,398.1432129261084
11,0.5454545617103577,0.5454545617103577,0.7166666666666667,0.03716929392381152,mmlu:us_foreign_policy,validation,11.596675644163042
100,0.5600000023841858,0.5699999928474426,0.5653409090909092,0.03034779548645017,mmlu:us_foreign_policy,test,107.77215061802417
18,0.4444444477558136,0.4444444477558136,0.6125,0.12999722692701554,mmlu:virology,validation,22.502821340225637
166,0.3674698770046234,0.3674698770046234,0.5449648711943793,0.21636113883501074,mmlu:virology,test,257.3016778980382
19,0.5789473652839661,0.5789473652839661,0.8409090909090908,0.11358375612058134,mmlu:world_religions,validation,14.555468962993473
171,0.5146198868751526,0.5146198868751526,0.6154846659364732,0.09556838190346434,mmlu:world_religions,test,136.34847406297922
18,0.8333333134651184,0.8333333134651184,0.5,0.21838055716620547,mmlu:high_school_european_history,validation,9.934252047911286
165,0.7090908885002136,0.7090908885002136,0.5825320512820513,0.09321040854309547,mmlu:high_school_european_history,test,50.90513485111296
26,0.7307692170143127,0.7307692170143127,0.5488721804511278,0.1299214202624101,mmlu:high_school_world_history,validation,4.657422346994281
237,0.552742600440979,0.552742600440979,0.46892553651159447,0.0462145845598309,mmlu:high_school_world_history,test,37.48677921714261
86,0.41860464215278625,0.41860464215278625,0.5255555555555556,0.16746184299158495,mmlu:miscellaneous,validation,2.9692388011608273
783,0.4533844292163849,0.4546615481376648,0.6008621824404369,0.13143087704671905,mmlu:miscellaneous,test,23.672088737832382
100,0.5099999904632568,0.5099999904632568,0.5994397759103642,0.07201211690902709,mmlu:moral_scenarios,validation,6.424259386025369
895,0.46145251393318176,0.46145251393318176,0.48888308400229075,0.1204356848860586,mmlu:moral_scenarios,test,54.75437271595001
31,0.06451612710952759,0.06451612710952759,0.8103448275862069,0.5043481953682438,mmlu:professional_accounting,validation,2.343194769928232
282,0.1560283750295639,0.1560283750295639,0.47798892284186406,0.41445236594964424,mmlu:professional_accounting,test,19.614851877093315
170,0.30588236451148987,0.3235294222831726,0.5079041720990873,0.2255501256269567,mmlu:professional_law,validation,25.489473002031446
1534,0.3200782239437103,0.3200782239437103,0.46696432232729884,0.23000666207720122,mmlu:professional_law,test,235.52969054109417
31,0.25806450843811035,0.25806450843811035,0.5516304347826086,0.32772546237514866,mmlu:professional_medicine,validation,3.9981290749274194
272,0.23529411852359772,0.23529411852359772,0.46788611778846156,0.35022586759398966,mmlu:professional_medicine,test,33.2309461038094
