N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.8181818723678589,0.8333333333333334,0.29248524254018615,mmlu:abstract_algebra,validation,34.932068809866905
100,0.2199999988079071,0.7799999713897705,0.412004662004662,0.2537473726272583,mmlu:abstract_algebra,test,302.73889912106097
14,0.2857142984867096,0.7142857313156128,0.8,0.16452578987394062,mmlu:anatomy,validation,41.35905173048377
135,0.4444444477558136,0.555555522441864,0.496,0.006585631105634926,mmlu:anatomy,test,402.4140410795808
16,0.625,0.375,0.43333333333333335,0.18030083179473877,mmlu:astronomy,validation,49.441226767376065
152,0.46710526943206787,0.5328947305679321,0.4523561119805251,0.023021512909939368,mmlu:astronomy,test,471.1798966806382
11,0.5454545617103577,0.3636363744735718,0.8166666666666668,0.15033073316920886,mmlu:business_ethics,validation,33.75832953862846
100,0.3499999940395355,0.5199999809265137,0.5657142857142856,0.007443745136261004,mmlu:business_ethics,test,309.34789219871163
29,0.24137930572032928,0.7586206793785095,0.39285714285714285,0.20224482848726466,mmlu:clinical_knowledge,validation,86.2506730556488
265,0.3660377264022827,0.6339622735977173,0.47999509081983305,0.07886355170663795,mmlu:clinical_knowledge,test,799.355763822794
16,0.3125,0.75,0.23636363636363633,0.21498125791549683,mmlu:college_biology,validation,47.559587836265564
144,0.2916666567325592,0.7083333134651184,0.47058823529411764,0.1736071904500326,mmlu:college_biology,test,429.02134041674435
8,0.25,0.75,0.4166666666666667,0.22134530544281006,mmlu:college_chemistry,validation,23.991243926808238
100,0.14000000059604645,0.85999995470047,0.3965946843853821,0.3281752324104309,mmlu:college_chemistry,test,297.89238952472806
11,0.0,1.0,,0.4745190143585205,mmlu:college_computer_science,validation,33.36418574862182
100,0.17999999225139618,0.7999999523162842,0.521680216802168,0.2753564596176148,mmlu:college_computer_science,test,304.87019427120686
11,0.0,1.0,,0.48081541061401367,mmlu:college_mathematics,validation,32.846680937334895
100,0.17000000178813934,0.7999999523162842,0.4014883061658398,0.27988760471344,mmlu:college_mathematics,test,297.54366110265255
22,0.3636363744735718,0.6363636255264282,0.4375,0.08485175262797962,mmlu:college_medicine,validation,65.36547712422907
173,0.34682080149650574,0.647398829460144,0.5901917404129793,0.0990511323675255,mmlu:college_medicine,test,514.789207931608
11,0.27272728085517883,0.7272727489471436,0.41666666666666663,0.19732198931954126,mmlu:college_physics,validation,32.264878410845995
102,0.18627451360225677,0.8137255311012268,0.5814838300570704,0.28038181744369806,mmlu:college_physics,test,303.4311698731035
11,0.4545454680919647,0.6363636255264282,0.25,0.10956348072398792,mmlu:computer_security,validation,32.138564970344305
100,0.4399999976158142,0.5600000023841858,0.3782467532467532,0.03470164299011236,mmlu:computer_security,test,294.00109209120274
26,0.3076923191547394,0.692307710647583,0.40277777777777773,0.159008842248183,mmlu:conceptual_physics,validation,76.6834542453289
235,0.4170212745666504,0.5829787254333496,0.5788768061969314,0.050100920555439354,mmlu:conceptual_physics,test,687.7668366730213
12,0.0,1.0,,0.46596455574035645,mmlu:econometrics,validation,35.696685928851366
114,0.14912280440330505,0.8421052694320679,0.5245603395997575,0.2956891593180204,mmlu:econometrics,test,337.77576641365886
16,0.1875,0.8125,0.9871794871794871,0.2543641924858093,mmlu:electrical_engineering,validation,47.019977163523436
145,0.20000000298023224,0.800000011920929,0.5329964328180737,0.24518357515335087,mmlu:electrical_engineering,test,423.3477192763239
41,0.24390242993831635,0.7560975551605225,0.4403225806451613,0.2248537598586664,mmlu:elementary_mathematics,validation,122.48515383154154
378,0.33597883582115173,0.6640211343765259,0.5134893496878628,0.13440337761369336,mmlu:elementary_mathematics,test,1116.9775050096214
14,0.3571428656578064,0.6428571939468384,0.46666666666666673,0.12018431084496639,mmlu:formal_logic,validation,41.49440864101052
126,0.2539682686328888,0.7460317611694336,0.5643284574468085,0.21528349793146528,mmlu:formal_logic,test,372.8357346858829
10,0.20000000298023224,0.800000011920929,0.53125,0.2656329154968262,mmlu:global_facts,validation,29.454997792840004
100,0.14000000059604645,0.85999995470047,0.4950166112956811,0.33002726793289183,mmlu:global_facts,test,297.01410801149905
32,0.1875,0.8125,0.5512820512820513,0.27746790647506714,mmlu:high_school_biology,validation,95.69897884130478
310,0.4193548262119293,0.5806451439857483,0.5427350427350426,0.04545034708515294,mmlu:high_school_biology,test,931.4560682550073
22,0.22727273404598236,0.8181818723678589,0.40588235294117647,0.2957485968416388,mmlu:high_school_chemistry,validation,64.89850436523557
203,0.15763546526432037,0.842364490032196,0.52640716374269,0.31988195803365094,mmlu:high_school_chemistry,test,601.4597887899727
9,0.3333333432674408,0.6666666865348816,0.3888888888888889,0.10910973946253455,mmlu:high_school_computer_science,validation,27.335307190194726
100,0.4699999988079071,0.5299999713897705,0.4592533119229225,0.023747773170471165,mmlu:high_school_computer_science,test,303.53021635860205
22,0.4545454680919647,0.5454545617103577,0.3958333333333333,0.0028893188996748087,mmlu:high_school_geography,validation,64.82049682736397
198,0.3787878751754761,0.6212121248245239,0.3839024390243902,0.07740604516231653,mmlu:high_school_geography,test,577.9659447241575
21,0.380952388048172,0.6190476417541504,0.49999999999999994,0.05325750226066228,mmlu:high_school_government_and_politics,validation,62.3431151881814
193,0.47668391466140747,0.5233160257339478,0.4578669823504089,0.04316916397816162,mmlu:high_school_government_and_politics,test,567.9198853559792
43,0.5116279125213623,0.4883720874786377,0.4805194805194805,0.056575292764708074,mmlu:high_school_macroeconomics,validation,123.57907710783184
390,0.3641025722026825,0.6358974575996399,0.5075107905497501,0.0925834557948968,mmlu:high_school_macroeconomics,test,1158.693072969094
29,0.06896551698446274,0.8965517282485962,0.5,0.37430589980092543,mmlu:high_school_mathematics,validation,86.48485876061022
270,0.07777777314186096,0.9148147702217102,0.42168674698795183,0.39467369008947306,mmlu:high_school_mathematics,test,807.9294503610581
26,0.38461539149284363,0.6153846383094788,0.45937500000000003,0.0729213723769555,mmlu:high_school_microeconomics,validation,75.57770133391023
238,0.3361344635486603,0.6638655662536621,0.5422863924050633,0.118861237994763,mmlu:high_school_microeconomics,test,700.4414525106549
17,0.23529411852359772,0.5882353186607361,0.7115384615384616,0.0802810542723712,mmlu:high_school_physics,validation,50.165745202451944
151,0.17880794405937195,0.6026490330696106,0.4039725209080048,0.0951029989893073,mmlu:high_school_physics,test,451.7289750352502
60,0.5333333611488342,0.46666669845581055,0.42410714285714285,0.071346910794576,mmlu:high_school_psychology,validation,174.95884525962174
545,0.5064220428466797,0.4935779869556427,0.47526399439685363,0.045312022506643845,mmlu:high_school_psychology,test,1613.3266857042909
23,0.21739131212234497,0.695652186870575,0.46111111111111114,0.17775272027305933,mmlu:high_school_statistics,validation,68.17773240618408
216,0.23148147761821747,0.7361111044883728,0.5730120481927711,0.21906006998485994,mmlu:high_school_statistics,test,646.8792199064046
22,0.5909091234207153,0.40909093618392944,0.4358974358974359,0.15052047100934113,mmlu:high_school_us_history,validation,75.61007558368146
204,0.6127451062202454,0.387254923582077,0.4556962025316456,0.17494266407162534,mmlu:high_school_us_history,test,697.3475481048226
23,0.30434784293174744,0.695652186870575,0.7410714285714286,0.17383288041405054,mmlu:human_aging,validation,66.43412383645773
223,0.3497757911682129,0.6502242684364319,0.5268788682581786,0.125637597300012,mmlu:human_aging,test,651.8310031909496
12,0.5,0.5,0.5416666666666666,0.04225945472717285,mmlu:human_sexuality,validation,35.20396095700562
131,0.47328245639801025,0.5267175436019897,0.47510518934081347,0.011784659087202942,mmlu:human_sexuality,test,387.50580538250506
13,0.1538461595773697,0.8461538553237915,0.2727272727272727,0.2988423017355112,mmlu:international_law,validation,38.27339584752917
121,0.45454543828964233,0.5454545021057129,0.35812672176308535,0.0016726417974992636,mmlu:international_law,test,357.9306310042739
11,0.3636363744735718,0.6363636255264282,0.4464285714285714,0.07903880964625964,mmlu:jurisprudence,validation,32.213584169745445
108,0.4166666567325592,0.5833333134651184,0.5082892416225749,0.021561940511067745,mmlu:jurisprudence,test,319.6692841295153
18,0.4444444477558136,0.5555555820465088,0.6062500000000001,0.018841001722547768,mmlu:logical_fallacies,validation,53.62226909585297
163,0.44785276055336,0.5521472096443176,0.5200913242009133,0.016904026087076418,mmlu:logical_fallacies,test,487.34440712817013
11,0.1818181872367859,0.8181818723678589,0.6666666666666667,0.25466281717473815,mmlu:machine_learning,validation,33.227355225011706
112,0.2142857313156128,0.785714328289032,0.5305397727272727,0.22931917224611553,mmlu:machine_learning,test,334.32760266400874
11,0.4545454680919647,0.5454545617103577,0.43333333333333335,0.007267610593275631,mmlu:management,validation,31.767685920000076
103,0.4563106894493103,0.5436893105506897,0.44395896656534956,0.009068181213823356,mmlu:management,test,303.4963468275964
25,0.23999999463558197,0.7599999904632568,0.6754385964912281,0.20779741764068604,mmlu:marketing,validation,73.89180204086006
234,0.4572649896144867,0.5427350401878357,0.43733902421075865,0.01160287602334964,mmlu:marketing,test,697.2896863091737
11,0.7272727489471436,0.27272728085517883,0.5208333333333333,0.2773768089034341,mmlu:medical_genetics,validation,32.24011858925223
100,0.4599999785423279,0.5399999618530273,0.4879227053140097,0.006958148479461634,mmlu:medical_genetics,test,300.25714906305075
38,0.3947368562221527,0.6052631735801697,0.4942028985507247,0.05500309090865285,mmlu:moral_disputes,validation,111.98599375598133
346,0.36994218826293945,0.6300578117370605,0.484787127293578,0.08617712479795339,mmlu:moral_disputes,test,1021.8311258833855
33,0.3636363744735718,0.6363636255264282,0.6130952380952381,0.09405506740916858,mmlu:nutrition,validation,97.09203172288835
306,0.35947713255882263,0.6405228972434998,0.5044758812615955,0.09886209014194458,mmlu:nutrition,test,913.3117555379868
34,0.38235294818878174,0.6176470518112183,0.48901098901098905,0.08869183764738198,mmlu:philosophy,validation,98.82050766982138
311,0.33118969202041626,0.6655948162078857,0.5419856235997014,0.13658312892607172,mmlu:philosophy,test,915.3582377433777
35,0.2857142984867096,0.7142857313156128,0.46,0.16039852585111347,mmlu:prehistory,validation,102.82832727581263
324,0.4104938209056854,0.5895061492919922,0.5540880998307286,0.033774262961046214,mmlu:prehistory,test,958.044729873538
69,0.3913043439388275,0.6086956858634949,0.5198412698412698,0.06494345872298535,mmlu:professional_psychology,validation,204.22768453881145
612,0.32679739594459534,0.673202633857727,0.4847633495145631,0.128222624850429,mmlu:professional_psychology,test,1828.3042155690491
12,0.5,0.5,0.6527777777777778,0.06428718566894531,mmlu:public_relations,validation,35.516274036839604
110,0.3272727131843567,0.6727272272109985,0.6204954954954955,0.11186598322608254,mmlu:public_relations,test,324.6746469885111
27,0.5925925970077515,0.40740740299224854,0.32954545454545453,0.1537585810378746,mmlu:security_studies,validation,80.72377207875252
245,0.5510203838348389,0.44897958636283875,0.49383838383838385,0.11388775158901604,mmlu:security_studies,test,734.2405602112412
22,0.4545454680919647,0.5454545617103577,0.4041666666666666,0.013991133733229244,mmlu:sociology,validation,64.58244994655252
201,0.4079601764678955,0.5920397639274597,0.49349251895880303,0.03604034315887372,mmlu:sociology,test,589.9308318402618
11,0.7272727489471436,0.27272728085517883,0.4791666666666667,0.3131637356498025,mmlu:us_foreign_policy,validation,32.780181335285306
100,0.5999999642372131,0.3999999761581421,0.45875,0.18178287744522093,mmlu:us_foreign_policy,test,294.2356869876385
18,0.5,0.5,0.6790123456790124,0.05286496877670288,mmlu:virology,validation,53.598228795453906
166,0.3192771077156067,0.6807228922843933,0.5421606278176657,0.13101112770746992,mmlu:virology,test,488.8817876800895
19,0.6842105388641357,0.31578946113586426,0.3717948717948718,0.22275816139421967,mmlu:world_religions,validation,56.3881172966212
171,0.5964912176132202,0.4035087823867798,0.5085251491901108,0.13303388210765105,mmlu:world_religions,test,502.68263839557767
