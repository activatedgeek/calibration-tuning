N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
22,0.5,0.5454545617103577,0.628099173553719,0.14977796240286395,mmlu:college_medicine,validation,89.12049156427383
173,0.3410404622554779,0.35260114073753357,0.5284716027356527,0.37470017278814594,mmlu:college_medicine,test,669.7784756720066
11,0.6363636255264282,0.6363636255264282,0.48214285714285715,0.189186383377422,mmlu:us_foreign_policy,validation,41.85417188331485
100,0.5799999833106995,0.5799999833106995,0.5654761904761905,0.23080179870128636,mmlu:us_foreign_policy,test,336.8879733942449
12,0.0833333358168602,0.0833333358168602,0.6363636363636364,0.7410024901231129,mmlu:econometrics,validation,45.40112589672208
114,0.15789473056793213,0.17543859779834747,0.43605324074074076,0.6258934830364428,mmlu:econometrics,test,441.0197247005999
16,0.3125,0.3125,0.7,0.4186958409845829,mmlu:astronomy,validation,60.28751618228853
152,0.5,0.5,0.6114092797783934,0.24513951100801162,mmlu:astronomy,test,552.149770623073
26,0.5769230723381042,0.5769230723381042,0.5151515151515152,0.21966116703473607,mmlu:high_school_world_history,validation,109.95771226659417
237,0.5274261236190796,0.5274261236190796,0.5634285714285714,0.26184116712602384,mmlu:high_school_world_history,test,987.4854345005006
13,0.38461539149284363,0.38461539149284363,0.36250000000000004,0.42284838969890887,mmlu:international_law,validation,45.81091184541583
121,0.5371900796890259,0.5371900796890259,0.5418956043956045,0.19944807517627056,mmlu:international_law,test,411.1500265803188
11,0.6363636255264282,0.6363636255264282,0.6785714285714286,0.13228840177709406,mmlu:management,validation,73.80369317531586
103,0.4660194218158722,0.4757281541824341,0.6412878787878787,0.2983197245783019,mmlu:management,test,606.2815990895033
41,0.2682926654815674,0.2682926654815674,0.47575757575757577,0.4681841789222345,mmlu:elementary_mathematics,validation,148.25846084579825
378,0.3809523582458496,0.3809523582458496,0.5193198005698005,0.36654084558209415,mmlu:elementary_mathematics,test,1527.4715232662857
12,0.25,0.1666666716337204,0.37037037037037035,0.5332701305548351,mmlu:public_relations,validation,45.28882973920554
110,0.30909091234207153,0.3545454442501068,0.5830108359133127,0.37577348514036696,mmlu:public_relations,test,381.33372589666396
31,0.5161290168762207,0.5161290168762207,0.55625,0.23196599752672253,mmlu:professional_medicine,validation,118.92234929278493
272,0.3235294222831726,0.3235294222831726,0.5138339920948616,0.4215505171348066,mmlu:professional_medicine,test,1028.5924172010273
14,0.4285714626312256,0.4285714626312256,0.6354166666666667,0.40938963208879736,mmlu:formal_logic,validation,52.87788254208863
126,0.1984127163887024,0.1984127163887024,0.5992079207920792,0.6473679864217364,mmlu:formal_logic,test,440.30634057335556
69,0.36231884360313416,0.36231884360313416,0.44045454545454543,0.37611974322277575,mmlu:professional_psychology,validation,252.0150595139712
612,0.3235294222831726,0.3235294222831726,0.5198604401502952,0.413131051301177,mmlu:professional_psychology,test,2240.6867264527828
23,0.17391304671764374,0.17391304671764374,0.5526315789473684,0.6968456791794818,mmlu:high_school_statistics,validation,86.00958263501525
216,0.25462964177131653,0.25462964177131653,0.45172219085262566,0.6111662950780656,mmlu:high_school_statistics,test,810.1453329641372
31,0.12903225421905518,0.12903225421905518,0.5,0.7029017363825152,mmlu:professional_accounting,validation,130.4754413740011
282,0.173758864402771,0.173758864402771,0.5268459315056495,0.6568951507409414,mmlu:professional_accounting,test,1139.8703585509793
16,0.375,0.375,0.6416666666666667,0.43443945422768593,mmlu:electrical_engineering,validation,65.93345446139574
145,0.22758620977401733,0.22758620977401733,0.579004329004329,0.5801384724419693,mmlu:electrical_engineering,test,590.1811602041125
86,0.6162790656089783,0.6162790656089783,0.5214408233276158,0.15218436995217965,mmlu:miscellaneous,validation,322.0769738536328
783,0.6194124817848206,0.6219667792320251,0.6221857053898845,0.1455260703237882,mmlu:miscellaneous,test,2981.003094924614
38,0.28947368264198303,0.28947368264198303,0.3434343434343435,0.4571255868987033,mmlu:moral_disputes,validation,255.93246597796679
346,0.39017340540885925,0.39306357502937317,0.5425838160435317,0.3555485783629335,mmlu:moral_disputes,test,2310.764394734055
11,0.3636363744735718,0.3636363744735718,0.32142857142857145,0.47906261140649975,mmlu:computer_security,validation,41.19685408473015
100,0.4399999976158142,0.4399999976158142,0.6436688311688311,0.3659414267539978,mmlu:computer_security,test,340.95439616404474
18,0.4444444477558136,0.4444444477558136,0.5,0.3389817972977956,mmlu:virology,validation,120.151227876544
166,0.3253012001514435,0.3253012001514435,0.5672949735449735,0.4496458596493824,mmlu:virology,test,1096.6169982999563
170,0.4117647111415863,0.4000000059604645,0.5062142857142857,0.3215844322653378,mmlu:professional_law,validation,677.311274971813
1534,0.3826597034931183,0.397653192281723,0.5304647150780102,0.33058617000784996,mmlu:professional_law,test,6245.972551705316
17,0.1764705926179886,0.1764705926179886,0.35714285714285715,0.6992240442949182,mmlu:high_school_physics,validation,61.63749869726598
151,0.22516556084156036,0.22516556084156036,0.47184514831573654,0.6446265163800575,mmlu:high_school_physics,test,518.3204355258495
26,0.3461538553237915,0.3461538553237915,0.6830065359477124,0.4511892933111925,mmlu:conceptual_physics,validation,87.10453851893544
235,0.45957446098327637,0.45957446098327637,0.49792213473315833,0.3357382520716241,mmlu:conceptual_physics,test,808.5048233382404
10,0.20000000298023224,0.20000000298023224,0.5625,0.5823015689849853,mmlu:global_facts,validation,37.087869476526976
100,0.20999999344348907,0.20999999344348907,0.5307414104882459,0.5664337408542632,mmlu:global_facts,test,349.75727666169405
9,0.2222222238779068,0.2222222238779068,0.7142857142857142,0.5590353343221877,mmlu:high_school_computer_science,validation,38.43798389285803
100,0.44999998807907104,0.44999998807907104,0.5018181818181818,0.32181086838245393,mmlu:high_school_computer_science,test,383.30176901072264
34,0.2647058963775635,0.2647058963775635,0.5555555555555556,0.552674708997502,mmlu:philosophy,validation,225.00864748097956
311,0.33118969202041626,0.33118969202041626,0.5049943988050785,0.49841225492225966,mmlu:philosophy,test,2051.9079619068652
100,0.3400000035762787,0.3400000035762787,0.6105169340463459,0.35571952402591706,mmlu:moral_scenarios,validation,338.37740604020655
895,0.30614525079727173,0.30614525079727173,0.513764002021698,0.3895295133137836,mmlu:moral_scenarios,test,3016.838881816715
22,0.40909093618392944,0.40909093618392944,0.7094017094017093,0.33443172953345557,mmlu:high_school_geography,validation,84.2418879494071
198,0.38383838534355164,0.38383838534355164,0.683455565142364,0.35477721931958445,mmlu:high_school_geography,test,757.3800171008334
26,0.42307692766189575,0.42307692766189575,0.5939393939393939,0.3999576155955975,mmlu:high_school_microeconomics,validation,96.29132886044681
238,0.38655462861061096,0.38655462861061096,0.45812239428231094,0.4309869904478057,mmlu:high_school_microeconomics,test,881.225895896554
22,0.5909091234207153,0.6363636255264282,0.9102564102564102,0.277550074187192,mmlu:sociology,validation,146.52605478838086
201,0.4029850661754608,0.42288556694984436,0.6215534979423868,0.2795034101353356,mmlu:sociology,test,1330.5820531882346
43,0.39534884691238403,0.39534884691238403,0.6889140271493213,0.4121224935664687,mmlu:high_school_macroeconomics,validation,165.8802964873612
390,0.3461538553237915,0.34871795773506165,0.6208569353667392,0.4465320921861208,mmlu:high_school_macroeconomics,test,1486.923254672438
33,0.3333333432674408,0.3333333432674408,0.5516528925619835,0.4107558799512459,mmlu:nutrition,validation,222.63508551940322
306,0.3366013169288635,0.3366013169288635,0.5321631833181882,0.41452464286018825,mmlu:nutrition,test,2059.2177620641887
12,0.3333333432674408,0.5833333730697632,0.625,0.30409617225329083,mmlu:human_sexuality,validation,79.99619373306632
131,0.40458014607429504,0.5267175436019897,0.660377358490566,0.132649652830517,mmlu:human_sexuality,test,899.8090237658471
22,0.13636364042758942,0.13636364042758942,0.7894736842105263,0.6894841004501688,mmlu:high_school_chemistry,validation,85.44906899519265
203,0.1822660118341446,0.1822660118341446,0.6218658417453599,0.6392875977337653,mmlu:high_school_chemistry,test,786.4096222287044
14,0.2857142984867096,0.2857142984867096,0.8625,0.4818842623914991,mmlu:anatomy,validation,49.73006128706038
135,0.46666666865348816,0.46666666865348816,0.4826940035273369,0.3026109492337262,mmlu:anatomy,test,485.0736970854923
11,0.09090909361839294,0.09090909361839294,1.0,0.756121960553256,mmlu:college_mathematics,validation,42.05115056037903
100,0.12999999523162842,0.12999999523162842,0.5698496905393458,0.7101446700096131,mmlu:college_mathematics,test,340.02525847032666
11,0.6363636255264282,0.6363636255264282,0.6607142857142857,0.18632946773008868,mmlu:medical_genetics,validation,42.58786268904805
100,0.429999977350235,0.429999977350235,0.5999592003263974,0.3795461690425873,mmlu:medical_genetics,test,366.1844340786338
11,0.27272728085517883,0.27272728085517883,0.5625,0.5469106327403676,mmlu:college_physics,validation,42.184831087477505
102,0.21568627655506134,0.21568627655506134,0.5181818181818181,0.6197888599891288,mmlu:college_physics,test,376.02213120646775
35,0.37142857909202576,0.37142857909202576,0.4912587412587413,0.44619302749633794,mmlu:prehistory,validation,130.8704794626683
324,0.4783950746059418,0.4783950746059418,0.5933765985875167,0.34333470850079145,mmlu:prehistory,test,1192.5864577153698
23,0.260869562625885,0.260869562625885,0.31862745098039214,0.45138993988866394,mmlu:human_aging,validation,79.03902621939778
223,0.3632287085056305,0.37219732999801636,0.5302990784211441,0.3393256797918825,mmlu:human_aging,test,755.4834485258907
18,0.5555555820465088,0.5555555820465088,0.55625,0.2533545030487908,mmlu:logical_fallacies,validation,64.31279144389555
163,0.5030674934387207,0.5030674934387207,0.6175850647395363,0.30360047692901515,mmlu:logical_fallacies,test,817.3325967751443
16,0.1875,0.1875,0.5897435897435896,0.5462227091193199,mmlu:college_biology,validation,61.65815756749362
144,0.4166666567325592,0.4166666567325592,0.5701388888888889,0.3248027666575379,mmlu:college_biology,test,544.6230257619172
25,0.3199999928474426,0.3199999928474426,0.6801470588235294,0.4497196745872498,mmlu:marketing,validation,169.00624174252152
234,0.4829060137271881,0.4829060137271881,0.551232355737585,0.281646415973321,mmlu:marketing,test,1736.981932707131
29,0.24137930572032928,0.24137930572032928,0.6948051948051949,0.4823131602385949,mmlu:clinical_knowledge,validation,107.0869963876903
265,0.3094339668750763,0.3094339668750763,0.5466480074636813,0.42029309497689304,mmlu:clinical_knowledge,test,951.4276815485209
29,0.10344827175140381,0.10344827175140381,0.6794871794871795,0.7279432354302241,mmlu:high_school_mathematics,validation,99.46614485606551
270,0.08518518507480621,0.08518518507480621,0.482837528604119,0.7348761516588707,mmlu:high_school_mathematics,test,917.6358883483335
11,0.1818181872367859,0.1818181872367859,0.5833333333333334,0.6551378152587197,mmlu:college_computer_science,validation,40.21932636201382
100,0.22999998927116394,0.22999998927116394,0.606154714850367,0.6065822899341583,mmlu:college_computer_science,test,356.6112419962883
60,0.5833333730697632,0.5833333730697632,0.6417142857142857,0.19396911064783728,mmlu:high_school_psychology,validation,224.87375202775002
545,0.5449541211128235,0.5467889904975891,0.5309139784946236,0.22686759966229086,mmlu:high_school_psychology,test,2141.4540210757405
11,0.09090909361839294,0.09090909361839294,0.7500000000000001,0.7765273180874911,mmlu:abstract_algebra,validation,42.90378623921424
100,0.25,0.25,0.5992000000000001,0.6139193177223206,mmlu:abstract_algebra,test,375.9904192080721
19,0.6315789222717285,0.6315789222717285,0.5654761904761905,0.18531798688988937,mmlu:world_religions,validation,72.01216139644384
171,0.6374269127845764,0.6374269127845764,0.48239124001183786,0.1827293379962096,mmlu:world_religions,test,630.7719914019108
11,0.6363636255264282,0.6363636255264282,0.7678571428571429,0.18263335661454635,mmlu:business_ethics,validation,44.428591307252645
100,0.3799999952316284,0.3799999952316284,0.5689728353140916,0.4135214304924011,mmlu:business_ethics,test,372.96035093069077
8,0.125,0.125,0.5,0.6922355741262436,mmlu:college_chemistry,validation,30.93999245762825
100,0.17000000178813934,0.17000000178813934,0.3621545003543586,0.6662498420476913,mmlu:college_chemistry,test,362.87684584409
21,0.4761904776096344,0.4761904776096344,0.5818181818181818,0.2929953904378982,mmlu:high_school_government_and_politics,validation,81.15408354066312
193,0.5388600826263428,0.5388600826263428,0.6576815038893692,0.22427908219204049,mmlu:high_school_government_and_politics,test,728.7541529126465
27,0.5555555820465088,0.5555555820465088,0.5194444444444444,0.1583856322147228,mmlu:security_studies,validation,101.93372741527855
245,0.5469387769699097,0.5469387769699097,0.5170431625655507,0.1657008317052102,mmlu:security_studies,test,918.8083582483232
11,0.3636363744735718,0.3636363744735718,0.7142857142857142,0.4399442889473656,mmlu:machine_learning,validation,75.52843286842108
112,0.2232142984867096,0.2232142984867096,0.512183908045977,0.5791367356266294,mmlu:machine_learning,test,762.4896912798285
32,0.375,0.375,0.48750000000000004,0.38358893245458603,mmlu:high_school_biology,validation,109.84068897459656
310,0.4677419364452362,0.4677419364452362,0.559916405433647,0.30193998159900787,mmlu:high_school_biology,test,1049.438257470727
