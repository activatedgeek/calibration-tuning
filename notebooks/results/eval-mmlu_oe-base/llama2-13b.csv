N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
22,0.5909090638160706,0.5909090638160706,0.48717948717948717,0.2003669738769531,mmlu:high_school_us_history,validation,59.66337094595656
204,0.6225489974021912,0.6225489974021912,0.5537376009816956,0.14689820040674773,mmlu:high_school_us_history,test,494.68028396880254
18,0.7222222089767456,0.7222222089767456,0.676923076923077,0.07998571130964488,mmlu:high_school_european_history,validation,49.53605681308545
165,0.6000000238418579,0.6000000238418579,0.6127946127946129,0.21304168520551736,mmlu:high_school_european_history,test,416.79035318107344
26,0.6153846383094788,0.6153846383094788,0.38437499999999997,0.17911923390168405,mmlu:high_school_world_history,validation,44.42171727993991
237,0.5274261832237244,0.5274261832237244,0.5559999999999999,0.2601224279604884,mmlu:high_school_world_history,test,357.11472115200013
86,0.604651153087616,0.604651153087616,0.5811651583710407,0.16197620366894927,mmlu:miscellaneous,validation,54.354022621992044
783,0.6168582439422607,0.6194125413894653,0.6089786059351276,0.1442832418480748,mmlu:miscellaneous,test,499.5163256600499
100,0.47999998927116394,0.47999998927116394,0.5358573717948718,0.24091397643089293,mmlu:moral_scenarios,validation,87.53918822703417
895,0.44134077429771423,0.44134077429771423,0.5398227848101266,0.2816270806935912,mmlu:moral_scenarios,test,773.882856752025
31,0.09677419066429138,0.09677419066429138,0.7261904761904763,0.7388938896117672,mmlu:professional_accounting,validation,27.953246786026284
282,0.14539006352424622,0.14539006352424622,0.6217488108491043,0.6851838226859451,mmlu:professional_accounting,test,254.4621674460359
170,0.364705890417099,0.364705890417099,0.4319743130227001,0.3820120152305154,mmlu:professional_law,validation,253.2347059759777
1534,0.29400262236595154,0.29400262236595154,0.5327209668470393,0.45621309325468123,mmlu:professional_law,test,2271.8878598189913
31,0.35483869910240173,0.35483869910240173,0.45227272727272727,0.33873031600829095,mmlu:professional_medicine,validation,45.43723481800407
272,0.3345588147640228,0.3345588147640228,0.4858235686964969,0.3566754357341458,mmlu:professional_medicine,test,347.4575646109879
11,0.09090909361839294,0.09090909361839294,0.6,0.7732941833409396,mmlu:abstract_algebra,validation,17.57656578719616
100,0.22999998927116394,0.22999998927116394,0.6888763410502541,0.6354502630233765,mmlu:abstract_algebra,test,67.9996696319431
14,0.2142857313156128,0.2142857313156128,0.8333333333333333,0.5574526701654707,mmlu:anatomy,validation,9.95774731785059
135,0.45185184478759766,0.45185184478759766,0.5321222862206468,0.31265934396673134,mmlu:anatomy,test,83.06231458671391
16,0.25,0.25,0.6354166666666666,0.48311325162649155,mmlu:astronomy,validation,11.727573597803712
152,0.5131579041481018,0.5131579041481018,0.6764553014553015,0.23324632095663173,mmlu:astronomy,test,101.19703273847699
11,0.4545454680919647,0.4545454680919647,0.85,0.3639208024198359,mmlu:business_ethics,validation,11.008875677362084
100,0.3199999928474426,0.32999998331069946,0.5873161764705882,0.47170271396636965,mmlu:business_ethics,test,77.3739627301693
29,0.24137930572032928,0.24137930572032928,0.711038961038961,0.4848113265530816,mmlu:clinical_knowledge,validation,19.999971823766828
265,0.3207547068595886,0.3207547068595886,0.5119607843137255,0.4098416715298059,mmlu:clinical_knowledge,test,177.10299684479833
16,0.25,0.25,0.46875,0.47928037121891975,mmlu:college_biology,validation,11.155683370307088
144,0.3958333432674408,0.3958333432674408,0.592458156886469,0.34398285879029167,mmlu:college_biology,test,100.33476967550814
8,0.125,0.125,0.2857142857142857,0.6958494484424591,mmlu:college_chemistry,validation,5.898107135668397
100,0.14999999105930328,0.14999999105930328,0.38823529411764707,0.6869483983516693,mmlu:college_chemistry,test,76.50840403884649
11,0.1818181872367859,0.1818181872367859,0.6111111111111112,0.6548799980770459,mmlu:college_computer_science,validation,12.66892508789897
100,0.2199999988079071,0.2199999988079071,0.5868298368298368,0.6160001629590989,mmlu:college_computer_science,test,101.60973275639117
11,0.1818181872367859,0.1818181872367859,0.7777777777777778,0.6636695428328081,mmlu:college_mathematics,validation,11.854817930608988
100,0.09999999403953552,0.09999999403953552,0.576111111111111,0.7418001407384872,mmlu:college_mathematics,test,82.77657677419484
22,0.5,0.5454545617103577,0.6198347107438017,0.14953251318498093,mmlu:college_medicine,validation,16.668495755642653
173,0.3583815097808838,0.3815028667449951,0.577884335948852,0.3420574100031329,mmlu:college_medicine,test,147.3516882341355
11,0.3636363744735718,0.3636363744735718,0.6428571428571429,0.45459550619125366,mmlu:college_physics,validation,11.042095618322492
102,0.21568627655506134,0.21568627655506134,0.5582386363636365,0.6218003992940865,mmlu:college_physics,test,80.35933936014771
11,0.3636363744735718,0.3636363744735718,0.5178571428571428,0.4784762967716564,mmlu:computer_security,validation,10.694976454600692
100,0.4599999785423279,0.4599999785423279,0.6099033816425121,0.34949994862079625,mmlu:computer_security,test,66.67990682274103
26,0.3461538553237915,0.3461538553237915,0.5588235294117647,0.44972213873496425,mmlu:conceptual_physics,validation,19.099222045391798
235,0.44255316257476807,0.44255316257476807,0.4629697592483853,0.35278910753574777,mmlu:conceptual_physics,test,150.64798012003303
12,0.0833333358168602,0.0833333358168602,0.5454545454545454,0.7486431002616882,mmlu:econometrics,validation,12.550480790436268
114,0.19298246502876282,0.21052631735801697,0.4258893280632411,0.580088940628788,mmlu:econometrics,test,97.12502892687917
16,0.375,0.375,0.6416666666666666,0.43194495141506195,mmlu:electrical_engineering,validation,11.420287100598216
145,0.2344827651977539,0.2344827651977539,0.579226285108638,0.5729534580789764,mmlu:electrical_engineering,test,104.49934718571603
41,0.2926829159259796,0.2926829159259796,0.45114942528735624,0.4499736486411676,mmlu:elementary_mathematics,validation,33.71985408291221
378,0.4021163880825043,0.4021163880825043,0.558540987424313,0.34167478592307476,mmlu:elementary_mathematics,test,272.0957910101861
14,0.3571428656578064,0.3571428656578064,0.4555555555555556,0.48722439152853836,mmlu:formal_logic,validation,12.255905095487833
126,0.1904762089252472,0.1904762089252472,0.6341911764705883,0.6570768029916855,mmlu:formal_logic,test,94.2381419017911
10,0.30000001192092896,0.30000001192092896,0.40476190476190477,0.47968940734863286,mmlu:global_facts,validation,9.922205805778503
100,0.23999999463558197,0.23999999463558197,0.4588815789473684,0.5362591654062272,mmlu:global_facts,test,70.63635529391468
32,0.34375,0.34375,0.5043290043290044,0.41847684793174267,mmlu:high_school_biology,validation,22.298144390806556
310,0.47096773982048035,0.47096773982048035,0.5704978282659539,0.29827126687572847,mmlu:high_school_biology,test,216.32555427215993
22,0.04545454680919647,0.04545454680919647,0.40476190476190477,0.7764108668674122,mmlu:high_school_chemistry,validation,17.44601721316576
203,0.19704432785511017,0.19704432785511017,0.626840490797546,0.6240150397047033,mmlu:high_school_chemistry,test,150.78370747342706
9,0.2222222238779068,0.2222222238779068,0.7857142857142857,0.5521882838673062,mmlu:high_school_computer_science,validation,10.860503483563662
100,0.41999998688697815,0.41999998688697815,0.5662972085385879,0.35049211859703067,mmlu:high_school_computer_science,test,95.03579358011484
22,0.40909093618392944,0.40909093618392944,0.7435897435897436,0.3465000526471572,mmlu:high_school_geography,validation,15.52118469029665
198,0.3787878751754761,0.3787878751754761,0.6951219512195121,0.35734404367629924,mmlu:high_school_geography,test,124.3909758515656
21,0.4761904776096344,0.4761904776096344,0.5181818181818182,0.2940433195659093,mmlu:high_school_government_and_politics,validation,15.855664651840925
193,0.5544041395187378,0.5544041395187378,0.6761030210823734,0.21035958911470792,mmlu:high_school_government_and_politics,test,131.22099709138274
43,0.41860464215278625,0.41860464215278625,0.6744444444444444,0.38634956853334296,mmlu:high_school_macroeconomics,validation,30.237305412068963
390,0.34358975291252136,0.3461538553237915,0.6593108675373134,0.44768620270949144,mmlu:high_school_macroeconomics,test,264.74496191367507
29,0.13793103396892548,0.13793103396892548,0.425,0.6925994938817518,mmlu:high_school_mathematics,validation,23.91821856237948
270,0.10000000149011612,0.10000000149011612,0.5333028501752781,0.7213681119459646,mmlu:high_school_mathematics,test,210.11526300013065
26,0.38461539149284363,0.38461539149284363,0.6281249999999999,0.4380038265998547,mmlu:high_school_microeconomics,validation,19.19641792960465
238,0.3781512677669525,0.3781512677669525,0.503003003003003,0.4375059021120312,mmlu:high_school_microeconomics,test,152.06374063156545
17,0.11764705926179886,0.11764705926179886,0.5,0.7608587075682247,mmlu:high_school_physics,validation,15.978296028450131
151,0.20529800653457642,0.20529800653457642,0.49892473118279573,0.6655074843507728,mmlu:high_school_physics,test,113.35697226971388
60,0.6000000238418579,0.6000000238418579,0.6087962962962963,0.1791634092728297,mmlu:high_school_psychology,validation,43.17571602202952
545,0.5357798337936401,0.5357798337936401,0.5309978883534571,0.2387062091346181,mmlu:high_school_psychology,test,403.31071675382555
23,0.043478261679410934,0.043478261679410934,0.5909090909090908,0.8249685220096421,mmlu:high_school_statistics,validation,20.670647744089365
216,0.25925925374031067,0.25925925374031067,0.4938058035714285,0.6055215575076915,mmlu:high_school_statistics,test,279.3648350611329
23,0.3478260934352875,0.3478260934352875,0.3958333333333333,0.37781733533610473,mmlu:human_aging,validation,15.729542223736644
223,0.3497757911682129,0.3677130341529846,0.5274977895667551,0.3415312144253821,mmlu:human_aging,test,138.81149594672024
12,0.25,0.5833333730697632,0.8333333333333334,0.3782374064127604,mmlu:human_sexuality,validation,10.018838359043002
131,0.442748099565506,0.5877862572669983,0.7104393008974964,0.11930189514888154,mmlu:human_sexuality,test,86.18977881409228
13,0.3076923191547394,0.3076923191547394,0.5555555555555556,0.44687228019420916,mmlu:international_law,validation,10.318063251674175
121,0.5206611156463623,0.5206611156463623,0.488232074438971,0.21468045987373544,mmlu:international_law,test,84.89488811604679
11,0.3636363744735718,0.3636363744735718,0.8214285714285715,0.4717825596982783,mmlu:jurisprudence,validation,9.696210701018572
108,0.39814814925193787,0.39814814925193787,0.5991055456171736,0.43124843581959055,mmlu:jurisprudence,test,71.92921151779592
18,0.5555555820465088,0.5555555820465088,0.48750000000000004,0.2516656650437249,mmlu:logical_fallacies,validation,15.189107496291399
163,0.460122674703598,0.460122674703598,0.5957575757575758,0.3438161183719986,mmlu:logical_fallacies,test,111.38982954993844
11,0.4545454680919647,0.4545454680919647,0.5333333333333334,0.35067428242076526,mmlu:machine_learning,validation,11.593535846099257
112,0.2232142984867096,0.2232142984867096,0.5259770114942528,0.5826500563749245,mmlu:machine_learning,test,91.04961018823087
11,0.8181818723678589,0.8181818723678589,0.3888888888888889,0.1094721880826083,mmlu:management,validation,9.02948009967804
103,0.43689319491386414,0.4466019570827484,0.6080459770114942,0.3240977913430593,mmlu:management,test,65.08750333823264
25,0.35999998450279236,0.35999998450279236,0.638888888888889,0.4079833149909973,mmlu:marketing,validation,20.40030248463154
234,0.5170940160751343,0.5170940160751343,0.5603013237767863,0.24663155608707005,mmlu:marketing,test,162.8025507107377
11,0.7272727489471436,0.7272727489471436,0.8958333333333334,0.09494746273214164,mmlu:medical_genetics,validation,8.42181515134871
100,0.4699999988079071,0.4699999988079071,0.5688478522681654,0.33817025065422057,mmlu:medical_genetics,test,63.24030767939985
38,0.3947368562221527,0.3947368562221527,0.446376811594203,0.35191780485604934,mmlu:moral_disputes,validation,26.27434143424034
346,0.42485547065734863,0.42774564027786255,0.5540115543704919,0.3222975791189712,mmlu:moral_disputes,test,232.9264558646828
33,0.3030303120613098,0.3030303120613098,0.4869565217391305,0.4368176008715774,mmlu:nutrition,validation,26.21281285583973
306,0.36274510622024536,0.36274510622024536,0.5321783321783321,0.3845758533555698,mmlu:nutrition,test,217.4898030627519
34,0.3235294222831726,0.3235294222831726,0.49407114624505927,0.5185250885346356,mmlu:philosophy,validation,24.675521420314908
311,0.34405145049095154,0.34405145049095154,0.5314046179219352,0.48403392209884055,mmlu:philosophy,test,194.7401986103505
35,0.3142857253551483,0.3142857253551483,0.5435606060606061,0.49907544510705126,mmlu:prehistory,validation,25.62517775967717
324,0.48148149251937866,0.48148149251937866,0.6127709096459096,0.3407452557189965,mmlu:prehistory,test,214.07162682525814
69,0.3913043439388275,0.3913043439388275,0.47619047619047616,0.34451305261556653,mmlu:professional_psychology,validation,51.468574084341526
612,0.3006536066532135,0.3006536066532135,0.5394466172287687,0.4347685322262882,mmlu:professional_psychology,test,438.71542989462614
12,0.25,0.1666666716337204,0.37037037037037035,0.5241971760988235,mmlu:public_relations,validation,10.070815863087773
110,0.30909091234207153,0.3545454442501068,0.5820433436532507,0.3890643531625921,mmlu:public_relations,test,72.41412119567394
27,0.48148149251937866,0.48148149251937866,0.5329670329670331,0.23542130214196663,mmlu:security_studies,validation,23.281854236498475
245,0.5265305638313293,0.5265305638313293,0.5736434108527131,0.18659212418964935,mmlu:security_studies,test,188.7294244300574
22,0.5909091234207153,0.6363636255264282,0.8931623931623932,0.16543954068964176,mmlu:sociology,validation,14.819427477195859
201,0.4129353165626526,0.4378109276294708,0.6293649172963038,0.2590438738391174,mmlu:sociology,test,132.44030121341348
11,0.6363636255264282,0.6363636255264282,0.625,0.19237666238438,mmlu:us_foreign_policy,validation,9.558422479778528
100,0.5699999928474426,0.5699999928474426,0.5924112607099142,0.24121792376041412,mmlu:us_foreign_policy,test,64.64814860746264
18,0.3333333432674408,0.3333333432674408,0.38888888888888895,0.4498979647954305,mmlu:virology,validation,15.294079655781388
166,0.33734938502311707,0.33734938502311707,0.5632305194805194,0.4348833568124886,mmlu:virology,test,108.26646942459047
19,0.6315789222717285,0.6315789222717285,0.5416666666666666,0.186060695271743,mmlu:world_religions,validation,13.2816342394799
171,0.6432748436927795,0.6432748436927795,0.5406110283159463,0.17683401686406275,mmlu:world_religions,test,104.3204442486167
