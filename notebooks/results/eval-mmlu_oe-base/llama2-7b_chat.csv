N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.09090909361839294,0.04999999999999999,0.7682481624863364,mmlu:abstract_algebra,validation,5.443439114838839
100,0.20999999344348907,0.2199999988079071,0.403254972875226,0.6485039931535721,mmlu:abstract_algebra,test,33.94627480581403
14,0.2142857313156128,0.2142857313156128,0.8484848484848485,0.7091554616178785,mmlu:anatomy,validation,4.256747122853994
135,0.385185182094574,0.385185182094574,0.6576691380908248,0.5286093451358654,mmlu:anatomy,test,41.756772462278605
16,0.5625,0.5625,0.38888888888888895,0.32216832786798477,mmlu:astronomy,validation,7.88192006573081
152,0.42763158679008484,0.44078949093818665,0.6270557029177719,0.4425945532949347,mmlu:astronomy,test,63.113098446279764
11,0.4545454680919647,0.4545454680919647,0.4833333333333333,0.5291499332948164,mmlu:business_ethics,validation,5.527832496911287
100,0.32999998331069946,0.32999998331069946,0.6361374943464496,0.6513404732942583,mmlu:business_ethics,test,47.613798540085554
29,0.17241379618644714,0.17241379618644714,0.6208333333333333,0.7424466753828114,mmlu:clinical_knowledge,validation,9.785184923559427
265,0.2792452871799469,0.28301888704299927,0.5281944247912835,0.6263004552643254,mmlu:clinical_knowledge,test,97.5780515447259
16,0.375,0.375,0.675,0.5629080832004547,mmlu:college_biology,validation,6.291356705129147
144,0.3402777910232544,0.3402777910232544,0.6089151450053706,0.5872255778974956,mmlu:college_biology,test,53.470144499093294
8,0.0,0.0,,0.9250170215964317,mmlu:college_chemistry,validation,4.090814579278231
100,0.14000000059604645,0.14000000059604645,0.5755813953488371,0.7923970198631287,mmlu:college_chemistry,test,38.88447905704379
11,0.27272728085517883,0.3636363744735718,0.7083333333333333,0.5945220914754001,mmlu:college_computer_science,validation,6.793401163071394
100,0.17000000178813934,0.1899999976158142,0.5145287030474841,0.6920945292711258,mmlu:college_computer_science,test,54.18059911951423
11,0.0,0.0,,0.9533958435058594,mmlu:college_mathematics,validation,6.047117158770561
100,0.2199999988079071,0.23999999463558197,0.6118881118881119,0.7154719245433807,mmlu:college_mathematics,test,38.24030075967312
22,0.3181818127632141,0.3181818127632141,0.4666666666666667,0.5573708252473311,mmlu:college_medicine,validation,7.8663320653140545
173,0.2947976887226105,0.2947976887226105,0.576342012214722,0.534065297573288,mmlu:college_medicine,test,80.77355546504259
11,0.09090909361839294,0.1818181872367859,0.9500000000000001,0.7708822163668545,mmlu:college_physics,validation,5.679040249437094
102,0.0882352963089943,0.0882352963089943,0.5633213859020311,0.8320761340505937,mmlu:college_physics,test,37.527690675109625
11,0.6363636255264282,0.6363636255264282,0.875,0.2979439226063815,mmlu:computer_security,validation,6.591649662703276
100,0.5,0.5099999904632568,0.5444,0.4578067177534103,mmlu:computer_security,test,44.50591404363513
26,0.1538461595773697,0.1538461595773697,0.5909090909090909,0.7787055166868063,mmlu:conceptual_physics,validation,13.683319881558418
235,0.3787233829498291,0.3787233829498291,0.48137601970140065,0.5515974699182713,mmlu:conceptual_physics,test,104.20612038299441
12,0.3333333432674408,0.5833333730697632,0.65625,0.4068325807650884,mmlu:econometrics,validation,6.6655632592737675
114,0.17543859779834747,0.41228070855140686,0.6202127659574469,0.35534130742675385,mmlu:econometrics,test,62.30721214413643
16,0.1875,0.25,0.5,0.5980917550623417,mmlu:electrical_engineering,validation,4.722016770392656
145,0.2137930989265442,0.20689654350280762,0.43873797396717595,0.670236546828829,mmlu:electrical_engineering,test,62.105624325573444
41,0.3658536374568939,0.3658536374568939,0.45,0.5680874905935147,mmlu:elementary_mathematics,validation,12.672131534665823
378,0.28042328357696533,0.28042328357696533,0.5644076026637069,0.6594757253215426,mmlu:elementary_mathematics,test,181.88150273635983
14,0.4285714626312256,0.4285714626312256,0.5,0.5012392614568982,mmlu:formal_logic,validation,8.576937429606915
126,0.2539682686328888,0.2539682686328888,0.3439162234042553,0.5829142795668708,mmlu:formal_logic,test,61.96698387339711
10,0.20000000298023224,0.20000000298023224,0.4375,0.6995142221450805,mmlu:global_facts,validation,5.581412684172392
100,0.07999999821186066,0.07999999821186066,0.6039402173913043,0.8283838444948196,mmlu:global_facts,test,45.10437202826142
32,0.3125,0.3125,0.42954545454545456,0.6321859676390886,mmlu:high_school_biology,validation,14.684948984533548
310,0.3838709592819214,0.3870967626571655,0.511659113907343,0.5464931488037109,mmlu:high_school_biology,test,136.5357569977641
22,0.1818181872367859,0.1818181872367859,0.45833333333333337,0.7432265227491206,mmlu:high_school_chemistry,validation,9.383990731090307
203,0.1428571343421936,0.1428571343421936,0.5661910424098295,0.7674282516164732,mmlu:high_school_chemistry,test,82.3534677401185
9,0.4444444477558136,0.4444444477558136,0.85,0.4547849827342564,mmlu:high_school_computer_science,validation,5.956909988075495
100,0.4099999964237213,0.4099999964237213,0.49627945431996695,0.5000227105617523,mmlu:high_school_computer_science,test,62.031220346689224
22,0.4545454680919647,0.4545454680919647,0.42083333333333334,0.4708936756307429,mmlu:high_school_geography,validation,11.214613754302263
198,0.3737373650074005,0.3737373650074005,0.634590235396687,0.5350587587765974,mmlu:high_school_geography,test,85.94740756228566
21,0.523809552192688,0.523809552192688,0.37272727272727274,0.43376287676039194,mmlu:high_school_government_and_politics,validation,10.629395831376314
193,0.5233160257339478,0.5233160257339478,0.5799074472664659,0.4274797970766848,mmlu:high_school_government_and_politics,test,92.84116667881608
43,0.39534884691238403,0.39534884691238403,0.3744343891402715,0.5259778735249542,mmlu:high_school_macroeconomics,validation,21.099247097969055
390,0.2897436022758484,0.29487180709838867,0.4913581035749657,0.5857740564224048,mmlu:high_school_macroeconomics,test,175.03684467822313
29,0.0,0.0,,0.9089648004235893,mmlu:high_school_mathematics,validation,7.685228563845158
270,0.0555555559694767,0.0555555559694767,0.44352941176470584,0.8655684894985624,mmlu:high_school_mathematics,test,74.8715835697949
26,0.26923078298568726,0.26923078298568726,0.4210526315789474,0.678927013507256,mmlu:high_school_microeconomics,validation,10.735992655158043
238,0.3403361439704895,0.3403361439704895,0.5644412990485177,0.5936537354934115,mmlu:high_school_microeconomics,test,96.57363102957606
17,0.0,0.0,,0.9790476560592651,mmlu:high_school_physics,validation,8.426166404038668
151,0.18543046712875366,0.18543046712875366,0.59465737514518,0.7915617661760344,mmlu:high_school_physics,test,60.08006926998496
60,0.5666667222976685,0.5666667222976685,0.5294117647058824,0.38091325958569844,mmlu:high_school_psychology,validation,24.64184693619609
545,0.5009174346923828,0.5009174346923828,0.5229476405946993,0.44677909208000255,mmlu:high_school_psychology,test,251.3699131757021
23,0.17391304671764374,0.17391304671764374,0.4078947368421053,0.7709273359049921,mmlu:high_school_statistics,validation,10.206964679062366
216,0.19907407462596893,0.20370370149612427,0.49106062642828335,0.7433281386340105,mmlu:high_school_statistics,test,118.10513431206346
23,0.30434784293174744,0.30434784293174744,0.6473214285714286,0.6585948933725772,mmlu:human_aging,validation,9.312280721962452
223,0.33183857798576355,0.33183857798576355,0.5547796118265917,0.6278294370313398,mmlu:human_aging,test,92.85704124346375
12,0.25,0.25,0.3888888888888889,0.6816994448502859,mmlu:human_sexuality,validation,6.867937821894884
131,0.4198473393917084,0.42748090624809265,0.5151913875598086,0.5123686917865549,mmlu:human_sexuality,test,55.321057103574276
13,0.46153849363327026,0.46153849363327026,0.40476190476190477,0.4043323351786687,mmlu:international_law,validation,5.252871617674828
121,0.6115702390670776,0.6115702390670776,0.599051178838413,0.2840597880773308,mmlu:international_law,test,49.981692265719175
11,0.5454545617103577,0.5454545617103577,0.6,0.3435247215357694,mmlu:jurisprudence,validation,5.788504473865032
108,0.5185185074806213,0.5185185074806213,0.4012706043956044,0.393323626783159,mmlu:jurisprudence,test,50.57904013246298
18,0.4444444477558136,0.4444444477558136,0.7374999999999999,0.514215373330646,mmlu:logical_fallacies,validation,8.113011330366135
163,0.42944782972335815,0.42944782972335815,0.4809523809523809,0.5298993700852423,mmlu:logical_fallacies,test,67.35576360300183
11,0.3636363744735718,0.3636363744735718,0.6071428571428572,0.5120163343169473,mmlu:machine_learning,validation,7.301212828606367
112,0.196428582072258,0.2142857313156128,0.5588383838383838,0.5923484755413873,mmlu:machine_learning,test,46.42588860914111
11,0.27272728085517883,0.27272728085517883,0.75,0.666755437850952,mmlu:management,validation,6.9064670614898205
103,0.3689320385456085,0.3689320385456085,0.5234817813765182,0.5781449525101671,mmlu:management,test,44.11229371279478
25,0.19999998807907104,0.19999998807907104,0.455,0.7745921039581298,mmlu:marketing,validation,11.685741398483515
234,0.39743590354919434,0.39743590354919434,0.5732860520094564,0.5789353541838818,mmlu:marketing,test,106.81824041157961
11,0.7272727489471436,0.7272727489471436,0.2916666666666667,0.22767528078772803,mmlu:medical_genetics,validation,6.60783277079463
100,0.4099999964237213,0.4099999964237213,0.5584952459694088,0.5339927440881729,mmlu:medical_genetics,test,44.52280727401376
38,0.4736842215061188,0.4736842215061188,0.5180555555555555,0.4040317551085823,mmlu:moral_disputes,validation,18.09419099614024
346,0.41040462255477905,0.41040462255477905,0.5288766915216792,0.4698403746406467,mmlu:moral_disputes,test,156.0692782215774
33,0.3636363744735718,0.3333333432674408,0.5019841269841271,0.46804981881921937,mmlu:nutrition,validation,17.408214312046766
306,0.4084967374801636,0.4313725531101227,0.5821436464088399,0.3386558886446984,mmlu:nutrition,test,137.11990494653583
34,0.3529411852359772,0.3529411852359772,0.6287878787878789,0.6060798922005822,mmlu:philosophy,validation,15.223536122590303
311,0.3376205861568451,0.3376205861568451,0.5198335644937587,0.6273742078584875,mmlu:philosophy,test,137.43121495842934
35,0.2857142984867096,0.2857142984867096,0.598,0.6782805783408029,mmlu:prehistory,validation,18.452366940677166
324,0.34259259700775146,0.34259259700775146,0.5435223956350718,0.6265312144417822,mmlu:prehistory,test,146.67867498472333
69,0.37681159377098083,0.37681159377098083,0.490608228980322,0.5352000931034917,mmlu:professional_psychology,validation,34.61790166050196
612,0.32189542055130005,0.32189542055130005,0.485383156993456,0.5903544476608825,mmlu:professional_psychology,test,281.7850212305784
12,0.3333333432674408,0.3333333432674408,0.25,0.6372331877549489,mmlu:public_relations,validation,5.393037110567093
110,0.3272727131843567,0.34545454382896423,0.5219594594594594,0.6185719809748909,mmlu:public_relations,test,32.043740682303905
27,0.7407407760620117,0.7407407760620117,0.6678571428571429,0.17919801561920734,mmlu:security_studies,validation,14.458599235862494
245,0.6816326379776001,0.6816326379776001,0.6371487793643481,0.234903917993818,mmlu:security_studies,test,122.83779592439532
22,0.5,0.5,0.49586776859504134,0.4565216302871704,mmlu:sociology,validation,11.04921057075262
201,0.45771142840385437,0.45771142840385437,0.6214599122457121,0.5018816391626995,mmlu:sociology,test,88.84100665524602
11,0.5454545617103577,0.5454545617103577,0.7166666666666667,0.40187247232957324,mmlu:us_foreign_policy,validation,4.98469428345561
100,0.550000011920929,0.5600000023841858,0.6345454545454545,0.39253113329410555,mmlu:us_foreign_policy,test,32.78472903370857
18,0.2777777910232544,0.2777777910232544,0.5076923076923077,0.6398649480607774,mmlu:virology,validation,8.592737101018429
166,0.34337347745895386,0.34337347745895386,0.6093674553355867,0.6045643726745284,mmlu:virology,test,74.60240780934691
19,0.6315789222717285,0.6315789222717285,0.8095238095238095,0.3458864437906366,mmlu:world_religions,validation,6.718189623206854
171,0.5380116701126099,0.5380116701126099,0.6114474408365437,0.4404522173585947,mmlu:world_religions,test,59.761725928634405
