N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.6363636255264282,0.3636363744735718,0.3392857142857143,0.5693891752849926,mmlu:us_foreign_policy,validation,36.48709230707027
100,0.6100000143051147,0.38999998569488525,0.419714165615805,0.5328840047121048,mmlu:us_foreign_policy,test,295.8166036379989
23,0.260869562625885,0.739130437374115,0.7205882352941176,0.11306216664936233,mmlu:human_aging,validation,65.12695631291717
223,0.3363228738307953,0.6636771559715271,0.5024324324324324,0.05304007866992007,mmlu:human_aging,test,741.7187538072467
26,0.3076923191547394,0.692307710647583,0.3680555555555555,0.05391369416163522,mmlu:conceptual_physics,validation,75.71338595077395
235,0.42553189396858215,0.5744680762290955,0.5787777777777777,0.15770346281376288,mmlu:conceptual_physics,test,681.9571174178272
100,0.2800000011920929,0.7199999690055847,0.4494047619047619,0.07676190316677092,mmlu:moral_scenarios,validation,399.87892671488225
895,0.29832401871681213,0.7016759514808655,0.49166547389012144,0.057850221482069086,mmlu:moral_scenarios,test,3493.7790426164865
22,0.4545454680919647,0.5454545617103577,0.4083333333333333,0.2676562314683741,mmlu:high_school_geography,validation,67.7445306070149
198,0.39898988604545593,0.6010100841522217,0.40330815870652054,0.1948280171914534,mmlu:high_school_geography,test,605.0352153815329
32,0.21875,0.78125,0.6428571428571428,0.11820138804614544,mmlu:high_school_biology,validation,89.97664587199688
310,0.4354838728904724,0.5645161271095276,0.5446560846560846,0.1811544906708502,mmlu:high_school_biology,test,842.2379851825535
11,0.09090909361839294,0.9090909361839294,0.19999999999999996,0.26812939752231946,mmlu:college_mathematics,validation,37.658941462635994
100,0.1599999964237213,0.8100000023841858,0.39992559523809523,0.1647629350423813,mmlu:college_mathematics,test,301.0166458915919
11,0.5454545617103577,0.4545454680919647,0.31666666666666665,0.3776798790151423,mmlu:management,validation,44.317586459219456
103,0.42718446254730225,0.5728155374526978,0.4895993836671803,0.26134047693419227,mmlu:management,test,406.04627856984735
29,0.06896551698446274,0.8965517282485962,0.6574074074074074,0.23634572070220425,mmlu:high_school_mathematics,validation,93.12993591837585
270,0.07777777314186096,0.9148147702217102,0.4513291260279212,0.26876844807907396,mmlu:high_school_mathematics,test,852.49565112032
19,0.7368420958518982,0.2631579041481018,0.44285714285714284,0.499741930710642,mmlu:world_religions,validation,57.132449756376445
171,0.584795355796814,0.4152046740055084,0.4662676056338028,0.33581803172652486,mmlu:world_religions,test,503.8042269172147
11,0.7272727489471436,0.27272728085517883,0.5625,0.5415897369384766,mmlu:medical_genetics,validation,34.564266823232174
100,0.4699999988079071,0.5299999713897705,0.4173022882376556,0.28283527612686155,mmlu:medical_genetics,test,286.3787103574723
26,0.3076923191547394,0.692307710647583,0.4652777777777778,0.11272352704635039,mmlu:high_school_microeconomics,validation,78.16062287520617
238,0.3613445460796356,0.6386554837226868,0.5289550183598531,0.1572130400092662,mmlu:high_school_microeconomics,test,725.3867486650124
11,0.6363636255264282,0.27272728085517883,0.8571428571428571,0.39729354598305444,mmlu:business_ethics,validation,35.18341973423958
100,0.3100000023841858,0.5199999809265137,0.5995792426367461,0.07121689558029175,mmlu:business_ethics,test,293.8835230190307
18,0.4444444477558136,0.5555555820465088,0.69375,0.19609501295619544,mmlu:logical_fallacies,validation,51.95570205338299
163,0.43558281660079956,0.5644171833992004,0.5214329454990814,0.17650989630470978,mmlu:logical_fallacies,test,448.85448264330626
16,0.375,0.625,0.475,0.2802877426147461,mmlu:astronomy,validation,52.80503973807208
152,0.44736841320991516,0.5526315569877625,0.41500350140056025,0.2885792176974447,mmlu:astronomy,test,455.880366376834
38,0.3947368562221527,0.6052631735801697,0.5405797101449276,0.214506734358637,mmlu:moral_disputes,validation,117.50416511110961
346,0.3786126971244812,0.621387243270874,0.4647789810047932,0.18439256903753112,mmlu:moral_disputes,test,1033.3837542627007
31,0.4516128897666931,0.5483870506286621,0.5252100840336135,0.15530372050500682,mmlu:professional_medicine,validation,101.53155546449125
272,0.35661765933036804,0.6433823704719543,0.46833578792341674,0.061234225245083054,mmlu:professional_medicine,test,825.6719277929515
60,0.4833333492279053,0.5166667103767395,0.38932146829810904,0.24140050013860068,mmlu:high_school_psychology,validation,189.3857375299558
545,0.5100917220115662,0.48990824818611145,0.47321693207231963,0.27397500145325965,mmlu:high_school_psychology,test,1653.6825103526935
14,0.4285714626312256,0.5714285969734192,0.40624999999999994,0.09130756344114033,mmlu:formal_logic,validation,40.315650541335344
126,0.2698412835597992,0.7301587462425232,0.5676150895140664,0.11430457092466807,mmlu:formal_logic,test,344.62646047212183
22,0.5909091234207153,0.40909093618392944,0.38888888888888895,0.44796104322780267,mmlu:high_school_us_history,validation,77.09976059105247
204,0.5833333730697632,0.4166666865348816,0.4734552644587247,0.44696609646666285,mmlu:high_school_us_history,test,705.6932821040973
12,0.0,1.0,,0.2804209142923355,mmlu:econometrics,validation,36.69881219789386
114,0.1315789520740509,0.859649121761322,0.5212121212121212,0.1054013643348426,mmlu:econometrics,test,331.54061950556934
14,0.2142857313156128,0.785714328289032,0.7272727272727273,0.16489172833306454,mmlu:anatomy,validation,41.67982403188944
135,0.4296296238899231,0.5703703761100769,0.5348186296462158,0.24328302498216983,mmlu:anatomy,test,365.5153444670141
29,0.27586206793785095,0.7241379022598267,0.4821428571428572,0.12278125409422251,mmlu:clinical_knowledge,validation,88.72213499806821
265,0.350943386554718,0.649056613445282,0.4871842960740184,0.19161867533089982,mmlu:clinical_knowledge,test,909.3896626289934
22,0.5,0.5,0.4380165289256198,0.3606109023094177,mmlu:sociology,validation,86.76279570162296
201,0.39303481578826904,0.606965184211731,0.46088400083004777,0.23846719899580845,mmlu:sociology,test,787.7098403312266
16,0.1875,0.8125,0.9743589743589743,0.14409681409597394,mmlu:electrical_engineering,validation,50.38139746431261
145,0.2344827651977539,0.7655172348022461,0.5515368309485956,0.07330460671720836,mmlu:electrical_engineering,test,456.1864340752363
27,0.5555555820465088,0.4444444477558136,0.4111111111111111,0.4340448224986041,mmlu:security_studies,validation,78.82227111980319
245,0.5510203838348389,0.44897958636283875,0.4763299663299664,0.4205084233867879,mmlu:security_studies,test,708.1828444954008
11,0.27272728085517883,0.7272727489471436,0.41666666666666663,0.07214224338531493,mmlu:college_physics,validation,33.67942217178643
102,0.14705882966518402,0.8529412150382996,0.5766283524904214,0.12358104364544735,mmlu:college_physics,test,293.5858047641814
170,0.4000000059604645,0.6000000238418579,0.4816176470588236,0.3232610520194559,mmlu:professional_law,validation,513.2873861859844
1534,0.36245110630989075,0.6375488638877869,0.4924002515778788,0.2840426483785313,mmlu:professional_law,test,4844.799522345973
17,0.23529411852359772,0.5882353186607361,0.6634615384615384,0.19131373307284186,mmlu:high_school_physics,validation,54.097583347931504
151,0.17218543589115143,0.6092715263366699,0.40153846153846157,0.09052284782295986,mmlu:high_school_physics,test,449.1671140752733
22,0.09090909361839294,0.8636363744735718,0.3125,0.294984370470047,mmlu:high_school_chemistry,validation,67.68353065196425
203,0.15763546526432037,0.842364490032196,0.5276864035087719,0.20014240912028722,mmlu:high_school_chemistry,test,604.8206357695162
43,0.5116279125213623,0.4883720874786377,0.47510822510822515,0.3056706065355346,mmlu:high_school_macroeconomics,validation,124.88024737499654
390,0.31794872879981995,0.6820513010025024,0.4861144797477565,0.1181088808255318,mmlu:high_school_macroeconomics,test,1120.414692942053
31,0.12903225421905518,0.8709677457809448,0.6342592592592592,0.10295353974065476,mmlu:professional_accounting,validation,94.39754484966397
282,0.1560283601284027,0.8439716100692749,0.4991883116883116,0.038201487233452784,mmlu:professional_accounting,test,974.6108977161348
11,0.1818181872367859,0.8181818723678589,0.8333333333333334,0.28637411377646704,mmlu:abstract_algebra,validation,33.54805827513337
100,0.22999998927116394,0.7699999809265137,0.43026538678712595,0.09250986754894257,mmlu:abstract_algebra,test,285.1784870605916
12,0.4166666865348816,0.5833333730697632,0.27142857142857146,0.31861935059229535,mmlu:public_relations,validation,36.268448473885655
110,0.29999998211860657,0.699999988079071,0.5777253049980323,0.18360115668990393,mmlu:public_relations,test,305.93535099737346
41,0.24390242993831635,0.7560975551605225,0.3806451612903226,0.10165261931535678,mmlu:elementary_mathematics,validation,143.54407432302833
378,0.31481480598449707,0.6851851940155029,0.5228577917653549,0.04878359638824667,mmlu:elementary_mathematics,test,1135.7993890701327
11,0.3636363744735718,0.5454545617103577,0.41071428571428575,0.14382774721492422,mmlu:computer_security,validation,35.7496467041783
100,0.4099999964237213,0.5899999737739563,0.3648201736254651,0.12371122539043425,mmlu:computer_security,test,295.2689997900743
23,0.17391304671764374,0.739130437374115,0.3092105263157895,0.1621033963949784,mmlu:high_school_statistics,validation,65.14264675788581
216,0.23148147761821747,0.7361111044883728,0.5674096385542168,0.14031409113495436,mmlu:high_school_statistics,test,595.6245067436248
12,0.4166666865348816,0.5833333730697632,0.5857142857142857,0.25212786595026654,mmlu:human_sexuality,validation,48.615301825106144
131,0.47328245639801025,0.5267175436019897,0.5257129499766245,0.2339674311739798,mmlu:human_sexuality,test,510.2757943943143
18,0.6111111044883728,0.3888888955116272,0.5454545454545454,0.384458045164744,mmlu:high_school_european_history,validation,65.18086965568364
165,0.6545454263687134,0.34545454382896423,0.4939083820662768,0.4293729178833239,mmlu:high_school_european_history,test,568.4801832921803
16,0.3125,0.75,0.23636363636363636,0.25367508083581924,mmlu:college_biology,validation,47.06129562854767
144,0.3194444477558136,0.6805555820465088,0.501552795031056,0.07214799109432429,mmlu:college_biology,test,403.14600662887096
10,0.30000001192092896,0.699999988079071,0.7380952380952381,0.2328922331333161,mmlu:global_facts,validation,31.39077138993889
100,0.17000000178813934,0.8299999833106995,0.45322466335931966,0.11799228429794308,mmlu:global_facts,test,295.55521130375564
21,0.3333333432674408,0.6666666865348816,0.5561224489795918,0.21338865019026254,mmlu:high_school_government_and_politics,validation,62.25512466952205
193,0.5077720284461975,0.4922279715538025,0.4590762620837809,0.3895591942139858,mmlu:high_school_government_and_politics,test,568.687206113711
9,0.3333333432674408,0.6666666865348816,0.3888888888888889,0.17865785625245836,mmlu:high_school_computer_science,validation,29.448221844621003
100,0.3999999761581421,0.5999999642372131,0.5070833333333333,0.22961799025535584,mmlu:high_school_computer_science,test,297.38160925731063
34,0.3529411852359772,0.6470588445663452,0.42045454545454547,0.09829302921014671,mmlu:philosophy,validation,133.18423600494862
311,0.3344051241874695,0.6623793840408325,0.5392047565960609,0.06499627567947486,mmlu:philosophy,test,1221.0701549686491
11,0.27272728085517883,0.7272727489471436,0.5416666666666666,0.18218636512756348,mmlu:machine_learning,validation,45.25835792720318
112,0.2053571492433548,0.7946428656578064,0.6424035173424523,0.13649222254753116,mmlu:machine_learning,test,447.6002213284373
33,0.39393940567970276,0.6060606241226196,0.6711538461538462,0.17317649089928827,mmlu:nutrition,validation,95.55774415656924
306,0.3758170008659363,0.6241829991340637,0.4987480081948554,0.15709266982047385,mmlu:nutrition,test,857.1798066720366
18,0.5,0.5,0.6666666666666667,0.3353884319464366,mmlu:virology,validation,70.83902298100293
166,0.35542166233062744,0.6445782780647278,0.5687470299382228,0.1787976626172123,mmlu:virology,test,649.6508460342884
8,0.125,0.875,0.2857142857142857,0.1744486689567566,mmlu:college_chemistry,validation,25.091478776186705
100,0.12999999523162842,0.8700000047683716,0.4858532272325376,0.14837614059448245,mmlu:college_chemistry,test,290.80055546574295
25,0.2800000011920929,0.7199999690055847,0.6547619047619048,0.16494880914688115,mmlu:marketing,validation,97.54049745947123
234,0.4572649896144867,0.5427350401878357,0.4848038854956214,0.2950570764195205,mmlu:marketing,test,909.9668427780271
69,0.37681159377098083,0.6231884360313416,0.5304114490161003,0.18271352242732394,mmlu:professional_psychology,validation,185.55766395106912
612,0.30718955397605896,0.6928104758262634,0.49661280610196706,0.10189735178464378,mmlu:professional_psychology,test,1649.019168984145
35,0.2857142984867096,0.7142857313156128,0.528,0.13381265572139198,mmlu:prehistory,validation,138.43016562238336
324,0.4135802388191223,0.5864197611808777,0.5406520031421838,0.25810883148216907,mmlu:prehistory,test,1264.0748782232404
11,0.09090909361839294,0.9090909361839294,0.8,0.2645142349329862,mmlu:college_computer_science,validation,35.33402349008247
100,0.17000000178813934,0.7899999618530273,0.5542168674698795,0.17090861320495612,mmlu:college_computer_science,test,302.18585742404684
86,0.5348837375640869,0.45348837971687317,0.3948369565217391,0.18074038278224858,mmlu:miscellaneous,validation,342.005207285285
783,0.578544020652771,0.418901652097702,0.41320489664860527,0.21814090866086433,mmlu:miscellaneous,test,3104.332199972123
26,0.5,0.5,0.4112426035502959,0.23973939281243545,mmlu:high_school_world_history,validation,95.8300591300067
237,0.48101264238357544,0.5189872980117798,0.5415062045357296,0.2314248364182967,mmlu:high_school_world_history,test,832.5698487480113
11,0.3636363744735718,0.6363636255264282,0.3571428571428572,0.24862143668261444,mmlu:jurisprudence,validation,45.69149228557944
108,0.35185185074806213,0.6481481790542603,0.5022556390977444,0.21572125013227814,mmlu:jurisprudence,test,418.2107948847115
13,0.23076924681663513,0.7692307829856873,0.4666666666666667,0.057906347971696116,mmlu:international_law,validation,44.18714376538992
121,0.46280989050865173,0.5371900796890259,0.38337912087912085,0.2709590615319811,mmlu:international_law,test,372.31203682534397
22,0.3636363744735718,0.6363636255264282,0.4375,0.22327144037593494,mmlu:college_medicine,validation,66.5826788879931
173,0.35260114073753357,0.6416184902191162,0.5409836065573771,0.2035008152096257,mmlu:college_medicine,test,519.5506712067872
