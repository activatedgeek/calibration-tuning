N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.020454368808052736,0.27272728085517883,0.7272727489471436,0.5,0.2642034454779192,mmlu:abstract_algebra,validation,5.67473282199353
100,0.02814638584852219,0.29999998211860657,0.7299999594688416,0.4488095238095239,0.1748162615299225,mmlu:abstract_algebra,test,43.15368374297395
14,0.23522004272256578,0.4285714626312256,0.6428571939468384,0.375,0.2248993899141039,mmlu:anatomy,validation,6.7739879549480975
135,0.10418175017392191,0.5259259343147278,0.6370370388031006,0.3665272887323943,0.13866200402930928,mmlu:anatomy,test,60.95972556807101
16,0.2370399609208107,0.625,0.6875,0.18333333333333332,0.18302703648805618,mmlu:astronomy,validation,10.152362826978788
152,0.11185478419065475,0.5197368264198303,0.6184210777282715,0.5,0.1810930371284485,mmlu:astronomy,test,95.54567349888384
11,0.27402270382100885,0.3636363744735718,0.8181818723678589,0.6607142857142857,0.16631927273490213,mmlu:business_ethics,validation,6.793804017128423
100,0.08373758316040039,0.5299999713897705,0.7299999594688416,0.40967482938578886,0.057816282510757426,mmlu:business_ethics,test,61.71368913888
29,0.14254401058986269,0.5862069129943848,0.48275861144065857,0.6495098039215685,0.3202601445132288,mmlu:clinical_knowledge,validation,14.927545913029462
265,0.04184016101765183,0.6000000238418579,0.701886773109436,0.46935445591550967,0.08622722468286187,mmlu:clinical_knowledge,test,135.1244769981131
16,0.17430640012025833,0.5,0.625,0.40625,0.10523738339543341,mmlu:college_biology,validation,8.834977876162156
144,0.0555728864338663,0.5625,0.6527777910232544,0.443758573388203,0.08223221161299282,mmlu:college_biology,test,78.77665856317617
8,0.4137810505926609,0.625,0.375,0.8666666666666667,0.47193455696105957,mmlu:college_chemistry,validation,4.801979617914185
100,0.08861296325922012,0.44999998807907104,0.6499999761581421,0.4563636363636364,0.224388182759285,mmlu:college_chemistry,test,58.02340793097392
11,0.14435522664677014,0.5454545617103577,0.4545454680919647,0.5666666666666667,0.38156679543581873,mmlu:college_computer_science,validation,8.380320962052792
100,0.09748851984739304,0.4399999976158142,0.5999999642372131,0.46002435064935066,0.2372889471054077,mmlu:college_computer_science,test,76.06299415393732
11,0.05229922316291114,0.27272728085517883,0.6363636255264282,0.25,0.20684380422938953,mmlu:college_mathematics,validation,6.747870231978595
100,0.0662127861380577,0.29999998211860657,0.6699999570846558,0.5204761904761905,0.16693680047988893,mmlu:college_mathematics,test,59.65354218194261
22,0.14157267727635126,0.5909091234207153,0.7272727489471436,0.26495726495726496,0.1542274708097631,mmlu:college_medicine,validation,12.426563166081905
173,0.07063847935268644,0.5491329431533813,0.5838150382041931,0.5097165991902833,0.1887347274432982,mmlu:college_medicine,test,100.30915007204749
11,0.13204363530332391,0.5454545617103577,0.5454545617103577,0.36666666666666664,0.24251845749941742,mmlu:college_physics,validation,6.243854085216299
102,0.16193334553755964,0.2549019753932953,0.6960784792900085,0.4845647773279352,0.11468673921098899,mmlu:college_physics,test,55.89042325108312
11,0.316260505806316,0.8181818723678589,0.5454545617103577,0.75,0.31768398935144593,mmlu:computer_security,validation,5.7956992068793625
100,0.0524847185611725,0.7099999785423279,0.7599999904632568,0.6291889266634288,0.10485516548156737,mmlu:computer_security,test,46.716942340135574
26,0.16535433668356678,0.42307692766189575,0.5769230723381042,0.3666666666666667,0.22273245912331802,mmlu:conceptual_physics,validation,10.151707447133958
235,0.1055033838495295,0.40425530076026917,0.6510637998580933,0.43353383458646616,0.16091215914868295,mmlu:conceptual_physics,test,89.59776811511256
12,0.08985197544097902,0.3333333432674408,0.75,0.53125,0.1277689089377721,mmlu:econometrics,validation,7.5631199611816555
114,0.14770011316265977,0.2631579041481018,0.6754385828971863,0.38750000000000007,0.11338546924423752,mmlu:econometrics,test,71.33717533294111
16,0.17423784360289574,0.3125,0.75,0.5818181818181818,0.21677082404494286,mmlu:electrical_engineering,validation,8.421338228043169
145,0.08578206074648889,0.45517241954803467,0.6068965196609497,0.3855005753739931,0.1729586227186795,mmlu:electrical_engineering,test,74.32725252886303
41,0.12378357605236331,0.39024388790130615,0.6829267740249634,0.44625,0.2222235856986627,mmlu:elementary_mathematics,validation,23.76598267816007
378,0.07046122754377032,0.3253968060016632,0.6507936120033264,0.5197353738243266,0.14754761621434853,mmlu:elementary_mathematics,test,215.72856490011327
14,0.060698868972914544,0.2857142984867096,0.6428571939468384,0.2875,0.2197563605649131,mmlu:formal_logic,validation,9.104014495154843
126,0.05406149677814,0.3809524178504944,0.5634921193122864,0.4262820512820513,0.15334858118541655,mmlu:formal_logic,test,78.77514487900771
10,0.24575822651386262,0.5,0.699999988079071,0.6599999999999999,0.25336328148841863,mmlu:global_facts,validation,5.283624171977863
100,0.06567679733037948,0.3499999940395355,0.6599999666213989,0.43296703296703304,0.1901689112186432,mmlu:global_facts,test,51.0732826939784
32,0.183054325170815,0.53125,0.6875,0.49607843137254903,0.1867030616849661,mmlu:high_school_biology,validation,18.419327612034976
310,0.056588047262161024,0.6645160913467407,0.699999988079071,0.4539068334578043,0.11809995135953347,mmlu:high_school_biology,test,177.04044430609792
22,0.1478794542225925,0.3181818127632141,0.7272727489471436,0.4857142857142857,0.3243048489093781,mmlu:high_school_chemistry,validation,12.456971910083666
203,0.05498649011104565,0.4729064106941223,0.5615763664245605,0.5046242211838007,0.24805092253708488,mmlu:high_school_chemistry,test,112.60077091306448
9,0.1722969247235192,0.6666666865348816,0.8888888955116272,0.5,0.11432101991441512,mmlu:high_school_computer_science,validation,7.571923868032172
100,0.11656764656305313,0.5600000023841858,0.699999988079071,0.40685876623376627,0.0874899059534073,mmlu:high_school_computer_science,test,84.08447499712929
22,0.12113347920504486,0.7272727489471436,0.7727273106575012,0.4322916666666667,0.07157544656233353,mmlu:high_school_geography,validation,11.10079815518111
198,0.07095408906238249,0.7222222089767456,0.6464646458625793,0.4772409408773045,0.15942965824194633,mmlu:high_school_geography,test,98.4986361511983
21,0.18720501377469018,0.7142857313156128,0.8571428656578064,0.9333333333333333,0.09237509398233322,mmlu:high_school_government_and_politics,validation,11.386988829821348
193,0.07135360861689315,0.8341968655586243,0.8082901239395142,0.7480590062111803,0.07391215884006087,mmlu:high_school_government_and_politics,test,103.34669287502766
43,0.11051061610842859,0.5348837375640869,0.604651153087616,0.576086956521739,0.20152123584303747,mmlu:high_school_macroeconomics,validation,21.452315832022578
390,0.06800052661162158,0.5487179756164551,0.5974358916282654,0.5732795242141037,0.16834451739604653,mmlu:high_school_macroeconomics,test,194.63879029382952
29,0.07622800716038407,0.24137930572032928,0.7931034564971924,0.29220779220779214,0.08721896697734965,mmlu:high_school_mathematics,validation,16.379885361995548
270,0.0742746145636947,0.2481481432914734,0.7333333492279053,0.4477611940298508,0.11133771914022941,mmlu:high_school_mathematics,test,151.28017749194987
26,0.16030863156685463,0.6153846383094788,0.5769230723381042,0.53125,0.1844237309235793,mmlu:high_school_microeconomics,validation,13.188543650088832
238,0.08985476058070402,0.5924370288848877,0.6092437505722046,0.5116253564378154,0.15797912949273568,mmlu:high_school_microeconomics,test,118.89471908216365
17,0.21806448522736044,0.23529411852359772,0.5882353186607361,0.40384615384615385,0.4384614334386938,mmlu:high_school_physics,validation,10.061038207029924
151,0.06010663884365007,0.3907284736633301,0.6092715263366699,0.5297531319086219,0.2066744187020308,mmlu:high_school_physics,test,87.65670200809836
60,0.08489794433116914,0.8166667222976685,0.9166666865348816,0.5009276437847866,0.05538249413172404,mmlu:high_school_psychology,validation,33.99352640612051
545,0.05301170928762592,0.7688073515892029,0.7816513776779175,0.6245311967269007,0.06826806932414343,mmlu:high_school_psychology,test,308.24859066004865
23,0.2082076798314634,0.43478262424468994,0.695652186870575,0.6153846153846154,0.20831978580226068,mmlu:high_school_statistics,validation,17.358830753946677
216,0.05403580958092653,0.45370370149612427,0.6018518805503845,0.46709616049809755,0.20212449768075239,mmlu:high_school_statistics,test,166.54682610416785
22,0.17092653567140753,0.7727273106575012,0.6818181872367859,0.5941176470588235,0.24995610117912295,mmlu:high_school_us_history,validation,42.128981256857514
204,0.06210238647227194,0.7598039507865906,0.779411792755127,0.645687952600395,0.07044922633498324,mmlu:high_school_us_history,test,393.8186554911081
23,0.277157108420911,0.5652173757553101,0.739130437374115,0.6076923076923076,0.24334001541137698,mmlu:human_aging,validation,9.042227564845234
223,0.06303087839096652,0.6098654866218567,0.7130045294761658,0.4603617308992562,0.07125810122810672,mmlu:human_aging,test,86.6545966998674
12,0.2232336774468422,0.5,0.5833333730697632,0.7777777777777779,0.3029340356588364,mmlu:human_sexuality,validation,5.240236774086952
131,0.08028131063657863,0.6183205842971802,0.6335877776145935,0.47555555555555556,0.17373325033042264,mmlu:human_sexuality,test,56.81082316697575
13,0.1884430990769313,0.7692307829856873,0.8461538553237915,0.33333333333333337,0.10054232523991508,mmlu:international_law,validation,8.568746128119528
121,0.07355331315481958,0.7355371713638306,0.8099173307418823,0.569873595505618,0.040557563304901144,mmlu:international_law,test,79.11787947104312
11,0.225065984509208,0.4545454680919647,0.9090909361839294,0.3333333333333333,0.21179890090768988,mmlu:jurisprudence,validation,5.694554286077619
108,0.10316727144850626,0.7037037014961243,0.7129629850387573,0.5359786184210527,0.06128873096572026,mmlu:jurisprudence,test,53.8307815680746
18,0.2209937125444412,0.7777777910232544,0.7222222089767456,0.7321428571428572,0.22560489177703857,mmlu:logical_fallacies,validation,9.49774175696075
163,0.030425915505988475,0.6564416885375977,0.699386477470398,0.5569926568758344,0.12409327988244273,mmlu:logical_fallacies,test,85.15467214398086
11,0.19092808799310163,0.4545454680919647,0.6363636255264282,0.6,0.19387190992181952,mmlu:machine_learning,validation,7.443088284926489
112,0.18320334303591934,0.2232142984867096,0.7500000596046448,0.4342528735632184,0.07314837138567654,mmlu:machine_learning,test,74.15736870490946
11,0.14025694944641806,0.7272727489471436,0.4545454680919647,0.5833333333333334,0.34891229867935175,mmlu:management,validation,4.33562515093945
103,0.1099159769641543,0.7766990661621094,0.6893203854560852,0.5627717391304348,0.10817842344635897,mmlu:management,test,38.8246140149422
25,0.23016020774841311,0.8399999737739563,0.8799999952316284,0.5416666666666666,0.13574827909469608,mmlu:marketing,validation,12.911510538076982
234,0.07295603846382893,0.7991453409194946,0.8162393569946289,0.48111275457958813,0.077837361739232,mmlu:marketing,test,118.75441541103646
11,0.17484930970452048,0.8181818723678589,0.8181818723678589,0.6666666666666667,0.21974715319546786,mmlu:medical_genetics,validation,5.325521195074543
100,0.1140047150850296,0.5799999833106995,0.6100000143051147,0.5233990147783252,0.13841394066810614,mmlu:medical_genetics,test,45.39772927411832
38,0.1480865847123297,0.5263158082962036,0.5263158082962036,0.6375,0.26037440017650004,mmlu:moral_disputes,validation,20.96129420516081
346,0.05284241315601878,0.6069363951683044,0.6416184902191162,0.4690826330532213,0.14872856532907208,mmlu:moral_disputes,test,188.66583516588435
33,0.22739287398078226,0.7878788113594055,0.6666666865348816,0.4697802197802198,0.1711867722597989,mmlu:nutrition,validation,20.928036298137158
306,0.06387726767779954,0.6209150552749634,0.6176470518112183,0.578584392014519,0.1867669900647955,mmlu:nutrition,test,195.13838274707086
34,0.1774869929341709,0.6176470518112183,0.7941176295280457,0.6684981684981685,0.1385236031868879,mmlu:philosophy,validation,14.094218506943434
311,0.09222502417119753,0.6495176553726196,0.6752411723136902,0.5911299845580887,0.14107740212866726,mmlu:philosophy,test,124.70559819182381
35,0.11937405381883892,0.6285714507102966,0.6000000238418579,0.4965034965034965,0.18952542543411252,mmlu:prehistory,validation,20.5484483060427
324,0.058732609138076694,0.6358024477958679,0.6975308656692505,0.4559198617739016,0.08795534699787329,mmlu:prehistory,test,187.0711651260499
69,0.19898831541987433,0.5797101259231567,0.6231884360313416,0.6504310344827587,0.17148722513862283,mmlu:professional_psychology,validation,42.15361729986034
612,0.06996925077796759,0.5702614188194275,0.6307189464569092,0.5778759519321908,0.15448769284229652,mmlu:professional_psychology,test,365.02280629985034
12,0.4128243600328763,0.5,0.75,0.48611111111111116,0.11043542126814525,mmlu:public_relations,validation,6.4358261111192405
110,0.09289706620303068,0.6545454263687134,0.7272726893424988,0.3373538011695907,0.09351617748087102,mmlu:public_relations,test,56.48847787594423
27,0.23150667658558596,0.5925925970077515,0.7407407760620117,0.5056818181818181,0.17178147148202969,mmlu:security_studies,validation,29.429132302990183
245,0.051245465935493006,0.6204081177711487,0.6734693646430969,0.5451329937747597,0.16475304900383464,mmlu:security_studies,test,268.00411356589757
22,0.1560781083323739,0.8181818723678589,0.7272727489471436,0.3819444444444444,0.13018352606079794,mmlu:sociology,validation,11.673767485888675
201,0.0648687692423958,0.7711442708969116,0.7412934899330139,0.6079242636746143,0.08726815738488192,mmlu:sociology,test,104.91303876810707
11,0.13359317996285178,0.9090909361839294,0.9090909361839294,0.95,0.17740956761620258,mmlu:us_foreign_policy,validation,5.773547186981887
100,0.1177100756764412,0.8399999737739563,0.7799999713897705,0.6350446428571428,0.06134023189544675,mmlu:us_foreign_policy,test,50.95908806310035
18,0.22458775672647688,0.4444444477558136,0.4444444477558136,0.48124999999999996,0.2949153747823503,mmlu:virology,validation,8.393670177087188
166,0.17101406261145352,0.4337349236011505,0.5722891092300415,0.4923167848699764,0.23662288145846633,mmlu:virology,test,72.90616914001293
19,0.18126036305176588,0.7894737124443054,0.8421052694320679,0.5833333333333333,0.11740348527306002,mmlu:world_religions,validation,7.186742886900902
171,0.04564571502613047,0.7660818696022034,0.8128654956817627,0.6159351145038168,0.0461495518684387,mmlu:world_religions,test,64.10984625085257
18,0.20601813660727605,0.6666666865348816,0.8333333134651184,0.9305555555555556,0.14414315422375998,mmlu:high_school_european_history,validation,25.16406110697426
165,0.0861229925444632,0.6545454263687134,0.7757575511932373,0.8304093567251462,0.050246499162731745,mmlu:high_school_european_history,test,195.57892870903015
26,0.19605586620477528,0.5384615659713745,0.692307710647583,0.8392857142857143,0.26336702475181,mmlu:high_school_world_history,validation,16.92538485908881
237,0.05227537987604423,0.7257384061813354,0.7637130618095398,0.7852415026833631,0.08085982231148188,mmlu:high_school_world_history,test,148.6266573900357
86,0.10223267175430475,0.6627907156944275,0.7674418687820435,0.8003629764065335,0.12279249277225758,mmlu:miscellaneous,validation,17.2641833210364
783,0.05993499229085247,0.7598978281021118,0.7982119917869568,0.834918648310388,0.04492769745270107,mmlu:miscellaneous,test,157.2650905949995
100,0.09922337323427202,0.30000001192092896,0.699999988079071,0.657142857142857,0.20675329208374021,mmlu:moral_scenarios,validation,34.64375521498732
895,0.043047082956942755,0.34860333800315857,0.651396632194519,0.6186282271187931,0.25582163959908083,mmlu:moral_scenarios,test,308.80596957099624
31,0.12492190349486564,0.3870967626571655,0.4516128897666931,0.4890350877192982,0.32737726357675373,mmlu:professional_accounting,validation,11.194159780163318
282,0.027022563502298178,0.41843971610069275,0.6773049831390381,0.6719977263331955,0.14106001329760176,mmlu:professional_accounting,test,100.8331893500872
170,0.12071063693831949,0.38235294818878174,0.5647059082984924,0.6202197802197802,0.20469750972355114,mmlu:professional_law,validation,120.96564210299402
1534,0.09201111709589752,0.4054758846759796,0.5788787603378296,0.6332510083488464,0.1818260825597323,mmlu:professional_law,test,1102.5055607301183
31,0.23182383852620275,0.4838709533214569,0.6451612710952759,0.7166666666666666,0.12073575873528757,mmlu:professional_medicine,validation,16.859665635041893
272,0.09213407786891742,0.5404411554336548,0.6433823704719543,0.713795918367347,0.12136646557380172,mmlu:professional_medicine,test,147.49151621898636
