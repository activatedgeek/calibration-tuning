N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.1818181872367859,0.41666666666666663,0.49184844168749725,mmlu:abstract_algebra,validation,6.883481444092467
100,0.2199999988079071,0.23000000417232513,0.5623543123543124,0.4305195611715317,mmlu:abstract_algebra,test,3.444749167887494
14,0.2857142984867096,0.3571428656578064,0.525,0.23211147529738294,mmlu:anatomy,validation,0.6337528398726135
135,0.4148148000240326,0.39259257912635803,0.4970614828209765,0.2226759186497441,mmlu:anatomy,test,3.612351296003908
16,0.4375,0.875,0.9047619047619048,0.3299665227532387,mmlu:astronomy,validation,0.7275742939673364
152,0.5065789222717285,0.5921052694320679,0.6370562770562771,0.0328938913972754,mmlu:astronomy,test,5.448349185055122
11,0.6363636255264282,0.5454545617103577,0.4464285714285714,0.05233619971708819,mmlu:business_ethics,validation,0.6175641368608922
100,0.30000001192092896,0.5799999833106995,0.6333333333333333,0.08947872996330263,mmlu:business_ethics,test,4.56368331797421
29,0.24137930572032928,0.27586206793785095,0.4805194805194805,0.30620033782103967,mmlu:clinical_knowledge,validation,0.9920419028494507
265,0.35849055647850037,0.4075471758842468,0.6104024767801858,0.17805978689553606,mmlu:clinical_knowledge,test,7.870004953118041
16,0.3125,0.3125,0.7000000000000001,0.4496104344725609,mmlu:college_biology,validation,0.6855486750137061
144,0.2986111044883728,0.3055555522441864,0.5760994704121575,0.41073473294576013,mmlu:college_biology,test,5.479670291068032
8,0.125,0.125,0.7857142857142857,0.5801658555865288,mmlu:college_chemistry,validation,0.4564695740118623
100,0.14000000059604645,0.15000000596046448,0.47549833887043186,0.5907400220632553,mmlu:college_chemistry,test,4.656062904046848
11,0.0,0.0,,0.6996655518358403,mmlu:college_computer_science,validation,1.2942839730530977
100,0.17000000178813934,0.23000000417232513,0.6495393338058115,0.47616387903690344,mmlu:college_computer_science,test,7.861435672966763
11,0.0,0.0,,0.6514888243241743,mmlu:college_mathematics,validation,0.7514662470202893
100,0.1599999964237213,0.23000000417232513,0.5844494047619048,0.4322130042314529,mmlu:college_mathematics,test,5.471399176167324
22,0.3636363744735718,0.40909090638160706,0.7321428571428571,0.24358888918703253,mmlu:college_medicine,validation,0.9963155970908701
173,0.36994218826293945,0.4393063485622406,0.5996272935779816,0.19062265667612158,mmlu:college_medicine,test,10.154616842977703
11,0.27272728085517883,0.3636363744735718,0.6041666666666666,0.43410597064278345,mmlu:college_physics,validation,0.699991833884269
102,0.14705882966518402,0.14705882966518402,0.5325670498084292,0.5900961371029125,mmlu:college_physics,test,5.047779510030523
11,0.7272727489471436,0.8181818127632141,0.75,0.16484698382290924,mmlu:computer_security,validation,0.5482119061052799
100,0.4300000071525574,0.44999998807907104,0.5322317421460628,0.22023501634597778,mmlu:computer_security,test,3.3645238378085196
26,0.3076923191547394,0.3461538553237915,0.4652777777777778,0.30725568303695094,mmlu:conceptual_physics,validation,0.8178264580201358
235,0.4127659499645233,0.4127659499645233,0.5085910652920962,0.25966286938241184,mmlu:conceptual_physics,test,6.330807268852368
12,0.0833333358168602,0.0833333358168602,0.4090909090909091,0.6449647645155588,mmlu:econometrics,validation,0.7788358898833394
114,0.14912280440330505,0.2017543911933899,0.40388114008490006,0.4779040008260493,mmlu:econometrics,test,6.385431549977511
16,0.125,0.1875,0.42857142857142855,0.4132533185184002,mmlu:electrical_engineering,validation,0.6885124249383807
145,0.1862068921327591,0.2137930989265442,0.5753295668549906,0.4121728671008143,mmlu:electrical_engineering,test,5.672373665962368
41,0.26829269528388977,0.26829269528388977,0.603030303030303,0.4144256173110589,mmlu:elementary_mathematics,validation,1.7849837432149798
378,0.32275131344795227,0.3333333432674408,0.4995997694672131,0.35116838683526985,mmlu:elementary_mathematics,test,15.627827981021255
14,0.5,0.5,0.6224489795918368,0.08954065186636789,mmlu:formal_logic,validation,0.7944544828496873
126,0.30158731341362,0.420634925365448,0.5986842105263158,0.15189987515646314,mmlu:formal_logic,test,6.008720736019313
10,0.30000001192092896,0.30000001192092896,0.3571428571428571,0.4533559560775757,mmlu:global_facts,validation,0.46348726912401617
100,0.17000000178813934,0.18000000715255737,0.6481218993621545,0.509963402748108,mmlu:global_facts,test,3.6018565220292658
32,0.15625,0.375,0.8185185185185185,0.1853906121104956,mmlu:high_school_biology,validation,1.3013770070392638
310,0.41290321946144104,0.5451613068580627,0.5793054601648351,0.034268224239349325,mmlu:high_school_biology,test,11.727788345189765
22,0.13636364042758942,0.13636364042758942,0.2894736842105263,0.5388274545019323,mmlu:high_school_chemistry,validation,1.0802644919604063
203,0.16748768091201782,0.19211822748184204,0.589888618169161,0.46447555596018075,mmlu:high_school_chemistry,test,9.01623517414555
9,0.2222222238779068,0.2222222238779068,0.7142857142857143,0.39912190702226424,mmlu:high_school_computer_science,validation,2.0420214429032058
100,0.3700000047683716,0.3700000047683716,0.47726297726297734,0.28209570646286014,mmlu:high_school_computer_science,test,6.924489828990772
18,0.7222222089767456,0.7777777910232544,0.3384615384615384,0.16525510946909586,mmlu:high_school_european_history,validation,5.399309515953064
165,0.6727272868156433,0.6666666865348816,0.6426426426426425,0.04278950546727032,mmlu:high_school_european_history,test,49.40083081717603
22,0.4545454680919647,0.5909090638160706,0.7875000000000001,0.04232177138328552,mmlu:high_school_geography,validation,0.7302520829252899
198,0.3636363744735718,0.40909090638160706,0.6684303350970017,0.17167338217147673,mmlu:high_school_geography,test,5.706017112126574
21,0.4285714328289032,0.4761904776096344,0.5694444444444444,0.24191791386831374,mmlu:high_school_government_and_politics,validation,0.7880885121412575
193,0.48704662919044495,0.4922279715538025,0.5933806146572104,0.23668439215329026,mmlu:high_school_government_and_politics,test,6.098068585852161
43,0.41860464215278625,0.44186046719551086,0.5111111111111111,0.23392023873883624,mmlu:high_school_macroeconomics,validation,1.3228838888462633
390,0.34358975291252136,0.38461539149284363,0.5680387126865671,0.2854288382407946,mmlu:high_school_macroeconomics,test,11.476127383066341
29,0.03448275849223137,0.03448275849223137,0.7321428571428571,0.6470955569168617,mmlu:high_school_mathematics,validation,1.6040086259599775
270,0.08148147910833359,0.08148147910833359,0.565340909090909,0.6211827350987329,mmlu:high_school_mathematics,test,13.16284943697974
26,0.3076923191547394,0.3076923191547394,0.6736111111111112,0.4063260234319247,mmlu:high_school_microeconomics,validation,0.846627363935113
238,0.32773110270500183,0.3235294222831726,0.5839743589743589,0.3764559135717504,mmlu:high_school_microeconomics,test,6.893947212956846
17,0.23529411852359772,0.1764705926179886,0.4326923076923077,0.5604398145395166,mmlu:high_school_physics,validation,0.9102399740368128
151,0.17880794405937195,0.18543046712875366,0.5170250896057348,0.5430762933579503,mmlu:high_school_physics,test,7.125118315918371
60,0.5,0.5,0.79,0.17471257646878557,mmlu:high_school_psychology,validation,2.390971898799762
545,0.5064220428466797,0.5082568526268005,0.5010101826410215,0.1584636190615663,mmlu:high_school_psychology,test,21.080986316083
23,0.1304347813129425,0.1304347813129425,0.5166666666666666,0.5722483992576599,mmlu:high_school_statistics,validation,1.5543360027950257
216,0.24074074625968933,0.24537037312984467,0.47525797373358347,0.46430960877074134,mmlu:high_school_statistics,test,13.452622561017051
22,0.5909090638160706,0.5454545617103577,0.5470085470085471,0.1266992363062772,mmlu:high_school_us_history,validation,5.128898028982803
204,0.5980392098426819,0.593137264251709,0.6447421031587366,0.07922624489840342,mmlu:high_school_us_history,test,47.04711149004288
26,0.5384615659713745,0.5384615659713745,0.6547619047619048,0.19590190740732047,mmlu:high_school_world_history,validation,4.424638296011835
237,0.4345991611480713,0.4303797483444214,0.6082089552238805,0.2784632235639709,mmlu:high_school_world_history,test,36.07240773411468
23,0.21739129722118378,0.21739129722118378,0.8444444444444444,0.4656147671782452,mmlu:human_aging,validation,0.7257206870708615
223,0.340807169675827,0.340807169675827,0.5392051557465092,0.3478450948881996,mmlu:human_aging,test,6.093201105948538
12,0.4166666567325592,0.4166666567325592,0.5,0.21181050439675653,mmlu:human_sexuality,validation,0.48693398712202907
131,0.47328245639801025,0.47328245639801025,0.5755025712949976,0.1925425515830062,mmlu:human_sexuality,test,3.9903461418580264
13,0.23076923191547394,0.3076923191547394,0.6333333333333333,0.33697874729449934,mmlu:international_law,validation,0.648432892980054
121,0.4876033067703247,0.4628099203109741,0.4626845270639694,0.14000972292639993,mmlu:international_law,test,4.740200078813359
11,0.4545454680919647,0.5454545617103577,0.65,0.08015996759588068,mmlu:jurisprudence,validation,0.49901675898581743
108,0.37037035822868347,0.45370370149612427,0.5066176470588235,0.11740682577645337,mmlu:jurisprudence,test,3.440830545965582
18,0.4444444477558136,0.5,0.6687500000000001,0.16458205382029217,mmlu:logical_fallacies,validation,0.7467703679576516
163,0.42944785952568054,0.4601227045059204,0.57642089093702,0.16889332481688518,mmlu:logical_fallacies,test,5.816912331152707
11,0.27272728085517883,0.27272728085517883,0.125,0.4662654941732233,mmlu:machine_learning,validation,0.7213945100083947
112,0.2857142984867096,0.3125,0.5509765625,0.29614791327289175,mmlu:machine_learning,test,5.814298870973289
11,0.4545454680919647,0.5454545617103577,0.5333333333333334,0.013003094629807865,mmlu:management,validation,0.43677954794839025
103,0.4563106894493103,0.5728155374526978,0.638677811550152,0.039672294288005686,mmlu:management,test,2.5867326939478517
25,0.2800000011920929,0.4000000059604645,0.48412698412698413,0.1655477571487427,mmlu:marketing,validation,0.9924656171351671
234,0.4572649598121643,0.504273533821106,0.5798071969975714,0.06325773321665248,mmlu:marketing,test,7.310223289066926
11,0.7272727489471436,0.7272727489471436,0.625,0.0796354413032532,mmlu:medical_genetics,validation,0.41246961895376444
100,0.4699999988079071,0.4699999988079071,0.5847049377759936,0.21928570032119746,mmlu:medical_genetics,test,2.6844198571052402
86,0.5465116500854492,0.5465116500854492,0.6033824331696672,0.19064515136009044,mmlu:miscellaneous,validation,2.323195607867092
783,0.5874840617179871,0.5938697457313538,0.6119464261677212,0.13721127992693338,mmlu:miscellaneous,test,21.028283007908612
38,0.42105263471603394,0.44736841320991516,0.5369318181818182,0.13372778108245448,mmlu:moral_disputes,validation,1.4657438958529383
346,0.41040462255477905,0.47398844361305237,0.6219103838718586,0.09862875042623179,mmlu:moral_disputes,test,12.245945061091334
100,0.3499999940395355,0.6499999761581421,0.5287912087912088,0.02468193769454957,mmlu:moral_scenarios,validation,5.984411235200241
895,0.3173184394836426,0.6826815605163574,0.5351997418224568,0.08174728428185318,mmlu:moral_scenarios,test,52.176187351113185
33,0.3636363744735718,0.3333333432674408,0.3293650793650794,0.3662958379947777,mmlu:nutrition,validation,1.416241361061111
306,0.38235294818878174,0.38562092185020447,0.5695066250621806,0.29012187945297346,mmlu:nutrition,test,12.27561041386798
34,0.29411765933036804,0.29411765933036804,0.41041666666666665,0.33669918074327365,mmlu:philosophy,validation,1.088772282935679
311,0.3247588276863098,0.3376205861568451,0.4962281942479962,0.3010628848213858,mmlu:philosophy,test,8.863698459928855
35,0.3142857253551483,0.3142857253551483,0.48484848484848486,0.3148256642477853,mmlu:prehistory,validation,1.3194336788728833
324,0.4166666567325592,0.4444444477558136,0.5878894767783657,0.1739838616347607,mmlu:prehistory,test,11.153223898028955
31,0.12903225421905518,0.12903225421905518,0.4444444444444444,0.5436230840221528,mmlu:professional_accounting,validation,2.1425564331002533
282,0.152482271194458,0.1666666716337204,0.4985890824170477,0.49799372752507526,mmlu:professional_accounting,test,18.474439746933058
170,0.3117647171020508,0.3117647171020508,0.4263022093210772,0.31833924160284155,mmlu:professional_law,validation,24.39913596608676
1534,0.2777053415775299,0.2907431423664093,0.48609981186759543,0.3388747195610011,mmlu:professional_law,test,224.43580734310672
31,0.4193548262119293,0.4193548262119293,0.6495726495726496,0.23650234168575654,mmlu:professional_medicine,validation,3.6130596860311925
272,0.27941176295280457,0.2904411852359772,0.5817333512352308,0.3554464092149454,mmlu:professional_medicine,test,31.596524497959763
69,0.3913043439388275,0.4202898442745209,0.5855379188712522,0.24706636477207794,mmlu:professional_psychology,validation,3.0699921881314367
612,0.30882352590560913,0.3480392098426819,0.5862071122118404,0.29822573679334974,mmlu:professional_psychology,test,24.387397231068462
12,0.4166666567325592,0.6666666865348816,0.6571428571428573,0.15185361107190448,mmlu:public_relations,validation,0.5354904739651829
110,0.3181818127632141,0.5636363625526428,0.5849523809523809,0.019055167111483494,mmlu:public_relations,test,3.6736253439448774
27,0.5925925970077515,0.40740740299224854,0.3835227272727273,0.23290785595222757,mmlu:security_studies,validation,1.4257852770388126
245,0.5306122303009033,0.4693877696990967,0.523010033444816,0.16109841405128944,mmlu:security_studies,test,12.054129363968968
22,0.3181818127632141,0.3181818127632141,0.6857142857142857,0.3176407624374736,mmlu:sociology,validation,0.7634923860896379
201,0.3781094551086426,0.39303481578826904,0.5740526315789474,0.23349265079593182,mmlu:sociology,test,6.081450963858515
11,0.6363636255264282,0.27272728085517883,0.3571428571428571,0.27615225315094,mmlu:us_foreign_policy,validation,0.4721330339089036
100,0.5799999833106995,0.550000011920929,0.6178160919540229,0.046304033994674705,mmlu:us_foreign_policy,test,3.0783181299921125
18,0.5,0.5555555820465088,0.47530864197530864,0.15215369065602619,mmlu:virology,validation,0.7809944581240416
166,0.3313252925872803,0.608433723449707,0.5583128583128582,0.10079019435917042,mmlu:virology,test,5.087858153972775
19,0.7368420958518982,0.7368420958518982,0.7285714285714284,0.1009339721579301,mmlu:world_religions,validation,0.5864898927975446
171,0.5847952961921692,0.5847952961921692,0.6191549295774648,0.12632953562931712,mmlu:world_religions,test,4.272189022041857
