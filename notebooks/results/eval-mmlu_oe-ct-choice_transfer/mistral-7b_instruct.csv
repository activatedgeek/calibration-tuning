N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.8181818127632141,0.19444444444444448,0.16486545584418555,mmlu:abstract_algebra,validation,7.808945868164301
100,0.30000001192092896,0.699999988079071,0.4807142857142857,0.11283426702022553,mmlu:abstract_algebra,test,3.586392638972029
14,0.3571428656578064,0.6428571343421936,0.7666666666666666,0.21223507182938708,mmlu:anatomy,validation,0.79349818197079
135,0.5185185074806213,0.48148149251937866,0.728901098901099,0.23310910860697429,mmlu:anatomy,test,3.6158108098898083
16,0.5,0.5,0.8359375,0.27117227762937546,mmlu:astronomy,validation,0.8620749399997294
152,0.6907894611358643,0.30921053886413574,0.6534954407294833,0.4387222242198492,mmlu:astronomy,test,5.677819499047473
11,0.5454545617103577,0.4545454680919647,0.75,0.37005323713476,mmlu:business_ethics,validation,0.7208420541137457
100,0.4300000071525574,0.5699999928474426,0.6766625866993065,0.26907256543636326,mmlu:business_ethics,test,4.504934964934364
29,0.4137931168079376,0.5862069129943848,0.5661764705882353,0.07780826502832877,mmlu:clinical_knowledge,validation,1.210380804957822
265,0.4226415157318115,0.6075471639633179,0.7048902894491129,0.041488495637785734,mmlu:clinical_knowledge,test,8.395448294933885
16,0.375,0.625,0.48333333333333334,0.08458469063043593,mmlu:college_biology,validation,0.8371751150116324
144,0.4791666567325592,0.6041666865348816,0.6977777777777777,0.05129374605086118,mmlu:college_biology,test,5.720351199852303
8,0.0,1.0,,0.21082712709903717,mmlu:college_chemistry,validation,0.7211806839331985
100,0.25999999046325684,0.7300000190734863,0.7182952182952184,0.09213528990745545,mmlu:college_chemistry,test,4.789240875048563
11,0.1818181872367859,0.6363636255264282,0.7777777777777778,0.2387117689306086,mmlu:college_computer_science,validation,1.0804086111020297
100,0.3100000023841858,0.7400000095367432,0.7043010752688171,0.04777223408222202,mmlu:college_computer_science,test,7.791738658910617
11,0.09090909361839294,0.9090909361839294,0.19999999999999996,0.1916388544169339,mmlu:college_mathematics,validation,0.9241322891321033
100,0.14000000059604645,0.8500000238418579,0.6648671096345514,0.11657523512840273,mmlu:college_mathematics,test,5.719835321884602
22,0.40909090638160706,0.5909090638160706,0.4871794871794871,0.19097406213933774,mmlu:college_medicine,validation,0.9931037710048258
173,0.4624277353286743,0.5491329431533813,0.7081989247311827,0.21719767110196153,mmlu:college_medicine,test,9.720513757085428
11,0.1818181872367859,0.8181818127632141,1.0,0.1871597116643732,mmlu:college_physics,validation,0.6981542077846825
102,0.19607843458652496,0.7843137383460999,0.5719512195121952,0.10561732451121014,mmlu:college_physics,test,4.8830551719293
11,0.8181818127632141,0.1818181872367859,0.8888888888888888,0.5141943855719133,mmlu:computer_security,validation,0.6270283800549805
100,0.6800000071525574,0.3199999928474426,0.5454963235294118,0.4173880171775818,mmlu:computer_security,test,3.573869823012501
26,0.38461539149284363,0.5769230723381042,0.5187499999999999,0.15655499467482933,mmlu:conceptual_physics,validation,0.8374465778470039
235,0.46382978558540344,0.5404255390167236,0.6414737148682103,0.17545564326834173,mmlu:conceptual_physics,test,5.913730588974431
12,0.4166666567325592,0.5833333134651184,0.5285714285714286,0.25532206892967224,mmlu:econometrics,validation,0.7844166909344494
114,0.31578946113586426,0.6754385828971863,0.5797720797720799,0.1343756495860585,mmlu:econometrics,test,6.104910642839968
16,0.3125,0.6875,0.7090909090909091,0.16048958897590637,mmlu:electrical_engineering,validation,0.7957678961101919
145,0.43448275327682495,0.565517246723175,0.6172086720867208,0.18044808198665752,mmlu:electrical_engineering,test,5.826119491830468
41,0.3658536672592163,0.6341463327407837,0.6102564102564103,0.19398198767406183,mmlu:elementary_mathematics,validation,1.9296284050215036
378,0.45502644777297974,0.5449735522270203,0.612370173854143,0.2069232578946169,mmlu:elementary_mathematics,test,15.85524485213682
14,0.2857142984867096,0.7142857313156128,0.5,0.15282243490219116,mmlu:formal_logic,validation,0.7915170369669795
126,0.380952388048172,0.6190476417541504,0.5189636752136753,0.19356877226678154,mmlu:formal_logic,test,6.061420131009072
10,0.5,0.5,0.6200000000000001,0.27767742276191715,mmlu:global_facts,validation,0.5285686498973519
100,0.20999999344348907,0.7900000214576721,0.40506329113924056,0.1155232048034668,mmlu:global_facts,test,3.532248699106276
32,0.40625,0.65625,0.6923076923076923,0.1252461913973093,mmlu:high_school_biology,validation,1.3502640498336405
310,0.57419353723526,0.47741934657096863,0.7245701395982296,0.19141965777643263,mmlu:high_school_biology,test,11.772089454112574
22,0.22727273404598236,0.7727272510528564,0.6529411764705882,0.08986668153242632,mmlu:high_school_chemistry,validation,1.107733858982101
203,0.2807881832122803,0.7241379022598267,0.5563566450372507,0.06270006519233064,mmlu:high_school_chemistry,test,9.105411774013191
9,0.4444444477558136,0.5555555820465088,0.6,0.21822014119890004,mmlu:high_school_computer_science,validation,0.7590777478180826
100,0.5099999904632568,0.49000000953674316,0.6362545018007203,0.2653956240415573,mmlu:high_school_computer_science,test,6.794084914028645
18,0.8333333134651184,0.1666666716337204,0.7222222222222222,0.5343174007203844,mmlu:high_school_european_history,validation,5.24400839000009
165,0.8060606122016907,0.19393938779830933,0.6949013157894737,0.5116577928716487,mmlu:high_school_european_history,test,47.173090788768604
22,0.3636363744735718,0.6363636255264282,0.4910714285714286,0.0907224172895605,mmlu:high_school_geography,validation,0.8024015759583563
198,0.4595959484577179,0.5454545617103577,0.6013659237958303,0.13211692975024983,mmlu:high_school_geography,test,5.476448760833591
21,0.761904776096344,0.2380952388048172,0.875,0.47574036461966385,mmlu:high_school_government_and_politics,validation,0.8580672189127654
193,0.6269429922103882,0.38860103487968445,0.667929292929293,0.2851043655464686,mmlu:high_school_government_and_politics,test,6.107474655145779
43,0.5116279125213623,0.4883720874786377,0.577922077922078,0.21700737504071965,mmlu:high_school_macroeconomics,validation,1.4221512309741229
390,0.5102564096450806,0.4923076927661896,0.5641558578231473,0.21071873842141567,mmlu:high_school_macroeconomics,test,11.243490232853219
29,0.13793103396892548,0.8620689511299133,0.25,0.12288155432405143,mmlu:high_school_mathematics,validation,1.6233938680961728
270,0.11481481790542603,0.885185182094574,0.5108651639897422,0.09295403162638344,mmlu:high_school_mathematics,test,13.446474815020338
26,0.38461539149284363,0.6153846383094788,0.628125,0.08495110502609846,mmlu:high_school_microeconomics,validation,0.9157057271804661
238,0.45798319578170776,0.5378151535987854,0.6516961809259656,0.15836117022177748,mmlu:high_school_microeconomics,test,6.8404127629473805
17,0.1764705926179886,0.9411764740943909,0.9761904761904763,0.3394574487910551,mmlu:high_school_physics,validation,0.9968259639572352
151,0.38410595059394836,0.5761589407920837,0.5493140526510938,0.026523363906026706,mmlu:high_school_physics,test,7.310271342983469
60,0.6333333253860474,0.38333332538604736,0.7296650717703348,0.2715140014886856,mmlu:high_school_psychology,validation,2.262067056959495
545,0.6091743111610413,0.4000000059604645,0.7017860173086713,0.25223245948826506,mmlu:high_school_psychology,test,19.58878873893991
23,0.30434781312942505,0.695652186870575,0.5089285714285714,0.1465244837429212,mmlu:high_school_statistics,validation,1.5302102509886026
216,0.40740740299224854,0.6018518805503845,0.6253995028409092,0.1145983559113962,mmlu:high_school_statistics,test,13.180714905029163
22,0.8181818127632141,0.1818181872367859,0.8333333333333334,0.5465279058976606,mmlu:high_school_us_history,validation,5.004048242000863
204,0.7352941036224365,0.2647058963775635,0.7269753086419752,0.4375944660574782,mmlu:high_school_us_history,test,44.97301573003642
26,0.692307710647583,0.3076923191547394,0.7465277777777777,0.38913639233662534,mmlu:high_school_world_history,validation,4.209049368975684
237,0.7257384061813354,0.27426159381866455,0.7558139534883721,0.40858148673415684,mmlu:high_school_world_history,test,34.22018456598744
23,0.43478259444236755,0.5652173757553101,0.6846153846153846,0.16320648141529248,mmlu:human_aging,validation,0.7653259388171136
223,0.46188339591026306,0.5381165742874146,0.6480582524271845,0.15279596883619848,mmlu:human_aging,test,5.9193941480480134
12,0.5,0.5833333134651184,0.7361111111111112,0.2188839763402939,mmlu:human_sexuality,validation,0.5534731459338218
131,0.6030534505844116,0.40458014607429504,0.7226144109055502,0.3039242534237054,mmlu:human_sexuality,test,4.161528402939439
13,0.6153846383094788,0.38461539149284363,0.4875,0.4465705110476567,mmlu:international_law,validation,0.7315352079458535
121,0.7851239442825317,0.22314049303531647,0.541497975708502,0.5523298200496958,mmlu:international_law,test,5.032447018893436
11,0.7272727489471436,0.27272728085517883,0.4791666666666667,0.5091259750452908,mmlu:jurisprudence,validation,0.5814798029605299
108,0.7407407164573669,0.25925925374031067,0.5323660714285714,0.4994961006773843,mmlu:jurisprudence,test,3.75567384599708
18,0.6666666865348816,0.3333333432674408,0.8055555555555556,0.42532825138833785,mmlu:logical_fallacies,validation,0.7784226490184665
163,0.5889570713043213,0.4110429584980011,0.6016013681592041,0.3102721389085969,mmlu:logical_fallacies,test,5.9038370319176465
11,0.4545454680919647,0.5454545617103577,0.7000000000000001,0.2279688824306835,mmlu:machine_learning,validation,0.7767921390477568
112,0.4642857015132904,0.5357142686843872,0.49455128205128207,0.2428645619324276,mmlu:machine_learning,test,5.767119341995567
11,0.6363636255264282,0.3636363744735718,0.5178571428571428,0.35949163545261725,mmlu:management,validation,0.5225866679102182
103,0.49514561891555786,0.5048543810844421,0.6325414781297135,0.2319047045939177,mmlu:management,test,2.951570051955059
25,0.36000001430511475,0.6399999856948853,0.642361111111111,0.11079656362533573,mmlu:marketing,validation,0.9770645040553063
234,0.4444444477558136,0.5555555820465088,0.7431213017751479,0.16074845041984168,mmlu:marketing,test,6.9142774739302695
11,0.7272727489471436,0.27272728085517883,0.9166666666666666,0.4029774557460438,mmlu:medical_genetics,validation,0.5161588478367776
100,0.5600000023841858,0.4300000071525574,0.6909496753246753,0.25521294713020326,mmlu:medical_genetics,test,2.6718064409215003
86,0.6744186282157898,0.5,0.705972906403941,0.0912923334642898,mmlu:miscellaneous,validation,2.5149349470157176
783,0.6666666865348816,0.5351213216781616,0.7102288574742003,0.053394299509577095,mmlu:miscellaneous,test,21.607511603971943
38,0.6315789222717285,0.3684210479259491,0.6130952380952381,0.3210018261482841,mmlu:moral_disputes,validation,1.5106626939959824
346,0.5780346989631653,0.4219653308391571,0.6046061643835617,0.278501479267385,mmlu:moral_disputes,test,11.815931770019233
100,0.5,0.5,0.5444,0.32545769691467286,mmlu:moral_scenarios,validation,5.638999429997057
895,0.5307262539863586,0.46927374601364136,0.5806867167919798,0.3582075069736502,mmlu:moral_scenarios,test,48.28435772494413
33,0.5454545617103577,0.4545454680919647,0.6055555555555556,0.37283667831709894,mmlu:nutrition,validation,1.5942029089201242
306,0.5522875785827637,0.45098039507865906,0.5803999481708635,0.35627446046062544,mmlu:nutrition,test,12.993660019012168
34,0.47058823704719543,0.5882353186607361,0.7447916666666666,0.07409536137300379,mmlu:philosophy,validation,1.1223300641868263
311,0.4308681786060333,0.5755627155303955,0.6554937178514207,0.055834571456602526,mmlu:philosophy,test,8.662614637054503
35,0.4571428596973419,0.5428571701049805,0.6661184210526316,0.16447030305862428,mmlu:prehistory,validation,1.4427328740712255
324,0.5555555820465088,0.4444444477558136,0.585108024691358,0.2395809443644535,mmlu:prehistory,test,10.969980766065419
31,0.25806450843811035,0.7419354915618896,0.5597826086956521,0.12625512192326213,mmlu:professional_accounting,validation,2.1210274901241064
282,0.20921985805034637,0.7907801270484924,0.6092194269210305,0.04462887949131906,mmlu:professional_accounting,test,17.525355037068948
170,0.4647058844566345,0.5352941155433655,0.6075949367088608,0.22824250564855683,mmlu:professional_law,validation,23.23258948000148
1534,0.36245110630989075,0.6375488638877869,0.6367062791484605,0.13436945550134008,mmlu:professional_law,test,213.75172793888487
31,0.4193548262119293,0.5806451439857483,0.7457264957264957,0.1882108449935913,mmlu:professional_medicine,validation,3.5058564678765833
272,0.375,0.625,0.6615051903114186,0.12224717438220978,mmlu:professional_medicine,test,29.713131519034505
69,0.5362318754196167,0.47826087474823,0.7191722972972974,0.19686416525771652,mmlu:professional_psychology,validation,2.960786814102903
612,0.4395424723625183,0.5620915293693542,0.689027496287947,0.1224163162942026,mmlu:professional_psychology,test,23.884803655091673
12,0.4166666567325592,0.5833333134651184,0.8714285714285713,0.17707956830660504,mmlu:public_relations,validation,0.6199899460189044
110,0.37272727489471436,0.6272727251052856,0.6770943796394486,0.11335067911581562,mmlu:public_relations,test,3.576644165907055
27,0.6666666865348816,0.3333333432674408,0.6975308641975309,0.4318096836407979,mmlu:security_studies,validation,1.5543081699870527
245,0.7877551317214966,0.2122448980808258,0.6037764049422081,0.5744922095415544,mmlu:security_studies,test,12.25089308898896
22,0.6818181872367859,0.40909090638160706,0.6333333333333333,0.18458213860338385,mmlu:sociology,validation,0.8670904031023383
201,0.5671641826629639,0.4776119291782379,0.6353599516031458,0.14188424508963055,mmlu:sociology,test,6.163709509186447
11,0.9090909361839294,0.09090909361839294,0.9,0.616175954992121,mmlu:us_foreign_policy,validation,0.6205051720608026
100,0.7900000214576721,0.20999999344348907,0.5997588908981313,0.48610609591007237,mmlu:us_foreign_policy,test,3.52759009716101
18,0.6666666865348816,0.3333333432674408,0.8055555555555556,0.4186494052410126,mmlu:virology,validation,0.9215530040673912
166,0.6867470145225525,0.3192771077156067,0.5905870445344129,0.3694125169731048,mmlu:virology,test,5.55287543614395
19,0.6315789222717285,0.3684210479259491,0.988095238095238,0.4098969352872747,mmlu:world_religions,validation,0.6967972561251372
171,0.6900584697723389,0.31578946113586426,0.6827630316597378,0.33016638344491434,mmlu:world_religions,test,4.514080021996051
