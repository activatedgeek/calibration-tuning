N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.27272728085517883,0.5454545617103577,0.5208333333333333,0.09446486559781159,mmlu:abstract_algebra,validation,33.121800255030394
100,0.29999998211860657,0.5699999928474426,0.48190476190476195,0.08624580085277558,mmlu:abstract_algebra,test,285.929499768652
14,0.3571428656578064,0.4285714626312256,0.6555555555555556,0.22176421540124078,mmlu:anatomy,validation,39.9585773255676
135,0.5629629492759705,0.6222221851348877,0.7215655664585191,0.1020635759388959,mmlu:anatomy,test,386.5522121023387
16,0.375,0.375,0.5416666666666666,0.22678625211119652,mmlu:astronomy,validation,46.14356513135135
152,0.42763158679008484,0.6118420958518982,0.7507515473032714,0.029332842481763734,mmlu:astronomy,test,437.34570562373847
11,0.5454545617103577,0.6363636255264282,0.6833333333333333,0.08263771100477739,mmlu:business_ethics,validation,32.46704217419028
100,0.3499999940395355,0.4899999797344208,0.6949450549450549,0.13004408180713656,mmlu:business_ethics,test,293.2130004391074
29,0.3103448152542114,0.6206896305084229,0.5722222222222222,0.08438621512774767,mmlu:clinical_knowledge,validation,84.5713685946539
265,0.3094339668750763,0.6075471639633179,0.5727375716380115,0.05948081466386905,mmlu:clinical_knowledge,test,771.6907011484727
16,0.25,0.25,0.7083333333333333,0.45429765805602074,mmlu:college_biology,validation,46.81048330850899
144,0.4236111044883728,0.4513888955116272,0.6447758246099151,0.2534055676725176,mmlu:college_biology,test,418.24802051857114
8,0.25,0.375,0.6666666666666666,0.19200125336647034,mmlu:college_chemistry,validation,23.199064536951482
100,0.22999998927116394,0.3700000047683716,0.715132693393563,0.24751875698566433,mmlu:college_chemistry,test,296.3855497678742
11,0.1818181872367859,0.3636363744735718,0.19444444444444448,0.2895206754857843,mmlu:college_computer_science,validation,33.14878677204251
100,0.2199999988079071,0.4599999785423279,0.6095571095571096,0.17273406744003295,mmlu:college_computer_science,test,299.07368215173483
11,0.1818181872367859,0.5454545617103577,0.6111111111111112,0.13293968547474255,mmlu:college_mathematics,validation,32.15801207534969
100,0.19999998807907104,0.6399999856948853,0.45343749999999994,0.06878667831420897,mmlu:college_mathematics,test,293.83450946584344
22,0.5909091234207153,0.6818181872367859,0.6367521367521367,0.16561148112470453,mmlu:college_medicine,validation,64.83112745732069
173,0.38728323578834534,0.5260115265846252,0.5909602928752464,0.10551975055926109,mmlu:college_medicine,test,498.8064709827304
11,0.5454545617103577,0.6363636255264282,0.7666666666666666,0.14029716903513129,mmlu:college_physics,validation,31.658092240802944
102,0.2549019753932953,0.29411765933036804,0.6629554655870445,0.37176497660431207,mmlu:college_physics,test,298.8496045432985
11,0.8181818723678589,0.7272727489471436,0.6388888888888888,0.14617583426562222,mmlu:computer_security,validation,32.38816111534834
100,0.47999998927116394,0.5099999904632568,0.6338141025641024,0.1343237715959549,mmlu:computer_security,test,291.38866051938385
26,0.26923078298568726,0.42307692766189575,0.6917293233082706,0.21032151121359605,mmlu:conceptual_physics,validation,77.67292303778231
235,0.5106382966041565,0.6255319118499756,0.7042391304347826,0.05619792684595634,mmlu:conceptual_physics,test,682.0390166556463
12,0.4166666865348816,0.5,0.6428571428571429,0.13494186600049338,mmlu:econometrics,validation,35.53217764850706
114,0.25438597798347473,0.5438596606254578,0.46166328600405676,0.10040498407263505,mmlu:econometrics,test,337.79749650042504
16,0.25,0.1875,0.40625,0.391266830265522,mmlu:electrical_engineering,validation,46.96804640535265
145,0.25517240166664124,0.4206896424293518,0.5807057057057057,0.1642089235371557,mmlu:electrical_engineering,test,424.0165671221912
41,0.39024388790130615,0.39024388790130615,0.3737499999999999,0.22026271209484194,mmlu:elementary_mathematics,validation,119.42222507018596
378,0.4444444179534912,0.4920634627342224,0.5775085034013606,0.13929111632720503,mmlu:elementary_mathematics,test,1108.7990587670356
14,0.3571428656578064,0.7142857313156128,0.6222222222222223,0.27351395572934833,mmlu:formal_logic,validation,41.794615539722145
126,0.3650793731212616,0.3888889253139496,0.4782608695652174,0.21306956949688138,mmlu:formal_logic,test,370.3803923446685
10,0.20000000298023224,0.5,0.125,0.12167605757713316,mmlu:global_facts,validation,29.745982422493398
100,0.20999999344348907,0.3799999952316284,0.4553948161543099,0.19570857048034665,mmlu:global_facts,test,292.00467093940824
32,0.375,0.5,0.66875,0.16277256421744823,mmlu:high_school_biology,validation,92.72504467796534
310,0.48709675669670105,0.5612903237342834,0.674622016743721,0.133045817190601,mmlu:high_school_biology,test,909.2110698753968
22,0.13636364042758942,0.4545454680919647,0.5087719298245614,0.4369908950545571,mmlu:high_school_chemistry,validation,65.56272711977363
203,0.19211822748184204,0.467980295419693,0.7603971232020014,0.1441551764023128,mmlu:high_school_chemistry,test,595.3128892211244
9,0.6666666865348816,0.7777777910232544,0.8055555555555556,0.16705913676155937,mmlu:high_school_computer_science,validation,28.359391052275896
100,0.5299999713897705,0.5699999928474426,0.6585708550782818,0.0847423368692398,mmlu:high_school_computer_science,test,295.30569399613887
22,0.5,0.4545454680919647,0.7479338842975206,0.240084168585864,mmlu:high_school_geography,validation,63.126895217224956
198,0.4343434274196625,0.5,0.6412998338870431,0.17865126301543882,mmlu:high_school_geography,test,579.3570843376219
21,0.523809552192688,0.5714285969734192,0.7090909090909091,0.10909102360407512,mmlu:high_school_government_and_politics,validation,63.238851733505726
193,0.5388600826263428,0.559585452079773,0.6661084701815039,0.12570225790992307,mmlu:high_school_government_and_politics,test,564.9290212644264
43,0.4651162624359131,0.4651162624359131,0.6478260869565218,0.20168063806933026,mmlu:high_school_macroeconomics,validation,125.12219193857163
390,0.36153846979141235,0.4512820541858673,0.6446352787034663,0.19009425961054288,mmlu:high_school_macroeconomics,test,1133.4708427805454
29,0.03448275849223137,0.20689654350280762,0.07142857142857145,0.38632566969970183,mmlu:high_school_mathematics,validation,85.59682450257242
270,0.12222222238779068,0.24074073135852814,0.651643012402506,0.3574691143300799,mmlu:high_school_mathematics,test,792.8450917350128
26,0.38461539149284363,0.5384615659713745,0.69375,0.13634764460416943,mmlu:high_school_microeconomics,validation,75.48086354974657
238,0.3907563090324402,0.5,0.7368557656655543,0.16662107570832516,mmlu:high_school_microeconomics,test,691.9753093905747
17,0.1764705926179886,0.23529411852359772,0.45238095238095233,0.4772791406687569,mmlu:high_school_physics,validation,50.03327463567257
151,0.1986754983663559,0.2384105920791626,0.5115702479338844,0.44726778300392706,mmlu:high_school_physics,test,447.63815051689744
60,0.5833333730697632,0.6500000357627869,0.7559999999999999,0.0962493767340978,mmlu:high_school_psychology,validation,174.85068560298532
545,0.5541284680366516,0.5816513895988464,0.6210516992341865,0.12116663401279973,mmlu:high_school_psychology,test,1607.4410457536578
23,0.1304347813129425,0.3478260934352875,0.7166666666666667,0.24895907744117404,mmlu:high_school_statistics,validation,66.79766113776714
216,0.3055555522441864,0.46296295523643494,0.6590909090909092,0.15614090363184613,mmlu:high_school_statistics,test,642.4328095568344
22,0.5,0.5,0.8388429752066116,0.27036319537596276,mmlu:high_school_us_history,validation,74.57653916906565
204,0.6225490570068359,0.6372549533843994,0.714950403926782,0.1104319519272038,mmlu:high_school_us_history,test,684.2627531280741
23,0.3913043439388275,0.43478262424468994,0.626984126984127,0.32070334838784265,mmlu:human_aging,validation,67.42843740619719
223,0.37219732999801636,0.3946188688278198,0.5816695352839931,0.33678240572925106,mmlu:human_aging,test,646.0797525476664
12,0.3333333432674408,0.5833333730697632,0.75,0.2945751051108042,mmlu:human_sexuality,validation,35.559268632903695
131,0.4885496199131012,0.6183205842971802,0.6049440298507462,0.03670038294246178,mmlu:human_sexuality,test,384.7801787164062
13,0.38461539149284363,0.692307710647583,0.525,0.12108133847896865,mmlu:international_law,validation,38.23835432343185
121,0.5785123705863953,0.42975205183029175,0.3939775910364146,0.15229429587844978,mmlu:international_law,test,355.9489170778543
11,0.4545454680919647,0.3636363744735718,0.6666666666666666,0.38628928769718524,mmlu:jurisprudence,validation,31.860487424768507
108,0.5277777910232544,0.5555555820465088,0.5588235294117647,0.053682855985782776,mmlu:jurisprudence,test,314.1453436249867
18,0.5,0.7222222089767456,0.808641975308642,0.10875779390335082,mmlu:logical_fallacies,validation,53.616210042499006
163,0.5030674934387207,0.5950919985771179,0.6003462812405902,0.037163775025701215,mmlu:logical_fallacies,test,479.4889078810811
11,0.3636363744735718,0.4545454680919647,0.5,0.24463281306353482,mmlu:machine_learning,validation,32.997165811248124
112,0.1785714328289032,0.4732142984867096,0.5801630434782609,0.10857105787311282,mmlu:machine_learning,test,334.20362100191414
11,0.7272727489471436,0.5454545617103577,0.5833333333333333,0.20897368951277298,mmlu:management,validation,32.17998183891177
103,0.43689319491386414,0.5631067752838135,0.7413793103448275,0.11134514415148394,mmlu:management,test,295.639554544352
25,0.3199999928474426,0.4399999976158142,0.8566176470588235,0.2715893220901489,mmlu:marketing,validation,72.17199665494263
234,0.4829060137271881,0.5256410241127014,0.6636071089007534,0.15201996254105854,mmlu:marketing,test,677.703968747519
11,0.7272727489471436,0.7272727489471436,0.5,0.21904567696831445,mmlu:medical_genetics,validation,32.22779894899577
100,0.5799999833106995,0.5999999642372131,0.7027914614121511,0.10410792887210846,mmlu:medical_genetics,test,291.16580116469413
38,0.5,0.6315789222717285,0.7686980609418282,0.16943376158413131,mmlu:moral_disputes,validation,111.15474974550307
346,0.39306357502937317,0.5115606784820557,0.6522233893557423,0.13379126649371462,mmlu:moral_disputes,test,1021.7049642363563
33,0.4545454680919647,0.39393940567970276,0.5129629629629631,0.2253323287674875,mmlu:nutrition,validation,99.79471425432712
306,0.4019607901573181,0.5359477400779724,0.598649429117242,0.07678786348673251,mmlu:nutrition,test,897.2431419482455
34,0.4117647111415863,0.5,0.7017857142857142,0.21164957214804256,mmlu:philosophy,validation,99.87765855062753
311,0.3376205861568451,0.45016077160835266,0.6291030975496995,0.2417683656959288,mmlu:philosophy,test,907.3944889847189
35,0.4000000059604645,0.48571428656578064,0.7431972789115646,0.2139667068208967,mmlu:prehistory,validation,104.4093349929899
324,0.4691358208656311,0.5185185074806213,0.6261283659730722,0.12370719769854603,mmlu:prehistory,test,1050.8237732369453
69,0.4057971239089966,0.49275362491607666,0.7081881533101045,0.18432524152424026,mmlu:professional_psychology,validation,206.2015338242054
612,0.3807189464569092,0.4493464231491089,0.6361953186044141,0.22860585581632997,mmlu:professional_psychology,test,1811.8967145057395
12,0.25,0.4166666865348816,0.888888888888889,0.2742167164882024,mmlu:public_relations,validation,35.428433950059116
110,0.33636361360549927,0.44545453786849976,0.6815994076268049,0.19533489834178577,mmlu:public_relations,test,324.17237723991275
27,0.5555555820465088,0.5925925970077515,0.6194444444444445,0.12526315892184223,mmlu:security_studies,validation,80.83613851387054
245,0.5224489569664001,0.5306122303009033,0.4599358974358974,0.02874189177337955,mmlu:security_studies,test,730.1240615583956
22,0.5454545617103577,0.6363636255264282,0.6875,0.10666533220898022,mmlu:sociology,validation,64.446598473005
201,0.42786067724227905,0.5024875402450562,0.6605662285136501,0.1531330317407105,mmlu:sociology,test,593.7804299909621
11,0.5454545617103577,0.6363636255264282,0.65,0.22860101136294278,mmlu:us_foreign_policy,validation,31.93400940671563
100,0.6599999666213989,0.7199999690055847,0.7009803921568628,0.05188117802143096,mmlu:us_foreign_policy,test,291.7265010457486
18,0.3333333432674408,0.3888888955116272,0.48611111111111105,0.19734656810760498,mmlu:virology,validation,52.61943347379565
166,0.34939756989479065,0.5421686768531799,0.6077586206896552,0.04693171453763208,mmlu:virology,test,489.989060360007
19,0.7894737124443054,0.7368420958518982,0.7166666666666667,0.11411528838308233,mmlu:world_religions,validation,55.30579835455865
171,0.6725146174430847,0.6666666865348816,0.6428571428571429,0.04167648609618694,mmlu:world_religions,test,500.683620871976
