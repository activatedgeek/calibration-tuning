N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.4545454680919647,0.3636363744735718,0.033333333333333326,0.4105936288833618,mmlu:abstract_algebra,validation,5.629954953910783
100,0.28999999165534973,0.6299999952316284,0.5475959203496842,0.07604956209659579,mmlu:abstract_algebra,test,3.582981174113229
14,0.4285714328289032,0.5,0.6979166666666666,0.20567942091396876,mmlu:anatomy,validation,0.7133853798732162
135,0.5703703761100769,0.6296296119689941,0.7295118674429019,0.09835126311690717,mmlu:anatomy,test,3.3275003638118505
16,0.375,0.625,0.6416666666666667,0.09974781423807144,mmlu:astronomy,validation,0.8132761570159346
152,0.41447368264198303,0.6447368264198303,0.7938291421437489,0.04700180103904322,mmlu:astronomy,test,4.982954980107024
11,0.6363636255264282,0.7272727489471436,0.6785714285714286,0.08663925257596101,mmlu:business_ethics,validation,0.7211266541853547
100,0.3499999940395355,0.4699999988079071,0.6696703296703296,0.14592674314975737,mmlu:business_ethics,test,4.268025598023087
29,0.24137930572032928,0.48275861144065857,0.5584415584415584,0.1318525363659037,mmlu:clinical_knowledge,validation,0.9998945440165699
265,0.35849055647850037,0.6113207340240479,0.6475541795665635,0.061334344575989914,mmlu:clinical_knowledge,test,7.398679697886109
16,0.25,0.25,0.71875,0.45616959035396576,mmlu:college_biology,validation,0.7935240380465984
144,0.3958333432674408,0.4236111044883728,0.6460980036297641,0.2809201731450028,mmlu:college_biology,test,5.205002518836409
8,0.125,0.125,0.8571428571428572,0.4437599182128906,mmlu:college_chemistry,validation,0.5624747311230749
100,0.23000000417232513,0.33000001311302185,0.6860530773574253,0.2908511078357697,mmlu:college_chemistry,test,4.557880175998434
11,0.09090909361839294,0.27272728085517883,0.30000000000000004,0.37072609771381726,mmlu:college_computer_science,validation,1.028778000967577
100,0.20999999344348907,0.4699999988079071,0.6220614828209765,0.16303253054618835,mmlu:college_computer_science,test,7.572044367901981
11,0.09090909361839294,0.6363636255264282,0.0,0.2196272069757635,mmlu:college_mathematics,validation,0.815127259818837
100,0.20000000298023224,0.6499999761581421,0.6221875,0.08097233474254611,mmlu:college_mathematics,test,5.340891696047038
22,0.5,0.5909090638160706,0.7190082644628099,0.04023005745627661,mmlu:college_medicine,validation,0.9628108830656856
173,0.39306357502937317,0.5317919254302979,0.5967086834733893,0.10143577191181954,mmlu:college_medicine,test,9.306520791957155
11,0.4545454680919647,0.5454545617103577,0.7666666666666666,0.1971307017586448,mmlu:college_physics,validation,0.649798768106848
102,0.23529411852359772,0.2647058963775635,0.6199252136752137,0.39593180195958017,mmlu:college_physics,test,4.510914216982201
11,0.6363636255264282,0.5454545617103577,0.6428571428571428,0.2718596729365262,mmlu:computer_security,validation,0.6118311979807913
100,0.49000000953674316,0.5199999809265137,0.5904361744697879,0.1226073980331421,mmlu:computer_security,test,3.0474652380216867
26,0.3076923191547394,0.4615384638309479,0.8333333333333334,0.19924176656282863,mmlu:conceptual_physics,validation,0.7760702911764383
235,0.48085105419158936,0.5787234306335449,0.6853329464674307,0.09037194302741516,mmlu:conceptual_physics,test,5.690667669055983
12,0.5,0.5833333134651184,0.7083333333333334,0.12645478049914044,mmlu:econometrics,validation,0.7871086117811501
114,0.21929824352264404,0.5614035129547119,0.6092134831460674,0.10311743721627352,mmlu:econometrics,test,5.994487472809851
16,0.3125,0.125,0.1272727272727273,0.4502992033958435,mmlu:electrical_engineering,validation,0.752819349989295
145,0.2896551787853241,0.4689655303955078,0.5888811835413778,0.11111270148178627,mmlu:electrical_engineering,test,5.260010275058448
41,0.3658536672592163,0.39024388790130615,0.3782051282051282,0.21520486692102944,mmlu:elementary_mathematics,validation,1.74527533701621
378,0.44708994030952454,0.5052909851074219,0.5792021743438747,0.1264006064997779,mmlu:elementary_mathematics,test,14.311188084073365
14,0.4285714328289032,0.5,0.6875000000000001,0.11148979408400399,mmlu:formal_logic,validation,0.755193738033995
126,0.3095238208770752,0.3492063581943512,0.4939581491305629,0.252130357045976,mmlu:formal_logic,test,5.786394943017513
10,0.20000000298023224,0.5,0.46875,0.1170741319656372,mmlu:global_facts,validation,0.47030844213441014
100,0.1899999976158142,0.36000001430511475,0.5305393112410657,0.2194206416606903,mmlu:global_facts,test,3.2722331990953535
32,0.46875,0.59375,0.5803921568627451,0.19521606527268887,mmlu:high_school_biology,validation,1.2452071751467884
310,0.5064516067504883,0.5645161271095276,0.6885849881353814,0.12872845030600022,mmlu:high_school_biology,test,10.756600209046155
22,0.13636364042758942,0.4545454680919647,0.7982456140350878,0.34811077334664087,mmlu:high_school_chemistry,validation,1.0671615730971098
203,0.2019704431295395,0.467980295419693,0.7501505570611262,0.14325958490371704,mmlu:high_school_chemistry,test,8.53252917691134
9,0.4444444477558136,0.5555555820465088,0.5,0.2505887945493062,mmlu:high_school_computer_science,validation,0.7292480310425162
100,0.5699999928474426,0.6100000143051147,0.6578947368421053,0.08089078485965731,mmlu:high_school_computer_science,test,6.620292023988441
18,0.7222222089767456,0.7222222089767456,0.7307692307692307,0.13278333014912072,mmlu:high_school_european_history,validation,5.182341389823705
165,0.678787887096405,0.6969696879386902,0.7464622641509434,0.12561964663592254,mmlu:high_school_european_history,test,46.760510079097
22,0.3636363744735718,0.40909090638160706,0.7366071428571428,0.29161420735445887,mmlu:high_school_geography,validation,0.7313934240955859
198,0.4444444477558136,0.4898989796638489,0.6130681818181818,0.18999707156961615,mmlu:high_school_geography,test,5.1108618741855025
21,0.5714285969734192,0.6190476417541504,0.6574074074074074,0.09612112385886057,mmlu:high_school_government_and_politics,validation,0.7852298598736525
193,0.5544041395187378,0.5595855116844177,0.6160073896978917,0.12687440950018136,mmlu:high_school_government_and_politics,test,5.575331205967814
43,0.44186046719551086,0.4883720874786377,0.6732456140350878,0.18121517952098404,mmlu:high_school_macroeconomics,validation,1.2454813870135695
390,0.3692307770252228,0.4769230782985687,0.682983288166215,0.16532104779512458,mmlu:high_school_macroeconomics,test,10.11362141603604
29,0.06896551698446274,0.24137930572032928,0.4444444444444445,0.3554204373524107,mmlu:high_school_mathematics,validation,1.562983935000375
270,0.12962962687015533,0.2518518567085266,0.5651063829787234,0.3435285577067622,mmlu:high_school_mathematics,test,12.575770837021992
26,0.42307692766189575,0.5769230723381042,0.7454545454545455,0.1891750739170955,mmlu:high_school_microeconomics,validation,0.8337304969318211
238,0.3781512677669525,0.48739495873451233,0.7274399399399399,0.18038991945130484,mmlu:high_school_microeconomics,test,6.216590929077938
17,0.1764705926179886,0.23529411852359772,0.6428571428571428,0.49773086169186764,mmlu:high_school_physics,validation,0.9214819660410285
151,0.20529800653457642,0.23178808391094208,0.4962365591397849,0.4527623029734126,mmlu:high_school_physics,test,6.572871198877692
60,0.6333333253860474,0.6833333373069763,0.7559808612440191,0.06993801991144817,mmlu:high_school_psychology,validation,2.2134438240900636
545,0.5596330165863037,0.5761467814445496,0.6196653005464481,0.12626584812041816,mmlu:high_school_psychology,test,18.68042759387754
23,0.30434781312942505,0.47826087474823,0.5714285714285714,0.11991857445758321,mmlu:high_school_statistics,validation,1.5096661779098213
216,0.32870370149612427,0.48148149251937866,0.6630888780961631,0.13755155051196066,mmlu:high_school_statistics,test,12.753971687052399
22,0.5909090638160706,0.5909090638160706,0.888888888888889,0.2773692878809842,mmlu:high_school_us_history,validation,4.918973874067888
204,0.6421568393707275,0.656862735748291,0.7524835302729269,0.09341958252822653,mmlu:high_school_us_history,test,44.53094841586426
26,0.5769230723381042,0.5769230723381042,0.6333333333333334,0.18617867735716012,mmlu:high_school_world_history,validation,4.184170287102461
237,0.4388185739517212,0.4388185739517212,0.7223467322151533,0.30973196029663097,mmlu:high_school_world_history,test,33.8740222027991
23,0.30434781312942505,0.3478260934352875,0.7857142857142857,0.4046332706575808,mmlu:human_aging,validation,0.7801906859967858
223,0.34529146552085876,0.36771300435066223,0.6485500800569295,0.36415170473902747,mmlu:human_aging,test,5.530757829081267
12,0.3333333432674408,0.5833333134651184,0.53125,0.2888531635204951,mmlu:human_sexuality,validation,0.5604969700798392
131,0.49618321657180786,0.5954198241233826,0.6672494172494173,0.02661946893648339,mmlu:human_sexuality,test,3.733291298849508
13,0.4615384638309479,0.6153846383094788,0.5714285714285714,0.03964524544202366,mmlu:international_law,validation,0.6417977688834071
121,0.5619834661483765,0.44628098607063293,0.4787735849056604,0.1334948436287809,mmlu:international_law,test,4.248334233183414
11,0.4545454680919647,0.4545454680919647,0.6833333333333333,0.2942183397032998,mmlu:jurisprudence,validation,0.5301789320074022
108,0.49074074625968933,0.5370370149612427,0.6060034305317324,0.06872447883641279,mmlu:jurisprudence,test,3.2705478600692004
18,0.5,0.6666666865348816,0.8518518518518519,0.10045352247026233,mmlu:logical_fallacies,validation,0.7443891551811248
163,0.47852760553359985,0.5950919985771179,0.6625188536953243,0.04347448480641182,mmlu:logical_fallacies,test,5.254679186968133
11,0.1818181872367859,0.5454545617103577,1.0,0.17973073504187842,mmlu:machine_learning,validation,0.7269972749054432
112,0.2767857015132904,0.5,0.5631222620469932,0.08813658835632464,mmlu:machine_learning,test,5.531863821204752
11,0.6363636255264282,0.6363636255264282,0.6964285714285714,0.0992262363433838,mmlu:management,validation,0.46401998098008335
103,0.3980582654476166,0.582524299621582,0.7606215578284815,0.12137542766274759,mmlu:management,test,2.4310479830019176
25,0.2800000011920929,0.4000000059604645,0.8174603174603174,0.28671098470687867,mmlu:marketing,validation,0.9534333199262619
234,0.47863247990608215,0.5213675498962402,0.6735948477751756,0.1558135032144367,mmlu:marketing,test,6.550321460003033
11,0.7272727489471436,0.7272727489471436,0.875,0.24845948002555154,mmlu:medical_genetics,validation,0.4724128369707614
100,0.550000011920929,0.5899999737739563,0.7375757575757577,0.11230168998241424,mmlu:medical_genetics,test,2.4947315100580454
86,0.5930232405662537,0.604651153087616,0.7201680672268909,0.10272489037624627,mmlu:miscellaneous,validation,2.27007778105326
783,0.6245210766792297,0.6704980731010437,0.6982909728308502,0.03536415663411028,mmlu:miscellaneous,test,19.095974608091637
38,0.3684210479259491,0.4736842215061188,0.7410714285714286,0.27189917627133825,mmlu:moral_disputes,validation,1.4200405669398606
346,0.40751445293426514,0.5231214165687561,0.6792769417055872,0.12349272118827512,mmlu:moral_disputes,test,11.064646070124581
100,0.5899999737739563,0.5799999833106995,0.5845390657296403,0.03721289038658139,mmlu:moral_scenarios,validation,5.596553260926157
895,0.5329608917236328,0.6134078502655029,0.6384776263127802,0.038984712209115494,mmlu:moral_scenarios,test,47.78168473299593
33,0.39393940567970276,0.3333333432674408,0.4153846153846154,0.2894571206786416,mmlu:nutrition,validation,1.4511720528826118
306,0.4346405267715454,0.5588235259056091,0.6018731800599765,0.09472458405432357,mmlu:nutrition,test,11.292497061891481
34,0.38235294818878174,0.44117647409439087,0.6831501831501833,0.2521386129014633,mmlu:philosophy,validation,1.189650523941964
311,0.34405145049095154,0.4565916359424591,0.6720725673446949,0.20993823809639056,mmlu:philosophy,test,8.473011736059561
35,0.37142857909202576,0.4000000059604645,0.7132867132867133,0.2824405738285609,mmlu:prehistory,validation,1.3408525369595736
324,0.45987653732299805,0.5216049551963806,0.6635858101629913,0.12023432828761914,mmlu:prehistory,test,9.907895736163482
31,0.19354838132858276,0.29032257199287415,0.4366666666666667,0.38065957446252147,mmlu:professional_accounting,validation,2.086357652908191
282,0.173758864402771,0.21985815465450287,0.6050188315669616,0.4679740369319915,mmlu:professional_accounting,test,17.01474394602701
170,0.4000000059604645,0.44117647409439087,0.5250865051903114,0.18763513074201696,mmlu:professional_law,validation,22.818423439050093
1534,0.35071706771850586,0.4276401698589325,0.6141424433794658,0.20289308539891648,mmlu:professional_law,test,209.6454036210198
31,0.4516128897666931,0.4516128897666931,0.5903361344537815,0.2477583731374433,mmlu:professional_medicine,validation,3.5206985629629344
272,0.35661765933036804,0.48161765933036804,0.6489543446244477,0.19576033248620875,mmlu:professional_medicine,test,29.18605110910721
69,0.43478259444236755,0.52173912525177,0.7320512820512821,0.16090305559877038,mmlu:professional_psychology,validation,2.895482210209593
612,0.3660130798816681,0.4215686321258545,0.6123780375552283,0.255721319929447,mmlu:professional_psychology,test,22.43173686414957
12,0.3333333432674408,0.5,0.75,0.26033681631088257,mmlu:public_relations,validation,0.5795781549531966
110,0.30909091234207153,0.4363636374473572,0.6987229102167182,0.203338422016664,mmlu:public_relations,test,3.4339730029460043
27,0.5925925970077515,0.6666666865348816,0.6505681818181819,0.09533430691118591,mmlu:security_studies,validation,1.4406497220043093
245,0.5469387769699097,0.5387755036354065,0.5387252924566357,0.02442632962246329,mmlu:security_studies,test,11.106143854092807
22,0.5,0.5454545617103577,0.6280991735537189,0.17177549546415155,mmlu:sociology,validation,0.8121126170735806
201,0.45771142840385437,0.5323383212089539,0.7108595931392102,0.12384412122603079,mmlu:sociology,test,5.482708973111585
11,0.7272727489471436,0.8181818127632141,0.6666666666666667,0.26824962550943543,mmlu:us_foreign_policy,validation,0.559521917020902
100,0.6100000143051147,0.6700000166893005,0.7488440521227407,0.053897738456726046,mmlu:us_foreign_policy,test,2.858134549111128
18,0.3888888955116272,0.5555555820465088,0.5324675324675324,0.08300776614083183,mmlu:virology,validation,0.8235442701261491
166,0.34939759969711304,0.5481927990913391,0.5806194125159643,0.07079727606601025,mmlu:virology,test,4.716914489865303
19,0.6842105388641357,0.7368420958518982,0.6858974358974359,0.17370299602809705,mmlu:world_religions,validation,0.6582098808139563
171,0.6725146174430847,0.6900584697723389,0.6958850931677019,0.036229511102040625,mmlu:world_religions,test,3.9981697138864547
