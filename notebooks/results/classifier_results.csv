N,logits_ece,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts,model_name,train_mode,eval_mode,fuzzy_gpt-3.5-turbo-1106_acc,fuzzy_gpt-3.5-turbo-1106_unc_acc,fuzzy_gpt-3.5-turbo-1106_unc_auroc,fuzzy_gpt-3.5-turbo-1106_unc_ece
11,0.12410461631688204,0.27272728085517883,0.7272727489471436,0.75,0.2737883708693764,mmlu:abstract_algebra,validation,4.572419252246618,llama2_7b,choice,choice,,,,
100,0.07953203886747359,0.32999998331069946,0.6599999666213989,0.5626413387607418,0.08722876965999601,mmlu:abstract_algebra,test,10.942548049613833,llama2_7b,choice,choice,,,,
14,0.22909083962440496,0.6428571939468384,0.5,0.2666666666666666,0.23303002970559258,mmlu:anatomy,validation,1.6590513112023473,llama2_7b,choice,choice,,,,
135,0.07160205487851744,0.4740740656852722,0.5925925970077515,0.5795554577464789,0.1230466255435237,mmlu:anatomy,test,15.729030864778906,llama2_7b,choice,choice,,,,
16,0.19345908984541893,0.4375,0.625,0.5555555555555556,0.07419443503022195,mmlu:astronomy,validation,2.9900210769847035,llama2_7b,choice,choice,,,,
152,0.07946011345637473,0.43421053886413574,0.5394737124443054,0.642706131078224,0.18586426541993495,mmlu:astronomy,test,27.537310626823455,llama2_7b,choice,choice,,,,
11,0.27413684400645166,0.6363636255264282,0.5454545617103577,0.8392857142857143,0.10348952358419244,mmlu:business_ethics,validation,2.0859912019222975,llama2_7b,choice,choice,,,,
100,0.06629755079746247,0.5099999904632568,0.5600000023841858,0.49519807923169273,0.05597925961017612,mmlu:business_ethics,test,18.029196294024587,llama2_7b,choice,choice,,,,
29,0.19685095548629758,0.41379308700561523,0.41379308700561523,0.43137254901960786,0.287348942510013,mmlu:clinical_knowledge,validation,3.8486860231496394,llama2_7b,choice,choice,,,,
265,0.06912144422531129,0.47924530506134033,0.501886785030365,0.6070409677051238,0.20773469974409856,mmlu:clinical_knowledge,test,34.46673904871568,llama2_7b,choice,choice,,,,
16,0.11853781528770924,0.375,0.4375,0.7666666666666666,0.2742762304842472,mmlu:college_biology,validation,2.4872198780067265,llama2_7b,choice,choice,,,,
144,0.053375539059440306,0.4513888955116272,0.472222238779068,0.5518987341772152,0.23960318954454526,mmlu:college_biology,test,22.606402272824198,llama2_7b,choice,choice,,,,
8,0.2892436720430851,0.5,0.75,0.4375,0.16717343032360077,mmlu:college_chemistry,validation,1.5960121699608862,llama2_7b,choice,choice,,,,
100,0.032890627086162555,0.3799999952316284,0.5600000023841858,0.5649405772495757,0.10042951703071595,mmlu:college_chemistry,test,17.289100375026464,llama2_7b,choice,choice,,,,
11,0.3420012484897267,0.5454545617103577,0.7272727489471436,0.6333333333333333,0.09820052168586037,mmlu:college_computer_science,validation,2.866351356729865,llama2_7b,choice,choice,,,,
100,0.1280004048347473,0.35999998450279236,0.47999998927116394,0.6319444444444444,0.15446908473968507,mmlu:college_computer_science,test,25.989061968866736,llama2_7b,choice,choice,,,,
11,0.03877500783313405,0.27272728085517883,0.6363636255264282,0.16666666666666666,0.23662409457293423,mmlu:college_mathematics,validation,2.060546675696969,llama2_7b,choice,choice,,,,
100,0.054067380130290985,0.3400000035762787,0.5600000023841858,0.6343582887700534,0.03451708078384402,mmlu:college_mathematics,test,17.30486492579803,llama2_7b,choice,choice,,,,
22,0.2142181071368131,0.4545454680919647,0.40909093618392944,0.5666666666666667,0.32996419343081385,mmlu:college_medicine,validation,3.7721268692985177,llama2_7b,choice,choice,,,,
173,0.11501230221952316,0.39306357502937317,0.4393063485622406,0.6292016806722689,0.2793041340188484,mmlu:college_medicine,test,39.967421696987,llama2_7b,choice,choice,,,,
11,0.21258875998583704,0.5454545617103577,0.5454545617103577,0.5333333333333333,0.185715296051719,mmlu:college_physics,validation,1.7676662309095263,llama2_7b,choice,choice,,,,
102,0.22993910575614251,0.2450980544090271,0.5882353186607361,0.40935064935064935,0.15749403249983696,mmlu:college_physics,test,15.103582268115133,llama2_7b,choice,choice,,,,
11,0.22450180216269058,0.5454545617103577,0.7272727489471436,0.7666666666666666,0.188430287621238,mmlu:computer_security,validation,1.7020811620168388,llama2_7b,choice,choice,,,,
100,0.08922634243965148,0.5699999928474426,0.6100000143051147,0.5862913096695226,0.12441659688949587,mmlu:computer_security,test,12.764286846388131,llama2_7b,choice,choice,,,,
26,0.18823484159432927,0.42307692766189575,0.6153846383094788,0.34545454545454546,0.04262561752245978,mmlu:conceptual_physics,validation,2.650234506931156,llama2_7b,choice,choice,,,,
235,0.07460749441004814,0.42978721857070923,0.5361701846122742,0.4978572484114083,0.11644166758719914,mmlu:conceptual_physics,test,22.659956952091306,llama2_7b,choice,choice,,,,
12,0.22660113126039508,0.1666666716337204,0.5833333730697632,0.14999999999999997,0.03329059978326161,mmlu:econometrics,validation,2.3666772302240133,llama2_7b,choice,choice,,,,
114,0.160347292036341,0.2631579041481018,0.5350877046585083,0.6948412698412698,0.10620302171037907,mmlu:econometrics,test,21.53002143697813,llama2_7b,choice,choice,,,,
16,0.2047780603170395,0.5625,0.625,0.46031746031746035,0.17381786555051804,mmlu:electrical_engineering,validation,2.1764633068814874,llama2_7b,choice,choice,,,,
145,0.06166888701504676,0.41379308700561523,0.5034482479095459,0.5233333333333333,0.18290567521391246,mmlu:electrical_engineering,test,18.79284348571673,llama2_7b,choice,choice,,,,
41,0.14025519025035021,0.24390242993831635,0.2926829159259796,0.2516129032258065,0.4410868461539106,mmlu:elementary_mathematics,validation,6.941825516056269,llama2_7b,choice,choice,,,,
378,0.07987583432563398,0.23544973134994507,0.357142835855484,0.49475137047548695,0.29596780689935837,mmlu:elementary_mathematics,test,61.50822301115841,llama2_7b,choice,choice,,,,
14,0.130864645753588,0.2142857313156128,0.5714285969734192,0.45454545454545453,0.13519981929234096,mmlu:formal_logic,validation,3.387435161974281,llama2_7b,choice,choice,,,,
126,0.06414164673714412,0.3809524178504944,0.6111111640930176,0.4099893162393162,0.05788111260959081,mmlu:formal_logic,test,23.985832845792174,llama2_7b,choice,choice,,,,
10,0.3176395118236542,0.0,0.800000011920929,,0.2925922393798828,mmlu:global_facts,validation,1.4411990670487285,llama2_7b,choice,choice,,,,
100,0.09342762321233748,0.3400000035762787,0.5099999904632568,0.573529411764706,0.11444991588592532,mmlu:global_facts,test,13.106270010117441,llama2_7b,choice,choice,,,,
32,0.181044046767056,0.34375,0.5625,0.6883116883116882,0.26333955116569996,mmlu:high_school_biology,validation,5.298727970104665,llama2_7b,choice,choice,,,,
310,0.05201598828838717,0.47741934657096863,0.522580623626709,0.6340298631965299,0.2043506876114876,mmlu:high_school_biology,test,50.720324125140905,llama2_7b,choice,choice,,,,
22,0.1400937952778556,0.3636363744735718,0.5909091234207153,0.7589285714285715,0.21360514651645313,mmlu:high_school_chemistry,validation,3.680306287948042,llama2_7b,choice,choice,,,,
203,0.0769685204393171,0.3645320236682892,0.467980295419693,0.5737481667714226,0.18648086745163497,mmlu:high_school_chemistry,test,32.11588848289102,llama2_7b,choice,choice,,,,
9,0.28806057572364796,0.5555555820465088,0.4444444477558136,0.6000000000000001,0.2831749386257595,mmlu:high_school_computer_science,validation,2.7245741710066795,llama2_7b,choice,choice,,,,
100,0.11607320010662078,0.3700000047683716,0.5399999618530273,0.5454740454740455,0.10032615423202515,mmlu:high_school_computer_science,test,29.723310838919133,llama2_7b,choice,choice,,,,
22,0.1442040042443709,0.7272727489471436,0.5909091234207153,0.7291666666666666,0.1466248550198295,mmlu:high_school_geography,validation,2.706533297896385,llama2_7b,choice,choice,,,,
198,0.09743383571957097,0.49494948983192444,0.5404040217399597,0.6052551020408163,0.12296214880365312,mmlu:high_school_geography,test,24.13745568273589,llama2_7b,choice,choice,,,,
21,0.10629567362013317,0.5714285969734192,0.5714285969734192,0.6944444444444444,0.14673268795013428,mmlu:high_school_government_and_politics,validation,3.135328152216971,llama2_7b,choice,choice,,,,
193,0.07709574560427294,0.6839377880096436,0.6839377880096436,0.6955414803775459,0.05108680348322179,mmlu:high_school_government_and_politics,test,28.08954467996955,llama2_7b,choice,choice,,,,
43,0.1392642717028773,0.3255814015865326,0.3255814015865326,0.5024630541871922,0.4031938771868861,mmlu:high_school_macroeconomics,validation,5.43916077259928,llama2_7b,choice,choice,,,,
390,0.03156019563858327,0.4435897469520569,0.48974359035491943,0.598492315068858,0.23720889718104632,mmlu:high_school_macroeconomics,test,48.818155301734805,llama2_7b,choice,choice,,,,
29,0.13491651724124776,0.4482758641242981,0.5862069129943848,0.27403846153846156,0.06560764641597354,mmlu:high_school_mathematics,validation,4.630914055742323,llama2_7b,choice,choice,,,,
270,0.03309374628243622,0.28148147463798523,0.5518518686294556,0.5417797069994574,0.0352946709703516,mmlu:high_school_mathematics,test,41.80696285190061,llama2_7b,choice,choice,,,,
26,0.20861088427213517,0.3076923191547394,0.46153849363327026,0.8055555555555556,0.2110745562956884,mmlu:high_school_microeconomics,validation,3.2758860760368407,llama2_7b,choice,choice,,,,
238,0.09542872374799069,0.4495798647403717,0.47478994727134705,0.6160376685453379,0.20731214339993587,mmlu:high_school_microeconomics,test,30.24552221922204,llama2_7b,choice,choice,,,,
17,0.0683927851564744,0.29411765933036804,0.4117647111415863,0.6,0.183454972856185,mmlu:high_school_physics,validation,3.1054706210270524,llama2_7b,choice,choice,,,,
151,0.08500831154798041,0.2781457006931305,0.38410595059394836,0.4844910441240716,0.22833482477049163,mmlu:high_school_physics,test,26.071333781816065,llama2_7b,choice,choice,,,,
60,0.16206413507461548,0.6666666865348816,0.6666666865348816,0.601875,0.08823228279749554,mmlu:high_school_psychology,validation,9.61674099508673,llama2_7b,choice,choice,,,,
545,0.08431016540308613,0.6385321021080017,0.6220183372497559,0.6032805297858685,0.10585238944499863,mmlu:high_school_psychology,test,88.44137656223029,llama2_7b,choice,choice,,,,
23,0.1365445126657901,0.3913043439388275,0.52173912525177,0.6349206349206349,0.1347023844718933,mmlu:high_school_statistics,validation,5.804115817882121,llama2_7b,choice,choice,,,,
216,0.1113107421055988,0.25462964177131653,0.46759259700775146,0.5168831168831169,0.14285228898127875,mmlu:high_school_statistics,test,55.89040675992146,llama2_7b,choice,choice,,,,
22,0.282535351135514,0.6818181872367859,0.6818181872367859,0.3142857142857143,0.12602596662261273,mmlu:high_school_us_history,validation,21.642328904941678,llama2_7b,choice,choice,,,,
204,0.11903949388686351,0.5980392098426819,0.6029412150382996,0.612405037984806,0.08062704287323297,mmlu:high_school_us_history,test,192.05547555722296,llama2_7b,choice,choice,,,,
23,0.2809789556524028,0.6521739363670349,0.6086956858634949,0.5583333333333333,0.14402182465014252,mmlu:human_aging,validation,2.389809228014201,llama2_7b,choice,choice,,,,
223,0.07518315649353334,0.5515695214271545,0.5201793909072876,0.5924796747967479,0.16912438757216447,mmlu:human_aging,test,22.36127217998728,llama2_7b,choice,choice,,,,
12,0.26402338594198227,0.5833333730697632,0.75,0.8,0.11879666646321614,mmlu:human_sexuality,validation,1.4606353607960045,llama2_7b,choice,choice,,,,
131,0.08122670195484889,0.5343511700630188,0.5114504098892212,0.49156908665105387,0.14604375289596674,mmlu:human_sexuality,test,15.445458874106407,llama2_7b,choice,choice,,,,
13,0.2052622208228478,0.8461538553237915,0.692307710647583,0.6363636363636364,0.17207558338458723,mmlu:international_law,validation,2.7150981053709984,llama2_7b,choice,choice,,,,
121,0.07261978668614853,0.6198346614837646,0.6694214344024658,0.5666666666666668,0.12878814167227629,mmlu:international_law,test,23.53784168418497,llama2_7b,choice,choice,,,,
11,0.2205446470867504,0.5454545617103577,0.6363636255264282,0.7333333333333333,0.08148620887236162,mmlu:jurisprudence,validation,1.516364446375519,llama2_7b,choice,choice,,,,
108,0.1359325937098927,0.5,0.5740740895271301,0.5257201646090536,0.054066262863300456,mmlu:jurisprudence,test,13.818672809749842,llama2_7b,choice,choice,,,,
18,0.1694058063957426,0.7222222089767456,0.6111111044883728,0.4,0.1634913351800707,mmlu:logical_fallacies,validation,2.5464170882478356,llama2_7b,choice,choice,,,,
163,0.10805745450265569,0.558282196521759,0.5337423086166382,0.4056013431013431,0.10255528629923162,mmlu:logical_fallacies,test,22.802084679249674,llama2_7b,choice,choice,,,,
11,0.1587033515626734,0.1818181872367859,0.8181818723678589,0.7777777777777779,0.2307405092499473,mmlu:machine_learning,validation,2.269256600178778,llama2_7b,choice,choice,,,,
112,0.07231726204710348,0.4017857313156128,0.6071428656578064,0.4398009950248756,0.044252514306988004,mmlu:machine_learning,test,22.115383084863424,llama2_7b,choice,choice,,,,
11,0.31559918414462695,0.27272728085517883,0.5454545617103577,0.625,0.2109360694885254,mmlu:management,validation,1.10107844742015,llama2_7b,choice,choice,,,,
103,0.1128544046462161,0.6019417643547058,0.6019417643547058,0.6123131392604249,0.07540450223441263,mmlu:management,test,9.424663782119751,llama2_7b,choice,choice,,,,
25,0.2445056021213532,0.7999999523162842,0.7199999690055847,0.6699999999999999,0.10019187450408937,mmlu:marketing,validation,3.3497691368684173,llama2_7b,choice,choice,,,,
234,0.08369208260988578,0.6794872283935547,0.6452991962432861,0.6245702306079666,0.04029165679572993,mmlu:marketing,test,29.78887425130233,llama2_7b,choice,choice,,,,
11,0.1461060480637984,0.8181818723678589,0.7272727489471436,0.7222222222222222,0.23769787766716696,mmlu:medical_genetics,validation,1.4299561730585992,llama2_7b,choice,choice,,,,
100,0.10231235802173613,0.4899999797344208,0.6499999761581421,0.5396158463385354,0.06791745543479923,mmlu:medical_genetics,test,11.476417641155422,llama2_7b,choice,choice,,,,
38,0.17260245194560606,0.3684210479259491,0.6052631735801697,0.6428571428571428,0.06640422657916421,mmlu:moral_disputes,validation,5.626349119935185,llama2_7b,choice,choice,,,,
346,0.08882301968301651,0.5,0.5433526039123535,0.5145176918707608,0.10302893739904281,mmlu:moral_disputes,test,51.09587521292269,llama2_7b,choice,choice,,,,
33,0.166941144249656,0.6363636255264282,0.575757622718811,0.4880952380952381,0.1519577719948509,mmlu:nutrition,validation,6.210490095894784,llama2_7b,choice,choice,,,,
306,0.04637104058577346,0.5,0.5588235259056091,0.5091631423811356,0.09556801880107207,mmlu:nutrition,test,57.276010365691036,llama2_7b,choice,choice,,,,
34,0.23233361191609328,0.38235294818878174,0.6176470518112183,0.6538461538461539,0.09689515478470748,mmlu:philosophy,validation,3.8845141078345478,llama2_7b,choice,choice,,,,
311,0.06321764845173461,0.5723472833633423,0.581993579864502,0.4950367491763116,0.04800779049036202,mmlu:philosophy,test,34.26064488105476,llama2_7b,choice,choice,,,,
35,0.18537056701523916,0.4000000059604645,0.5428571701049805,0.7312925170068028,0.1488580908094134,mmlu:prehistory,validation,6.097642996348441,llama2_7b,choice,choice,,,,
324,0.08157189475533404,0.5154321193695068,0.5277777910232544,0.5808192532133185,0.1383729978108112,mmlu:prehistory,test,54.34063058393076,llama2_7b,choice,choice,,,,
69,0.12735103092331818,0.4057971239089966,0.52173912525177,0.5866724738675958,0.1152158059935639,mmlu:professional_psychology,validation,12.881097577046603,llama2_7b,choice,choice,,,,
612,0.05425680199869318,0.4264706075191498,0.5032680034637451,0.5825119254238028,0.13509263107979222,mmlu:professional_psychology,test,108.85832861298695,llama2_7b,choice,choice,,,,
12,0.18688620378573736,0.4166666865348816,0.4166666865348816,0.6857142857142857,0.2869807233413061,mmlu:public_relations,validation,1.8219989640638232,llama2_7b,choice,choice,,,,
110,0.12326701716943221,0.5181818008422852,0.5090909004211426,0.5013240648791791,0.1401268325068734,mmlu:public_relations,test,14.866398796904832,llama2_7b,choice,choice,,,,
27,0.12266812390751308,0.4444444477558136,0.6666666865348816,0.5166666666666666,0.20805234379238552,mmlu:security_studies,validation,11.696355212014169,llama2_7b,choice,choice,,,,
245,0.06686869227156347,0.4693877398967743,0.5632652640342712,0.6017391304347826,0.10371979475021365,mmlu:security_studies,test,106.1834853310138,llama2_7b,choice,choice,,,,
22,0.1639018695462834,0.6363636255264282,0.7727273106575012,0.6428571428571429,0.17412291331724689,mmlu:sociology,validation,3.034083853941411,llama2_7b,choice,choice,,,,
201,0.08370824536280846,0.641791045665741,0.6467661261558533,0.5957149009474592,0.06912400829258249,mmlu:sociology,test,27.912260469049215,llama2_7b,choice,choice,,,,
11,0.2221881720152768,0.4545454680919647,0.7272727489471436,0.6666666666666667,0.31337597695263947,mmlu:us_foreign_policy,validation,1.5679013337939978,llama2_7b,choice,choice,,,,
100,0.07565865606069566,0.6499999761581421,0.6399999856948853,0.5259340659340659,0.07999681651592257,mmlu:us_foreign_policy,test,12.994238237850368,llama2_7b,choice,choice,,,,
18,0.34210363692707485,0.3888888955116272,0.3888888955116272,0.5844155844155844,0.2872968547874027,mmlu:virology,validation,2.6869327472522855,llama2_7b,choice,choice,,,,
166,0.1310483037707317,0.41566264629364014,0.4518072009086609,0.4757209024353803,0.20618521556796798,mmlu:virology,test,19.41527558164671,llama2_7b,choice,choice,,,,
19,0.24312088834611995,0.7894737124443054,0.5789473652839661,0.33333333333333337,0.07652087588059274,mmlu:world_religions,validation,1.7269439906813204,llama2_7b,choice,choice,,,,
171,0.149397482474645,0.7134503126144409,0.5789473652839661,0.44948143191702916,0.06822290685441759,mmlu:world_religions,test,14.519255785737187,llama2_7b,choice,choice,,,,
11,0.29379816759716376,0.4545454680919647,0.4545454680919647,0.23333333333333336,0.3467485471205278,mmlu:abstract_algebra,validation,5.036942113190889,llama2_13b_chat,choice,choice,,,,
100,0.16200531616806985,0.28999999165534973,0.4599999785423279,0.41330743079164645,0.18715773701667784,mmlu:abstract_algebra,test,19.29186688736081,llama2_13b_chat,choice,choice,,,,
14,0.20662898250988554,0.5714285969734192,0.4285714626312256,0.47916666666666663,0.25191038421222145,mmlu:anatomy,validation,2.8683422058820724,llama2_13b_chat,choice,choice,,,,
135,0.19448365834024214,0.5111110806465149,0.5777777433395386,0.6054018445322793,0.14030720437014546,mmlu:anatomy,test,27.40001267194748,llama2_13b_chat,choice,choice,,,,
16,0.11424661241471767,0.625,0.75,0.5166666666666666,0.146540567278862,mmlu:astronomy,validation,5.035607013851404,llama2_13b_chat,choice,choice,,,,
152,0.245416279097921,0.5657894611358643,0.5723684430122375,0.5525898520084567,0.10696384977353249,mmlu:astronomy,test,46.877386815845966,llama2_13b_chat,choice,choice,,,,
11,0.22440953959118237,0.5454545617103577,0.7272727489471436,0.7333333333333333,0.2012151208790866,mmlu:business_ethics,validation,3.455784149467945,llama2_13b_chat,choice,choice,,,,
100,0.24410267770290378,0.5299999713897705,0.6399999856948853,0.7310317141710156,0.12714961707592012,mmlu:business_ethics,test,30.765335265547037,llama2_13b_chat,choice,choice,,,,
29,0.3209612348984028,0.517241358757019,0.5517241358757019,0.5380952380952381,0.33780766150047037,mmlu:clinical_knowledge,validation,6.955583181232214,llama2_13b_chat,choice,choice,,,,
265,0.20924414148870502,0.5660377740859985,0.5849056839942932,0.6402898550724637,0.2338558604132454,mmlu:clinical_knowledge,test,60.539891958236694,llama2_13b_chat,choice,choice,,,,
16,0.20605568774044514,0.5625,0.625,0.5714285714285714,0.31913210079073906,mmlu:college_biology,validation,4.425133552402258,llama2_13b_chat,choice,choice,,,,
144,0.1936526567571693,0.5833333134651184,0.5902777910232544,0.557936507936508,0.12877733384569484,mmlu:college_biology,test,38.42077350616455,llama2_13b_chat,choice,choice,,,,
8,0.5105344615876675,0.125,0.375,0.8571428571428572,0.40367621928453445,mmlu:college_chemistry,validation,2.6090672090649605,llama2_13b_chat,choice,choice,,,,
100,0.2275681433081627,0.3700000047683716,0.47999998927116394,0.572930072930073,0.2665808790922165,mmlu:college_chemistry,test,29.206071570515633,llama2_13b_chat,choice,choice,,,,
11,0.15991395170038397,0.5454545617103577,0.4545454680919647,0.6,0.19814736192876642,mmlu:college_computer_science,validation,4.801807664334774,llama2_13b_chat,choice,choice,,,,
100,0.15642848163843157,0.5399999618530273,0.5,0.4472624798711755,0.1613986897468567,mmlu:college_computer_science,test,43.09007290005684,llama2_13b_chat,choice,choice,,,,
11,0.25650960748845886,0.27272728085517883,0.6363636255264282,0.41666666666666663,0.2525199272415855,mmlu:college_mathematics,validation,3.479535724967718,llama2_13b_chat,choice,choice,,,,
100,0.2351979598402977,0.3499999940395355,0.47999998927116394,0.56,0.133512601852417,mmlu:college_mathematics,test,29.627770897001028,llama2_13b_chat,choice,choice,,,,
22,0.44382848387414764,0.3636363744735718,0.40909093618392944,0.6696428571428572,0.3644780164415186,mmlu:college_medicine,validation,6.373677302151918,llama2_13b_chat,choice,choice,,,,
173,0.2904427091165775,0.4624277353286743,0.5433526039123535,0.6513440860215054,0.18219597181143787,mmlu:college_medicine,test,57.77925503998995,llama2_13b_chat,choice,choice,,,,
11,0.3878866867585615,0.4545454680919647,0.5454545617103577,0.6000000000000001,0.12118115750226108,mmlu:college_physics,validation,2.9309351556003094,llama2_13b_chat,choice,choice,,,,
102,0.370677268096045,0.2450980544090271,0.529411792755127,0.6174025974025974,0.12474997721466365,mmlu:college_physics,test,26.328570138663054,llama2_13b_chat,choice,choice,,,,
11,0.45247231830250134,0.6363636255264282,0.6363636255264282,0.6428571428571428,0.30370105938477954,mmlu:computer_security,validation,2.8772139735519886,llama2_13b_chat,choice,choice,,,,
100,0.2238504680991173,0.6499999761581421,0.699999988079071,0.7424175824175825,0.11065117299556734,mmlu:computer_security,test,21.95774706453085,llama2_13b_chat,choice,choice,,,,
26,0.31387063173147345,0.46153849363327026,0.692307710647583,0.6190476190476191,0.1257164707550636,mmlu:conceptual_physics,validation,4.670250795781612,llama2_13b_chat,choice,choice,,,,
235,0.3247843713202375,0.4127659499645233,0.5744680762290955,0.5729493500672345,0.1028108424328743,mmlu:conceptual_physics,test,39.51338516548276,llama2_13b_chat,choice,choice,,,,
12,0.49937231590350467,0.3333333432674408,0.3333333432674408,0.53125,0.40851569175720215,mmlu:econometrics,validation,3.907022275030613,llama2_13b_chat,choice,choice,,,,
114,0.30435455237564285,0.31578946113586426,0.3947368562221527,0.545405982905983,0.3064419804957875,mmlu:econometrics,test,36.27259403094649,llama2_13b_chat,choice,choice,,,,
16,0.39805904775857925,0.5,0.625,0.765625,0.07388580963015559,mmlu:electrical_engineering,validation,3.9132087379693985,llama2_13b_chat,choice,choice,,,,
145,0.2309398133179237,0.4965517222881317,0.5103448033332825,0.5019025875190258,0.16278440459021207,mmlu:electrical_engineering,test,33.09578661248088,llama2_13b_chat,choice,choice,,,,
41,0.25017098609994093,0.4146341383457184,0.4878048598766327,0.6397058823529412,0.2056451076414527,mmlu:elementary_mathematics,validation,12.043550692498684,llama2_13b_chat,choice,choice,,,,
378,0.31418251179198114,0.3253968060016632,0.5052909851074219,0.5029491471385302,0.19690489879360906,mmlu:elementary_mathematics,test,106.93241550400853,llama2_13b_chat,choice,choice,,,,
14,0.5272892628397261,0.0714285746216774,0.2142857313156128,0.0,0.524597874709538,mmlu:formal_logic,validation,4.658260725438595,llama2_13b_chat,choice,choice,,,,
126,0.32209860214165287,0.2857142984867096,0.3095238208770752,0.677932098765432,0.48552296653626453,mmlu:formal_logic,test,40.53512832149863,llama2_13b_chat,choice,choice,,,,
10,0.47349956631660467,0.20000000298023224,0.5,1.0,0.2951575696468353,mmlu:global_facts,validation,2.504490204155445,llama2_13b_chat,choice,choice,,,,
100,0.3165890657901764,0.3100000023841858,0.47999998927116394,0.541841982234689,0.1581971234083176,mmlu:global_facts,test,23.203473147004843,llama2_13b_chat,choice,choice,,,,
32,0.2618219470605254,0.5625,0.59375,0.6111111111111112,0.28069022111594677,mmlu:high_school_biology,validation,9.37384406849742,llama2_13b_chat,choice,choice,,,,
310,0.1704712515877139,0.6774193644523621,0.6387096643447876,0.5910238095238095,0.07903698971194607,mmlu:high_school_biology,test,87.5709333345294,llama2_13b_chat,choice,choice,,,,
22,0.30064125359058386,0.40909093618392944,0.40909093618392944,0.6752136752136753,0.3376301472837275,mmlu:high_school_chemistry,validation,6.370975516736507,llama2_13b_chat,choice,choice,,,,
203,0.2409859713662434,0.41379308700561523,0.4088670015335083,0.4628351340536215,0.30617660313404255,mmlu:high_school_chemistry,test,55.039476688951254,llama2_13b_chat,choice,choice,,,,
9,0.2520365847481621,0.7777777910232544,0.5555555820465088,0.5714285714285714,0.28481103314293754,mmlu:high_school_computer_science,validation,4.595639515668154,llama2_13b_chat,choice,choice,,,,
100,0.1541334843635559,0.5999999642372131,0.6299999952316284,0.6410416666666667,0.08199216187000274,mmlu:high_school_computer_science,test,48.73259499296546,llama2_13b_chat,choice,choice,,,,
22,0.15720224651423365,0.7272727489471436,0.7727273106575012,0.5729166666666666,0.11894437941637907,mmlu:high_school_geography,validation,4.789596550166607,llama2_13b_chat,choice,choice,,,,
198,0.18159390278536866,0.7070707082748413,0.6262626051902771,0.47857142857142865,0.07598221542859318,mmlu:high_school_geography,test,42.44875102490187,llama2_13b_chat,choice,choice,,,,
21,0.22747943231037682,0.7142857313156128,0.7142857313156128,0.5777777777777777,0.2742633876346406,mmlu:high_school_government_and_politics,validation,5.441782407462597,llama2_13b_chat,choice,choice,,,,
193,0.1270896543801757,0.7927460670471191,0.7668393850326538,0.6173202614379085,0.07601584764342234,mmlu:high_school_government_and_politics,test,47.83863925561309,llama2_13b_chat,choice,choice,,,,
43,0.2938208836455678,0.4651162624359131,0.6744186282157898,0.5065217391304349,0.08383814401404806,mmlu:high_school_macroeconomics,validation,9.633495569229126,llama2_13b_chat,choice,choice,,,,
390,0.23552503035618708,0.535897433757782,0.6307692527770996,0.4958893970234476,0.08944167846288438,mmlu:high_school_macroeconomics,test,85.23419977724552,llama2_13b_chat,choice,choice,,,,
29,0.23744304940618322,0.27586206793785095,0.6206896305084229,0.5238095238095238,0.15792068736306555,mmlu:high_school_mathematics,validation,8.284314073622227,llama2_13b_chat,choice,choice,,,,
270,0.2369200842248069,0.28148147463798523,0.5629629492759705,0.45560906131307655,0.07991999740953797,mmlu:high_school_mathematics,test,73.5268993973732,llama2_13b_chat,choice,choice,,,,
26,0.21208596000304591,0.6153846383094788,0.5769230723381042,0.525,0.17667085161575904,mmlu:high_school_microeconomics,validation,5.8392793126404285,llama2_13b_chat,choice,choice,,,,
238,0.1999973366741373,0.5840336680412292,0.6134454011917114,0.5371702637889688,0.08937589436018167,mmlu:high_school_microeconomics,test,52.53318331763148,llama2_13b_chat,choice,choice,,,,
17,0.5390769944471472,0.29411765933036804,0.5882353186607361,0.4666666666666667,0.2766119872822481,mmlu:high_school_physics,validation,5.314466241747141,llama2_13b_chat,choice,choice,,,,
151,0.3287348271600458,0.33774834871292114,0.5827814340591431,0.482843137254902,0.15462316069381915,mmlu:high_school_physics,test,44.43336761370301,llama2_13b_chat,choice,choice,,,,
60,0.11621293028195703,0.8000000715255737,0.7000000476837158,0.7291666666666666,0.058691269159317036,mmlu:high_school_psychology,validation,16.62720111384988,llama2_13b_chat,choice,choice,,,,
545,0.1283313002608238,0.752293586730957,0.721100926399231,0.658238482384824,0.05128236155991161,mmlu:high_school_psychology,test,151.31211990118027,llama2_13b_chat,choice,choice,,,,
23,0.31580342028452013,0.3478260934352875,0.739130437374115,0.7333333333333334,0.10908298129620762,mmlu:high_school_statistics,validation,9.590963080525398,llama2_13b_chat,choice,choice,,,,
216,0.24046254544346418,0.36574074625968933,0.6157407164573669,0.4382333918506883,0.05862025061139354,mmlu:high_school_statistics,test,93.25010351836681,llama2_13b_chat,choice,choice,,,,
22,0.2284643677147952,0.7272727489471436,0.5909091234207153,0.5520833333333334,0.08630374073982236,mmlu:high_school_us_history,validation,34.50409084558487,llama2_13b_chat,choice,choice,,,,
204,0.14268829118387372,0.75,0.6127451062202454,0.5080097398436498,0.07668289571416147,mmlu:high_school_us_history,test,312.08933011442423,llama2_13b_chat,choice,choice,,,,
23,0.23342548505119656,0.695652186870575,0.6086956858634949,0.7857142857142857,0.27008024246796325,mmlu:human_aging,validation,4.219716839492321,llama2_13b_chat,choice,choice,,,,
223,0.1750242027199322,0.6457399129867554,0.6457399129867554,0.6397679324894515,0.10094246522193528,mmlu:human_aging,test,39.369511146098375,llama2_13b_chat,choice,choice,,,,
12,0.23100995272397995,0.4166666865348816,0.5833333730697632,0.6000000000000001,0.15737286210060117,mmlu:human_sexuality,validation,2.4328395165503025,llama2_13b_chat,choice,choice,,,,
131,0.20160232518465465,0.6106870174407959,0.6030534505844116,0.5841911764705883,0.10256752622036534,mmlu:human_sexuality,test,26.96799949556589,llama2_13b_chat,choice,choice,,,,
13,0.09920215606689457,0.8461538553237915,0.7692307829856873,0.0,0.30705286447818464,mmlu:international_law,validation,4.623979412019253,llama2_13b_chat,choice,choice,,,,
121,0.14776173135465825,0.7520660758018494,0.7685949802398682,0.7256410256410256,0.027330795102868198,mmlu:international_law,test,39.789948996156454,llama2_13b_chat,choice,choice,,,,
11,0.2845090708949349,0.4545454680919647,0.4545454680919647,0.6000000000000001,0.20376815579154273,mmlu:jurisprudence,validation,2.619430422782898,llama2_13b_chat,choice,choice,,,,
108,0.07530087784484582,0.7685185074806213,0.694444477558136,0.6520481927710844,0.07904778586493597,mmlu:jurisprudence,test,23.848368361592293,llama2_13b_chat,choice,choice,,,,
18,0.2260679933759901,0.7222222089767456,0.6666666865348816,0.49230769230769234,0.1869756082693736,mmlu:logical_fallacies,validation,4.409582059830427,llama2_13b_chat,choice,choice,,,,
163,0.18132933681727922,0.6748465895652771,0.7239263653755188,0.5821612349914237,0.0683830497455012,mmlu:logical_fallacies,test,38.816367857158184,llama2_13b_chat,choice,choice,,,,
11,0.3903419483791698,0.27272728085517883,0.4545454680919647,0.75,0.3353104537183588,mmlu:machine_learning,validation,3.8046592250466347,llama2_13b_chat,choice,choice,,,,
112,0.42653715983033186,0.2946428656578064,0.598214328289032,0.58036056770234,0.1263520738908223,mmlu:machine_learning,test,37.146657809615135,llama2_13b_chat,choice,choice,,,,
11,0.19820608875968238,0.8181818723678589,0.9090909361839294,0.8888888888888888,0.20826454596085983,mmlu:management,validation,2.016974840313196,llama2_13b_chat,choice,choice,,,,
103,0.12850591685008078,0.7281553745269775,0.737864077091217,0.724047619047619,0.055374316220144604,mmlu:management,test,16.9367368593812,llama2_13b_chat,choice,choice,,,,
25,0.1604520511627197,0.7999999523162842,0.7599999904632568,0.52,0.06770790100097654,mmlu:marketing,validation,5.944546684622765,llama2_13b_chat,choice,choice,,,,
234,0.0556038345536615,0.811965823173523,0.811965823173523,0.6998803827751197,0.05898205643026235,mmlu:marketing,test,52.27021423727274,llama2_13b_chat,choice,choice,,,,
11,0.19195573980158026,0.7272727489471436,0.8181818723678589,0.5833333333333334,0.25114706971428613,mmlu:medical_genetics,validation,2.509050976485014,llama2_13b_chat,choice,choice,,,,
100,0.2222991907596588,0.5699999928474426,0.6800000071525574,0.7070583435332518,0.0628212279081345,mmlu:medical_genetics,test,20.022704757750034,llama2_13b_chat,choice,choice,,,,
38,0.274641951448039,0.4736842215061188,0.5263158082962036,0.6555555555555556,0.17120618569223503,mmlu:moral_disputes,validation,9.784590169787407,llama2_13b_chat,choice,choice,,,,
346,0.2104136041134079,0.6011560559272766,0.5924855470657349,0.6092182274247492,0.11781503096481281,mmlu:moral_disputes,test,87.9328544549644,llama2_13b_chat,choice,choice,,,,
33,0.12391907067009898,0.7272727489471436,0.7272727489471436,0.5555555555555556,0.11462803320451219,mmlu:nutrition,validation,10.654906868934631,llama2_13b_chat,choice,choice,,,,
306,0.20404470599944294,0.5947712659835815,0.5816993713378906,0.5987903225806452,0.12648797463747413,mmlu:nutrition,test,97.45796264335513,llama2_13b_chat,choice,choice,,,,
34,0.3614660878391827,0.5588235259056091,0.7352941036224365,0.7192982456140351,0.07471155243761397,mmlu:philosophy,validation,6.637097839266062,llama2_13b_chat,choice,choice,,,,
311,0.2685818516939783,0.6141479015350342,0.668810248374939,0.5988438045375218,0.06704237491754858,mmlu:philosophy,test,58.27632603421807,llama2_13b_chat,choice,choice,,,,
35,0.24310854503086635,0.6285714507102966,0.5714285969734192,0.6433566433566433,0.17312621048518592,mmlu:prehistory,validation,10.559969794005156,llama2_13b_chat,choice,choice,,,,
324,0.2470247510958601,0.5956790447235107,0.6327160596847534,0.5843452121979196,0.07859171411873382,mmlu:prehistory,test,93.25833277776837,llama2_13b_chat,choice,choice,,,,
69,0.20283278304597607,0.6086956858634949,0.6376811861991882,0.6979717813051147,0.1250979969466942,mmlu:professional_psychology,validation,21.706998750567436,llama2_13b_chat,choice,choice,,,,
612,0.23851665124004962,0.5522875785827637,0.5735294222831726,0.5942642422148319,0.15345432195398545,mmlu:professional_psychology,test,184.82651480287313,llama2_13b_chat,choice,choice,,,,
12,0.4481361309687297,0.5,0.4166666865348816,0.24999999999999997,0.3623305857181549,mmlu:public_relations,validation,3.160069487988949,llama2_13b_chat,choice,choice,,,,
110,0.16180461211638014,0.6363636255264282,0.6727272272109985,0.74375,0.09490737373178654,mmlu:public_relations,test,25.568296298384666,llama2_13b_chat,choice,choice,,,,
27,0.34522028322573056,0.5555555820465088,0.5925925970077515,0.7611111111111112,0.2431912201422232,mmlu:security_studies,validation,18.681686509400606,llama2_13b_chat,choice,choice,,,,
245,0.22966081475724975,0.6408162713050842,0.6612244844436646,0.5945280833815866,0.13223894153322496,mmlu:security_studies,test,174.06443646550179,llama2_13b_chat,choice,choice,,,,
22,0.11438660730015147,0.8181818723678589,0.8181818723678589,0.6388888888888888,0.12621116909113797,mmlu:sociology,validation,5.375730037689209,llama2_13b_chat,choice,choice,,,,
201,0.1654659453316114,0.7661691308021545,0.7960199117660522,0.6930781983973473,0.04956385804646049,mmlu:sociology,test,47.72393833845854,llama2_13b_chat,choice,choice,,,,
11,0.09280334277586508,0.9090909361839294,0.8181818723678589,1.0,0.16001947359605267,mmlu:us_foreign_policy,validation,2.7217728942632675,llama2_13b_chat,choice,choice,,,,
100,0.12127714633941647,0.7899999618530273,0.7799999713897705,0.5575647980711272,0.040535873770713785,mmlu:us_foreign_policy,test,22.89336557686329,llama2_13b_chat,choice,choice,,,,
18,0.4539293646812439,0.4444444477558136,0.6111111044883728,0.675,0.22935646441247728,mmlu:virology,validation,4.338902644813061,llama2_13b_chat,choice,choice,,,,
166,0.32515772369252627,0.48192769289016724,0.5301204919815063,0.5337936046511628,0.26375785649540917,mmlu:virology,test,33.26165109872818,llama2_13b_chat,choice,choice,,,,
19,0.18241700686906515,0.7894737124443054,0.7368420958518982,0.7666666666666666,0.11078880021446627,mmlu:world_religions,validation,3.185320407152176,llama2_13b_chat,choice,choice,,,,
171,0.08028784359407706,0.7836257219314575,0.7953216433525085,0.740520371117386,0.038581849190226794,mmlu:world_religions,test,26.80996747687459,llama2_13b_chat,choice,choice,,,,
11,0.40860054980624805,0.1818181872367859,0.3636363744735718,0.33333333333333337,0.3832344846291976,mmlu:abstract_algebra,validation,3.94090324267745,llama2_7b_chat,choice,choice,,,,
100,0.33865155398845675,0.2199999988079071,0.5299999713897705,0.28583916083916083,0.21460786104202267,mmlu:abstract_algebra,test,11.181401470676064,llama2_7b_chat,choice,choice,,,,
14,0.16611006430217198,0.785714328289032,0.785714328289032,0.36363636363636365,0.3246688374451228,mmlu:anatomy,validation,1.7404253035783768,llama2_7b_chat,choice,choice,,,,
135,0.2326331599994942,0.4444444477558136,0.6370370388031006,0.5712222222222223,0.06687547409975975,mmlu:anatomy,test,16.014638513326645,llama2_7b_chat,choice,choice,,,,
16,0.31718727201223373,0.3125,0.6875,0.6,0.20251726359128952,mmlu:astronomy,validation,3.0786505360156298,llama2_7b_chat,choice,choice,,,,
152,0.2587384585487215,0.3486842215061188,0.7171052694320679,0.3215170573661139,0.07305338586631575,mmlu:astronomy,test,27.88690167479217,llama2_7b_chat,choice,choice,,,,
11,0.2636793255805969,0.5454545617103577,0.5454545617103577,0.5666666666666667,0.32509963620792737,mmlu:business_ethics,validation,2.185238130390644,llama2_7b_chat,choice,choice,,,,
100,0.2027903527021408,0.4899999797344208,0.7299999594688416,0.4707883153261304,0.055923838019371036,mmlu:business_ethics,test,18.287018593400717,llama2_7b_chat,choice,choice,,,,
29,0.30299188453575665,0.48275861144065857,0.517241358757019,0.5238095238095237,0.18697699596141945,mmlu:clinical_knowledge,validation,3.96349854208529,llama2_7b_chat,choice,choice,,,,
265,0.2012587421345261,0.5056604146957397,0.5622641444206238,0.5730887546997836,0.12831313790015453,mmlu:clinical_knowledge,test,34.92401184141636,llama2_7b_chat,choice,choice,,,,
16,0.3297007419168949,0.25,0.625,0.35416666666666663,0.20617683604359627,mmlu:college_biology,validation,2.581395659595728,llama2_7b_chat,choice,choice,,,,
144,0.16690380829903814,0.4791666567325592,0.6041666865348816,0.3498550724637681,0.0985035498936971,mmlu:college_biology,test,22.958308784291148,llama2_7b_chat,choice,choice,,,,
8,0.30733129382133484,0.25,0.75,0.0,0.284232959151268,mmlu:college_chemistry,validation,1.6292655896395445,llama2_7b_chat,choice,choice,,,,
100,0.3795311897993088,0.17000000178813934,0.6399999856948853,0.330970942593905,0.09102524995803835,mmlu:college_chemistry,test,17.43492310680449,llama2_7b_chat,choice,choice,,,,
11,0.37904362515969703,0.1818181872367859,0.8181818723678589,0.4444444444444444,0.13744736259633844,mmlu:college_computer_science,validation,2.9141146950423717,llama2_7b_chat,choice,choice,,,,
100,0.3648486855626107,0.1899999976158142,0.75,0.3001949317738791,0.04691624462604523,mmlu:college_computer_science,test,26.195273159071803,llama2_7b_chat,choice,choice,,,,
11,0.22788689082319086,0.4545454680919647,0.4545454680919647,0.43333333333333335,0.17674851959401908,mmlu:college_mathematics,validation,2.127473995089531,llama2_7b_chat,choice,choice,,,,
100,0.18770410388708117,0.25,0.5899999737739563,0.388,0.12021578073501585,mmlu:college_mathematics,test,17.490864496678114,llama2_7b_chat,choice,choice,,,,
22,0.3398749489675869,0.3181818127632141,0.5909091234207153,0.6095238095238095,0.1655839789997448,mmlu:college_medicine,validation,3.857906023040414,llama2_7b_chat,choice,choice,,,,
173,0.3578732292776163,0.32947975397109985,0.5549132823944092,0.4583333333333333,0.14460180846252885,mmlu:college_medicine,test,40.33939125947654,llama2_7b_chat,choice,choice,,,,
11,0.2627552070400932,0.4545454680919647,0.7272727489471436,0.0,0.2783309438011863,mmlu:college_physics,validation,1.847661454230547,llama2_7b_chat,choice,choice,,,,
102,0.33012838369491054,0.2352941334247589,0.6960784792900085,0.4823717948717949,0.11857736169123181,mmlu:college_physics,test,15.281791156157851,llama2_7b_chat,choice,choice,,,,
11,0.37034989757971326,0.27272728085517883,0.8181818723678589,0.375,0.271360072222623,mmlu:computer_security,validation,1.787004429847002,llama2_7b_chat,choice,choice,,,,
100,0.28003013134002686,0.4899999797344208,0.7299999594688416,0.3387354941976791,0.028574723601341268,mmlu:computer_security,test,12.975602077320218,llama2_7b_chat,choice,choice,,,,
26,0.3869931823932208,0.3461538553237915,0.6153846383094788,0.5620915032679739,0.06392181378144485,mmlu:conceptual_physics,validation,2.740708064287901,llama2_7b_chat,choice,choice,,,,
235,0.31803804483819514,0.4170212745666504,0.5021276473999023,0.4696112021450916,0.114801084741633,mmlu:conceptual_physics,test,23.038359751924872,llama2_7b_chat,choice,choice,,,,
12,0.5138435711463293,0.0833333358168602,0.5833333730697632,0.6363636363636364,0.18823039035002392,mmlu:econometrics,validation,2.4378681499511003,llama2_7b_chat,choice,choice,,,,
114,0.26663590131098763,0.3245614171028137,0.6491228342056274,0.511934011934012,0.09554161732656911,mmlu:econometrics,test,21.75370061211288,llama2_7b_chat,choice,choice,,,,
16,0.3721194565296173,0.1875,0.875,0.15384615384615383,0.13711652159690857,mmlu:electrical_engineering,validation,2.2442150730639696,llama2_7b_chat,choice,choice,,,,
145,0.29587967991828923,0.29655173420906067,0.751724123954773,0.17305061559507523,0.04359830946757875,mmlu:electrical_engineering,test,19.043987734243274,llama2_7b_chat,choice,choice,,,,
41,0.26353369907635016,0.19512194395065308,0.7804877758026123,0.36363636363636365,0.07546968721761939,mmlu:elementary_mathematics,validation,7.06143206730485,llama2_7b_chat,choice,choice,,,,
378,0.32520310919751566,0.15608465671539307,0.6878306865692139,0.23479092503055093,0.1034695397293757,mmlu:elementary_mathematics,test,62.132423266768456,llama2_7b_chat,choice,choice,,,,
14,0.3947497137955257,0.2142857313156128,0.3571428656578064,0.6969696969696969,0.2896813239370074,mmlu:formal_logic,validation,2.7626573964953423,llama2_7b_chat,choice,choice,,,,
126,0.34293854993487166,0.1666666716337204,0.5793651342391968,0.4954648526077098,0.11044424630346751,mmlu:formal_logic,test,24.254093067720532,llama2_7b_chat,choice,choice,,,,
10,0.39951248168945314,0.5,0.4000000059604645,0.52,0.41510528922081,mmlu:global_facts,validation,1.5275207683444023,llama2_7b_chat,choice,choice,,,,
100,0.19522883623838427,0.3700000047683716,0.5999999642372131,0.46696696696696693,0.05631412148475645,mmlu:global_facts,test,13.29813788831234,llama2_7b_chat,choice,choice,,,,
32,0.26464015059173107,0.34375,0.75,0.28571428571428575,0.14211409166455266,mmlu:high_school_biology,validation,5.37654123455286,llama2_7b_chat,choice,choice,,,,
310,0.19769324294982418,0.45483869314193726,0.6741935610771179,0.36166016198749423,0.057827269454156185,mmlu:high_school_biology,test,51.19866621866822,llama2_7b_chat,choice,choice,,,,
22,0.288499116897583,0.3181818127632141,0.5909091234207153,0.39999999999999997,0.20129678195173092,mmlu:high_school_chemistry,validation,3.7583629339933395,llama2_7b_chat,choice,choice,,,,
203,0.32531837201470815,0.2807881832122803,0.49753692746162415,0.4161860129776496,0.18931086075129766,mmlu:high_school_chemistry,test,32.45753861218691,llama2_7b_chat,choice,choice,,,,
9,0.3720434374279446,0.3333333432674408,0.5555555820465088,0.2777777777777778,0.18965187999937266,mmlu:high_school_computer_science,validation,2.798708375543356,llama2_7b_chat,choice,choice,,,,
100,0.3044472533464432,0.3199999928474426,0.7599999904632568,0.375,0.051304118037223824,mmlu:high_school_computer_science,test,29.915479570627213,llama2_7b_chat,choice,choice,,,,
22,0.11895058371803977,0.6818181872367859,0.9090909361839294,0.02857142857142858,0.1500533087687059,mmlu:high_school_geography,validation,2.809797704219818,llama2_7b_chat,choice,choice,,,,
198,0.21035245632884475,0.5252525210380554,0.7575757503509521,0.298588379705401,0.046617555798906286,mmlu:high_school_geography,test,24.503775592893362,llama2_7b_chat,choice,choice,,,,
21,0.49150010801496963,0.3333333432674408,0.6190476417541504,0.8163265306122449,0.16451920497985115,mmlu:high_school_government_and_politics,validation,3.2203532475978136,llama2_7b_chat,choice,choice,,,,
193,0.11383651482626563,0.6994818449020386,0.7150259017944336,0.5611749680715198,0.02475643528557814,mmlu:high_school_government_and_politics,test,28.480233998969197,llama2_7b_chat,choice,choice,,,,
43,0.25150079574695855,0.44186046719551086,0.5813953280448914,0.4967105263157895,0.12372322415196617,mmlu:high_school_macroeconomics,validation,5.55974836088717,llama2_7b_chat,choice,choice,,,,
390,0.24026215068804913,0.41025641560554504,0.6615384817123413,0.5242798913043478,0.05084820282764926,mmlu:high_school_macroeconomics,test,49.48162585683167,llama2_7b_chat,choice,choice,,,,
29,0.2573509483501829,0.20689654350280762,0.6551724076271057,0.3586956521739131,0.12680231702738795,mmlu:high_school_mathematics,validation,4.7294497564435005,llama2_7b_chat,choice,choice,,,,
270,0.2809365680924169,0.20000000298023224,0.729629635810852,0.31875857338820307,0.0350809521145291,mmlu:high_school_mathematics,test,42.26543371938169,llama2_7b_chat,choice,choice,,,,
26,0.3872666691358273,0.3461538553237915,0.5,0.40522875816993464,0.16668272935427153,mmlu:high_school_microeconomics,validation,3.389654805883765,llama2_7b_chat,choice,choice,,,,
238,0.2912635302343288,0.3571428656578064,0.6386554837226868,0.3771626297577855,0.06786312651233517,mmlu:high_school_microeconomics,test,30.686856154352427,llama2_7b_chat,choice,choice,,,,
17,0.30807772454093485,0.1764705926179886,0.7058823704719543,0.6428571428571428,0.13523862642400405,mmlu:high_school_physics,validation,3.2091957088559866,llama2_7b_chat,choice,choice,,,,
151,0.2579703638885195,0.2450331151485443,0.6622516512870789,0.29836415362731156,0.07146246227997026,mmlu:high_school_physics,test,26.350164471194148,llama2_7b_chat,choice,choice,,,,
60,0.1757079487045606,0.6666666865348816,0.8000000715255737,0.431875,0.09904001851876577,mmlu:high_school_psychology,validation,9.788603665307164,llama2_7b_chat,choice,choice,,,,
545,0.13719539418133028,0.5853211283683777,0.7449541091918945,0.414632285627098,0.04337566500410025,mmlu:high_school_psychology,test,89.41557026095688,llama2_7b_chat,choice,choice,,,,
23,0.25403486645740014,0.260869562625885,0.5652173757553101,0.696078431372549,0.1118422668913136,mmlu:high_school_statistics,validation,5.914392625913024,llama2_7b_chat,choice,choice,,,,
216,0.30122099596041224,0.25,0.5277777910232544,0.5211476909007773,0.13831099067573197,mmlu:high_school_statistics,test,56.31015935540199,llama2_7b_chat,choice,choice,,,,
22,0.28984237665479834,0.40909093618392944,0.5454545617103577,0.23076923076923075,0.21469736912033777,mmlu:high_school_us_history,validation,21.78789034485817,llama2_7b_chat,choice,choice,,,,
204,0.15090080686644014,0.529411792755127,0.6911764740943909,0.33502121913580246,0.04674287461767007,mmlu:high_school_us_history,test,192.72053350321949,llama2_7b_chat,choice,choice,,,,
23,0.2563094224618829,0.695652186870575,0.5652173757553101,0.4464285714285714,0.07655638456344604,mmlu:human_aging,validation,2.4717414434999228,llama2_7b_chat,choice,choice,,,,
223,0.12175258673359995,0.5695067644119263,0.6278027296066284,0.4202345800524934,0.03774961388164569,mmlu:human_aging,test,22.715025952085853,llama2_7b_chat,choice,choice,,,,
12,0.2739627212285995,0.4166666865348816,0.5833333730697632,0.6857142857142858,0.0770757496356964,mmlu:human_sexuality,validation,1.5351748056709766,llama2_7b_chat,choice,choice,,,,
131,0.18593752816433218,0.5038167834281921,0.6870229244232178,0.5175990675990676,0.10819697016068092,mmlu:human_sexuality,test,15.68834769167006,llama2_7b_chat,choice,choice,,,,
13,0.13006082406410804,0.9230769872665405,0.8461538553237915,0.4166666666666667,0.1456491488676805,mmlu:international_law,validation,2.796491112560034,llama2_7b_chat,choice,choice,,,,
121,0.17942237927893964,0.6280991435050964,0.7520660758018494,0.5054093567251462,0.026168499603744393,mmlu:international_law,test,23.799563471227884,llama2_7b_chat,choice,choice,,,,
11,0.2877437797459689,0.3636363744735718,0.6363636255264282,0.5714285714285714,0.07579049197110263,mmlu:jurisprudence,validation,1.6110955569893122,llama2_7b_chat,choice,choice,,,,
108,0.1411077680963057,0.5462962985038757,0.6666666865348816,0.49290902801798686,0.06470493144459195,mmlu:jurisprudence,test,14.034496299922466,llama2_7b_chat,choice,choice,,,,
18,0.30899602837032747,0.6111111044883728,0.7222222089767456,0.5454545454545455,0.16294115119510225,mmlu:logical_fallacies,validation,2.636520965024829,llama2_7b_chat,choice,choice,,,,
163,0.24012123807076294,0.460122674703598,0.6625766754150391,0.4983333333333334,0.05277472076240494,mmlu:logical_fallacies,test,23.103309955447912,llama2_7b_chat,choice,choice,,,,
11,0.4008538722991944,0.09090909361839294,0.3636363744735718,0.6,0.3745359073985706,mmlu:machine_learning,validation,2.3400680385529995,llama2_7b_chat,choice,choice,,,,
112,0.39928808914763586,0.1875000149011612,0.6875000596046448,0.2658294086865515,0.12877669717584336,mmlu:machine_learning,test,22.361744599416852,llama2_7b_chat,choice,choice,,,,
11,0.20957784219221637,0.7272727489471436,0.6363636255264282,0.375,0.1375779617916454,mmlu:management,validation,1.1724361758679152,llama2_7b_chat,choice,choice,,,,
103,0.13900363300610513,0.6504854559898376,0.6310679912567139,0.5402155887230514,0.08654168161373693,mmlu:management,test,9.60556442849338,llama2_7b_chat,choice,choice,,,,
25,0.2425061905384064,0.7199999690055847,0.6399999856948853,0.7142857142857143,0.10789620399475097,mmlu:marketing,validation,3.4594199378043413,llama2_7b_chat,choice,choice,,,,
234,0.07061166704719901,0.7264957427978516,0.7264957427978516,0.7013786764705883,0.067354212459336,mmlu:marketing,test,30.2238607481122,llama2_7b_chat,choice,choice,,,,
11,0.25215952775695105,0.7272727489471436,0.8181818723678589,0.625,0.22891979867761786,mmlu:medical_genetics,validation,1.5051690712571144,llama2_7b_chat,choice,choice,,,,
100,0.2430890989303589,0.4399999976158142,0.7099999785423279,0.37337662337662336,0.01765112578868866,mmlu:medical_genetics,test,11.676655756309628,llama2_7b_chat,choice,choice,,,,
38,0.28020251424689047,0.4736842215061188,0.6578947305679321,0.5305555555555556,0.07508322439695661,mmlu:moral_disputes,validation,5.744659187272191,llama2_7b_chat,choice,choice,,,,
346,0.29246990391284744,0.4566473960876465,0.5838150382041931,0.5167822515486129,0.051758195795764836,mmlu:moral_disputes,test,51.697275118902326,llama2_7b_chat,choice,choice,,,,
33,0.2738685996243448,0.42424243688583374,0.8484848737716675,0.2518796992481203,0.07439169558611783,mmlu:nutrition,validation,6.324953148141503,llama2_7b_chat,choice,choice,,,,
306,0.2845178060477076,0.3464052379131317,0.741830050945282,0.24754716981132077,0.0664455316035576,mmlu:nutrition,test,57.812081560492516,llama2_7b_chat,choice,choice,,,,
34,0.3599341485430212,0.529411792755127,0.529411792755127,0.5833333333333334,0.13843933624379776,mmlu:philosophy,validation,4.006815800443292,llama2_7b_chat,choice,choice,,,,
311,0.22359934727095332,0.5755627155303955,0.6334404945373535,0.6144828169967834,0.020330771180977796,mmlu:philosophy,test,34.75592731684446,llama2_7b_chat,choice,choice,,,,
35,0.33360244716916765,0.37142857909202576,0.6857143044471741,0.465034965034965,0.03242332594735281,mmlu:prehistory,validation,6.2127266973257065,llama2_7b_chat,choice,choice,,,,
324,0.2215912996986766,0.48765432834625244,0.6419752836227417,0.39450205886838496,0.06534345135276699,mmlu:prehistory,test,54.89061144553125,llama2_7b_chat,choice,choice,,,,
69,0.3111147733702176,0.37681159377098083,0.5362318754196167,0.5335420393559929,0.1538969969403917,mmlu:professional_psychology,validation,13.058179125189781,llama2_7b_chat,choice,choice,,,,
612,0.2945669362065839,0.3741829991340637,0.5490196347236633,0.43340326313749183,0.1513799851626353,mmlu:professional_psychology,test,109.99786164052784,llama2_7b_chat,choice,choice,,,,
12,0.37314925591150916,0.5,0.4166666865348816,0.5,0.3510534117619197,mmlu:public_relations,validation,1.89671441167593,llama2_7b_chat,choice,choice,,,,
110,0.18714106326753444,0.5454545021057129,0.663636326789856,0.5168333333333333,0.050616692954843716,mmlu:public_relations,test,15.063211916014552,llama2_7b_chat,choice,choice,,,,
27,0.2797603011131287,0.48148149251937866,0.5555555820465088,0.6263736263736264,0.1925395969991331,mmlu:security_studies,validation,11.831039778888226,llama2_7b_chat,choice,choice,,,,
245,0.3246809972792256,0.3551020324230194,0.5673469305038452,0.4679906882002037,0.1933095769006379,mmlu:security_studies,test,106.85421110130847,llama2_7b_chat,choice,choice,,,,
22,0.17001411454244092,0.7727273106575012,0.7272727489471436,0.5999999999999999,0.10725469751791523,mmlu:sociology,validation,3.1384949795901775,llama2_7b_chat,choice,choice,,,,
201,0.1533688143711185,0.676616907119751,0.7213929891586304,0.5600678733031674,0.04839220746832697,mmlu:sociology,test,28.26029453240335,llama2_7b_chat,choice,choice,,,,
11,0.14814346757802097,0.7272727489471436,0.7272727489471436,0.8333333333333333,0.12302734635092996,mmlu:us_foreign_policy,validation,1.6491716261953115,llama2_7b_chat,choice,choice,,,,
100,0.15613329023122788,0.699999988079071,0.7199999690055847,0.47095238095238084,0.08042705893516541,mmlu:us_foreign_policy,test,13.202959328889847,llama2_7b_chat,choice,choice,,,,
18,0.28152537180317777,0.4444444477558136,0.7222222089767456,0.4875,0.22327786021762427,mmlu:virology,validation,2.76440161280334,llama2_7b_chat,choice,choice,,,,
166,0.3160623094762664,0.41566264629364014,0.5301204919815063,0.44808008366950547,0.15126838095216869,mmlu:virology,test,19.634311692789197,llama2_7b_chat,choice,choice,,,,
19,0.08325813945971036,0.7894737124443054,0.8421052694320679,0.6833333333333333,0.17423756812748153,mmlu:world_religions,validation,1.80825911834836,llama2_7b_chat,choice,choice,,,,
171,0.09975372141564798,0.6608186960220337,0.7836257219314575,0.314693317058285,0.08679402815668207,mmlu:world_religions,test,14.789651520550251,llama2_7b_chat,choice,choice,,,,
11,,,,,,mmlu:abstract_algebra,validation,15.989063248038292,llama2_13b,choice,oe,0.1818181872367859,0.3636363744735718,0.8888888888888888,0.33087780800732697
100,,,,,,mmlu:abstract_algebra,test,103.54675492085516,llama2_13b,choice,oe,0.25999999046325684,0.3700000047683716,0.5878378378378378,0.26375404298305516
14,,,,,,mmlu:anatomy,validation,15.332594382576644,llama2_13b,choice,oe,0.2857142984867096,0.5714285969734192,0.675,0.14039700797625948
135,,,,,,mmlu:anatomy,test,134.43636790383607,llama2_13b,choice,oe,0.4740740656852722,0.6666666269302368,0.6873899647887324,0.10070120935086849
16,,,,,,mmlu:astronomy,validation,16.285882431082428,llama2_13b,choice,oe,0.25,0.5625,0.6145833333333334,0.15129688009619713
152,,,,,,mmlu:astronomy,test,157.66600428242236,llama2_13b,choice,oe,0.5131579041481018,0.4934210479259491,0.47435897435897445,0.1178846892557646
11,,,,,,mmlu:business_ethics,validation,12.877179474569857,llama2_13b,choice,oe,0.5454545617103577,0.5454545617103577,0.6666666666666666,0.22306582602587616
100,,,,,,mmlu:business_ethics,test,111.09670135099441,llama2_13b,choice,oe,0.3400000035762787,0.32999998331069946,0.6187611408199644,0.4471464020013809
29,,,,,,mmlu:clinical_knowledge,validation,31.43380316067487,llama2_13b,choice,oe,0.27586206793785095,0.5517241358757019,0.42857142857142855,0.14169104962513365
265,,,,,,mmlu:clinical_knowledge,test,270.2995456075296,llama2_13b,choice,oe,0.31698113679885864,0.4867924451828003,0.5510392002104709,0.12469982111229087
16,,,,,,mmlu:college_biology,validation,22.701419785618782,llama2_13b,choice,oe,0.25,0.3125,0.4791666666666667,0.3830057382583618
144,,,,,,mmlu:college_biology,test,151.92398670315742,llama2_13b,choice,oe,0.3958333432674408,0.4513888955116272,0.5629159104658197,0.22361084529095226
8,,,,,,mmlu:college_chemistry,validation,8.705747371539474,llama2_13b,choice,oe,0.125,0.375,0.0,0.4593624845147133
100,,,,,,mmlu:college_chemistry,test,110.09326603543013,llama2_13b,choice,oe,0.17000000178813934,0.35999998450279236,0.6785967399007796,0.37237701475620266
11,,,,,,mmlu:college_computer_science,validation,15.78335308097303,llama2_13b,choice,oe,0.1818181872367859,0.6363636255264282,0.7222222222222223,0.3631531162695451
100,,,,,,mmlu:college_computer_science,test,139.09313723817468,llama2_13b,choice,oe,0.22999998927116394,0.429999977350235,0.5931677018633541,0.28615112066268916
11,,,,,,mmlu:college_mathematics,validation,14.179921993985772,llama2_13b,choice,oe,0.09090909361839294,0.4545454680919647,0.19999999999999996,0.18883834643797442
100,,,,,,mmlu:college_mathematics,test,121.85749560408294,llama2_13b,choice,oe,0.10999999940395355,0.6200000047683716,0.4039836567926456,0.063310683965683
22,,,,,,mmlu:college_medicine,validation,25.48816218599677,llama2_13b,choice,oe,0.4545454680919647,0.5,0.6,0.188753220168027
173,,,,,,mmlu:college_medicine,test,238.97677769418806,llama2_13b,choice,oe,0.34682080149650574,0.5549132823944092,0.5620206489675517,0.15782903281250438
11,,,,,,mmlu:college_physics,validation,13.418917391449213,llama2_13b,choice,oe,0.3636363744735718,0.3636363744735718,0.7142857142857143,0.28345388174057007
102,,,,,,mmlu:college_physics,test,120.22875682450831,llama2_13b,choice,oe,0.19607843458652496,0.3333333432674408,0.4564024390243902,0.3194129759190129
11,,,,,,mmlu:computer_security,validation,12.966890225186944,llama2_13b,choice,oe,0.4545454680919647,0.5454545617103577,0.43333333333333335,0.2708535682071339
100,,,,,,mmlu:computer_security,test,101.98039209842682,llama2_13b,choice,oe,0.4899999797344208,0.6100000143051147,0.6738695478191277,0.11173061430454256
26,,,,,,mmlu:conceptual_physics,validation,27.357936415821314,llama2_13b,choice,oe,0.26923078298568726,0.38461539149284363,0.6353383458646616,0.22583146049426153
235,,,,,,mmlu:conceptual_physics,test,235.99183891620487,llama2_13b,choice,oe,0.4382978677749634,0.52765953540802,0.5212562518387761,0.1095648093426481
12,,,,,,mmlu:econometrics,validation,14.32112086750567,llama2_13b,choice,oe,0.0833333358168602,0.25,1.0,0.43737613161404926
114,,,,,,mmlu:econometrics,test,139.18138243537396,llama2_13b,choice,oe,0.18421052396297455,0.28947368264198303,0.46979006656426003,0.3571135532437709
16,,,,,,mmlu:electrical_engineering,validation,17.038865122944117,llama2_13b,choice,oe,0.375,0.6875,0.49999999999999994,0.10384859889745714
145,,,,,,mmlu:electrical_engineering,test,158.5928309764713,llama2_13b,choice,oe,0.22758620977401733,0.475862056016922,0.5760281385281385,0.16037795091497486
41,,,,,,mmlu:elementary_mathematics,validation,47.8688394241035,llama2_13b,choice,oe,0.2926829159259796,0.39024388790130615,0.5100574712643678,0.3008504102869731
378,,,,,,mmlu:elementary_mathematics,test,414.7902135383338,llama2_13b,choice,oe,0.39947089552879333,0.4814814627170563,0.5793389153076406,0.18718553251690337
14,,,,,,mmlu:formal_logic,validation,17.60416665673256,llama2_13b,choice,oe,0.4285714626312256,0.5,0.65625,0.17221722858292715
126,,,,,,mmlu:formal_logic,test,142.54179213382304,llama2_13b,choice,oe,0.2063492238521576,0.547619104385376,0.5098076923076923,0.06015986204147341
10,,,,,,mmlu:global_facts,validation,11.983085898682475,llama2_13b,choice,oe,0.20000000298023224,0.30000001192092896,0.5,0.5936511874198913
100,,,,,,mmlu:global_facts,test,103.15721158217639,llama2_13b,choice,oe,0.19999998807907104,0.23999999463558197,0.5003124999999999,0.47021151781082154
32,,,,,,mmlu:high_school_biology,validation,34.079145189374685,llama2_13b,choice,oe,0.3125,0.40625,0.45681818181818185,0.26501595228910446
310,,,,,,mmlu:high_school_biology,test,333.9646259993315,llama2_13b,choice,oe,0.4741935431957245,0.5096774101257324,0.5234130462000751,0.16456997336879853
22,,,,,,mmlu:high_school_chemistry,validation,25.953068455681205,llama2_13b,choice,oe,0.09090909361839294,0.1818181872367859,0.36250000000000004,0.49103786728598847
203,,,,,,mmlu:high_school_chemistry,test,224.96536181494594,llama2_13b,choice,oe,0.18719211220741272,0.2610837519168854,0.5515948963317385,0.4277947583222037
9,,,,,,mmlu:high_school_computer_science,validation,13.771248714998364,llama2_13b,choice,oe,0.2222222238779068,0.3333333432674408,0.6428571428571428,0.4691421786944072
100,,,,,,mmlu:high_school_computer_science,test,134.6246206406504,llama2_13b,choice,oe,0.4099999964237213,0.5,0.6101694915254238,0.1338645797967911
22,,,,,,mmlu:high_school_geography,validation,25.48478699848056,llama2_13b,choice,oe,0.40909093618392944,0.6818181872367859,0.7094017094017093,0.09808661991899664
198,,,,,,mmlu:high_school_geography,test,200.62415517214686,llama2_13b,choice,oe,0.3737373650074005,0.5808081030845642,0.5884372275501308,0.10942833893226857
21,,,,,,mmlu:high_school_government_and_politics,validation,24.974020613357425,llama2_13b,choice,oe,0.523809552192688,0.6666666865348816,0.7363636363636364,0.07250935123080299
193,,,,,,mmlu:high_school_government_and_politics,test,208.31415481679142,llama2_13b,choice,oe,0.5699481964111328,0.5803108811378479,0.5494523548740416,0.058331307969562735
43,,,,,,mmlu:high_school_macroeconomics,validation,45.62596845906228,llama2_13b,choice,oe,0.44186046719551086,0.39534884691238403,0.5877192982456141,0.25577420827954317
390,,,,,,mmlu:high_school_macroeconomics,test,523.2489891694859,llama2_13b,choice,oe,0.3410256505012512,0.37948718667030334,0.5591995553085047,0.2788944369707352
29,,,,,,mmlu:high_school_mathematics,validation,36.06615438032895,llama2_13b,choice,oe,0.17241379618644714,0.37931033968925476,0.5625,0.2226353657656703
270,,,,,,mmlu:high_school_mathematics,test,318.7299193730578,llama2_13b,choice,oe,0.0962962955236435,0.3481481373310089,0.6580233291298865,0.2818801131513384
26,,,,,,mmlu:high_school_microeconomics,validation,29.676043890416622,llama2_13b,choice,oe,0.38461539149284363,0.6538462042808533,0.5375,0.2393130499583024
238,,,,,,mmlu:high_school_microeconomics,test,253.62139435578138,llama2_13b,choice,oe,0.38655462861061096,0.5084033608436584,0.48730643240023824,0.14186014422849444
17,,,,,,mmlu:high_school_physics,validation,22.388784470036626,llama2_13b,choice,oe,0.1764705926179886,0.3529411852359772,0.1428571428571429,0.2944418226971346
151,,,,,,mmlu:high_school_physics,test,182.3810276221484,llama2_13b,choice,oe,0.20529800653457642,0.42384105920791626,0.5553763440860214,0.21679879932214097
60,,,,,,mmlu:high_school_psychology,validation,66.75092055182904,llama2_13b,choice,oe,0.5833333730697632,0.5166667103767395,0.5828571428571429,0.19927519957224527
545,,,,,,mmlu:high_school_psychology,test,629.7734475247562,llama2_13b,choice,oe,0.5357798337936401,0.5412843823432922,0.5963709459093617,0.16244493985394817
23,,,,,,mmlu:high_school_statistics,validation,29.451725993305445,llama2_13b,choice,oe,0.21739131212234497,0.260869562625885,0.3888888888888889,0.3599785644075145
216,,,,,,mmlu:high_school_statistics,test,272.3441078523174,llama2_13b,choice,oe,0.236111119389534,0.42129629850387573,0.45858585858585854,0.1960527742350543
22,,,,,,mmlu:high_school_us_history,validation,64.82706901337951,llama2_13b,choice,oe,0.6818181872367859,0.6818181872367859,0.3238095238095238,0.26340392773801635
204,,,,,,mmlu:high_school_us_history,test,593.010608272627,llama2_13b,choice,oe,0.6421568989753723,0.6617647409439087,0.5905050716302416,0.035274808313332365
23,,,,,,mmlu:human_aging,validation,25.033921488560736,llama2_13b,choice,oe,0.30434784293174744,0.30434784293174744,0.39285714285714285,0.42665697699007776
223,,,,,,mmlu:human_aging,test,253.26541530154645,llama2_13b,choice,oe,0.3766816258430481,0.4035874605178833,0.5464628297362111,0.3281024862832553
12,,,,,,mmlu:human_sexuality,validation,13.186986291781068,llama2_13b,choice,oe,0.4166666865348816,0.5833333730697632,0.5428571428571429,0.08172893524169919
131,,,,,,mmlu:human_sexuality,test,142.71901492308825,llama2_13b,choice,oe,0.4198473393917084,0.5267175436019897,0.725598086124402,0.12590260223577948
13,,,,,,mmlu:international_law,validation,17.48638332542032,llama2_13b,choice,oe,0.38461539149284363,0.5384615659713745,0.525,0.2492825664006747
121,,,,,,mmlu:international_law,test,139.92499501165003,llama2_13b,choice,oe,0.5454545021057129,0.4710743725299835,0.45606060606060606,0.15657868858211296
11,,,,,,mmlu:jurisprudence,validation,13.035274696536362,llama2_13b,choice,oe,0.3636363744735718,0.5454545617103577,0.7857142857142857,0.2618710832162337
108,,,,,,mmlu:jurisprudence,test,115.93265867978334,llama2_13b,choice,oe,0.4166666567325592,0.5185185074806213,0.4617283950617284,0.1153050352025915
18,,,,,,mmlu:logical_fallacies,validation,21.31722527742386,llama2_13b,choice,oe,0.5555555820465088,0.6111111044883728,0.525,0.16807145873705545
163,,,,,,mmlu:logical_fallacies,test,199.81581829488277,llama2_13b,choice,oe,0.46625766158103943,0.5950919985771179,0.558983666061706,0.1615701467712964
11,,,,,,mmlu:machine_learning,validation,13.715759634040296,llama2_13b,choice,oe,0.5454545617103577,0.3636363744735718,0.3333333333333333,0.25475001335144043
112,,,,,,mmlu:machine_learning,test,133.79120675381273,llama2_13b,choice,oe,0.2142857313156128,0.4196428656578064,0.5906723484848485,0.2104242342923369
11,,,,,,mmlu:management,validation,13.017785074189305,llama2_13b,choice,oe,0.7272727489471436,0.6363636255264282,0.16666666666666669,0.21763481335206467
103,,,,,,mmlu:management,test,133.67652890551835,llama2_13b,choice,oe,0.4757281541824341,0.5436893105506897,0.5931594860166289,0.1756534964135549
25,,,,,,mmlu:marketing,validation,30.115643084980547,llama2_13b,choice,oe,0.3199999928474426,0.35999998450279236,0.6102941176470589,0.45378191947937013
234,,,,,,mmlu:marketing,test,255.61913364566863,llama2_13b,choice,oe,0.46153849363327026,0.4829060137271881,0.5609200470311582,0.26125539164257866
11,,,,,,mmlu:medical_genetics,validation,12.629950212314725,llama2_13b,choice,oe,0.7272727489471436,0.6363636255264282,0.75,0.15526103431528265
100,,,,,,mmlu:medical_genetics,test,111.71925863530487,llama2_13b,choice,oe,0.44999998807907104,0.47999998927116394,0.5860606060606062,0.22657069206237793
38,,,,,,mmlu:moral_disputes,validation,42.96588546503335,llama2_13b,choice,oe,0.28947368264198303,0.5789473652839661,0.2962962962962963,0.09441858530044553
346,,,,,,mmlu:moral_disputes,test,380.83922792505473,llama2_13b,choice,oe,0.398843914270401,0.5664739608764648,0.5317028985507246,0.04156109397811011
33,,,,,,mmlu:nutrition,validation,41.30175296869129,llama2_13b,choice,oe,0.3333333432674408,0.3333333432674408,0.4752066115702479,0.31709886500329687
306,,,,,,mmlu:nutrition,test,342.9323823582381,llama2_13b,choice,oe,0.379084974527359,0.48366013169288635,0.6295825771324863,0.18875213132964241
34,,,,,,mmlu:philosophy,validation,38.2568125417456,llama2_13b,choice,oe,0.29411765933036804,0.5,0.7041666666666666,0.17597761048990138
311,,,,,,mmlu:philosophy,test,340.8419063044712,llama2_13b,choice,oe,0.32797425985336304,0.5434083342552185,0.547635800731776,0.11804026901913607
35,,,,,,mmlu:prehistory,validation,38.935289015993476,llama2_13b,choice,oe,0.3142857253551483,0.4000000059604645,0.43939393939393934,0.23932809659412932
324,,,,,,mmlu:prehistory,test,380.223090428859,llama2_13b,choice,oe,0.4783950746059418,0.5555555820465088,0.5687726665394159,0.0773217306460863
69,,,,,,mmlu:professional_psychology,validation,82.75674564484507,llama2_13b,choice,oe,0.37681159377098083,0.3913043439388275,0.5406976744186047,0.2699531100798344
612,,,,,,mmlu:professional_psychology,test,687.3116359049454,llama2_13b,choice,oe,0.30718955397605896,0.3758170008659363,0.48588041951023686,0.2983327864431868
12,,,,,,mmlu:public_relations,validation,13.130572937428951,llama2_13b,choice,oe,0.25,0.4166666865348816,0.3333333333333333,0.2879145443439484
110,,,,,,mmlu:public_relations,test,119.27559565939009,llama2_13b,choice,oe,0.3272727131843567,0.4999999701976776,0.6373873873873874,0.21051076379689304
27,,,,,,mmlu:security_studies,validation,31.89075047429651,llama2_13b,choice,oe,0.5555555820465088,0.6666666865348816,0.46944444444444444,0.0847826246862058
245,,,,,,mmlu:security_studies,test,284.1633826373145,llama2_13b,choice,oe,0.5714285373687744,0.5755102038383484,0.5027210884353741,0.0711812072870683
22,,,,,,mmlu:sociology,validation,25.27585423272103,llama2_13b,choice,oe,0.5909091234207153,0.6363636255264282,0.6752136752136753,0.09707996249198912
201,,,,,,mmlu:sociology,test,221.87958667147905,llama2_13b,choice,oe,0.3980099558830261,0.43283581733703613,0.6129132231404958,0.2707047157026642
11,,,,,,mmlu:us_foreign_policy,validation,12.825309908948839,llama2_13b,choice,oe,0.6363636255264282,0.5454545617103577,0.5357142857142857,0.37591816620393237
100,,,,,,mmlu:us_foreign_policy,test,108.15266650915146,llama2_13b,choice,oe,0.5799999833106995,0.5399999618530273,0.4792692939244664,0.13332564413547518
18,,,,,,mmlu:virology,validation,21.43473580200225,llama2_13b,choice,oe,0.3333333432674408,0.3333333432674408,0.5,0.3410899009969499
166,,,,,,mmlu:virology,test,177.18845197930932,llama2_13b,choice,oe,0.34939756989479065,0.40361443161964417,0.5716794380587484,0.27820110105606455
19,,,,,,mmlu:world_religions,validation,21.16430532373488,llama2_13b,choice,oe,0.6842105388641357,0.7368420958518982,0.38461538461538464,0.25169514354906586
171,,,,,,mmlu:world_religions,test,205.28262194804847,llama2_13b,choice,oe,0.6491228342056274,0.6549707651138306,0.6232732732732733,0.04055374024207133
11,0.06920236890966242,0.1818181872367859,0.3636363744735718,0.5555555555555556,0.20478592677549884,mmlu:abstract_algebra,validation,4.642425149679184,llama2_13b,oe,choice,,,,
100,0.04222254246473312,0.3100000023841858,0.3799999952316284,0.5507246376811594,0.21088379085063935,mmlu:abstract_algebra,test,18.896620094776154,llama2_13b,oe,choice,,,,
14,0.14716745274407525,0.4285714626312256,0.4285714626312256,0.75,0.38068536349705284,mmlu:anatomy,validation,2.873669760301709,llama2_13b,oe,choice,,,,
135,0.09001349961316145,0.5111110806465149,0.5111110806465149,0.6021080368906455,0.27399814967755914,mmlu:anatomy,test,27.24381468258798,llama2_13b,oe,choice,,,,
16,0.2289632372558117,0.5625,0.625,0.8571428571428572,0.14100690186023715,mmlu:astronomy,validation,5.033633170649409,llama2_13b,oe,choice,,,,
152,0.1163935759349873,0.5131579041481018,0.5131579041481018,0.6768884268884269,0.23018378568323036,mmlu:astronomy,test,46.853402245789766,llama2_13b,oe,choice,,,,
11,0.25074630975723267,0.3636363744735718,0.3636363744735718,0.4285714285714286,0.4008104259317572,mmlu:business_ethics,validation,3.441248320043087,llama2_13b,oe,choice,,,,
100,0.08249628603458406,0.5299999713897705,0.5299999713897705,0.6240465676435167,0.22732236206531523,mmlu:business_ethics,test,30.697857595980167,llama2_13b,oe,choice,,,,
29,0.13683780308427484,0.5862069129943848,0.5862069129943848,0.45098039215686275,0.20125497826214495,mmlu:clinical_knowledge,validation,6.744833678007126,llama2_13b,oe,choice,,,,
265,0.03372989926698072,0.5886792540550232,0.5811320543289185,0.6469948247471183,0.13752648852906138,mmlu:clinical_knowledge,test,60.326055221259594,llama2_13b,oe,choice,,,,
16,0.1720481961965561,0.5625,0.5625,0.8492063492063492,0.22986050695180893,mmlu:college_biology,validation,4.205199591815472,llama2_13b,oe,choice,,,,
144,0.06489325004319352,0.5486111044883728,0.5486111044883728,0.655111976630964,0.24337123582760498,mmlu:college_biology,test,38.208680076524615,llama2_13b,oe,choice,,,,
8,0.40915826708078384,0.625,0.625,0.4666666666666667,0.2841598093509674,mmlu:college_chemistry,validation,2.4994894824922085,llama2_13b,oe,choice,,,,
100,0.12028073847293855,0.44999998807907104,0.4599999785423279,0.6105050505050504,0.27045974671840667,mmlu:college_chemistry,test,29.078812127932906,llama2_13b,oe,choice,,,,
11,0.23285808075558057,0.6363636255264282,0.4545454680919647,0.75,0.1760869188742204,mmlu:college_computer_science,validation,4.651950983330607,llama2_13b,oe,choice,,,,
100,0.1002258676290512,0.4399999976158142,0.5299999713897705,0.5525568181818182,0.07206275939941408,mmlu:college_computer_science,test,42.95733919553459,llama2_13b,oe,choice,,,,
11,0.12380083853548224,0.1818181872367859,0.5454545617103577,0.8333333333333334,0.08400603316046976,mmlu:college_mathematics,validation,3.3541375789791346,llama2_13b,oe,choice,,,,
100,0.06589578837156294,0.29999998211860657,0.5999999642372131,0.546904761904762,0.04200498759746555,mmlu:college_mathematics,test,29.44815469160676,llama2_13b,oe,choice,,,,
22,0.12571292438290338,0.5454545617103577,0.5454545617103577,0.8083333333333333,0.2847186218608509,mmlu:college_medicine,validation,6.2508627492934465,llama2_13b,oe,choice,,,,
173,0.058592356009290414,0.5549132823944092,0.5549132823944092,0.6288555194805195,0.1930946308064323,mmlu:college_medicine,test,57.56451851502061,llama2_13b,oe,choice,,,,
11,0.1288730718872764,0.5454545617103577,0.6363636255264282,0.8333333333333334,0.17755395715886896,mmlu:college_physics,validation,2.8992477003484964,llama2_13b,oe,choice,,,,
102,0.15867351404592106,0.2549019753932953,0.5098039507865906,0.6465080971659919,0.11603787366081687,mmlu:college_physics,test,26.195694180205464,llama2_13b,oe,choice,,,,
11,0.3201443932273171,0.8181818723678589,0.8181818723678589,0.8888888888888888,0.14284209229729392,mmlu:computer_security,validation,2.743725538253784,llama2_13b,oe,choice,,,,
100,0.07781153231859207,0.7099999785423279,0.7199999690055847,0.55560951918407,0.044830139875412,mmlu:computer_security,test,21.861122127622366,llama2_13b,oe,choice,,,,
26,0.15561166520302114,0.42307692766189575,0.46153849363327026,0.6848484848484848,0.25628658212148225,mmlu:conceptual_physics,validation,4.487974099814892,llama2_13b,oe,choice,,,,
235,0.12013903146094464,0.3914893567562103,0.40425530076026917,0.6208574034660991,0.31121353316814343,mmlu:conceptual_physics,test,39.30044244043529,llama2_13b,oe,choice,,,,
12,0.17015917847553888,0.25,0.1666666716337204,0.4814814814814815,0.5204853415489197,mmlu:econometrics,validation,3.8938521686941385,llama2_13b,oe,choice,,,,
114,0.1632876720344811,0.24561403691768646,0.2719298303127289,0.5490033222591362,0.3905435110393324,mmlu:econometrics,test,36.24751828983426,llama2_13b,oe,choice,,,,
16,0.13311614841222763,0.375,0.5,0.65,0.32748810946941376,mmlu:electrical_engineering,validation,3.7716244366019964,llama2_13b,oe,choice,,,,
145,0.0973424523041166,0.4413793087005615,0.48275861144065857,0.7476851851851852,0.23610634269385503,mmlu:electrical_engineering,test,33.17780532501638,llama2_13b,oe,choice,,,,
41,0.09600169629585452,0.4146341383457184,0.4146341383457184,0.5367647058823529,0.22224545624197983,mmlu:elementary_mathematics,validation,11.890183011069894,llama2_13b,oe,choice,,,,
378,0.06784735217926996,0.31216931343078613,0.3492063283920288,0.4972294654498044,0.29198252807849295,mmlu:elementary_mathematics,test,106.67089467309415,llama2_13b,oe,choice,,,,
14,0.12916469999722072,0.2857142984867096,0.2857142984867096,0.6,0.43340055431638447,mmlu:formal_logic,validation,4.516170045360923,llama2_13b,oe,choice,,,,
126,0.02843788242529311,0.3492063581943512,0.3492063581943512,0.5695676274944568,0.3801449646079351,mmlu:formal_logic,test,40.38606961071491,llama2_13b,oe,choice,,,,
10,0.14060280919075013,0.5,0.4000000059604645,0.72,0.1491527557373047,mmlu:global_facts,validation,2.399564104154706,llama2_13b,oe,choice,,,,
100,0.08612264096736909,0.3499999940395355,0.5299999713897705,0.5054945054945055,0.043956020474433935,mmlu:global_facts,test,22.852420261129737,llama2_13b,oe,choice,,,,
32,0.1209655273705721,0.53125,0.53125,0.5294117647058824,0.29145573265850544,mmlu:high_school_biology,validation,9.117697758600116,llama2_13b,oe,choice,,,,
310,0.060094018520847454,0.6645160913467407,0.6645160913467407,0.6021751306945482,0.16127023177762181,mmlu:high_school_biology,test,87.5567141212523,llama2_13b,oe,choice,,,,
22,0.10005006465044892,0.3636363744735718,0.40909093618392944,0.5267857142857143,0.38646045327186584,mmlu:high_school_chemistry,validation,6.327123144641519,llama2_13b,oe,choice,,,,
203,0.05729783227291012,0.4729064106941223,0.4876847267150879,0.5667348130841121,0.2643809394883405,mmlu:high_school_chemistry,test,54.85128217190504,llama2_13b,oe,choice,,,,
9,0.17603182130389744,0.6666666865348816,0.7777777910232544,0.888888888888889,0.12165375550587969,mmlu:high_school_computer_science,validation,4.45201051607728,llama2_13b,oe,choice,,,,
100,0.09345588743686677,0.5399999618530273,0.5699999928474426,0.6555958132045089,0.0859214526414871,mmlu:high_school_computer_science,test,48.603773375973105,llama2_13b,oe,choice,,,,
22,0.14594153247096323,0.7272727489471436,0.7272727489471436,0.8229166666666666,0.07000973820686339,mmlu:high_school_geography,validation,4.754889177158475,llama2_13b,oe,choice,,,,
198,0.06559802004785248,0.7222222089767456,0.7222222089767456,0.678639542275906,0.08086793982621392,mmlu:high_school_geography,test,42.27096359618008,llama2_13b,oe,choice,,,,
21,0.1844906466347831,0.7142857313156128,0.7142857313156128,0.8333333333333334,0.1420272134599232,mmlu:high_school_government_and_politics,validation,5.241333676502109,llama2_13b,oe,choice,,,,
193,0.04912939513285542,0.8238341808319092,0.8186528086662292,0.5843507214206437,0.05122611590617679,mmlu:high_school_government_and_politics,test,47.604850593954325,llama2_13b,oe,choice,,,,
43,0.16379689199979913,0.5116279125213623,0.5581395626068115,0.6666666666666666,0.12536921196205675,mmlu:high_school_macroeconomics,validation,9.377882102504373,llama2_13b,oe,choice,,,,
390,0.07977168086247566,0.5333333611488342,0.5384615659713745,0.6631577557058326,0.15254549995446817,mmlu:high_school_macroeconomics,test,84.98526310175657,llama2_13b,oe,choice,,,,
29,0.11061135551025127,0.24137930572032928,0.6551724076271057,0.3896103896103896,0.07804680692738498,mmlu:high_school_mathematics,validation,8.048621824011207,llama2_13b,oe,choice,,,,
270,0.09013029590800958,0.23333333432674408,0.5518518686294556,0.3934130818188789,0.04178467922740513,mmlu:high_school_mathematics,test,73.06030590087175,llama2_13b,oe,choice,,,,
26,0.23534159706189087,0.692307710647583,0.692307710647583,0.5763888888888888,0.045927627728535564,mmlu:high_school_microeconomics,validation,5.662933325394988,llama2_13b,oe,choice,,,,
238,0.070158546086119,0.5756303071975708,0.5924370288848877,0.6419382814193827,0.09872259562756835,mmlu:high_school_microeconomics,test,52.28702647984028,llama2_13b,oe,choice,,,,
17,0.214115626671735,0.23529411852359772,0.3529411852359772,0.5192307692307692,0.2883891813895282,mmlu:high_school_physics,validation,5.1384915839880705,llama2_13b,oe,choice,,,,
151,0.032332958172488685,0.3907284736633301,0.3907284736633301,0.5512159174649963,0.2491662711497174,mmlu:high_school_physics,test,44.142260091379285,llama2_13b,oe,choice,,,,
60,0.11067090133825937,0.8000000715255737,0.8000000715255737,0.6727430555555556,0.0505953947703044,mmlu:high_school_psychology,validation,16.60383302718401,llama2_13b,oe,choice,,,,
545,0.05436075614133011,0.7614678740501404,0.7614678740501404,0.694105653382762,0.05026155907079717,mmlu:high_school_psychology,test,151.00858535803854,llama2_13b,oe,choice,,,,
23,0.1703792395799056,0.43478262424468994,0.6086956858634949,0.623076923076923,0.06300046132958453,mmlu:high_school_statistics,validation,9.456851473078132,llama2_13b,oe,choice,,,,
216,0.04346492265661556,0.4490740895271301,0.5231481790542603,0.6073377804730139,0.11837100679123845,mmlu:high_school_statistics,test,93.00666287355125,llama2_13b,oe,choice,,,,
22,0.17520021985877646,0.7727273106575012,0.7727273106575012,0.4588235294117647,0.10072554512457418,mmlu:high_school_us_history,validation,34.325808783993125,llama2_13b,oe,choice,,,,
204,0.09055403050254372,0.7598039507865906,0.7598039507865906,0.6810401579986833,0.05916006454065735,mmlu:high_school_us_history,test,311.96836156211793,llama2_13b,oe,choice,,,,
23,0.29493607386298804,0.5652173757553101,0.5652173757553101,0.5269230769230769,0.2425028655840003,mmlu:human_aging,validation,4.19324029609561,llama2_13b,oe,choice,,,,
223,0.07797254281193688,0.5964125990867615,0.6008968949317932,0.6351712614870509,0.12986671096006314,mmlu:human_aging,test,38.946452440693974,llama2_13b,oe,choice,,,,
12,0.15332866211732227,0.5,0.5,0.7777777777777778,0.3025832573572795,mmlu:human_sexuality,validation,2.3615709114819765,llama2_13b,oe,choice,,,,
131,0.09053917058551583,0.6106870174407959,0.6106870174407959,0.6743872549019607,0.1966469997668084,mmlu:human_sexuality,test,26.621361715719104,llama2_13b,oe,choice,,,,
13,0.18429349935971776,0.7692307829856873,0.7692307829856873,0.6333333333333333,0.03403653089816754,mmlu:international_law,validation,4.58114393055439,llama2_13b,oe,choice,,,,
121,0.0732406697982599,0.719008207321167,0.719008207321167,0.6125760649087222,0.07551370327137716,mmlu:international_law,test,39.77044410444796,llama2_13b,oe,choice,,,,
11,0.22142491828311575,0.4545454680919647,0.4545454680919647,0.9333333333333333,0.33570596304806793,mmlu:jurisprudence,validation,2.512894442304969,llama2_13b,oe,choice,,,,
108,0.10479138874345355,0.7037037014961243,0.7037037014961243,0.6122532894736842,0.023702676097551993,mmlu:jurisprudence,test,23.80730159021914,llama2_13b,oe,choice,,,,
18,0.2224999864896138,0.7777777910232544,0.7777777910232544,0.6071428571428572,0.10039555364184911,mmlu:logical_fallacies,validation,4.3621218632906675,llama2_13b,oe,choice,,,,
163,0.06698918635128467,0.6380367875099182,0.6564416885375977,0.725635593220339,0.08603033734245533,mmlu:logical_fallacies,test,38.75312535651028,llama2_13b,oe,choice,,,,
11,0.19108336080204355,0.4545454680919647,0.4545454680919647,0.26666666666666666,0.15161903337998822,mmlu:machine_learning,validation,3.6766961608082056,llama2_13b,oe,choice,,,,
112,0.19081376971943037,0.2142857313156128,0.2767857313156128,0.5395359848484848,0.3521224877664021,mmlu:machine_learning,test,37.18924995884299,llama2_13b,oe,choice,,,,
11,0.23109854893250903,0.7272727489471436,0.7272727489471436,0.75,0.2504722205075351,mmlu:management,validation,1.905543264001608,llama2_13b,oe,choice,,,,
103,0.10133581601300287,0.7766990661621094,0.7669903039932251,0.607608695652174,0.05461381187716733,mmlu:management,test,16.63794280961156,llama2_13b,oe,choice,,,,
25,0.2459735798835755,0.8399999737739563,0.8399999737739563,0.6666666666666666,0.06644035339355467,mmlu:marketing,validation,5.768787819892168,llama2_13b,oe,choice,,,,
234,0.0601038861478496,0.7820513248443604,0.7820513248443604,0.6300225008036,0.02521628447068041,mmlu:marketing,test,52.120808655396104,llama2_13b,oe,choice,,,,
11,0.17915785854512994,0.8181818723678589,0.8181818723678589,0.7222222222222222,0.1259747581048445,mmlu:medical_genetics,validation,2.3958062902092934,llama2_13b,oe,choice,,,,
100,0.1411105951666832,0.5799999833106995,0.5799999833106995,0.5835385878489329,0.23762769401073455,mmlu:medical_genetics,test,19.94202104769647,llama2_13b,oe,choice,,,,
38,0.18718513611115908,0.5263158082962036,0.5263158082962036,0.6458333333333334,0.2670397523202394,mmlu:moral_disputes,validation,9.633735788986087,llama2_13b,oe,choice,,,,
346,0.055437243484348246,0.6098265647888184,0.6098265647888184,0.5747761979989469,0.16969282950969108,mmlu:moral_disputes,test,87.49669132009149,llama2_13b,oe,choice,,,,
33,0.1813181160074292,0.7575757503509521,0.7575757503509521,0.815,0.10977427706573945,mmlu:nutrition,validation,10.486395586282015,llama2_13b,oe,choice,,,,
306,0.07220801623428569,0.6241829991340637,0.6274510025978088,0.6823810607785112,0.09032820389161701,mmlu:nutrition,test,97.24008858762681,llama2_13b,oe,choice,,,,
34,0.20816840319072502,0.6470588445663452,0.6470588445663452,0.5075757575757576,0.1603669120984919,mmlu:philosophy,validation,6.570330778136849,llama2_13b,oe,choice,,,,
311,0.09089757631446005,0.6495176553726196,0.6495176553726196,0.5304296484694341,0.15896498198677875,mmlu:philosophy,test,57.81220767274499,llama2_13b,oe,choice,,,,
35,0.18569657632282802,0.6285714507102966,0.6285714507102966,0.541958041958042,0.17778842619487217,mmlu:prehistory,validation,10.271798433735967,llama2_13b,oe,choice,,,,
324,0.06019172900252873,0.6419752836227417,0.6388888955116272,0.6367498342175066,0.16429593938368334,mmlu:prehistory,test,93.01255234517157,llama2_13b,oe,choice,,,,
69,0.15859784207482272,0.5652173757553101,0.5652173757553101,0.6188034188034188,0.21733042900113092,mmlu:professional_psychology,validation,21.579129984602332,llama2_13b,oe,choice,,,,
612,0.0725067993199903,0.5555555820465088,0.5555555820465088,0.6280439013840831,0.22818896505567765,mmlu:professional_psychology,test,184.31915041804314,llama2_13b,oe,choice,,,,
12,0.49819476405779517,0.5833333730697632,0.5833333730697632,0.4571428571428572,0.21863939861456555,mmlu:public_relations,validation,3.0789145417511463,llama2_13b,oe,choice,,,,
110,0.07987526167522778,0.6363636255264282,0.6272727251052856,0.6866071428571427,0.135403343222358,mmlu:public_relations,test,25.428514501079917,llama2_13b,oe,choice,,,,
27,0.23700715546254758,0.5925925970077515,0.5925925970077515,0.5909090909090909,0.15507098480507175,mmlu:security_studies,validation,18.590784467756748,llama2_13b,oe,choice,,,,
245,0.047171321328805416,0.6326530575752258,0.6326530575752258,0.5695340501792114,0.12857106461816908,mmlu:security_studies,test,173.83118628896773,llama2_13b,oe,choice,,,,
22,0.160487486557527,0.8181818723678589,0.8181818723678589,0.5694444444444444,0.12398258393461054,mmlu:sociology,validation,5.230691622942686,llama2_13b,oe,choice,,,,
201,0.06170249207695916,0.7661691308021545,0.7711442708969116,0.6329096435479414,0.05174659466862087,mmlu:sociology,test,47.676964823156595,llama2_13b,oe,choice,,,,
11,0.13227141445333307,0.9090909361839294,0.9090909361839294,0.0,0.19563791968605734,mmlu:us_foreign_policy,validation,2.61267894692719,llama2_13b,oe,choice,,,,
100,0.06834511309862137,0.8499999642372131,0.8499999642372131,0.4862745098039215,0.0812280839681625,mmlu:us_foreign_policy,test,22.733949419111013,llama2_13b,oe,choice,,,,
18,0.24425924155447218,0.5,0.5,0.7160493827160495,0.21297520730230546,mmlu:virology,validation,4.308843018487096,llama2_13b,oe,choice,,,,
166,0.17515957481171712,0.4457831084728241,0.4518072009086609,0.5782902467685076,0.28130444058452747,mmlu:virology,test,33.01248092763126,llama2_13b,oe,choice,,,,
19,0.08429366820736936,0.7894737124443054,0.7894737124443054,0.4666666666666667,0.11076057898370846,mmlu:world_religions,validation,3.0327290426939726,llama2_13b,oe,choice,,,,
171,0.04342272372273675,0.7719298601150513,0.7719298601150513,0.6748251748251748,0.07142806122874655,mmlu:world_religions,test,26.64856169372797,llama2_13b,oe,choice,,,,
11,,,,,,mmlu:abstract_algebra,validation,15.393035515211523,llama2_13b,oe,oe,0.1818181872367859,0.6363636255264282,0.4444444444444444,0.1826487887989391
100,,,,,,mmlu:abstract_algebra,test,107.78980270400643,llama2_13b,oe,oe,0.23999999463558197,0.6299999952316284,0.36951754385964913,0.05556112110614777
14,,,,,,mmlu:anatomy,validation,15.762436387129128,llama2_13b,oe,oe,0.4285714626312256,0.6428571939468384,0.5625,0.1714645964758737
135,,,,,,mmlu:anatomy,test,134.07414611196145,llama2_13b,oe,oe,0.4814814627170563,0.6074073910713196,0.7432967032967033,0.14601559638977052
16,,,,,,mmlu:astronomy,validation,16.861292873043567,llama2_13b,oe,oe,0.4375,0.5625,0.7301587301587302,0.3693855255842209
152,,,,,,mmlu:astronomy,test,158.6464875638485,llama2_13b,oe,oe,0.46710526943206787,0.5394737124443054,0.5848548078595026,0.14377153155050781
11,,,,,,mmlu:business_ethics,validation,12.898651289753616,llama2_13b,oe,oe,0.5454545617103577,0.6363636255264282,0.7333333333333334,0.24844877828251233
100,,,,,,mmlu:business_ethics,test,111.97576177306473,llama2_13b,oe,oe,0.3100000023841858,0.38999998569488525,0.6694717157550257,0.31930376827716833
29,,,,,,mmlu:clinical_knowledge,validation,33.08372376905754,llama2_13b,oe,oe,0.24137930572032928,0.48275861144065857,0.7012987012987013,0.14665928585775967
265,,,,,,mmlu:clinical_knowledge,test,272.10097303800285,llama2_13b,oe,oe,0.29811322689056396,0.5169811248779297,0.6528855315094596,0.14190921131170023
16,,,,,,mmlu:college_biology,validation,17.562310197856277,llama2_13b,oe,oe,0.1875,0.4375,0.5897435897435898,0.24205376207828522
144,,,,,,mmlu:college_biology,test,155.82487478293478,llama2_13b,oe,oe,0.3958333432674408,0.5138888955116272,0.6317806009276064,0.18658479965395397
8,,,,,,mmlu:college_chemistry,validation,8.978947321884334,llama2_13b,oe,oe,0.125,0.375,0.8571428571428572,0.44826025515794754
100,,,,,,mmlu:college_chemistry,test,111.0120681989938,llama2_13b,oe,oe,0.1599999964237213,0.5399999618530273,0.5970982142857143,0.19116912484169007
11,,,,,,mmlu:college_computer_science,validation,15.839873814024031,llama2_13b,oe,oe,0.1818181872367859,0.5454545617103577,0.11111111111111116,0.22701868143948642
100,,,,,,mmlu:college_computer_science,test,139.8200746853836,llama2_13b,oe,oe,0.2199999988079071,0.5600000023841858,0.4976689976689977,0.221421058177948
11,,,,,,mmlu:college_mathematics,validation,14.055380113888532,llama2_13b,oe,oe,0.09090909361839294,1.0,0.09999999999999998,0.1401311375878074
100,,,,,,mmlu:college_mathematics,test,121.97274239826947,llama2_13b,oe,oe,0.12999999523162842,0.7099999785423279,0.4314765694076039,0.10778123915195464
22,,,,,,mmlu:college_medicine,validation,25.38403229881078,llama2_13b,oe,oe,0.4545454680919647,0.5909091234207153,0.7583333333333334,0.1582605947147716
173,,,,,,mmlu:college_medicine,test,204.18239783495665,llama2_13b,oe,oe,0.2832369804382324,0.5202311873435974,0.6835911784068466,0.22640117399954382
11,,,,,,mmlu:college_physics,validation,13.636975366156548,llama2_13b,oe,oe,0.3636363744735718,0.8181818723678589,0.35714285714285715,0.21102417599071158
102,,,,,,mmlu:college_physics,test,118.49130813917145,llama2_13b,oe,oe,0.1764705926179886,0.7843137383460999,0.3333333333333333,0.05558741209553735
11,,,,,,mmlu:computer_security,validation,12.803939556702971,llama2_13b,oe,oe,0.27272728085517883,0.4545454680919647,0.6249999999999999,0.13359565084630792
100,,,,,,mmlu:computer_security,test,101.98940038634464,llama2_13b,oe,oe,0.4399999976158142,0.5899999737739563,0.6461038961038961,0.057629426717758184
26,,,,,,mmlu:conceptual_physics,validation,27.175802876241505,llama2_13b,oe,oe,0.38461539149284363,0.5384615659713745,0.39375,0.26287258817599374
235,,,,,,mmlu:conceptual_physics,test,232.97020045900717,llama2_13b,oe,oe,0.4510638117790222,0.5574467778205872,0.5764955389790845,0.1261198292387293
12,,,,,,mmlu:econometrics,validation,14.431797535158694,llama2_13b,oe,oe,0.0833333358168602,0.5,1.0,0.12451305985450746
114,,,,,,mmlu:econometrics,test,139.44256663694978,llama2_13b,oe,oe,0.14912280440330505,0.6315789222717285,0.49727107337780474,0.054843575808039904
16,,,,,,mmlu:electrical_engineering,validation,16.77651061117649,llama2_13b,oe,oe,0.375,0.625,0.4,0.13274847343564034
145,,,,,,mmlu:electrical_engineering,test,156.33024742500857,llama2_13b,oe,oe,0.24137930572032928,0.5724138021469116,0.503896103896104,0.11844779211899327
41,,,,,,mmlu:elementary_mathematics,validation,47.383270480670035,llama2_13b,oe,oe,0.2926829159259796,0.7560975551605225,0.46551724137931033,0.11116355366823147
378,,,,,,mmlu:elementary_mathematics,test,415.9731574081816,llama2_13b,oe,oe,0.3809523582458496,0.6534391045570374,0.3571343779677113,0.07664246218545097
14,,,,,,mmlu:formal_logic,validation,17.357635198161006,llama2_13b,oe,oe,0.4285714626312256,0.4285714626312256,0.5625,0.23563835450581144
126,,,,,,mmlu:formal_logic,test,143.83177494211122,llama2_13b,oe,oe,0.1904762089252472,0.2777777910232544,0.45343137254901966,0.37811159472616906
10,,,,,,mmlu:global_facts,validation,14.166053629945964,llama2_13b,oe,oe,0.20000000298023224,0.800000011920929,0.3125,0.33193285465240485
100,,,,,,mmlu:global_facts,test,330.35029898164794,llama2_13b,oe,oe,0.1899999976158142,0.5899999737739563,0.5549057829759585,0.07038900256156924
32,,,,,,mmlu:high_school_biology,validation,34.281078054104,llama2_13b,oe,oe,0.40625,0.34375,0.4251012145748988,0.3889170605689287
310,,,,,,mmlu:high_school_biology,test,341.7265888918191,llama2_13b,oe,oe,0.44516128301620483,0.4935483932495117,0.6007119986518369,0.265023507033625
22,,,,,,mmlu:high_school_chemistry,validation,27.243604802060872,llama2_13b,oe,oe,0.13636364042758942,0.5,0.2631578947368421,0.219051025130532
203,,,,,,mmlu:high_school_chemistry,test,227.3598304130137,llama2_13b,oe,oe,0.1822660118341446,0.45812806487083435,0.5673233474438294,0.23283885911180466
9,,,,,,mmlu:high_school_computer_science,validation,13.791070118080825,llama2_13b,oe,oe,0.2222222238779068,0.4444444477558136,0.2142857142857143,0.26650610897276134
100,,,,,,mmlu:high_school_computer_science,test,131.87264056317508,llama2_13b,oe,oe,0.4099999964237213,0.5699999928474426,0.5888797023563457,0.1155151402950287
22,,,,,,mmlu:high_school_geography,validation,24.399716740008444,llama2_13b,oe,oe,0.5,0.6818181872367859,0.5206611570247934,0.273407437584617
198,,,,,,mmlu:high_school_geography,test,204.1900398149155,llama2_13b,oe,oe,0.38383838534355164,0.6111111044883728,0.6368636755823984,0.0963736086180716
21,,,,,,mmlu:high_school_government_and_politics,validation,24.19668260589242,llama2_13b,oe,oe,0.5714285969734192,0.5714285969734192,0.5740740740740741,0.15382612035388035
193,,,,,,mmlu:high_school_government_and_politics,test,337.0325264399871,llama2_13b,oe,oe,0.5388600826263428,0.5647668242454529,0.61052290406223,0.12117775116559755
43,,,,,,mmlu:high_school_macroeconomics,validation,44.21037371829152,llama2_13b,oe,oe,0.44186046719551086,0.5348837375640869,0.46491228070175433,0.17286345709201903
390,,,,,,mmlu:high_school_macroeconomics,test,396.4013717826456,llama2_13b,oe,oe,0.3410256505012512,0.5,0.5421286679734356,0.1487838647304437
29,,,,,,mmlu:high_school_mathematics,validation,35.76725732116029,llama2_13b,oe,oe,0.06896551698446274,0.931034505367279,0.37037037037037035,0.058953531857194603
270,,,,,,mmlu:high_school_mathematics,test,322.09553049784154,llama2_13b,oe,oe,0.09259258955717087,0.8740740418434143,0.29289795918367345,0.03924505644374424
26,,,,,,mmlu:high_school_microeconomics,validation,27.453804180026054,llama2_13b,oe,oe,0.3461538553237915,0.42307692766189575,0.4901960784313726,0.24521233714543858
238,,,,,,mmlu:high_school_microeconomics,test,239.342870533932,llama2_13b,oe,oe,0.3907563090324402,0.5084033608436584,0.5918057100482016,0.14929628998291591
17,,,,,,mmlu:high_school_physics,validation,21.777577774133533,llama2_13b,oe,oe,0.11764705926179886,0.7647058963775635,0.6,0.16624045021393724
151,,,,,,mmlu:high_school_physics,test,171.42181257391348,llama2_13b,oe,oe,0.23178808391094208,0.5960264801979065,0.44285714285714284,0.13148128828465547
60,,,,,,mmlu:high_school_psychology,validation,65.34729164978489,llama2_13b,oe,oe,0.6000000238418579,0.5333333611488342,0.6747685185185186,0.16808202167352043
545,,,,,,mmlu:high_school_psychology,test,598.0626040999778,llama2_13b,oe,oe,0.5357798337936401,0.5834862589836121,0.611030645947263,0.12871379994471138
23,,,,,,mmlu:high_school_statistics,validation,29.27358141867444,llama2_13b,oe,oe,0.21739131212234497,0.6521739363670349,0.4666666666666667,0.14415803940399832
216,,,,,,mmlu:high_school_statistics,test,271.80489552160725,llama2_13b,oe,oe,0.23148147761821747,0.569444477558136,0.42373493975903614,0.1303122283683883
22,,,,,,mmlu:high_school_us_history,validation,64.81227821623906,llama2_13b,oe,oe,0.6818181872367859,0.6818181872367859,0.39047619047619053,0.1797683428634297
204,,,,,,mmlu:high_school_us_history,test,605.8857971201651,llama2_13b,oe,oe,0.6225490570068359,0.6617647409439087,0.6788526434195726,0.061555896319595044
23,,,,,,mmlu:human_aging,validation,23.72580244904384,llama2_13b,oe,oe,0.3478260934352875,0.3478260934352875,0.47500000000000003,0.3405242458633755
223,,,,,,mmlu:human_aging,test,221.64082416286692,llama2_13b,oe,oe,0.3677130341529846,0.5156950950622559,0.6844404082338695,0.2563663520620543
12,,,,,,mmlu:human_sexuality,validation,12.155937016941607,llama2_13b,oe,oe,0.5,0.5,0.41666666666666663,0.14530625939369202
131,,,,,,mmlu:human_sexuality,test,134.413665602915,llama2_13b,oe,oe,0.4198473393917084,0.6106870174407959,0.7127990430622008,0.10198787468990296
13,,,,,,mmlu:international_law,validation,16.40357758803293,llama2_13b,oe,oe,0.38461539149284363,0.46153849363327026,0.35,0.2974196443190942
121,,,,,,mmlu:international_law,test,130.3793426612392,llama2_13b,oe,oe,0.5123966932296753,0.6033057570457458,0.6463914707490432,0.11671392582664802
11,,,,,,mmlu:jurisprudence,validation,12.050900136120617,llama2_13b,oe,oe,0.3636363744735718,0.4545454680919647,0.39285714285714285,0.20946709134361957
108,,,,,,mmlu:jurisprudence,test,109.81529458612204,llama2_13b,oe,oe,0.40740740299224854,0.5648148059844971,0.5788352272727273,0.13865891595681507
18,,,,,,mmlu:logical_fallacies,validation,20.41658637020737,llama2_13b,oe,oe,0.4444444477558136,0.3333333432674408,0.625,0.35429378350575774
163,,,,,,mmlu:logical_fallacies,test,175.09939500596374,llama2_13b,oe,oe,0.46625766158103943,0.5950919985771179,0.597020568663037,0.11039622978198745
11,,,,,,mmlu:machine_learning,validation,13.625923287123442,llama2_13b,oe,oe,0.3636363744735718,0.4545454680919647,0.07142857142857142,0.20798218250274655
112,,,,,,mmlu:machine_learning,test,129.508573517669,llama2_13b,oe,oe,0.1875000149011612,0.455357164144516,0.4225536368393511,0.19704603190932957
11,,,,,,mmlu:management,validation,11.603190822061151,llama2_13b,oe,oe,0.7272727489471436,0.6363636255264282,0.5833333333333334,0.18768002770163794
103,,,,,,mmlu:management,test,111.23691357299685,llama2_13b,oe,oe,0.4466019570827484,0.5922330021858215,0.5867658276125095,0.09616587636540236
25,,,,,,mmlu:marketing,validation,28.45969201484695,llama2_13b,oe,oe,0.35999998450279236,0.3999999761581421,0.6909722222222222,0.32814099073410036
234,,,,,,mmlu:marketing,test,242.3197507020086,llama2_13b,oe,oe,0.47435900568962097,0.5,0.5902732000292976,0.21734334057212898
11,,,,,,mmlu:medical_genetics,validation,11.853942864574492,llama2_13b,oe,oe,0.7272727489471436,0.8181818723678589,0.875,0.192926287651062
100,,,,,,mmlu:medical_genetics,test,99.831260681618,llama2_13b,oe,oe,0.47999998927116394,0.5799999833106995,0.5997596153846154,0.13579067885875704
38,,,,,,mmlu:moral_disputes,validation,41.57097466895357,llama2_13b,oe,oe,0.44736841320991516,0.5263158082962036,0.5210084033613446,0.23174455761909488
346,,,,,,mmlu:moral_disputes,test,369.99531486909837,llama2_13b,oe,oe,0.3815028667449951,0.47109824419021606,0.6174242424242423,0.19435991079821063
33,,,,,,mmlu:nutrition,validation,38.14624630426988,llama2_13b,oe,oe,0.3333333432674408,0.42424243688583374,0.5537190082644627,0.3071834553371776
306,,,,,,mmlu:nutrition,test,356.06666752975434,llama2_13b,oe,oe,0.40522876381874084,0.5457516312599182,0.707550514002127,0.16455262315039543
34,,,,,,mmlu:philosophy,validation,35.991804321762174,llama2_13b,oe,oe,0.2647058963775635,0.4117647111415863,0.6622222222222223,0.2906029504888198
311,,,,,,mmlu:philosophy,test,312.8085777820088,llama2_13b,oe,oe,0.3215433955192566,0.3536977469921112,0.5912322274881516,0.35808331828408685
35,,,,,,mmlu:prehistory,validation,37.147622037213296,llama2_13b,oe,oe,0.4571428596973419,0.5428571701049805,0.6513157894736843,0.12148898158754619
324,,,,,,mmlu:prehistory,test,358.7141859252006,llama2_13b,oe,oe,0.4938271641731262,0.645061731338501,0.5747522865853658,0.025840219892101546
69,,,,,,mmlu:professional_psychology,validation,78.29791625030339,llama2_13b,oe,oe,0.3478260934352875,0.43478262424468994,0.42916666666666664,0.23726249777752423
612,,,,,,mmlu:professional_psychology,test,678.0960721690208,llama2_13b,oe,oe,0.32189542055130005,0.46078431606292725,0.5613662772919088,0.21764204091106365
12,,,,,,mmlu:public_relations,validation,14.30440640123561,llama2_13b,oe,oe,0.3333333432674408,0.5833333730697632,0.0,0.4001726557811101
110,,,,,,mmlu:public_relations,test,116.58741901488975,llama2_13b,oe,oe,0.3181818127632141,0.5999999642372131,0.6394285714285715,0.20168340693820602
27,,,,,,mmlu:security_studies,validation,32.158040676731616,llama2_13b,oe,oe,0.48148149251937866,0.5555555820465088,0.6923076923076923,0.19614713721805146
245,,,,,,mmlu:security_studies,test,286.01276575634256,llama2_13b,oe,oe,0.5755102038383484,0.5959183573722839,0.5821399345335516,0.09021226143350403
22,,,,,,mmlu:sociology,validation,23.52595168305561,llama2_13b,oe,oe,0.5,0.5,0.5289256198347108,0.31242426417090674
201,,,,,,mmlu:sociology,test,205.15738437185064,llama2_13b,oe,oe,0.4079601764678955,0.6019900441169739,0.5373027259684362,0.09779867396425844
11,,,,,,mmlu:us_foreign_policy,validation,12.0914816102013,llama2_13b,oe,oe,0.5454545617103577,0.6363636255264282,0.7666666666666666,0.2495181614702398
100,,,,,,mmlu:us_foreign_policy,test,103.81883858889341,llama2_13b,oe,oe,0.5799999833106995,0.6699999570846558,0.7034072249589491,0.03414169609546664
18,,,,,,mmlu:virology,validation,20.778623098041862,llama2_13b,oe,oe,0.3888888955116272,0.5,0.5064935064935066,0.2449878454208374
166,,,,,,mmlu:virology,test,171.45199780073017,llama2_13b,oe,oe,0.33734938502311707,0.46987950801849365,0.5292207792207793,0.18341636909059733
19,,,,,,mmlu:world_religions,validation,19.587731218896806,llama2_13b,oe,oe,0.6842105388641357,0.7368420958518982,0.5897435897435896,0.10118756482475678
171,,,,,,mmlu:world_religions,test,168.56035433989018,llama2_13b,oe,oe,0.6257309913635254,0.6315789222717285,0.6125146028037384,0.0969603201102095
11,,,,,,mmlu:abstract_algebra,validation,17.141521330922842,mistral_7b,choice,oe,0.4545454680919647,0.4545454680919647,0.4333333333333333,0.5066895159808072
100,,,,,,mmlu:abstract_algebra,test,97.29979278892279,mistral_7b,choice,oe,0.32999998331069946,0.32999998331069946,0.44097693351424694,0.6350778794288636
14,,,,,,mmlu:anatomy,validation,16.196251448243856,mistral_7b,choice,oe,0.3571428656578064,0.3571428656578064,0.7111111111111111,0.5661842695304325
135,,,,,,mmlu:anatomy,test,124.62479039281607,mistral_7b,choice,oe,0.5777777433395386,0.5629629492759705,0.542285200179937,0.2990854210323758
16,,,,,,mmlu:astronomy,validation,15.010950829833746,mistral_7b,choice,oe,0.125,0.375,0.9642857142857143,0.3886621557176113
152,,,,,,mmlu:astronomy,test,151.55264550447464,mistral_7b,choice,oe,0.44736841320991516,0.4934210479259491,0.6116946778711485,0.25269205711389847
11,,,,,,mmlu:business_ethics,validation,12.243347816169262,mistral_7b,choice,oe,0.3636363744735718,0.5454545617103577,0.6071428571428572,0.38449133526195184
100,,,,,,mmlu:business_ethics,test,93.76699358224869,mistral_7b,choice,oe,0.32999998331069946,0.3799999952316284,0.44414292175486203,0.454684213399887
29,,,,,,mmlu:clinical_knowledge,validation,30.302904397249222,mistral_7b,choice,oe,0.20689654350280762,0.41379308700561523,0.6268115942028986,0.37819644294936083
265,,,,,,mmlu:clinical_knowledge,test,252.48808237165213,mistral_7b,choice,oe,0.31320756673812866,0.3698113262653351,0.6052892890242287,0.46855779301445444
16,,,,,,mmlu:college_biology,validation,16.675769601017237,mistral_7b,choice,oe,0.25,0.3125,0.8541666666666667,0.5326340086758137
144,,,,,,mmlu:college_biology,test,133.8483825661242,mistral_7b,choice,oe,0.3888888955116272,0.4513888955116272,0.4891436688311689,0.3993769155608283
8,,,,,,mmlu:college_chemistry,validation,8.676181446760893,mistral_7b,choice,oe,0.25,0.25,0.0,0.5190090090036392
100,,,,,,mmlu:college_chemistry,test,95.39294996857643,mistral_7b,choice,oe,0.19999998807907104,0.4099999964237213,0.595,0.35357605218887334
11,,,,,,mmlu:college_computer_science,validation,12.301360238343477,mistral_7b,choice,oe,0.09090909361839294,0.09090909361839294,0.09999999999999998,0.6964181011373346
100,,,,,,mmlu:college_computer_science,test,107.58567447587848,mistral_7b,choice,oe,0.20999999344348907,0.2800000011920929,0.4984930681133213,0.5705002480745316
11,,,,,,mmlu:college_mathematics,validation,11.837236933410168,mistral_7b,choice,oe,0.27272728085517883,0.4545454680919647,0.7083333333333333,0.422206537290053
100,,,,,,mmlu:college_mathematics,test,100.579170294106,mistral_7b,choice,oe,0.17999999225139618,0.25,0.5799457994579946,0.5826785778999328
22,,,,,,mmlu:college_medicine,validation,23.532444283366203,mistral_7b,choice,oe,0.5454545617103577,0.5909091234207153,0.6291666666666668,0.253465091640299
173,,,,,,mmlu:college_medicine,test,169.4915648251772,mistral_7b,choice,oe,0.3757225275039673,0.4393063485622406,0.6036324786324787,0.3273261782061847
11,,,,,,mmlu:college_physics,validation,11.211310222744942,mistral_7b,choice,oe,0.5454545617103577,0.7272727489471436,0.7333333333333333,0.25528655268929223
102,,,,,,mmlu:college_physics,test,173.42899440601468,mistral_7b,choice,oe,0.2352941334247589,0.4019607901573181,0.375267094017094,0.36320174909105485
11,,,,,,mmlu:computer_security,validation,11.36153930425644,mistral_7b,choice,oe,0.4545454680919647,0.27272728085517883,0.30000000000000004,0.6237131953239441
100,,,,,,mmlu:computer_security,test,98.51690743491054,mistral_7b,choice,oe,0.5,0.5,0.45439999999999997,0.3484443855285645
26,,,,,,mmlu:conceptual_physics,validation,27.844172693789005,mistral_7b,choice,oe,0.3076923191547394,0.3076923191547394,0.48611111111111116,0.4857779236940237
235,,,,,,mmlu:conceptual_physics,test,232.65966478735209,mistral_7b,choice,oe,0.4893616735935211,0.52765953540802,0.5214130434782609,0.26474428252970916
12,,,,,,mmlu:econometrics,validation,12.294710773974657,mistral_7b,choice,oe,0.4166666865348816,0.5,0.31428571428571433,0.4807675530513127
114,,,,,,mmlu:econometrics,test,123.93887421116233,mistral_7b,choice,oe,0.2368421107530594,0.28070175647735596,0.5261813537675607,0.5367143530594676
16,,,,,,mmlu:electrical_engineering,validation,17.251460816711187,mistral_7b,choice,oe,0.125,0.125,0.33928571428571425,0.7295886017382145
145,,,,,,mmlu:electrical_engineering,test,150.4711991213262,mistral_7b,choice,oe,0.2689655125141144,0.3379310369491577,0.5598693759071118,0.5154796176943286
41,,,,,,mmlu:elementary_mathematics,validation,45.684947077184916,mistral_7b,choice,oe,0.4146341383457184,0.4146341383457184,0.3382352941176471,0.43383518806317956
378,,,,,,mmlu:elementary_mathematics,test,389.2745133154094,mistral_7b,choice,oe,0.46296295523643494,0.4841269552707672,0.544588318085855,0.3611235460907063
14,,,,,,mmlu:formal_logic,validation,16.431107074022293,mistral_7b,choice,oe,0.4285714626312256,0.5,0.6458333333333334,0.30060864772115437
126,,,,,,mmlu:formal_logic,test,133.1114620603621,mistral_7b,choice,oe,0.3095238208770752,0.3492063581943512,0.5333038608900678,0.4534140560362074
10,,,,,,mmlu:global_facts,validation,11.356538090854883,mistral_7b,choice,oe,0.20000000298023224,0.4000000059604645,0.3125,0.5861674129962922
100,,,,,,mmlu:global_facts,test,101.49221113324165,mistral_7b,choice,oe,0.2199999988079071,0.35999998450279236,0.4449300699300699,0.4333456772565842
32,,,,,,mmlu:high_school_biology,validation,34.78046192601323,mistral_7b,choice,oe,0.375,0.3125,0.45625,0.5552360042929649
310,,,,,,mmlu:high_school_biology,test,318.9730933085084,mistral_7b,choice,oe,0.4580644965171814,0.5161290168762207,0.5122401073105298,0.30691747396223007
22,,,,,,mmlu:high_school_chemistry,validation,31.508281864225864,mistral_7b,choice,oe,0.1818181872367859,0.40909093618392944,0.5902777777777778,0.343730628490448
203,,,,,,mmlu:high_school_chemistry,test,232.49616089463234,mistral_7b,choice,oe,0.17733989655971527,0.35467979311943054,0.4429474384564205,0.3839557549636352
9,,,,,,mmlu:high_school_computer_science,validation,12.198023565113544,mistral_7b,choice,oe,0.5555555820465088,0.4444444477558136,0.8,0.4259519974390666
100,,,,,,mmlu:high_school_computer_science,test,108.09178690239787,mistral_7b,choice,oe,0.5399999618530273,0.550000011920929,0.6318438003220611,0.32764921247959133
22,,,,,,mmlu:high_school_geography,validation,23.513539645820856,mistral_7b,choice,oe,0.40909093618392944,0.5454545617103577,0.5512820512820513,0.21317629651589826
198,,,,,,mmlu:high_school_geography,test,200.15497186779976,mistral_7b,choice,oe,0.43939393758773804,0.5,0.5498602050326189,0.30671691111843996
21,,,,,,mmlu:high_school_government_and_politics,validation,24.447378013283014,mistral_7b,choice,oe,0.4761904776096344,0.4285714328289032,0.36818181818181817,0.39206194593792865
193,,,,,,mmlu:high_school_government_and_politics,test,189.6022378206253,mistral_7b,choice,oe,0.5181347131729126,0.5388600826263428,0.5356989247311827,0.31683634383690795
43,,,,,,mmlu:high_school_macroeconomics,validation,46.584240078926086,mistral_7b,choice,oe,0.41860464215278625,0.44186046719551086,0.3277777777777778,0.42420359960822174
390,,,,,,mmlu:high_school_macroeconomics,test,508.81398524716496,mistral_7b,choice,oe,0.37435898184776306,0.3692307770252228,0.47167639793397703,0.4365675365313505
29,,,,,,mmlu:high_school_mathematics,validation,34.78869868069887,mistral_7b,choice,oe,0.06896551698446274,0.4482758641242981,0.4444444444444445,0.4028124788711811
270,,,,,,mmlu:high_school_mathematics,test,302.3556777872145,mistral_7b,choice,oe,0.1259259283542633,0.4296296238899231,0.4952642073778664,0.3010888821548886
26,,,,,,mmlu:high_school_microeconomics,validation,28.343571726232767,mistral_7b,choice,oe,0.38461539149284363,0.46153849363327026,0.603125,0.4657626862709339
238,,,,,,mmlu:high_school_microeconomics,test,241.79170106723905,mistral_7b,choice,oe,0.34873950481414795,0.4285714626312256,0.43167508744656036,0.3851056244193005
17,,,,,,mmlu:high_school_physics,validation,23.202736616134644,mistral_7b,choice,oe,0.05882352963089943,0.23529411852359772,0.3125,0.46483203593422384
151,,,,,,mmlu:high_school_physics,test,157.2849086523056,mistral_7b,choice,oe,0.1986754983663559,0.41721853613853455,0.5862258953168045,0.3402780243103078
60,,,,,,mmlu:high_school_psychology,validation,61.12640352919698,mistral_7b,choice,oe,0.6000000238418579,0.550000011920929,0.48958333333333337,0.2284422000249227
545,,,,,,mmlu:high_school_psychology,test,548.2521961182356,mistral_7b,choice,oe,0.5706422328948975,0.5761467814445496,0.5224874268282628,0.23404979662064018
23,,,,,,mmlu:high_school_statistics,validation,26.799081914126873,mistral_7b,choice,oe,0.21739131212234497,0.260869562625885,0.7555555555555555,0.6063722242479739
216,,,,,,mmlu:high_school_statistics,test,228.08529866486788,mistral_7b,choice,oe,0.31018519401550293,0.31481480598449707,0.5450766302714615,0.5857556291200496
22,,,,,,mmlu:high_school_us_history,validation,43.098290268331766,mistral_7b,choice,oe,0.5454545617103577,0.5909091234207153,0.5083333333333333,0.2781542918898843
204,,,,,,mmlu:high_school_us_history,test,534.779114741832,mistral_7b,choice,oe,0.6519607901573181,0.6617647409439087,0.4860743407815313,0.1953938892659019
23,,,,,,mmlu:human_aging,validation,24.85431756451726,mistral_7b,choice,oe,0.30434784293174744,0.3478260934352875,0.45089285714285715,0.5420433827068494
223,,,,,,mmlu:human_aging,test,221.53233087062836,mistral_7b,choice,oe,0.37219732999801636,0.41255608201026917,0.4864027538726334,0.4270443050316096
12,,,,,,mmlu:human_sexuality,validation,12.864082004874945,mistral_7b,choice,oe,0.25,0.4166666865348816,0.5370370370370371,0.4756856014331181
131,,,,,,mmlu:human_sexuality,test,134.19216809421778,mistral_7b,choice,oe,0.48091602325439453,0.49618321657180786,0.5234593837535013,0.33525238555806286
13,,,,,,mmlu:international_law,validation,17.03678772598505,mistral_7b,choice,oe,0.5384615659713745,0.46153849363327026,0.40476190476190477,0.48614218143316423
121,,,,,,mmlu:international_law,test,122.99777564778924,mistral_7b,choice,oe,0.6198346614837646,0.5619834661483765,0.46246376811594203,0.3350031528591124
11,,,,,,mmlu:jurisprudence,validation,12.670224219560623,mistral_7b,choice,oe,0.4545454680919647,0.6363636255264282,0.5333333333333334,0.32058928229592065
108,,,,,,mmlu:jurisprudence,test,109.74202332645655,mistral_7b,choice,oe,0.5,0.5092592835426331,0.48233882030178327,0.3341547968210997
18,,,,,,mmlu:logical_fallacies,validation,20.42531982064247,mistral_7b,choice,oe,0.5555555820465088,0.4444444477558136,0.275,0.41698237260182697
163,,,,,,mmlu:logical_fallacies,test,165.77879893779755,mistral_7b,choice,oe,0.47239261865615845,0.460122674703598,0.43672606463304137,0.40307317628450917
11,,,,,,mmlu:machine_learning,validation,14.094091057777405,mistral_7b,choice,oe,0.27272728085517883,0.3636363744735718,0.41666666666666663,0.5851787653836337
112,,,,,,mmlu:machine_learning,test,118.2251635082066,mistral_7b,choice,oe,0.2767857313156128,0.3392857313156128,0.6013540422142573,0.5511729797082288
11,,,,,,mmlu:management,validation,13.029664445668459,mistral_7b,choice,oe,0.5454545617103577,0.5454545617103577,0.29999999999999993,0.49752819538116455
103,,,,,,mmlu:management,test,106.01852967962623,mistral_7b,choice,oe,0.3786407709121704,0.42718446254730225,0.546875,0.4407737538652512
25,,,,,,mmlu:marketing,validation,28.280478172004223,mistral_7b,choice,oe,0.2800000011920929,0.35999998450279236,0.43253968253968245,0.4327400827407837
234,,,,,,mmlu:marketing,test,234.88874225318432,mistral_7b,choice,oe,0.5085470080375671,0.4700855016708374,0.5084764340518817,0.3125938699286208
11,,,,,,mmlu:medical_genetics,validation,11.865565706044436,mistral_7b,choice,oe,0.7272727489471436,0.6363636255264282,0.5416666666666666,0.2949029153043574
100,,,,,,mmlu:medical_genetics,test,95.40848657861352,mistral_7b,choice,oe,0.5199999809265137,0.4899999797344208,0.5693108974358975,0.4180837869644165
38,,,,,,mmlu:moral_disputes,validation,40.443645022809505,mistral_7b,choice,oe,0.34210526943206787,0.42105263471603394,0.6276923076923077,0.4550772779866269
346,,,,,,mmlu:moral_disputes,test,347.3634026758373,mistral_7b,choice,oe,0.36994218826293945,0.4161849617958069,0.5498853211009175,0.4166526053682228
33,,,,,,mmlu:nutrition,validation,37.222989320755005,mistral_7b,choice,oe,0.42424243688583374,0.4545454680919647,0.3834586466165414,0.34854230555621063
306,,,,,,mmlu:nutrition,test,307.8887113593519,mistral_7b,choice,oe,0.42810457944869995,0.45098039507865906,0.530338058887677,0.35302128745060335
34,,,,,,mmlu:philosophy,validation,36.68732359260321,mistral_7b,choice,oe,0.38235294818878174,0.38235294818878174,0.45421245421245426,0.5053697123247035
311,,,,,,mmlu:philosophy,test,299.2715198583901,mistral_7b,choice,oe,0.33118969202041626,0.35691317915916443,0.5088218820014937,0.5121878789935465
35,,,,,,mmlu:prehistory,validation,35.80593378469348,mistral_7b,choice,oe,0.37142857909202576,0.48571428656578064,0.33916083916083917,0.42951627969741824
324,,,,,,mmlu:prehistory,test,322.19785391166806,mistral_7b,choice,oe,0.4382716119289398,0.472222238779068,0.551965639993809,0.3558492292592555
69,,,,,,mmlu:professional_psychology,validation,73.70180470496416,mistral_7b,choice,oe,0.4492753744125366,0.42028987407684326,0.4927843803056027,0.39683710664942645
612,,,,,,mmlu:professional_psychology,test,621.7678135037422,mistral_7b,choice,oe,0.3888888955116272,0.43790850043296814,0.5431346335325574,0.39214109595304997
12,,,,,,mmlu:public_relations,validation,13.027497000992298,mistral_7b,choice,oe,0.25,0.25,0.16666666666666669,0.6064293881257374
110,,,,,,mmlu:public_relations,test,136.79905381798744,mistral_7b,choice,oe,0.2818181812763214,0.3545454442501068,0.5283789301755819,0.43753724044019526
27,,,,,,mmlu:security_studies,validation,29.569660607725382,mistral_7b,choice,oe,0.5925925970077515,0.5555555820465088,0.4005681818181818,0.34991635216606987
245,,,,,,mmlu:security_studies,test,274.85550325736403,mistral_7b,choice,oe,0.514285683631897,0.48571425676345825,0.4447445644924637,0.36383472851344517
22,,,,,,mmlu:sociology,validation,23.656946070492268,mistral_7b,choice,oe,0.5,0.40909093618392944,0.36363636363636365,0.5124263357032429
201,,,,,,mmlu:sociology,test,196.49450137466192,mistral_7b,choice,oe,0.46766167879104614,0.45771142840385437,0.4808610061642473,0.37584630855873447
11,,,,,,mmlu:us_foreign_policy,validation,13.107937514781952,mistral_7b,choice,oe,0.6363636255264282,0.6363636255264282,0.7142857142857143,0.1618807370012457
100,,,,,,mmlu:us_foreign_policy,test,97.85011076182127,mistral_7b,choice,oe,0.6399999856948853,0.6399999856948853,0.5987413194444444,0.1858306509256363
18,,,,,,mmlu:virology,validation,21.175796952098608,mistral_7b,choice,oe,0.5555555820465088,0.4444444477558136,0.44375000000000003,0.43631312582227916
166,,,,,,mmlu:virology,test,167.56124307960272,mistral_7b,choice,oe,0.3674698770046234,0.3734939694404602,0.45011709601873534,0.48079796512442896
19,,,,,,mmlu:world_religions,validation,19.199128907173872,mistral_7b,choice,oe,0.6842105388641357,0.5263158082962036,0.5064102564102565,0.24462688910333735
171,,,,,,mmlu:world_religions,test,168.6941968165338,mistral_7b,choice,oe,0.6725146174430847,0.5906432867050171,0.5022515527950311,0.19265657942197473
11,0.765133570541035,0.09090909361839294,0.3636363744735718,0.9,0.323426522991874,mmlu:abstract_algebra,validation,3.356628702953458,mistral_7b_instruct,oe,choice,,,,
100,0.393069417476654,0.3199999928474426,0.4099999964237213,0.4751838235294118,0.2943194317817688,mmlu:abstract_algebra,test,11.28260293789208,mistral_7b_instruct,oe,choice,,,,
14,0.4112160929611751,0.5714285969734192,0.5714285969734192,0.5625,0.20057279297283717,mmlu:anatomy,validation,1.7281963136047125,mistral_7b_instruct,oe,choice,,,,
135,0.30549711872030183,0.5999999642372131,0.6222221851348877,0.5673296753543667,0.0913375969286318,mmlu:anatomy,test,15.385048542171717,mistral_7b_instruct,oe,choice,,,,
16,0.34233415871858597,0.5625,0.6875,0.5476190476190477,0.15998777747154236,mmlu:astronomy,validation,2.9631717912852764,mistral_7b_instruct,oe,choice,,,,
152,0.2402420408631626,0.6513158082962036,0.5723684430122375,0.4310081951591385,0.07867433326809027,mmlu:astronomy,test,26.430381579324603,mistral_7b_instruct,oe,choice,,,,
11,0.2133804505521601,0.7272727489471436,0.3636363744735718,0.25,0.3908019174229015,mmlu:business_ethics,validation,2.0108236856758595,mistral_7b_instruct,oe,choice,,,,
100,0.3043138575553894,0.5600000023841858,0.5799999833106995,0.5111607142857143,0.10663181245326996,mmlu:business_ethics,test,16.95847957767546,mistral_7b_instruct,oe,choice,,,,
29,0.2928923409560631,0.6206896305084229,0.4482758641242981,0.3838383838383838,0.22321258536700547,mmlu:clinical_knowledge,validation,3.986618969589472,mistral_7b_instruct,oe,choice,,,,
265,0.21389452466424902,0.6905660629272461,0.5924528241157532,0.48657203785152603,0.09124899022984055,mmlu:clinical_knowledge,test,33.82304639182985,mistral_7b_instruct,oe,choice,,,,
16,0.280781714245677,0.6875,0.8125,0.6909090909090909,0.31656690314412117,mmlu:college_biology,validation,2.5157292429357767,mistral_7b_instruct,oe,choice,,,,
144,0.22419004763166112,0.7291666865348816,0.6597222089767456,0.5308913308913309,0.04158672442038854,mmlu:college_biology,test,21.68468077853322,mistral_7b_instruct,oe,choice,,,,
8,0.410574235022068,0.5,0.375,0.5,0.3073919340968132,mmlu:college_chemistry,validation,1.5440486427396536,mistral_7b_instruct,oe,choice,,,,
100,0.3482097971439362,0.44999998807907104,0.6399999856948853,0.49778582930756843,0.08254492938518523,mmlu:college_chemistry,test,16.800745638087392,mistral_7b_instruct,oe,choice,,,,
11,0.3158503472805023,0.4545454680919647,0.5454545617103577,0.5,0.13204353505914862,mmlu:college_computer_science,validation,2.845148330554366,mistral_7b_instruct,oe,choice,,,,
100,0.23187010854482654,0.5199999809265137,0.5799999833106995,0.4707532051282052,0.1935650491714478,mmlu:college_computer_science,test,25.561269383877516,mistral_7b_instruct,oe,choice,,,,
11,0.41089535301381896,0.5454545617103577,0.5454545617103577,0.13333333333333333,0.28494189002297143,mmlu:college_mathematics,validation,2.0656045470386744,mistral_7b_instruct,oe,choice,,,,
100,0.36699718654155733,0.3100000023841858,0.6299999952316284,0.44834034595605426,0.09155946016311647,mmlu:college_mathematics,test,17.158072402700782,mistral_7b_instruct,oe,choice,,,,
22,0.29160571098327637,0.6363636255264282,0.6818181872367859,0.3125,0.14364473928104746,mmlu:college_medicine,validation,3.5778545066714287,mistral_7b_instruct,oe,choice,,,,
173,0.3358282767279299,0.5780346393585205,0.5953757166862488,0.5656849315068493,0.09575190330516396,mmlu:college_medicine,test,32.304808432236314,mistral_7b_instruct,oe,choice,,,,
11,0.493214260448109,0.4545454680919647,0.5454545617103577,0.43333333333333335,0.29814284498041327,mmlu:college_physics,validation,1.8051464259624481,mistral_7b_instruct,oe,choice,,,,
102,0.3972641346501369,0.4117647111415863,0.5784313678741455,0.3847222222222222,0.08997931199915273,mmlu:college_physics,test,15.064197396859527,mistral_7b_instruct,oe,choice,,,,
11,0.3270850831812078,0.6363636255264282,0.7272727489471436,0.03571428571428571,0.11097006906162607,mmlu:computer_security,validation,1.6899467576295137,mistral_7b_instruct,oe,choice,,,,
100,0.20277144402265543,0.7199999690055847,0.7299999594688416,0.581845238095238,0.09110732972621918,mmlu:computer_security,test,12.367208909243345,mistral_7b_instruct,oe,choice,,,,
26,0.32021135664903205,0.5,0.5384615659713745,0.4556213017751479,0.24879807004561796,mmlu:conceptual_physics,validation,2.710196081548929,mistral_7b_instruct,oe,choice,,,,
235,0.3259811748849585,0.5106382966041565,0.5617021322250366,0.49384057971014494,0.14204650432505506,mmlu:conceptual_physics,test,22.919964967295527,mistral_7b_instruct,oe,choice,,,,
12,0.23544961710770929,0.6666666865348816,0.4166666865348816,0.6875,0.1859853466351827,mmlu:econometrics,validation,2.4987298976629972,mistral_7b_instruct,oe,choice,,,,
114,0.44112591027167813,0.4035087823867798,0.6052631735801697,0.5708120204603581,0.11032145065173769,mmlu:econometrics,test,21.0074400678277,mistral_7b_instruct,oe,choice,,,,
16,0.15299630351364613,0.6875,0.5,0.509090909090909,0.2046084627509117,mmlu:electrical_engineering,validation,2.2941190861165524,mistral_7b_instruct,oe,choice,,,,
145,0.27874617103872634,0.565517246723175,0.6275861859321594,0.4711575687185443,0.08657680297720023,mmlu:electrical_engineering,test,18.909883085638285,mistral_7b_instruct,oe,choice,,,,
41,0.5683083178066626,0.2926829159259796,0.6585365533828735,0.5948275862068966,0.11438869121598036,mmlu:elementary_mathematics,validation,6.933588927611709,mistral_7b_instruct,oe,choice,,,,
378,0.42598307227331494,0.38359788060188293,0.6058200597763062,0.4090572739381383,0.07479554840496604,mmlu:elementary_mathematics,test,60.899807980284095,mistral_7b_instruct,oe,choice,,,,
14,0.5300084905964988,0.3571428656578064,0.5,0.5555555555555556,0.17053284815379555,mmlu:formal_logic,validation,2.8424225337803364,mistral_7b_instruct,oe,choice,,,,
126,0.4288197330066136,0.3888889253139496,0.5793651342391968,0.5120593692022264,0.054677474593359296,mmlu:formal_logic,test,24.318916702643037,mistral_7b_instruct,oe,choice,,,,
10,0.6482203334569931,0.20000000298023224,0.800000011920929,0.5,0.09992736577987671,mmlu:global_facts,validation,1.4848432056605816,mistral_7b_instruct,oe,choice,,,,
100,0.48122519657015805,0.35999998450279236,0.6399999856948853,0.49914199914199914,0.07163481533527372,mmlu:global_facts,test,12.858668871223927,mistral_7b_instruct,oe,choice,,,,
32,0.24558557756245133,0.71875,0.71875,0.5507246376811594,0.08964744210243224,mmlu:high_school_biology,validation,5.268524266779423,mistral_7b_instruct,oe,choice,,,,
310,0.18493177121685397,0.7322580814361572,0.7193548083305359,0.519744174937636,0.06799082294587164,mmlu:high_school_biology,test,49.89910351112485,mistral_7b_instruct,oe,choice,,,,
22,0.34913468902761285,0.5454545617103577,0.5909091234207153,0.44166666666666665,0.19426243142648175,mmlu:high_school_chemistry,validation,3.7232909854501486,mistral_7b_instruct,oe,choice,,,,
203,0.3300257035957769,0.5024630427360535,0.45812806487083435,0.4449621432731508,0.2579098616914796,mmlu:high_school_chemistry,test,31.613263607025146,mistral_7b_instruct,oe,choice,,,,
9,0.3047038416067759,0.6666666865348816,0.5555555820465088,0.5555555555555556,0.07145808140436806,mmlu:high_school_computer_science,validation,2.7234466560184956,mistral_7b_instruct,oe,choice,,,,
100,0.25101123958826066,0.6299999952316284,0.6800000071525574,0.531960531960532,0.08900490164756775,mmlu:high_school_computer_science,test,28.624602483585477,mistral_7b_instruct,oe,choice,,,,
22,0.09892364794557745,0.8636363744735718,0.5,0.4210526315789474,0.18516124378551135,mmlu:high_school_geography,validation,2.713002920150757,mistral_7b_instruct,oe,choice,,,,
198,0.16457719137572283,0.7626262903213501,0.5757575631141663,0.43314076370297316,0.11555986813824586,mmlu:high_school_geography,test,23.307699928060174,mistral_7b_instruct,oe,choice,,,,
21,0.18571182092030847,0.761904776096344,0.6190476417541504,0.3,0.20445780243192402,mmlu:high_school_government_and_politics,validation,3.014145953580737,mistral_7b_instruct,oe,choice,,,,
193,0.12392692507239823,0.8290154933929443,0.7305699586868286,0.6178030303030303,0.06475061610572695,mmlu:high_school_government_and_politics,test,26.444434156641364,mistral_7b_instruct,oe,choice,,,,
43,0.22275190713793735,0.6744186282157898,0.7906976938247681,0.4716748768472907,0.21323008315507758,mmlu:high_school_macroeconomics,validation,5.158348558470607,mistral_7b_instruct,oe,choice,,,,
390,0.3108129061949559,0.5769230723381042,0.6051282286643982,0.5036094276094276,0.05459538102149963,mmlu:high_school_macroeconomics,test,45.85537553578615,mistral_7b_instruct,oe,choice,,,,
29,0.35391655769841424,0.37931033968925476,0.6206896305084229,0.2474747474747475,0.15063279867172238,mmlu:high_school_mathematics,validation,4.737407758831978,mistral_7b_instruct,oe,choice,,,,
270,0.34481427327350334,0.32222220301628113,0.5444444417953491,0.43715846994535523,0.1597179328953778,mmlu:high_school_mathematics,test,41.95721511915326,mistral_7b_instruct,oe,choice,,,,
26,0.2971332107598965,0.6538462042808533,0.6153846383094788,0.44444444444444453,0.25544594801389253,mmlu:high_school_microeconomics,validation,3.27009754255414,mistral_7b_instruct,oe,choice,,,,
238,0.25066431592993377,0.6596639156341553,0.5588235855102539,0.47652748289690966,0.14138435916740352,mmlu:high_school_microeconomics,test,29.079625576734543,mistral_7b_instruct,oe,choice,,,,
17,0.576501513228697,0.1764705926179886,0.3529411852359772,0.7857142857142857,0.42080607484368715,mmlu:high_school_physics,validation,3.061683762818575,mistral_7b_instruct,oe,choice,,,,
151,0.48068022056920645,0.3245033025741577,0.46357616782188416,0.49619847939175665,0.22972150788401927,mmlu:high_school_physics,test,25.353618333116174,mistral_7b_instruct,oe,choice,,,,
60,0.14687878390153253,0.8666667342185974,0.6666666865348816,0.4098557692307692,0.1220111648241679,mmlu:high_school_psychology,validation,9.138142433017492,mistral_7b_instruct,oe,choice,,,,
545,0.1524940463927908,0.7963302731513977,0.6568807363510132,0.46580982236154655,0.056685586588098365,mmlu:high_school_psychology,test,82.62401692941785,mistral_7b_instruct,oe,choice,,,,
23,0.33509852316068567,0.52173912525177,0.6086956858634949,0.7045454545454546,0.13901926123577618,mmlu:high_school_statistics,validation,5.786214046180248,mistral_7b_instruct,oe,choice,,,,
216,0.3680592295196321,0.45370370149612427,0.5833333134651184,0.4830940850916638,0.12143358422650233,mmlu:high_school_statistics,test,55.339307479560375,mistral_7b_instruct,oe,choice,,,,
22,0.20736756649884316,0.7727273106575012,0.6818181872367859,0.6470588235294117,0.10622990944168782,mmlu:high_school_us_history,validation,20.142277162522078,mistral_7b_instruct,oe,choice,,,,
204,0.1760429599705865,0.7647058963775635,0.7401961088180542,0.48143696581196577,0.09963285572388594,mmlu:high_school_us_history,test,185.35577603429556,mistral_7b_instruct,oe,choice,,,,
23,0.2849027877268584,0.739130437374115,0.43478262424468994,0.3137254901960784,0.2719019029451454,mmlu:human_aging,validation,2.508226592093706,mistral_7b_instruct,oe,choice,,,,
223,0.2803503311001132,0.6322870254516602,0.5964125990867615,0.48806434872859367,0.07454087167577358,mmlu:human_aging,test,22.529952397570014,mistral_7b_instruct,oe,choice,,,,
12,0.3910154501597087,0.5,0.5833333730697632,0.6944444444444444,0.13704646130402884,mmlu:human_sexuality,validation,1.4750420060008764,mistral_7b_instruct,oe,choice,,,,
131,0.18673584240538474,0.6870229244232178,0.6030534505844116,0.46246612466124654,0.07622497955351384,mmlu:human_sexuality,test,15.033196236938238,mistral_7b_instruct,oe,choice,,,,
13,0.04825018919431247,1.0,0.6153846383094788,,0.27347649519260114,mmlu:international_law,validation,2.639441153034568,mistral_7b_instruct,oe,choice,,,,
121,0.1990918629179316,0.7520660758018494,0.6363636255264282,0.49029304029304027,0.0302810072898865,mmlu:international_law,test,22.692077089101076,mistral_7b_instruct,oe,choice,,,,
11,0.4057095809416338,0.5454545617103577,0.7272727489471436,0.49999999999999994,0.22609104893424292,mmlu:jurisprudence,validation,1.5517935920506716,mistral_7b_instruct,oe,choice,,,,
108,0.1348436223687949,0.7777777910232544,0.7592592835426331,0.42807539682539686,0.16213330460919279,mmlu:jurisprudence,test,13.500722711905837,mistral_7b_instruct,oe,choice,,,,
18,0.2286232709884644,0.7222222089767456,0.2222222238779068,0.4461538461538462,0.39137162102593315,mmlu:logical_fallacies,validation,2.4884179141372442,mistral_7b_instruct,oe,choice,,,,
163,0.21580915911797366,0.6932514905929565,0.46625766158103943,0.3671681415929204,0.1880649426963432,mmlu:logical_fallacies,test,21.65517235547304,mistral_7b_instruct,oe,choice,,,,
11,0.4750036895275116,0.27272728085517883,0.7272727489471436,0.5,0.3674068776043979,mmlu:machine_learning,validation,2.269924785941839,mistral_7b_instruct,oe,choice,,,,
112,0.4009351400392396,0.4285714626312256,0.6339285969734192,0.42366536458333326,0.05488157059465136,mmlu:machine_learning,test,21.834320100024343,mistral_7b_instruct,oe,choice,,,,
11,0.08183464136990637,0.9090909361839294,0.5454545617103577,0.9,0.12190092693675648,mmlu:management,validation,1.151047419756651,mistral_7b_instruct,oe,choice,,,,
103,0.21182832440126284,0.7475728392601013,0.582524299621582,0.5731768231768232,0.07667447235977767,mmlu:management,test,9.862675251439214,mistral_7b_instruct,oe,choice,,,,
25,0.1364144992828369,0.8399999737739563,0.47999998927116394,0.5714285714285714,0.12603415250778197,mmlu:marketing,validation,3.297483131289482,mistral_7b_instruct,oe,choice,,,,
234,0.09125810224785762,0.8632479310035706,0.5854701399803162,0.3487778465346535,0.07884394256477681,mmlu:marketing,test,28.977959347888827,mistral_7b_instruct,oe,choice,,,,
11,0.0449044406414032,0.9090909361839294,0.6363636255264282,1.0,0.24910880218852646,mmlu:medical_genetics,validation,1.438467612490058,mistral_7b_instruct,oe,choice,,,,
100,0.2847048228979111,0.6599999666213989,0.5999999642372131,0.4006238859180036,0.09315320432186126,mmlu:medical_genetics,test,11.348394883796573,mistral_7b_instruct,oe,choice,,,,
38,0.40927351775922277,0.5,0.5789473652839661,0.3545706371191136,0.17277732491493225,mmlu:moral_disputes,validation,5.711624084040523,mistral_7b_instruct,oe,choice,,,,
346,0.21625922620296478,0.6878612637519836,0.6184970736503601,0.5630938880850898,0.04334634042888709,mmlu:moral_disputes,test,50.3781363517046,mistral_7b_instruct,oe,choice,,,,
33,0.20663583278656006,0.7272727489471436,0.6363636255264282,0.5787037037037037,0.11060623508511166,mmlu:nutrition,validation,5.992392014712095,mistral_7b_instruct,oe,choice,,,,
306,0.21835722107123703,0.6764705777168274,0.5915032625198364,0.43273312838530237,0.07440347920835408,mmlu:nutrition,test,54.87325437925756,mistral_7b_instruct,oe,choice,,,,
34,0.2439185065381667,0.7058823704719543,0.5,0.55,0.14773864255231972,mmlu:philosophy,validation,3.9863612428307533,mistral_7b_instruct,oe,choice,,,,
311,0.2319063437904959,0.6945337653160095,0.5530546307563782,0.4327729044834307,0.10413298825359037,mmlu:philosophy,test,33.83178965561092,mistral_7b_instruct,oe,choice,,,,
35,0.28488696813583375,0.6285714507102966,0.6285714507102966,0.3968531468531468,0.111401755469186,mmlu:prehistory,validation,5.904410820454359,mistral_7b_instruct,oe,choice,,,,
324,0.21219177268169548,0.7037037014961243,0.5987654328346252,0.4646838450292398,0.06815780036979252,mmlu:prehistory,test,52.127337547019124,mistral_7b_instruct,oe,choice,,,,
69,0.23504126244697013,0.695652186870575,0.52173912525177,0.4355158730158731,0.18058858919834742,mmlu:professional_psychology,validation,12.43972609564662,mistral_7b_instruct,oe,choice,,,,
612,0.26351112891840783,0.6372548937797546,0.5964052081108093,0.48280890164446655,0.06808974657183381,mmlu:professional_psychology,test,104.80187669023871,mistral_7b_instruct,oe,choice,,,,
12,0.2672729740540186,0.5833333730697632,0.5,0.3142857142857142,0.21530504524707794,mmlu:public_relations,validation,1.7930842768400908,mistral_7b_instruct,oe,choice,,,,
110,0.22116296250711792,0.699999988079071,0.581818163394928,0.36953955135773314,0.17642452933571554,mmlu:public_relations,test,14.125829895958304,mistral_7b_instruct,oe,choice,,,,
27,0.29305871327718097,0.6296296119689941,0.7407407760620117,0.6470588235294117,0.16049604504196732,mmlu:security_studies,validation,10.609268127009273,mistral_7b_instruct,oe,choice,,,,
245,0.2187763589985517,0.7061223983764648,0.6326530575752258,0.5071050096339114,0.02549893637092745,mmlu:security_studies,test,97.33075131848454,mistral_7b_instruct,oe,choice,,,,
22,0.09615165537053888,0.9090909361839294,0.5909091234207153,0.45,0.18277506665749982,mmlu:sociology,validation,3.003048440441489,mistral_7b_instruct,oe,choice,,,,
201,0.14599392737322187,0.8208954930305481,0.6467661261558533,0.40900673400673404,0.10445940939348138,mmlu:sociology,test,26.19505576789379,mistral_7b_instruct,oe,choice,,,,
11,0.09946483373641965,0.9090909361839294,0.7272727489471436,0.9,0.14951638200066308,mmlu:us_foreign_policy,validation,1.5838541518896818,mistral_7b_instruct,oe,choice,,,,
100,0.14641115546226502,0.8399999737739563,0.7799999713897705,0.6700148809523809,0.12795879244804384,mmlu:us_foreign_policy,test,12.706232495605946,mistral_7b_instruct,oe,choice,,,,
18,0.29886655012766516,0.6111111044883728,0.5,0.35064935064935066,0.2901589837339189,mmlu:virology,validation,2.5108629669994116,mistral_7b_instruct,oe,choice,,,,
166,0.4108055790504777,0.48795178532600403,0.5240963697433472,0.4638501742160279,0.2232663915099868,mmlu:virology,test,18.702496679499745,mistral_7b_instruct,oe,choice,,,,
19,0.16099958984475385,0.8421052694320679,0.8421052694320679,0.14583333333333334,0.30831841418617645,mmlu:world_religions,validation,1.8651052322238684,mistral_7b_instruct,oe,choice,,,,
171,0.13443411651410558,0.8245614171028137,0.7368420958518982,0.5141843971631205,0.07773015722196701,mmlu:world_religions,test,15.122773027047515,mistral_7b_instruct,oe,choice,,,,
11,,,,,,mmlu:abstract_algebra,validation,10.32059277780354,llama2_7b,choice,oe,0.1818181872367859,0.8181818723678589,0.7222222222222223,0.24326186830347238
100,,,,,,mmlu:abstract_algebra,test,43.53387499973178,llama2_7b,choice,oe,0.20999999344348907,0.6100000143051147,0.3767329716696805,0.1095674139261246
14,,,,,,mmlu:anatomy,validation,6.54486764781177,llama2_7b,choice,oe,0.2142857313156128,0.2142857313156128,0.3939393939393939,0.750136809689658
135,,,,,,mmlu:anatomy,test,62.93225985951722,llama2_7b,choice,oe,0.4296296238899231,0.4296296238899231,0.4867890729959696,0.5201341214003385
16,,,,,,mmlu:astronomy,validation,7.197496937587857,llama2_7b,choice,oe,0.3125,0.375,0.6545454545454545,0.5365378968417645
152,,,,,,mmlu:astronomy,test,66.20567142032087,llama2_7b,choice,oe,0.5328947305679321,0.5723684430122375,0.6553642844722657,0.29074553478705256
11,,,,,,mmlu:business_ethics,validation,6.837050575762987,llama2_7b,choice,oe,0.5454545617103577,0.4545454680919647,0.4333333333333333,0.2906004894863476
100,,,,,,mmlu:business_ethics,test,50.72556930780411,llama2_7b,choice,oe,0.3199999928474426,0.35999998450279236,0.3943014705882353,0.492440316081047
29,,,,,,mmlu:clinical_knowledge,validation,13.90578611753881,llama2_7b,choice,oe,0.24137930572032928,0.24137930572032928,0.6363636363636364,0.6614719978694258
265,,,,,,mmlu:clinical_knowledge,test,112.4490294251591,llama2_7b,choice,oe,0.350943386554718,0.350943386554718,0.44376719179794943,0.5507572639663264
16,,,,,,mmlu:college_biology,validation,7.273904459550977,llama2_7b,choice,oe,0.25,0.25,0.6041666666666666,0.678645234555006
144,,,,,,mmlu:college_biology,test,66.16916104778647,llama2_7b,choice,oe,0.3194444477558136,0.3333333432674408,0.5288376220053239,0.5761073720124033
8,,,,,,mmlu:college_chemistry,validation,3.8865446764975786,llama2_7b,choice,oe,0.125,0.25,0.8571428571428571,0.737051360309124
100,,,,,,mmlu:college_chemistry,test,48.94597943685949,llama2_7b,choice,oe,0.12999999523162842,0.2199999988079071,0.7816091954022989,0.6089938712120057
11,,,,,,mmlu:college_computer_science,validation,8.995645068585873,llama2_7b,choice,oe,0.09090909361839294,0.27272728085517883,0.4,0.513904874975031
100,,,,,,mmlu:college_computer_science,test,65.81962420418859,llama2_7b,choice,oe,0.1599999964237213,0.26999998092651367,0.453125,0.55550426363945
11,,,,,,mmlu:college_mathematics,validation,9.022794641554356,llama2_7b,choice,oe,0.0,0.7272727489471436,,0.37545249678871845
100,,,,,,mmlu:college_mathematics,test,54.15677882730961,llama2_7b,choice,oe,0.14999999105930328,0.3499999940395355,0.5376470588235295,0.3322248893976211
22,,,,,,mmlu:college_medicine,validation,10.78858751617372,llama2_7b,choice,oe,0.22727273404598236,0.22727273404598236,0.5529411764705883,0.6661105453968048
173,,,,,,mmlu:college_medicine,test,208.22280603460968,llama2_7b,choice,oe,0.32947975397109985,0.3352600932121277,0.5316091954022988,0.5463239643615105
11,,,,,,mmlu:college_physics,validation,7.111909644678235,llama2_7b,choice,oe,0.27272728085517883,0.5454545617103577,0.75,0.30624996532093396
102,,,,,,mmlu:college_physics,test,50.038261292502284,llama2_7b,choice,oe,0.13725490868091583,0.27450981736183167,0.6185064935064934,0.49470684808843274
11,,,,,,mmlu:computer_security,validation,6.860050540417433,llama2_7b,choice,oe,0.6363636255264282,0.7272727489471436,0.6071428571428572,0.2648900097066706
100,,,,,,mmlu:computer_security,test,45.35921863466501,llama2_7b,choice,oe,0.5099999904632568,0.4899999797344208,0.5732292917166867,0.33628328084945686
26,,,,,,mmlu:conceptual_physics,validation,13.70161815173924,llama2_7b,choice,oe,0.3461538553237915,0.3461538553237915,0.6601307189542482,0.5451698028124295
235,,,,,,mmlu:conceptual_physics,test,99.41418457962573,llama2_7b,choice,oe,0.4170212745666504,0.4170212745666504,0.5215998808282437,0.48632797789066395
12,,,,,,mmlu:econometrics,validation,154.14670068770647,llama2_7b,choice,oe,0.0,0.0833333358168602,,0.7299612661202748
114,,,,,,mmlu:econometrics,test,65.96022233739495,llama2_7b,choice,oe,0.15789473056793213,0.2368421107530594,0.4357638888888889,0.5605720694650684
16,,,,,,mmlu:electrical_engineering,validation,19.13859536498785,llama2_7b,choice,oe,0.25,0.25,0.3958333333333333,0.6021019145846367
145,,,,,,mmlu:electrical_engineering,test,68.12272618338466,llama2_7b,choice,oe,0.20689654350280762,0.25517240166664124,0.3807246376811594,0.6210018022307033
41,,,,,,mmlu:elementary_mathematics,validation,21.101288536563516,llama2_7b,choice,oe,0.19512194395065308,0.19512194395065308,0.6022727272727273,0.6090337910303254
378,,,,,,mmlu:elementary_mathematics,test,176.90723841451108,llama2_7b,choice,oe,0.31216931343078613,0.34656083583831787,0.5253585397653194,0.4455725205323053
14,,,,,,mmlu:formal_logic,validation,7.546081123873591,llama2_7b,choice,oe,0.4285714626312256,0.4285714626312256,0.75,0.35229406186512546
126,,,,,,mmlu:formal_logic,test,62.999752547591925,llama2_7b,choice,oe,0.2777777910232544,0.2936508059501648,0.5814756671899529,0.5163602597183652
10,,,,,,mmlu:global_facts,validation,6.335035089403391,llama2_7b,choice,oe,0.20000000298023224,0.20000000298023224,0.5,0.6065130174160004
100,,,,,,mmlu:global_facts,test,43.8126931861043,llama2_7b,choice,oe,0.17000000178813934,0.17999999225139618,0.5797306874557052,0.6222331517934799
32,,,,,,mmlu:high_school_biology,validation,14.44265384040773,llama2_7b,choice,oe,0.21875,0.28125,0.4514285714285714,0.6450801976025105
310,,,,,,mmlu:high_school_biology,test,144.03888754360378,llama2_7b,choice,oe,0.42258062958717346,0.43870967626571655,0.5178685658237024,0.4384027546451938
22,,,,,,mmlu:high_school_chemistry,validation,11.07266329973936,llama2_7b,choice,oe,0.09090909361839294,0.09090909361839294,0.65,0.7589163888584485
203,,,,,,mmlu:high_school_chemistry,test,96.60589711554348,llama2_7b,choice,oe,0.1428571343421936,0.15270934998989105,0.53824811732065,0.7074178430834427
9,,,,,,mmlu:high_school_computer_science,validation,7.3299338556826115,llama2_7b,choice,oe,0.3333333432674408,0.4444444477558136,0.5,0.5211520195007324
100,,,,,,mmlu:high_school_computer_science,test,63.26633654721081,llama2_7b,choice,oe,0.429999977350235,0.4899999797344208,0.5528355773153815,0.31966361463069914
22,,,,,,mmlu:high_school_geography,validation,9.726815151050687,llama2_7b,choice,oe,0.4545454680919647,0.4545454680919647,0.7333333333333333,0.3584419597278942
198,,,,,,mmlu:high_school_geography,test,82.42560107074678,llama2_7b,choice,oe,0.35353535413742065,0.39393940567970276,0.5308035714285715,0.44536893626656193
21,,,,,,mmlu:high_school_government_and_politics,validation,10.091880856081843,llama2_7b,choice,oe,0.380952388048172,0.4285714328289032,0.4230769230769231,0.4307486414909363
193,,,,,,mmlu:high_school_government_and_politics,test,92.48851002939045,llama2_7b,choice,oe,0.4715025722980499,0.47668391466140747,0.5794009911656971,0.39304729940977734
43,,,,,,mmlu:high_school_macroeconomics,validation,20.778232106938958,llama2_7b,choice,oe,0.39534884691238403,0.41860464215278625,0.45022624434389136,0.4142847574034403
390,,,,,,mmlu:high_school_macroeconomics,test,171.23123593069613,llama2_7b,choice,oe,0.3589743673801422,0.4000000059604645,0.6008,0.41683230568201113
29,,,,,,mmlu:high_school_mathematics,validation,15.459830313920975,llama2_7b,choice,oe,0.10344827175140381,0.41379308700561523,0.8205128205128205,0.35242163518379477
270,,,,,,mmlu:high_school_mathematics,test,136.25524682551622,llama2_7b,choice,oe,0.08148147910833359,0.38148146867752075,0.5821114369501466,0.307592562172148
26,,,,,,mmlu:high_school_microeconomics,validation,13.46765866316855,llama2_7b,choice,oe,0.38461539149284363,0.42307692766189575,0.3187499999999999,0.4811155383403485
238,,,,,,mmlu:high_school_microeconomics,test,100.13505729660392,llama2_7b,choice,oe,0.3445378243923187,0.3445378243923187,0.6024077548467792,0.5069973969659886
17,,,,,,mmlu:high_school_physics,validation,10.569921335205436,llama2_7b,choice,oe,0.11764705926179886,0.1764705926179886,0.26666666666666666,0.7357634656569536
151,,,,,,mmlu:high_school_physics,test,75.10951577313244,llama2_7b,choice,oe,0.17218543589115143,0.18543046712875366,0.5366153846153845,0.6762138747221587
60,,,,,,mmlu:high_school_psychology,validation,29.718096839264035,llama2_7b,choice,oe,0.45000001788139343,0.45000001788139343,0.5140291806958472,0.41192717949549357
545,,,,,,mmlu:high_school_psychology,test,247.7501218356192,llama2_7b,choice,oe,0.48440366983413696,0.49724769592285156,0.5281529709910493,0.36910727734959453
23,,,,,,mmlu:high_school_statistics,validation,13.486616833135486,llama2_7b,choice,oe,0.1304347813129425,0.30434784293174744,0.7,0.6082283388013426
216,,,,,,mmlu:high_school_statistics,test,122.59850801341236,llama2_7b,choice,oe,0.26851850748062134,0.28240740299224854,0.4896879092099519,0.5025782389221367
22,,,,,,mmlu:high_school_us_history,validation,35.16687807440758,llama2_7b,choice,oe,0.6818181872367859,0.7272727489471436,0.7904761904761906,0.09973606738177215
204,,,,,,mmlu:high_school_us_history,test,327.7933248784393,llama2_7b,choice,oe,0.5833333730697632,0.6029412150382996,0.5035096391497775,0.22511927871143117
23,,,,,,mmlu:human_aging,validation,12.243553310632706,llama2_7b,choice,oe,0.30434784293174744,0.30434784293174744,0.5178571428571428,0.5550133145373801
223,,,,,,mmlu:human_aging,test,91.70059027336538,llama2_7b,choice,oe,0.35874441266059875,0.35874441266059875,0.5212849650349649,0.5188938964642751
12,,,,,,mmlu:human_sexuality,validation,6.604458732530475,llama2_7b,choice,oe,0.4166666865348816,0.5,0.5428571428571429,0.4177979578574499
131,,,,,,mmlu:human_sexuality,test,60.16451056115329,llama2_7b,choice,oe,0.4580152630805969,0.4580152630805969,0.4406103286384977,0.4164532286520222
13,,,,,,mmlu:international_law,validation,7.747707400470972,llama2_7b,choice,oe,0.3076923191547394,0.3076923191547394,0.5555555555555557,0.5248855031453648
121,,,,,,mmlu:international_law,test,55.89062865637243,llama2_7b,choice,oe,0.5041322112083435,0.5289255976676941,0.5814207650273224,0.31745061647793477
11,,,,,,mmlu:jurisprudence,validation,6.368986815214157,llama2_7b,choice,oe,0.4545454680919647,0.4545454680919647,0.6,0.4250056581063705
108,,,,,,mmlu:jurisprudence,test,49.34244662709534,llama2_7b,choice,oe,0.39814814925193787,0.39814814925193787,0.5338103756708408,0.43956451780266226
18,,,,,,mmlu:logical_fallacies,validation,9.693799609318376,llama2_7b,choice,oe,0.4444444477558136,0.3888888955116272,0.6124999999999999,0.39867192837927073
163,,,,,,mmlu:logical_fallacies,test,72.51436625048518,llama2_7b,choice,oe,0.42331287264823914,0.453987717628479,0.5935090965155719,0.2838731100954161
11,,,,,,mmlu:machine_learning,validation,7.0677817314863205,llama2_7b,choice,oe,0.27272728085517883,0.3636363744735718,0.7916666666666666,0.4926503409038891
112,,,,,,mmlu:machine_learning,test,57.26296724379063,llama2_7b,choice,oe,0.2410714328289032,0.2589285969734192,0.5117647058823529,0.5376430324145727
11,,,,,,mmlu:management,validation,6.34748569317162,llama2_7b,choice,oe,0.4545454680919647,0.4545454680919647,0.26666666666666666,0.47782379388809204
103,,,,,,mmlu:management,test,41.85141378827393,llama2_7b,choice,oe,0.40776699781417847,0.40776699781417847,0.47677595628415304,0.37051561793077337
25,,,,,,mmlu:marketing,validation,13.710771227255464,llama2_7b,choice,oe,0.2800000011920929,0.2800000011920929,0.7301587301587302,0.6101162672042848
234,,,,,,mmlu:marketing,test,102.13434058241546,llama2_7b,choice,oe,0.47863250970840454,0.4829060137271881,0.5254317915690866,0.3930035875393795
11,,,,,,mmlu:medical_genetics,validation,6.35840998403728,llama2_7b,choice,oe,0.6363636255264282,0.6363636255264282,0.7321428571428571,0.34878073497252027
100,,,,,,mmlu:medical_genetics,test,43.57991706766188,llama2_7b,choice,oe,0.5099999904632568,0.5,0.5834333733493398,0.35256452322006226
38,,,,,,mmlu:moral_disputes,validation,17.17391843162477,llama2_7b,choice,oe,0.28947368264198303,0.28947368264198303,0.3872053872053872,0.6165552688272375
346,,,,,,mmlu:moral_disputes,test,153.37337384186685,llama2_7b,choice,oe,0.4161849617958069,0.4190751314163208,0.5609185918591859,0.4677855930576435
33,,,,,,mmlu:nutrition,validation,17.31210447847843,llama2_7b,choice,oe,0.4545454680919647,0.4545454680919647,0.40740740740740744,0.4754048730387832
306,,,,,,mmlu:nutrition,test,143.97928981296718,llama2_7b,choice,oe,0.3660130798816681,0.3660130798816681,0.46253681885125186,0.531821139692481
34,,,,,,mmlu:philosophy,validation,16.134623676538467,llama2_7b,choice,oe,0.3529411852359772,0.3529411852359772,0.5643939393939394,0.5141834318637848
311,,,,,,mmlu:philosophy,test,127.94724106788635,llama2_7b,choice,oe,0.3408360183238983,0.3376205861568451,0.5298205246203405,0.5314929933793292
35,,,,,,mmlu:prehistory,validation,16.506554389372468,llama2_7b,choice,oe,0.2571428716182709,0.2857142984867096,0.611111111111111,0.6132746968950544
324,,,,,,mmlu:prehistory,test,141.62270880490541,llama2_7b,choice,oe,0.4166666567325592,0.42283952236175537,0.5581422692533804,0.4187952149429439
69,,,,,,mmlu:professional_psychology,validation,34.11864542029798,llama2_7b,choice,oe,0.4057971239089966,0.4637681245803833,0.5670731707317073,0.42575155911238294
612,,,,,,mmlu:professional_psychology,test,287.3481742031872,llama2_7b,choice,oe,0.2957516312599182,0.30392158031463623,0.5268551870890003,0.5458137219637826
12,,,,,,mmlu:public_relations,validation,6.71226155012846,llama2_7b,choice,oe,0.5,0.5,0.4444444444444444,0.3411436478296916
110,,,,,,mmlu:public_relations,test,47.344096621498466,llama2_7b,choice,oe,0.37272727489471436,0.38181817531585693,0.549487451396253,0.4315532608465714
27,,,,,,mmlu:security_studies,validation,17.90635042078793,llama2_7b,choice,oe,0.5555555820465088,0.5555555820465088,0.46111111111111114,0.3564445243941413
245,,,,,,mmlu:security_studies,test,121.0550105329603,llama2_7b,choice,oe,0.5673469305038452,0.5673469305038452,0.5362087688339894,0.2781082423365846
22,,,,,,mmlu:sociology,validation,9.910738656297326,llama2_7b,choice,oe,0.40909093618392944,0.40909093618392944,0.5641025641025641,0.48989607800136914
201,,,,,,mmlu:sociology,test,86.06224156171083,llama2_7b,choice,oe,0.38308456540107727,0.38308456540107727,0.5249266862170088,0.4514491747860885
11,,,,,,mmlu:us_foreign_policy,validation,6.439924342557788,llama2_7b,choice,oe,0.7272727489471436,0.7272727489471436,0.5208333333333334,0.22280057451941748
100,,,,,,mmlu:us_foreign_policy,test,42.790066907182336,llama2_7b,choice,oe,0.5999999642372131,0.6200000047683716,0.6079166666666667,0.19969998240470888
18,,,,,,mmlu:virology,validation,10.300065029412508,llama2_7b,choice,oe,0.4444444477558136,0.3888888955116272,0.4124999999999999,0.4148828089237213
166,,,,,,mmlu:virology,test,71.91202166490257,llama2_7b,choice,oe,0.34939756989479065,0.3674698770046234,0.5328065134099618,0.5158706648522112
19,,,,,,mmlu:world_religions,validation,9.562861450016499,llama2_7b,choice,oe,0.7368420958518982,0.6315789222717285,0.7714285714285716,0.16615767227975947
171,,,,,,mmlu:world_religions,test,72.21747328527272,llama2_7b,choice,oe,0.6198830604553223,0.6081871390342712,0.5100145137880987,0.1487434743440639
11,0.17441788180307907,0.4545454680919647,0.4545454680919647,0.4666666666666667,0.42745098742571747,mmlu:abstract_algebra,validation,4.5270851738750935,mistral_7b,oe,choice,,,,
100,0.06442850440740583,0.32999998331069946,0.32999998331069946,0.48371777476255096,0.49208768963813787,mmlu:abstract_algebra,test,11.25876533985138,mistral_7b,oe,choice,,,,
14,0.12996737446103776,0.6428571939468384,0.6428571939468384,0.5777777777777777,0.2734923873628889,mmlu:anatomy,validation,1.7323172986507416,mistral_7b,oe,choice,,,,
135,0.07770858980991223,0.5703703761100769,0.5481481552124023,0.47066726377071205,0.2465709854055334,mmlu:anatomy,test,15.391496878117323,mistral_7b,oe,choice,,,,
16,0.18127261102199554,0.6875,0.6875,0.6181818181818182,0.1741933785378933,mmlu:astronomy,validation,2.94760599732399,mistral_7b,oe,choice,,,,
152,0.1195880966751199,0.6578947305679321,0.6644737124443054,0.5800961538461538,0.17328577684728724,mmlu:astronomy,test,26.43980071693659,mistral_7b,oe,choice,,,,
11,0.31494476578452363,0.5454545617103577,0.5454545617103577,0.3666666666666667,0.33648906512693927,mmlu:business_ethics,validation,1.9847596064209938,mistral_7b,oe,choice,,,,
100,0.10406364679336545,0.5899999737739563,0.5899999737739563,0.4981397271599835,0.29186640560626986,mmlu:business_ethics,test,16.960893262177706,mistral_7b,oe,choice,,,,
29,0.19262660474612794,0.6206896305084229,0.517241358757019,0.4494949494949495,0.1626906045551958,mmlu:clinical_knowledge,validation,3.8709112219512463,mistral_7b,oe,choice,,,,
265,0.10500043967984758,0.6754717230796814,0.5169811248779297,0.42955047421073145,0.1639633041507793,mmlu:clinical_knowledge,test,33.80440518632531,mistral_7b,oe,choice,,,,
16,0.1876346506178379,0.625,0.5625,0.7,0.24102302268147469,mmlu:college_biology,validation,2.494264531880617,mistral_7b,oe,choice,,,,
144,0.04377846585379708,0.7291666865348816,0.7013888955116272,0.6429792429792429,0.09172713342640137,mmlu:college_biology,test,21.69247292354703,mistral_7b,oe,choice,,,,
8,0.32298047840595245,0.25,0.5,0.5,0.4699174612760544,mmlu:college_chemistry,validation,1.528670597821474,mistral_7b,oe,choice,,,,
100,0.0650123029947281,0.4699999988079071,0.41999998688697815,0.5176635889201124,0.3372790372371674,mmlu:college_chemistry,test,16.807243708521128,mistral_7b,oe,choice,,,,
11,0.09047955816442316,0.4545454680919647,0.6363636255264282,0.8,0.25231136517091235,mmlu:college_computer_science,validation,2.8434967547655106,mistral_7b,oe,choice,,,,
100,0.17411124080419543,0.5399999618530273,0.5299999713897705,0.5026167471819646,0.2519653630256653,mmlu:college_computer_science,test,25.58831648156047,mistral_7b,oe,choice,,,,
11,0.09765914353457364,0.27272728085517883,0.27272728085517883,0.8541666666666666,0.6146107912063599,mmlu:college_mathematics,validation,2.071076273918152,mistral_7b,oe,choice,,,,
100,0.06678379207849502,0.32999998331069946,0.32999998331069946,0.5201266395296247,0.593022632598877,mmlu:college_mathematics,test,17.175607938319445,mistral_7b,oe,choice,,,,
22,0.20038289509036328,0.5454545617103577,0.5,0.4833333333333334,0.40211564844304865,mmlu:college_medicine,validation,3.566213011741638,mistral_7b,oe,choice,,,,
173,0.057301384865204044,0.6300578117370605,0.5838150382041931,0.5382024082568808,0.16689629327355088,mmlu:college_medicine,test,32.29516776651144,mistral_7b,oe,choice,,,,
11,0.2806849073279988,0.3636363744735718,0.7272727489471436,0.6428571428571429,0.28489090637727216,mmlu:college_physics,validation,1.8006007671356201,mistral_7b,oe,choice,,,,
102,0.11120533592560713,0.4215686321258545,0.5882353186607361,0.48226251478123766,0.045876154128242946,mmlu:college_physics,test,15.078909702599049,mistral_7b,oe,choice,,,,
11,0.37076828154650604,0.8181818723678589,0.8181818723678589,0.5,0.2397500655867837,mmlu:computer_security,validation,1.6788263954222202,mistral_7b,oe,choice,,,,
100,0.06696448236703875,0.7699999809265137,0.7400000095367432,0.5567476002258611,0.07744982659816743,mmlu:computer_security,test,12.33787927031517,mistral_7b,oe,choice,,,,
26,0.25595321219701034,0.46153849363327026,0.5384615659713745,0.5357142857142857,0.2926041850676903,mmlu:conceptual_physics,validation,2.7268939279019833,mistral_7b,oe,choice,,,,
235,0.05044980708588945,0.591489315032959,0.6170212626457214,0.5297511990407674,0.15220943993710456,mmlu:conceptual_physics,test,22.897727485746145,mistral_7b,oe,choice,,,,
12,0.23041644444068274,0.6666666865348816,0.6666666865348816,0.78125,0.21683865785598755,mmlu:econometrics,validation,2.4645415507256985,mistral_7b,oe,choice,,,,
114,0.08587186299917991,0.5087719559669495,0.5,0.5255541871921182,0.30396631360054016,mmlu:econometrics,test,21.01912682503462,mistral_7b,oe,choice,,,,
16,0.25773022696375847,0.625,0.75,0.8,0.16618701815605164,mmlu:electrical_engineering,validation,2.284347664564848,mistral_7b,oe,choice,,,,
145,0.08545136287294586,0.5793103575706482,0.5931034684181213,0.4924863387978142,0.1377771537879418,mmlu:electrical_engineering,test,18.901483610272408,mistral_7b,oe,choice,,,,
41,0.09747468407561138,0.4146341383457184,0.4878048598766327,0.7144607843137255,0.2334247275096614,mmlu:elementary_mathematics,validation,6.931098062545061,mistral_7b,oe,choice,,,,
378,0.06201344381564508,0.41534391045570374,0.4444444179534912,0.494206991958959,0.29417423296857764,mmlu:elementary_mathematics,test,60.92208509519696,mistral_7b,oe,choice,,,,
14,0.34706552752426695,0.2857142984867096,0.2857142984867096,0.24999999999999997,0.6131499367100852,mmlu:formal_logic,validation,2.8283875696361065,mistral_7b,oe,choice,,,,
126,0.08840034902095796,0.3888889253139496,0.3888889253139496,0.4614365226610125,0.4319383241827526,mmlu:formal_logic,test,24.3568097576499,mistral_7b,oe,choice,,,,
10,0.20264226198196417,0.6000000238418579,0.6000000238418579,0.5416666666666666,0.06650100350379944,mmlu:global_facts,validation,1.4801319055259228,mistral_7b,oe,choice,,,,
100,0.059538078308105466,0.32999998331069946,0.44999998807907104,0.48733604703753963,0.17052005648612978,mmlu:global_facts,test,12.83594136312604,mistral_7b,oe,choice,,,,
32,0.11322943214327094,0.6875,0.59375,0.47272727272727266,0.16927615366876125,mmlu:high_school_biology,validation,5.261981051415205,mistral_7b,oe,choice,,,,
310,0.04629246554067055,0.7645161151885986,0.7193548083305359,0.5636379400034681,0.061539396547502095,mmlu:high_school_biology,test,49.909254029393196,mistral_7b,oe,choice,,,,
22,0.2628293985670263,0.40909093618392944,0.4545454680919647,0.5982905982905982,0.24065355821089313,mmlu:high_school_chemistry,validation,3.71225119009614,mistral_7b,oe,choice,,,,
203,0.05231280015607186,0.5024630427360535,0.517241358757019,0.5853232382061736,0.210896216589829,mmlu:high_school_chemistry,test,31.610342752188444,mistral_7b,oe,choice,,,,
9,0.3007135225666894,0.6666666865348816,0.5555555820465088,0.3333333333333333,0.36039234532250297,mmlu:high_school_computer_science,validation,2.7134742066264153,mistral_7b,oe,choice,,,,
100,0.13785880148410795,0.7299999594688416,0.6299999952316284,0.547945205479452,0.07972221374511719,mmlu:high_school_computer_science,test,28.64289340376854,mistral_7b,oe,choice,,,,
22,0.14824948256666012,0.8181818723678589,0.5909091234207153,0.5416666666666667,0.15897535194050183,mmlu:high_school_geography,validation,2.7017757184803486,mistral_7b,oe,choice,,,,
198,0.030429966220952065,0.7979797720909119,0.7323232293128967,0.5954113924050632,0.041242206939543176,mmlu:high_school_geography,test,23.27508208528161,mistral_7b,oe,choice,,,,
21,0.16606875402586804,0.8571428656578064,0.4285714328289032,0.14814814814814814,0.33311995721998666,mmlu:high_school_government_and_politics,validation,3.0192378386855125,mistral_7b,oe,choice,,,,
193,0.06839079792017766,0.8860103487968445,0.6528497338294983,0.5467836257309941,0.04251449898734613,mmlu:high_school_government_and_politics,test,26.447455182671547,mistral_7b,oe,choice,,,,
43,0.07352438915607543,0.6511628031730652,0.604651153087616,0.6214285714285714,0.20592062972312752,mmlu:high_school_macroeconomics,validation,5.150058418512344,mistral_7b,oe,choice,,,,
390,0.08413507013748853,0.656410276889801,0.6435897350311279,0.573387943097015,0.1778768151234358,mmlu:high_school_macroeconomics,test,45.80963156372309,mistral_7b,oe,choice,,,,
29,0.09171333189668326,0.20689654350280762,0.3448275923728943,0.572463768115942,0.30790778069660585,mmlu:high_school_mathematics,validation,4.707457475364208,mistral_7b,oe,choice,,,,
270,0.052982342574331515,0.31111109256744385,0.4333333373069763,0.534242191500256,0.22570752656018295,mmlu:high_school_mathematics,test,41.99929781630635,mistral_7b,oe,choice,,,,
26,0.16145830773390257,0.7692307829856873,0.6153846383094788,0.325,0.19359775919180652,mmlu:high_school_microeconomics,validation,3.2549688667058945,mistral_7b,oe,choice,,,,
238,0.03960399868107643,0.6638655662536621,0.6092437505722046,0.5290348101265823,0.12827815228149672,mmlu:high_school_microeconomics,test,29.05305464193225,mistral_7b,oe,choice,,,,
17,0.21038203379687137,0.23529411852359772,0.3529411852359772,0.5961538461538461,0.4788317995912889,mmlu:high_school_physics,validation,3.044028952717781,mistral_7b,oe,choice,,,,
151,0.05913235355686669,0.3509933650493622,0.443708598613739,0.4713130535232961,0.3205919522323356,mmlu:high_school_physics,test,25.341395035386086,mistral_7b,oe,choice,,,,
60,0.06841527173916499,0.8833333849906921,0.7500000596046448,0.7466307277628033,0.062136516968409224,mmlu:high_school_psychology,validation,9.130088336765766,mistral_7b,oe,choice,,,,
545,0.029738220162347888,0.8183486461639404,0.7339449524879456,0.5123091905603117,0.0340206745567672,mmlu:high_school_psychology,test,82.69871209561825,mistral_7b,oe,choice,,,,
23,0.13216069729431817,0.52173912525177,0.43478262424468994,0.6287878787878788,0.3019240576287974,mmlu:high_school_statistics,validation,5.777718983590603,mistral_7b,oe,choice,,,,
216,0.09823555347544176,0.5740740895271301,0.5231481790542603,0.4929873772791024,0.24352517613658198,mmlu:high_school_statistics,test,55.41584227606654,mistral_7b,oe,choice,,,,
22,0.17673563008958643,0.7727273106575012,0.7272727489471436,0.4470588235294118,0.20104538039727643,mmlu:high_school_us_history,validation,20.16392893344164,mistral_7b,oe,choice,,,,
204,0.04254282411991383,0.779411792755127,0.7009804248809814,0.505171208944794,0.08135153119470556,mmlu:high_school_us_history,test,185.80531559884548,mistral_7b,oe,choice,,,,
23,0.23292865960494333,0.739130437374115,0.5652173757553101,0.3676470588235294,0.22098468179288114,mmlu:human_aging,validation,2.4990248419344425,mistral_7b,oe,choice,,,,
223,0.05373704019148788,0.6995515823364258,0.6322870254516602,0.5011959433601224,0.1274180773127774,mmlu:human_aging,test,22.510154761373997,mistral_7b,oe,choice,,,,
12,0.20912925402323407,0.5833333730697632,0.4166666865348816,0.4,0.30364191532135015,mmlu:human_sexuality,validation,1.4749009385704994,mistral_7b,oe,choice,,,,
131,0.10510530135103764,0.8015267252922058,0.6564885377883911,0.5527472527472528,0.07542667589114821,mmlu:human_sexuality,test,14.999621231108904,mistral_7b,oe,choice,,,,
13,0.1015930359180157,0.9230769872665405,0.8461538553237915,0.9166666666666666,0.20097137872989362,mmlu:international_law,validation,2.63077424839139,mistral_7b,oe,choice,,,,
121,0.03842827061976283,0.7933883666992188,0.7272726893424988,0.41208333333333336,0.10478989792264198,mmlu:international_law,test,22.73890643939376,mistral_7b,oe,choice,,,,
11,0.20057660612193018,0.6363636255264282,0.5454545617103577,0.8214285714285714,0.35683740269054065,mmlu:jurisprudence,validation,1.5326572135090828,mistral_7b,oe,choice,,,,
108,0.11406420226450321,0.8148148059844971,0.8055555820465088,0.5588068181818182,0.0727723980391467,mmlu:jurisprudence,test,13.478481020778418,mistral_7b,oe,choice,,,,
18,0.20586354533831278,0.7222222089767456,0.7222222089767456,0.3538461538461538,0.19312546319431728,mmlu:logical_fallacies,validation,2.4857230074703693,mistral_7b,oe,choice,,,,
163,0.1014370464839818,0.8098159432411194,0.8220858573913574,0.6237781036168133,0.0365383811523578,mmlu:logical_fallacies,test,21.637077555060387,mistral_7b,oe,choice,,,,
11,0.19773347269405017,0.27272728085517883,0.4545454680919647,0.8958333333333333,0.31241947412490845,mmlu:machine_learning,validation,2.2577875182032585,mistral_7b,oe,choice,,,,
112,0.13094645525727952,0.3750000298023224,0.4017857313156128,0.6030612244897959,0.35100733329142847,mmlu:machine_learning,test,21.859579522162676,mistral_7b,oe,choice,,,,
11,0.16335472735491666,0.9090909361839294,0.9090909361839294,1.0,0.1697598262266679,mmlu:management,validation,1.1596403270959854,mistral_7b,oe,choice,,,,
103,0.0489254851364395,0.7961165308952332,0.7961165308952332,0.6056910569105691,0.10760710598195643,mmlu:management,test,9.87945307418704,mistral_7b,oe,choice,,,,
25,0.07497458100318907,0.8799999952316284,0.8399999737739563,0.5,0.035808842182159434,mmlu:marketing,validation,3.292256087064743,mistral_7b,oe,choice,,,,
234,0.04650758295996573,0.8632479310035706,0.8547009229660034,0.48035272277227725,0.09417157422783029,mmlu:marketing,test,28.923885710537434,mistral_7b,oe,choice,,,,
11,0.1311386904933236,1.0,1.0,,0.1719987554983659,mmlu:medical_genetics,validation,1.4300804995000362,mistral_7b,oe,choice,,,,
100,0.12973693013191223,0.7299999594688416,0.6200000047683716,0.45129375951293765,0.214361292719841,mmlu:medical_genetics,test,11.347659274935722,mistral_7b,oe,choice,,,,
38,0.18127680922809403,0.6315789222717285,0.5789473652839661,0.5446428571428572,0.2294904495540418,mmlu:moral_disputes,validation,5.692568216472864,mistral_7b,oe,choice,,,,
346,0.06783685002023773,0.7023121118545532,0.6907514333724976,0.45399336769347554,0.14161404037062142,mmlu:moral_disputes,test,50.38582870364189,mistral_7b,oe,choice,,,,
33,0.14350027387792413,0.7575757503509521,0.7272727489471436,0.7125,0.11139764388402303,mmlu:nutrition,validation,6.018548630177975,mistral_7b,oe,choice,,,,
306,0.09732476168987797,0.7450980544090271,0.7091503143310547,0.5486111111111112,0.06068867425513422,mmlu:nutrition,test,54.89282700419426,mistral_7b,oe,choice,,,,
34,0.1901066610041787,0.7352941036224365,0.6470588445663452,0.48444444444444446,0.18481046136687784,mmlu:philosophy,validation,3.926348116248846,mistral_7b,oe,choice,,,,
311,0.04866222610810946,0.7266880869865417,0.6881029009819031,0.48669963560645496,0.15620686866079495,mmlu:philosophy,test,33.805311273783445,mistral_7b,oe,choice,,,,
35,0.1596931661878313,0.5714285969734192,0.5428571701049805,0.42333333333333334,0.25521819080625263,mmlu:prehistory,validation,5.863386772572994,mistral_7b,oe,choice,,,,
324,0.031491318878568264,0.7407407760620117,0.7037037014961243,0.5048363095238095,0.11569798084688776,mmlu:prehistory,test,52.1161353290081,mistral_7b,oe,choice,,,,
69,0.07041500875915305,0.7101449370384216,0.6811594367027283,0.3561224489795918,0.1588647572890572,mmlu:professional_psychology,validation,12.439271535724401,mistral_7b,oe,choice,,,,
612,0.04561248324275796,0.6813725829124451,0.6372548937797546,0.5641148619565886,0.1267194342769049,mmlu:professional_psychology,test,104.93461317569017,mistral_7b,oe,choice,,,,
12,0.23054789006710052,0.5,0.5,0.75,0.33293069402376807,mmlu:public_relations,validation,1.7737265527248383,mistral_7b,oe,choice,,,,
110,0.10268353657288982,0.663636326789856,0.663636326789856,0.6045908922621251,0.2184393508867784,mmlu:public_relations,test,14.095413900911808,mistral_7b,oe,choice,,,,
27,0.16775211581477412,0.7037037014961243,0.6666666865348816,0.7171052631578947,0.21364422418453072,mmlu:security_studies,validation,10.604344792664051,mistral_7b,oe,choice,,,,
245,0.08090466029789982,0.7510203719139099,0.7469387650489807,0.5646828225231647,0.10349821874073575,mmlu:security_studies,test,97.50533009693027,mistral_7b,oe,choice,,,,
22,0.11629392071203752,0.8636363744735718,0.7272727489471436,0.9298245614035088,0.18445166403597052,mmlu:sociology,validation,2.978224787861109,mistral_7b,oe,choice,,,,
201,0.03207025984626502,0.8407959938049316,0.6865671277046204,0.5624075443786982,0.06079230320394337,mmlu:sociology,test,26.147594671696424,mistral_7b,oe,choice,,,,
11,0.1911940574645996,0.9090909361839294,0.8181818723678589,0.7,0.15080414576963946,mmlu:us_foreign_policy,validation,1.5675807781517506,mistral_7b,oe,choice,,,,
100,0.0888331925868988,0.8799999952316284,0.7999999523162842,0.47727272727272724,0.031044683456420894,mmlu:us_foreign_policy,test,12.669955041259527,mistral_7b,oe,choice,,,,
18,0.23083103365368313,0.6666666865348816,0.4444444477558136,0.36111111111111116,0.3036215172873603,mmlu:virology,validation,2.5266151279211044,mistral_7b,oe,choice,,,,
166,0.2130287745630885,0.5361445546150208,0.5301204919815063,0.4948197869546184,0.20436585954872957,mmlu:virology,test,18.663903959095478,mistral_7b,oe,choice,,,,
19,0.20412473772701462,0.8947368264198303,0.5263158082962036,0.5882352941176471,0.23389122360631043,mmlu:world_religions,validation,1.8488534353673458,mistral_7b,oe,choice,,,,
171,0.04494706475943848,0.8187134265899658,0.5614035129547119,0.4661290322580645,0.135429146694161,mmlu:world_religions,test,15.07221344858408,mistral_7b,oe,choice,,,,
11,,,,,,mmlu:abstract_algebra,validation,15.340603923425078,llama2_13b_chat,choice,oe,0.09090909361839294,0.4545454680919647,0.09999999999999998,0.2255895950577476
100,,,,,,mmlu:abstract_algebra,test,97.67575374990702,llama2_13b_chat,choice,oe,0.32999998331069946,0.4599999785423279,0.5185436454093171,0.14913957238197326
14,,,,,,mmlu:anatomy,validation,5.260959818959236,llama2_13b_chat,choice,oe,0.2857142984867096,0.7142857313156128,0.75,0.07867091042654854
135,,,,,,mmlu:anatomy,test,44.54329178854823,llama2_13b_chat,choice,oe,0.43703702092170715,0.6370370388031006,0.5175066904549509,0.11055109633339773
16,,,,,,mmlu:astronomy,validation,8.63287027925253,llama2_13b_chat,choice,oe,0.3125,0.5625,0.4363636363636364,0.19288331642746925
152,,,,,,mmlu:astronomy,test,77.94169120304286,llama2_13b_chat,choice,oe,0.5,0.5197368264198303,0.5162742382271468,0.17387219204714427
11,,,,,,mmlu:business_ethics,validation,5.622132180258632,llama2_13b_chat,choice,oe,0.6363636255264282,0.7272727489471436,0.6428571428571428,0.23475972088900482
100,,,,,,mmlu:business_ethics,test,57.772140899673104,llama2_13b_chat,choice,oe,0.29999998211860657,0.32999998331069946,0.42809523809523814,0.4653311842679978
29,,,,,,mmlu:clinical_knowledge,validation,13.404391700401902,llama2_13b_chat,choice,oe,0.17241379618644714,0.6206896305084229,0.525,0.22449101867346932
265,,,,,,mmlu:clinical_knowledge,test,122.78946056775749,llama2_13b_chat,choice,oe,0.27169811725616455,0.5547170042991638,0.4951784686240645,0.107941143242818
16,,,,,,mmlu:college_biology,validation,7.559966277331114,llama2_13b_chat,choice,oe,0.25,0.375,0.7708333333333333,0.4171007387340069
144,,,,,,mmlu:college_biology,test,193.54159628413618,llama2_13b_chat,choice,oe,0.3263888955116272,0.5138888955116272,0.5525334503180522,0.1825139919916789
8,,,,,,mmlu:college_chemistry,validation,4.069598788395524,llama2_13b_chat,choice,oe,0.0,0.5,,0.4965074732899666
100,,,,,,mmlu:college_chemistry,test,51.173998126760125,llama2_13b_chat,choice,oe,0.17000000178813934,0.4099999964237213,0.41743444365698085,0.2955486613512039
11,,,,,,mmlu:college_computer_science,validation,10.675542082637548,llama2_13b_chat,choice,oe,0.27272728085517883,0.7272727489471436,0.75,0.23391614718870687
100,,,,,,mmlu:college_computer_science,test,81.82268851995468,llama2_13b_chat,choice,oe,0.20999999344348907,0.6200000047683716,0.5216998191681735,0.11685495495796204
11,,,,,,mmlu:college_mathematics,validation,9.247870579361916,llama2_13b_chat,choice,oe,0.0,0.5454545617103577,,0.4262719642032276
100,,,,,,mmlu:college_mathematics,test,87.51678927615285,llama2_13b_chat,choice,oe,0.17000000178813934,0.4699999988079071,0.4875974486180014,0.20827519714832307
22,,,,,,mmlu:college_medicine,validation,10.300545517355204,llama2_13b_chat,choice,oe,0.3636363744735718,0.40909093618392944,0.2946428571428571,0.27173124660145154
173,,,,,,mmlu:college_medicine,test,109.19443411193788,llama2_13b_chat,choice,oe,0.36994218826293945,0.4971098303794861,0.5823537844036698,0.17438189521690323
11,,,,,,mmlu:college_physics,validation,5.6074586994946,llama2_13b_chat,choice,oe,0.27272728085517883,0.4545454680919647,0.7083333333333333,0.22952324151992803
102,,,,,,mmlu:college_physics,test,59.06057164259255,llama2_13b_chat,choice,oe,0.13725490868091583,0.5882353186607361,0.39123376623376627,0.10992079505733415
11,,,,,,mmlu:computer_security,validation,5.525261772796512,llama2_13b_chat,choice,oe,0.4545454680919647,0.6363636255264282,0.43333333333333335,0.4821700778874484
100,,,,,,mmlu:computer_security,test,61.31913118623197,llama2_13b_chat,choice,oe,0.5699999928474426,0.550000011920929,0.4337005303957568,0.18764264047145843
26,,,,,,mmlu:conceptual_physics,validation,9.61366368830204,llama2_13b_chat,choice,oe,0.3461538553237915,0.42307692766189575,0.40522875816993464,0.21030276096784156
235,,,,,,mmlu:conceptual_physics,test,72.87582741118968,llama2_13b_chat,choice,oe,0.40851062536239624,0.5234042406082153,0.4627547961630695,0.1250048005834539
12,,,,,,mmlu:econometrics,validation,8.464856535196304,llama2_13b_chat,choice,oe,0.25,0.75,0.5185185185185185,0.2773960530757904
114,,,,,,mmlu:econometrics,test,125.89747421815991,llama2_13b_chat,choice,oe,0.12280701845884323,0.5263158082962036,0.4232142857142857,0.15942378734287466
16,,,,,,mmlu:electrical_engineering,validation,14.466325864195824,llama2_13b_chat,choice,oe,0.1875,0.625,0.5641025641025641,0.1953899972140789
145,,,,,,mmlu:electrical_engineering,test,118.46945958957076,llama2_13b_chat,choice,oe,0.19310344755649567,0.7172414064407349,0.4172771672771673,0.0788668320096772
41,,,,,,mmlu:elementary_mathematics,validation,23.467613143846393,llama2_13b_chat,choice,oe,0.2682926654815674,0.4390243887901306,0.5727272727272728,0.24202865652921723
378,,,,,,mmlu:elementary_mathematics,test,198.32615121267736,llama2_13b_chat,choice,oe,0.317460298538208,0.4894179701805115,0.5214793281653747,0.17954785010171315
14,,,,,,mmlu:formal_logic,validation,12.465737087652087,llama2_13b_chat,choice,oe,0.5,0.4285714626312256,0.40816326530612246,0.43208522881780353
126,,,,,,mmlu:formal_logic,test,90.04069855809212,llama2_13b_chat,choice,oe,0.40476194024086,0.4682539999485016,0.47542483660130724,0.26045387888711596
10,,,,,,mmlu:global_facts,validation,4.657728683203459,llama2_13b_chat,choice,oe,0.20000000298023224,0.4000000059604645,0.75,0.3809433579444886
100,,,,,,mmlu:global_facts,test,45.12648252956569,llama2_13b_chat,choice,oe,0.17000000178813934,0.28999999165534973,0.39759036144578314,0.4294239455461503
32,,,,,,mmlu:high_school_biology,validation,15.208463683724403,llama2_13b_chat,choice,oe,0.21875,0.59375,0.4657142857142857,0.21496043354272842
310,,,,,,mmlu:high_school_biology,test,178.03309018723667,llama2_13b_chat,choice,oe,0.43870967626571655,0.5,0.5396593982420554,0.18407864878254554
22,,,,,,mmlu:high_school_chemistry,validation,11.916010990738869,llama2_13b_chat,choice,oe,0.13636364042758942,0.13636364042758942,0.26315789473684215,0.5972737182270397
203,,,,,,mmlu:high_school_chemistry,test,109.10228441283107,llama2_13b_chat,choice,oe,0.1822660118341446,0.5221675038337708,0.5901986323673071,0.2196383570215385
9,,,,,,mmlu:high_school_computer_science,validation,9.327435513958335,llama2_13b_chat,choice,oe,0.5555555820465088,0.5555555820465088,0.6500000000000001,0.16322482294506496
100,,,,,,mmlu:high_school_computer_science,test,121.81010217219591,llama2_13b_chat,choice,oe,0.4099999964237213,0.5699999928474426,0.5198429102935097,0.15522100865840913
22,,,,,,mmlu:high_school_geography,validation,15.06533857434988,llama2_13b_chat,choice,oe,0.5454545617103577,0.5909091234207153,0.525,0.15820887413891876
198,,,,,,mmlu:high_school_geography,test,130.12655730359256,llama2_13b_chat,choice,oe,0.3333333432674408,0.5858585834503174,0.41580578512396693,0.06179554323957423
21,,,,,,mmlu:high_school_government_and_politics,validation,8.691171031445265,llama2_13b_chat,choice,oe,0.380952388048172,0.4761904776096344,0.7307692307692307,0.26807225034350435
193,,,,,,mmlu:high_school_government_and_politics,test,162.4147293511778,llama2_13b_chat,choice,oe,0.4715025722980499,0.5440414547920227,0.5468648998060763,0.10562132708149252
43,,,,,,mmlu:high_school_macroeconomics,validation,26.643564749509096,llama2_13b_chat,choice,oe,0.41860464215278625,0.5581395626068115,0.5488888888888889,0.13550688776859016
390,,,,,,mmlu:high_school_macroeconomics,test,236.74710244312882,llama2_13b_chat,choice,oe,0.28205129504203796,0.5615384578704834,0.5241396103896103,0.08754874284450824
29,,,,,,mmlu:high_school_mathematics,validation,13.655986323952675,llama2_13b_chat,choice,oe,0.06896551698446274,0.37931033968925476,0.3888888888888889,0.25744761886267825
270,,,,,,mmlu:high_school_mathematics,test,139.49218694120646,llama2_13b_chat,choice,oe,0.10370370000600815,0.4444444477558136,0.4606700118063754,0.20642541536578424
26,,,,,,mmlu:high_school_microeconomics,validation,18.711265658959746,llama2_13b_chat,choice,oe,0.19230769574642181,0.6153846383094788,0.2,0.09928416518064641
238,,,,,,mmlu:high_school_microeconomics,test,148.1261983308941,llama2_13b_chat,choice,oe,0.33193278312683105,0.605042040348053,0.5173553061062017,0.08972975761950516
17,,,,,,mmlu:high_school_physics,validation,13.975069308653474,llama2_13b_chat,choice,oe,0.1764705926179886,0.8235294222831726,0.4999999999999999,0.09542796892278335
151,,,,,,mmlu:high_school_physics,test,90.13542598672211,llama2_13b_chat,choice,oe,0.1986754983663559,0.7218543291091919,0.4706611570247934,0.10128842244874565
60,,,,,,mmlu:high_school_psychology,validation,29.52945883758366,llama2_13b_chat,choice,oe,0.5333333611488342,0.550000011920929,0.5178571428571428,0.1699561695257823
545,,,,,,mmlu:high_school_psychology,test,269.76966482773423,llama2_13b_chat,choice,oe,0.5192660689353943,0.5339449644088745,0.5472918296334259,0.14701004498595494
23,,,,,,mmlu:high_school_statistics,validation,29.125458747148514,llama2_13b_chat,choice,oe,0.17391304671764374,0.695652186870575,0.631578947368421,0.215254096881203
216,,,,,,mmlu:high_school_statistics,test,246.2944838758558,llama2_13b_chat,choice,oe,0.28240740299224854,0.6574074029922485,0.42533051295610785,0.08952001095921905
22,,,,,,mmlu:high_school_us_history,validation,42.31229551322758,llama2_13b_chat,choice,oe,0.6818181872367859,0.5,0.5476190476190477,0.11840600588104942
204,,,,,,mmlu:high_school_us_history,test,405.3086342457682,llama2_13b_chat,choice,oe,0.6715686321258545,0.6029412150382996,0.48747140211352,0.04353787297127294
23,,,,,,mmlu:human_aging,validation,20.302762664854527,llama2_13b_chat,choice,oe,0.43478262424468994,0.52173912525177,0.5846153846153846,0.23043428814929465
223,,,,,,mmlu:human_aging,test,252.8853011596948,llama2_13b_chat,choice,oe,0.3766816258430481,0.4798206388950348,0.4673689619732785,0.23848636855993569
12,,,,,,mmlu:human_sexuality,validation,10.094645291566849,llama2_13b_chat,choice,oe,0.3333333432674408,0.5,0.59375,0.2543669988711675
131,,,,,,mmlu:human_sexuality,test,98.90915753133595,llama2_13b_chat,choice,oe,0.49618321657180786,0.5572519302368164,0.4983682983682984,0.1833503214457563
13,,,,,,mmlu:international_law,validation,13.001026758924127,llama2_13b_chat,choice,oe,0.1538461595773697,0.6153846383094788,0.4545454545454546,0.19059505370947033
121,,,,,,mmlu:international_law,test,87.02227873168886,llama2_13b_chat,choice,oe,0.46280989050865173,0.586776852607727,0.39931318681318684,0.12036716790238688
11,,,,,,mmlu:jurisprudence,validation,7.649149714037776,llama2_13b_chat,choice,oe,0.27272728085517883,0.6363636255264282,0.75,0.12146966023878614
108,,,,,,mmlu:jurisprudence,test,50.5826834384352,llama2_13b_chat,choice,oe,0.40740740299224854,0.5555555820465088,0.5404829545454546,0.09004251162211102
18,,,,,,mmlu:logical_fallacies,validation,7.784935459494591,llama2_13b_chat,choice,oe,0.4444444477558136,0.7222222089767456,0.5499999999999999,0.08308265275425383
163,,,,,,mmlu:logical_fallacies,test,87.88182836771011,llama2_13b_chat,choice,oe,0.44785276055336,0.4907975196838379,0.5986301369863013,0.1946292958376598
11,,,,,,mmlu:machine_learning,validation,6.373645143583417,llama2_13b_chat,choice,oe,0.27272728085517883,0.5454545617103577,0.4583333333333333,0.2275541370565241
112,,,,,,mmlu:machine_learning,test,60.249869491904974,llama2_13b_chat,choice,oe,0.2857142984867096,0.5446428656578064,0.426171875,0.14695444862757415
11,,,,,,mmlu:management,validation,4.050904726609588,llama2_13b_chat,choice,oe,0.5454545617103577,0.5454545617103577,0.7333333333333334,0.308373667977073
103,,,,,,mmlu:management,test,180.1502907089889,llama2_13b_chat,choice,oe,0.41747573018074036,0.5048543810844421,0.4403100775193799,0.29281395615883243
25,,,,,,mmlu:marketing,validation,17.380700517445803,llama2_13b_chat,choice,oe,0.23999999463558197,0.5199999809265137,0.631578947368421,0.222086546421051
234,,,,,,mmlu:marketing,test,142.21659993194044,llama2_13b_chat,choice,oe,0.46581199765205383,0.5427350401878357,0.49475229357798167,0.08262098446870461
11,,,,,,mmlu:medical_genetics,validation,6.633231550455093,llama2_13b_chat,choice,oe,0.8181818723678589,0.6363636255264282,0.7222222222222222,0.15062633427706634
100,,,,,,mmlu:medical_genetics,test,62.043033853173256,llama2_13b_chat,choice,oe,0.4699999988079071,0.4399999976158142,0.523083099156965,0.2551618313789368
38,,,,,,mmlu:moral_disputes,validation,23.635696904733777,llama2_13b_chat,choice,oe,0.5789473652839661,0.3684210479259491,0.5326704545454546,0.299765872327905
346,,,,,,mmlu:moral_disputes,test,195.55689712055027,llama2_13b_chat,choice,oe,0.38728323578834534,0.5693641304969788,0.518463108983385,0.08100871026860498
33,,,,,,mmlu:nutrition,validation,22.757964622229338,llama2_13b_chat,choice,oe,0.3030303120613098,0.4545454680919647,0.4304347826086957,0.25799275708921027
306,,,,,,mmlu:nutrition,test,221.23857674747705,llama2_13b_chat,choice,oe,0.343137264251709,0.5457516312599182,0.46019900497512445,0.20162413244933083
34,,,,,,mmlu:philosophy,validation,10.597087990492582,llama2_13b_chat,choice,oe,0.29411765933036804,0.5,0.4916666666666667,0.11098580500658821
311,,,,,,mmlu:philosophy,test,142.07230811193585,llama2_13b_chat,choice,oe,0.27009645104408264,0.5273311734199524,0.5588158170757289,0.10009806773286924
35,,,,,,mmlu:prehistory,validation,15.465549387037754,llama2_13b_chat,choice,oe,0.3142857253551483,0.5142857432365417,0.5643939393939394,0.14988901104245866
324,,,,,,mmlu:prehistory,test,137.55911350995302,llama2_13b_chat,choice,oe,0.3919753134250641,0.540123462677002,0.4689635876733682,0.11003666674649275
69,,,,,,mmlu:professional_psychology,validation,81.03105261176825,llama2_13b_chat,choice,oe,0.3478260934352875,0.5362318754196167,0.5166666666666667,0.15493967222130817
612,,,,,,mmlu:professional_psychology,test,686.3428007401526,llama2_13b_chat,choice,oe,0.32679739594459534,0.48366013169288635,0.4683252427184466,0.17504164099303723
12,,,,,,mmlu:public_relations,validation,4.341782547533512,llama2_13b_chat,choice,oe,0.3333333432674408,0.3333333432674408,0.4375,0.3391294280687968
110,,,,,,mmlu:public_relations,test,155.34817300736904,llama2_13b_chat,choice,oe,0.2818181812763214,0.3999999761581421,0.6118824009799919,0.2718022335659374
27,,,,,,mmlu:security_studies,validation,21.28654956817627,llama2_13b_chat,choice,oe,0.5925925970077515,0.40740740299224854,0.5056818181818182,0.18726868099636498
245,,,,,,mmlu:security_studies,test,265.79771232791245,llama2_13b_chat,choice,oe,0.59183669090271,0.5346938371658325,0.5328620689655172,0.10938970726363513
22,,,,,,mmlu:sociology,validation,9.289276519790292,llama2_13b_chat,choice,oe,0.3636363744735718,0.40909093618392944,0.4464285714285714,0.29102526469664136
201,,,,,,mmlu:sociology,test,90.46913312934339,llama2_13b_chat,choice,oe,0.4079601764678955,0.5373134016990662,0.4705369952859193,0.13931009573722955
11,,,,,,mmlu:us_foreign_policy,validation,6.081879170611501,llama2_13b_chat,choice,oe,0.6363636255264282,0.7272727489471436,0.4642857142857143,0.19754253734241833
100,,,,,,mmlu:us_foreign_policy,test,54.04967123828828,llama2_13b_chat,choice,oe,0.550000011920929,0.429999977350235,0.39050505050505047,0.2292512518167496
18,,,,,,mmlu:virology,validation,11.182624228298664,llama2_13b_chat,choice,oe,0.3333333432674408,0.4444444477558136,0.6111111111111112,0.25175494286749095
166,,,,,,mmlu:virology,test,91.20198305137455,llama2_13b_chat,choice,oe,0.2650602459907532,0.4999999701976776,0.4914307004470939,0.1862798336758671
19,,,,,,mmlu:world_religions,validation,7.0041886027902365,llama2_13b_chat,choice,oe,0.7368420958518982,0.6315789222717285,0.30000000000000004,0.21178680030923142
171,,,,,,mmlu:world_religions,test,58.70839840173721,llama2_13b_chat,choice,oe,0.6023392081260681,0.5087719559669495,0.4955739577384352,0.2000370276601691
11,,,,,,mmlu:abstract_algebra,validation,16.299369618296623,mistral_7b,oe,oe,0.3636363744735718,0.4545454680919647,0.25,0.4618436802517284
100,,,,,,mmlu:abstract_algebra,test,98.67984669283032,mistral_7b,oe,oe,0.23999999463558197,0.4099999964237213,0.4276315789473685,0.3426043236255646
14,,,,,,mmlu:anatomy,validation,15.615589886903763,mistral_7b,oe,oe,0.4285714626312256,0.3571428656578064,0.6875,0.4118506142071315
135,,,,,,mmlu:anatomy,test,130.76113207638264,mistral_7b,oe,oe,0.5481481552124023,0.5037037134170532,0.447718210013292,0.30028553097336386
16,,,,,,mmlu:astronomy,validation,16.410316105931997,mistral_7b,oe,oe,0.125,0.375,0.2142857142857143,0.5523483194410801
152,,,,,,mmlu:astronomy,test,144.01035346463323,mistral_7b,oe,oe,0.44078949093818665,0.41447368264198303,0.48612818261633006,0.38891089237050014
11,,,,,,mmlu:business_ethics,validation,15.052787952125072,mistral_7b,oe,oe,0.4545454680919647,0.5454545617103577,0.43333333333333335,0.2642280838706277
100,,,,,,mmlu:business_ethics,test,97.9710656516254,mistral_7b,oe,oe,0.3100000023841858,0.4399999976158142,0.5932678821879381,0.3656657999753952
29,,,,,,mmlu:clinical_knowledge,validation,35.0443247705698,mistral_7b,oe,oe,0.27586206793785095,0.4482758641242981,0.37202380952380953,0.3166541765476096
265,,,,,,mmlu:clinical_knowledge,test,260.83150865510106,mistral_7b,oe,oe,0.324528306722641,0.43018868565559387,0.4389372482785501,0.31984398724897856
16,,,,,,mmlu:college_biology,validation,16.057263642549515,mistral_7b,oe,oe,0.3125,0.5,0.6181818181818182,0.3019792214035988
144,,,,,,mmlu:college_biology,test,144.36308728531003,mistral_7b,oe,oe,0.4027777910232544,0.5,0.5691659983961508,0.2998587402204672
8,,,,,,mmlu:college_chemistry,validation,9.079894598573446,mistral_7b,oe,oe,0.25,0.375,0.41666666666666663,0.341038316488266
100,,,,,,mmlu:college_chemistry,test,96.08369734883308,mistral_7b,oe,oe,0.19999998807907104,0.6800000071525574,0.595,0.1323414796590805
11,,,,,,mmlu:college_computer_science,validation,12.530932631343603,mistral_7b,oe,oe,0.09090909361839294,0.27272728085517883,0.4,0.6217058463530107
100,,,,,,mmlu:college_computer_science,test,106.08674904331565,mistral_7b,oe,oe,0.23999999463558197,0.41999998688697815,0.5860745614035088,0.44620522439479826
11,,,,,,mmlu:college_mathematics,validation,11.186779744923115,mistral_7b,oe,oe,0.3636363744735718,0.7272727489471436,0.75,0.2471235123547641
100,,,,,,mmlu:college_mathematics,test,100.18278524279594,mistral_7b,oe,oe,0.14999999105930328,0.4899999797344208,0.4725490196078431,0.3966337651014327
22,,,,,,mmlu:college_medicine,validation,23.038590900599957,mistral_7b,oe,oe,0.5,0.6363636255264282,0.6611570247933884,0.22333512793887744
173,,,,,,mmlu:college_medicine,test,170.9598313830793,mistral_7b,oe,oe,0.38728323578834534,0.47398841381073,0.5272458462404956,0.2970481711315971
11,,,,,,mmlu:college_physics,validation,12.311533588916063,mistral_7b,oe,oe,0.4545454680919647,0.5454545617103577,0.2833333333333333,0.3601476170799949
102,,,,,,mmlu:college_physics,test,103.47580451890826,mistral_7b,oe,oe,0.20588235557079315,0.5882353186607361,0.5817166372721928,0.18981132787816662
11,,,,,,mmlu:computer_security,validation,12.037906967103481,mistral_7b,oe,oe,0.6363636255264282,0.4545454680919647,0.14285714285714285,0.28034782409667974
100,,,,,,mmlu:computer_security,test,96.3787750005722,mistral_7b,oe,oe,0.5299999713897705,0.5,0.4112806101967081,0.2779147958755493
26,,,,,,mmlu:conceptual_physics,validation,26.070174004882574,mistral_7b,oe,oe,0.3461538553237915,0.3461538553237915,0.30065359477124187,0.4349110814241263
235,,,,,,mmlu:conceptual_physics,test,217.944219853729,mistral_7b,oe,oe,0.4893616735935211,0.4723404049873352,0.5202173913043477,0.25824163416598706
12,,,,,,mmlu:econometrics,validation,12.96487820520997,mistral_7b,oe,oe,0.3333333432674408,0.4166666865348816,0.875,0.3239450405041377
114,,,,,,mmlu:econometrics,test,113.8966608159244,mistral_7b,oe,oe,0.21052631735801697,0.44736841320991516,0.3856481481481482,0.30862439672152203
16,,,,,,mmlu:electrical_engineering,validation,16.26048317179084,mistral_7b,oe,oe,0.1875,0.4375,0.6025641025641025,0.42340966686606407
145,,,,,,mmlu:electrical_engineering,test,139.56165097281337,mistral_7b,oe,oe,0.2344827651977539,0.48275861144065857,0.46250662427133016,0.27543685682888686
41,,,,,,mmlu:elementary_mathematics,validation,40.92684165760875,mistral_7b,oe,oe,0.4390243887901306,0.6341463327407837,0.3115942028985508,0.23579949722057442
378,,,,,,mmlu:elementary_mathematics,test,368.5663407407701,mistral_7b,oe,oe,0.46296295523643494,0.5317460298538208,0.5476284306826178,0.2738905140647182
14,,,,,,mmlu:formal_logic,validation,15.139768041670322,mistral_7b,oe,oe,0.1428571492433548,0.5714285969734192,0.625,0.2699210388319834
126,,,,,,mmlu:formal_logic,test,121.20449435710907,mistral_7b,oe,oe,0.2857142984867096,0.5396825671195984,0.5344135802469135,0.17440612164754718
10,,,,,,mmlu:global_facts,validation,12.6251630038023,mistral_7b,oe,oe,0.20000000298023224,0.5,0.375,0.3119428515434266
100,,,,,,mmlu:global_facts,test,94.61895695701241,mistral_7b,oe,oe,0.2199999988079071,0.6599999666213989,0.47435897435897434,0.086875319480896
32,,,,,,mmlu:high_school_biology,validation,30.93580338358879,mistral_7b,oe,oe,0.375,0.53125,0.46249999999999997,0.23849068768322468
310,,,,,,mmlu:high_school_biology,test,295.4409100972116,mistral_7b,oe,oe,0.4677419364452362,0.46451613306999207,0.5254336468129571,0.33317657286120994
22,,,,,,mmlu:high_school_chemistry,validation,23.194750644266605,mistral_7b,oe,oe,0.09090909361839294,0.5454545617103577,0.475,0.23963009769266308
203,,,,,,mmlu:high_school_chemistry,test,192.30744183063507,mistral_7b,oe,oe,0.16748768091201782,0.5862069129943848,0.5497737556561086,0.15383557762418473
9,,,,,,mmlu:high_school_computer_science,validation,12.366090591996908,mistral_7b,oe,oe,0.5555555820465088,0.5555555820465088,0.85,0.3180188337961833
100,,,,,,mmlu:high_school_computer_science,test,99.39653219282627,mistral_7b,oe,oe,0.5299999713897705,0.5199999809265137,0.5535929345644319,0.271922562122345
22,,,,,,mmlu:high_school_geography,validation,23.27691814303398,mistral_7b,oe,oe,0.3636363744735718,0.4545454680919647,0.4732142857142857,0.3110015013001182
198,,,,,,mmlu:high_school_geography,test,188.94833074510098,mistral_7b,oe,oe,0.4141414165496826,0.5151515007019043,0.47907905803195966,0.2674158883817268
21,,,,,,mmlu:high_school_government_and_politics,validation,23.830151431262493,mistral_7b,oe,oe,0.4761904776096344,0.3333333432674408,0.38636363636363635,0.4585538733573186
193,,,,,,mmlu:high_school_government_and_politics,test,346.9754375182092,mistral_7b,oe,oe,0.5233160257339478,0.5181347131729126,0.4345135600516573,0.25461378678139013
43,,,,,,mmlu:high_school_macroeconomics,validation,40.52664814889431,mistral_7b,oe,oe,0.41860464215278625,0.5813953280448914,0.5022222222222222,0.15980660915374756
390,,,,,,mmlu:high_school_macroeconomics,test,361.14383697137237,mistral_7b,oe,oe,0.3692307770252228,0.535897433757782,0.4124181345980127,0.23091638516157098
29,,,,,,mmlu:high_school_mathematics,validation,31.147209390997887,mistral_7b,oe,oe,0.06896551698446274,0.6206896305084229,0.7407407407407407,0.17491878517742818
270,,,,,,mmlu:high_school_mathematics,test,267.2948146611452,mistral_7b,oe,oe,0.13333332538604736,0.7518518567085266,0.39607075023741695,0.09004079368379383
26,,,,,,mmlu:high_school_microeconomics,validation,26.089671969413757,mistral_7b,oe,oe,0.38461539149284363,0.38461539149284363,0.528125,0.3946902568523701
238,,,,,,mmlu:high_school_microeconomics,test,219.11264961957932,mistral_7b,oe,oe,0.3907563090324402,0.47478994727134705,0.47634408602150535,0.3035349713153198
17,,,,,,mmlu:high_school_physics,validation,17.5917933806777,mistral_7b,oe,oe,0.11764705926179886,0.7058823704719543,0.6333333333333333,0.1992030108676237
151,,,,,,mmlu:high_school_physics,test,151.91841204091907,mistral_7b,oe,oe,0.20529800653457642,0.503311276435852,0.5076612903225806,0.2554472266443518
60,,,,,,mmlu:high_school_psychology,validation,55.934734005481005,mistral_7b,oe,oe,0.6333333849906921,0.5833333730697632,0.5251196172248804,0.21804838478565214
545,,,,,,mmlu:high_school_psychology,test,529.9637322835624,mistral_7b,oe,oe,0.5559632778167725,0.5816513895988464,0.5451136022693179,0.217945108719922
23,,,,,,mmlu:high_school_statistics,validation,22.52878126129508,mistral_7b,oe,oe,0.21739131212234497,0.52173912525177,0.48888888888888893,0.3125765349553979
216,,,,,,mmlu:high_school_statistics,test,215.8125259168446,mistral_7b,oe,oe,0.3333333432674408,0.472222238779068,0.539014274691358,0.2864838010734982
22,,,,,,mmlu:high_school_us_history,validation,41.660255178809166,mistral_7b,oe,oe,0.5909091234207153,0.7272727489471436,0.4615384615384616,0.1033749742941423
204,,,,,,mmlu:high_school_us_history,test,372.8882096707821,mistral_7b,oe,oe,0.6421568989753723,0.5882353186607361,0.3891561225556834,0.176474397965506
23,,,,,,mmlu:human_aging,validation,22.43580510467291,mistral_7b,oe,oe,0.3478260934352875,0.43478262424468994,0.39166666666666666,0.36363659216010047
223,,,,,,mmlu:human_aging,test,209.36402985453606,mistral_7b,oe,oe,0.37219732999801636,0.5874439477920532,0.5330034423407918,0.20575033709607315
12,,,,,,mmlu:human_sexuality,validation,11.089352428913116,mistral_7b,oe,oe,0.25,0.1666666716337204,0.4444444444444444,0.610148121913274
131,,,,,,mmlu:human_sexuality,test,121.22866861149669,mistral_7b,oe,oe,0.48091602325439453,0.5496183037757874,0.5777310924369748,0.23428414750645182
13,,,,,,mmlu:international_law,validation,14.072559159249067,mistral_7b,oe,oe,0.5384615659713745,0.6153846383094788,0.47619047619047616,0.3155009609002334
121,,,,,,mmlu:international_law,test,117.76374102756381,mistral_7b,oe,oe,0.6033057570457458,0.4710743725299835,0.5423801369863014,0.34196545565423886
11,,,,,,mmlu:jurisprudence,validation,11.52397309616208,mistral_7b,oe,oe,0.3636363744735718,0.3636363744735718,0.39285714285714285,0.535876826806502
108,,,,,,mmlu:jurisprudence,test,96.16591018438339,mistral_7b,oe,oe,0.48148149251937866,0.5092592835426331,0.6215659340659341,0.30370414643375965
18,,,,,,mmlu:logical_fallacies,validation,19.52979326993227,mistral_7b,oe,oe,0.4444444477558136,0.3888888955116272,0.7625,0.4543573392762078
163,,,,,,mmlu:logical_fallacies,test,155.9896959066391,mistral_7b,oe,oe,0.48466256260871887,0.4907975196838379,0.5076853526220615,0.35290912470203234
11,,,,,,mmlu:machine_learning,validation,10.94214003905654,mistral_7b,oe,oe,0.5454545617103577,0.7272727489471436,0.3,0.16153773394497958
112,,,,,,mmlu:machine_learning,test,112.74784215167165,mistral_7b,oe,oe,0.2589285969734192,0.4196428656578064,0.49833818030743665,0.3334000020154884
11,,,,,,mmlu:management,validation,10.93380268290639,mistral_7b,oe,oe,0.7272727489471436,0.8181818723678589,0.5833333333333334,0.14797573739832098
103,,,,,,mmlu:management,test,100.69905819371343,mistral_7b,oe,oe,0.3689320385456085,0.5242718458175659,0.6038461538461538,0.2136288840793869
25,,,,,,mmlu:marketing,validation,48.976969324052334,mistral_7b,oe,oe,0.3199999928474426,0.4399999976158142,0.5220588235294118,0.3868138933181763
234,,,,,,mmlu:marketing,test,222.86502193659544,mistral_7b,oe,oe,0.504273533821106,0.5470085740089417,0.5493863237872589,0.2633988722267314
11,,,,,,mmlu:medical_genetics,validation,11.306071557104588,mistral_7b,oe,oe,0.7272727489471436,0.5454545617103577,0.45833333333333337,0.19657614556225864
100,,,,,,mmlu:medical_genetics,test,92.28892685472965,mistral_7b,oe,oe,0.550000011920929,0.6100000143051147,0.588080808080808,0.1943016988039017
38,,,,,,mmlu:moral_disputes,validation,35.88934962823987,mistral_7b,oe,oe,0.42105263471603394,0.3947368562221527,0.40340909090909094,0.4002924530129684
346,,,,,,mmlu:moral_disputes,test,332.1096669435501,mistral_7b,oe,oe,0.43063583970069885,0.4595375657081604,0.536231390317855,0.30871973389145957
33,,,,,,mmlu:nutrition,validation,33.90278333052993,mistral_7b,oe,oe,0.39393940567970276,0.4848484992980957,0.6711538461538462,0.26723290934707183
306,,,,,,mmlu:nutrition,test,303.7819367721677,mistral_7b,oe,oe,0.43790850043296814,0.4803921580314636,0.47574626865671643,0.3085918570655623
34,,,,,,mmlu:philosophy,validation,32.225557308644056,mistral_7b,oe,oe,0.3235294222831726,0.47058823704719543,0.466403162055336,0.42283484164406276
311,,,,,,mmlu:philosophy,test,364.86770236864686,mistral_7b,oe,oe,0.34726688265800476,0.3633440434932709,0.476829045794563,0.4356296737094401
35,,,,,,mmlu:prehistory,validation,35.99172876775265,mistral_7b,oe,oe,0.37142857909202576,0.37142857909202576,0.46503496503496505,0.4729251895632063
324,,,,,,mmlu:prehistory,test,329.64431047439575,mistral_7b,oe,oe,0.45679011940956116,0.4506172835826874,0.5462607493857494,0.34101103742917377
69,,,,,,mmlu:professional_psychology,validation,68.85519420355558,mistral_7b,oe,oe,0.4057971239089966,0.5362318754196167,0.5618466898954704,0.29754377275273425
612,,,,,,mmlu:professional_psychology,test,597.0562092512846,mistral_7b,oe,oe,0.37745097279548645,0.4444444477558136,0.5220142936678369,0.3129698253340191
12,,,,,,mmlu:public_relations,validation,10.69682278111577,mistral_7b,oe,oe,0.3333333432674408,0.5,0.71875,0.29390750825405126
110,,,,,,mmlu:public_relations,test,107.00777397304773,mistral_7b,oe,oe,0.2818181812763214,0.3636363446712494,0.5334830543078808,0.4529885042797436
27,,,,,,mmlu:security_studies,validation,26.79518911987543,mistral_7b,oe,oe,0.5555555820465088,0.5555555820465088,0.6166666666666667,0.3179363939497206
245,,,,,,mmlu:security_studies,test,240.11906020343304,mistral_7b,oe,oe,0.5346938371658325,0.5673469305038452,0.5654881478505424,0.2630727055121441
22,,,,,,mmlu:sociology,validation,24.51074370369315,mistral_7b,oe,oe,0.5,0.40909093618392944,0.5454545454545454,0.42540267380801117
201,,,,,,mmlu:sociology,test,195.94043607264757,mistral_7b,oe,oe,0.42288556694984436,0.4726368188858032,0.45613590263691683,0.34027728601474666
11,,,,,,mmlu:us_foreign_policy,validation,10.442611958831549,mistral_7b,oe,oe,0.5454545617103577,0.9090909361839294,0.5666666666666667,0.30135225165974006
100,,,,,,mmlu:us_foreign_policy,test,93.17607166618109,mistral_7b,oe,oe,0.5999999642372131,0.5999999642372131,0.49312500000000004,0.2254997944831848
18,,,,,,mmlu:virology,validation,18.494358241558075,mistral_7b,oe,oe,0.4444444477558136,0.4444444477558136,0.42499999999999993,0.42338021596272785
166,,,,,,mmlu:virology,test,161.5699764713645,mistral_7b,oe,oe,0.3614457845687866,0.4337349236011505,0.4827044025157232,0.3535478484917836
19,,,,,,mmlu:world_religions,validation,18.050634525716305,mistral_7b,oe,oe,0.7368420958518982,0.7894737124443054,0.6857142857142856,0.20773033405605112
171,,,,,,mmlu:world_religions,test,157.35365883260965,mistral_7b,oe,oe,0.6900584697723389,0.6783626079559326,0.5842660697153821,0.1352488893514488
11,,,,,,mmlu:abstract_algebra,validation,19.44934720546007,llama2_7b_chat,choice,oe,0.5454545617103577,0.4545454680919647,,0.09631143013636267
100,,,,,,mmlu:abstract_algebra,test,132.58361279591918,llama2_7b_chat,choice,oe,0.35999998450279236,0.5699999928474426,,0.19718989610671994
14,,,,,,mmlu:anatomy,validation,19.297642294317484,llama2_7b_chat,choice,oe,0.5714285969734192,0.2857142984867096,,0.5596788674592972
135,,,,,,mmlu:anatomy,test,170.38591765984893,llama2_7b_chat,choice,oe,0.5703703761100769,0.39259257912635803,,0.3308291367122105
16,,,,,,mmlu:astronomy,validation,21.822700314223766,llama2_7b_chat,choice,oe,0.625,0.4375,,0.2673292160034179
152,,,,,,mmlu:astronomy,test,206.36654743924737,llama2_7b_chat,choice,oe,0.4868420958518982,0.5460526347160339,,0.13518058626275317
11,,,,,,mmlu:business_ethics,validation,17.07221656292677,llama2_7b_chat,choice,oe,0.3636363744735718,0.7272727489471436,,0.4177675445874532
100,,,,,,mmlu:business_ethics,test,148.1958750039339,llama2_7b_chat,choice,oe,0.3199999928474426,0.5699999928474426,,0.44586755514144893
29,,,,,,mmlu:clinical_knowledge,validation,38.80470336228609,llama2_7b_chat,choice,oe,0.10344827175140381,0.6206896305084229,,0.8124140650033951
265,,,,,,mmlu:clinical_knowledge,test,362.8972393088043,llama2_7b_chat,choice,oe,0.33207547664642334,0.5773584842681885,,0.46504099778274993
16,,,,,,mmlu:college_biology,validation,21.889510665088892,llama2_7b_chat,choice,oe,0.75,0.25,,0.47815993428230286
144,,,,,,mmlu:college_biology,test,197.6551101654768,llama2_7b_chat,choice,oe,0.4791666567325592,0.4027777910232544,,0.5312085102001827
8,,,,,,mmlu:college_chemistry,validation,11.682152725756168,llama2_7b_chat,choice,oe,0.125,0.625,,0.8558482527732849
100,,,,,,mmlu:college_chemistry,test,144.99835432320833,llama2_7b_chat,choice,oe,0.26999998092651367,0.5399999618530273,,0.5297271242508521
11,,,,,,mmlu:college_computer_science,validation,21.131785061210394,llama2_7b_chat,choice,oe,0.27272728085517883,0.4545454680919647,,0.7134952147801716
100,,,,,,mmlu:college_computer_science,test,187.53224407881498,llama2_7b_chat,choice,oe,0.2199999988079071,0.6299999952316284,,0.5531083154678345
11,,,,,,mmlu:college_mathematics,validation,18.404965542256832,llama2_7b_chat,choice,oe,0.1818181872367859,0.6363636255264282,,0.2506450812021891
100,,,,,,mmlu:college_mathematics,test,159.0090576298535,llama2_7b_chat,choice,oe,0.1899999976158142,0.6599999666213989,,0.5220876336097717
22,,,,,,mmlu:college_medicine,validation,32.620443765074015,llama2_7b_chat,choice,oe,0.4545454680919647,0.40909093618392944,,0.5723747866494316
173,,,,,,mmlu:college_medicine,test,379.68941140174866,llama2_7b_chat,choice,oe,0.41040462255477905,0.4566473960876465,,0.3811756207392766
11,,,,,,mmlu:college_physics,validation,18.28165850788355,llama2_7b_chat,choice,oe,0.27272728085517883,0.5454545617103577,,0.371979554494222
102,,,,,,mmlu:college_physics,test,152.16230045259,llama2_7b_chat,choice,oe,0.2450980544090271,0.5980392098426819,,0.42802838178781366
11,,,,,,mmlu:computer_security,validation,13.532020423561335,llama2_7b_chat,choice,oe,0.6363636255264282,0.5454545617103577,,0.27286714315414434
100,,,,,,mmlu:computer_security,test,126.24260918423533,llama2_7b_chat,choice,oe,0.5600000023841858,0.41999998688697815,,0.3273842803069523
26,,,,,,mmlu:conceptual_physics,validation,34.87832685559988,llama2_7b_chat,choice,oe,0.6153846383094788,0.3076923191547394,,0.6114191157477243
235,,,,,,mmlu:conceptual_physics,test,296.4164646193385,llama2_7b_chat,choice,oe,0.6595744490623474,0.2595744729042053,,0.3797703193405928
12,,,,,,mmlu:econometrics,validation,19.712030697613955,llama2_7b_chat,choice,oe,0.3333333432674408,0.5833333730697632,,0.15226119756698608
114,,,,,,mmlu:econometrics,test,175.61720908805728,llama2_7b_chat,choice,oe,0.28070175647735596,0.5789473652839661,,0.2255573428812481
16,,,,,,mmlu:electrical_engineering,validation,22.171107925474644,llama2_7b_chat,choice,oe,0.5,0.4375,,0.2658950239419937
145,,,,,,mmlu:electrical_engineering,test,199.2422310784459,llama2_7b_chat,choice,oe,0.48275861144065857,0.3931034505367279,,0.3694915545953287
41,,,,,,mmlu:elementary_mathematics,validation,57.44514153897762,llama2_7b_chat,choice,oe,0.46341460943222046,0.5121951103210449,,0.38899578289552167
378,,,,,,mmlu:elementary_mathematics,test,543.5949411317706,llama2_7b_chat,choice,oe,0.40740740299224854,0.5052909851074219,,0.3473992402456245
14,,,,,,mmlu:formal_logic,validation,22.606228202581406,llama2_7b_chat,choice,oe,0.4285714626312256,0.5714285969734192,,0.5532270967960358
126,,,,,,mmlu:formal_logic,test,184.0338410809636,llama2_7b_chat,choice,oe,0.3888889253139496,0.3888889253139496,,0.49610187491374225
10,,,,,,mmlu:global_facts,validation,15.306957498192787,llama2_7b_chat,choice,oe,0.20000000298023224,0.6000000238418579,,0.6009925802548726
100,,,,,,mmlu:global_facts,test,133.49347814172506,llama2_7b_chat,choice,oe,0.17000000178813934,0.6699999570846558,,0.48519483667153585
32,,,,,,mmlu:high_school_biology,validation,43.48511395230889,llama2_7b_chat,choice,oe,0.40625,0.59375,,0.45429207384586334
310,,,,,,mmlu:high_school_biology,test,428.73453878983855,llama2_7b_chat,choice,oe,0.5354838371276855,0.4516128897666931,,0.33433008264927633
22,,,,,,mmlu:high_school_chemistry,validation,34.56087813898921,llama2_7b_chat,choice,oe,0.4545454680919647,0.27272728085517883,,0.7197905977567036
203,,,,,,mmlu:high_school_chemistry,test,292.7156223170459,llama2_7b_chat,choice,oe,0.4088670015335083,0.43842363357543945,,0.4260178826473378
9,,,,,,mmlu:high_school_computer_science,validation,14.466720934957266,llama2_7b_chat,choice,oe,0.6666666865348816,0.4444444477558136,,0.4324607029557228
100,,,,,,mmlu:high_school_computer_science,test,170.26503330469131,llama2_7b_chat,choice,oe,0.4699999988079071,0.47999998927116394,,0.3082701365152995
22,,,,,,mmlu:high_school_geography,validation,30.04764685407281,llama2_7b_chat,choice,oe,0.6818181872367859,0.3181818127632141,,0.31470944484074914
198,,,,,,mmlu:high_school_geography,test,253.8802659586072,llama2_7b_chat,choice,oe,0.6464646458625793,0.2929292917251587,,0.4553598574563569
21,,,,,,mmlu:high_school_government_and_politics,validation,29.977986697107553,llama2_7b_chat,choice,oe,0.6666666865348816,0.3333333432674408,,0.3673718372980754
193,,,,,,mmlu:high_school_government_and_politics,test,250.1733596213162,llama2_7b_chat,choice,oe,0.782383382320404,0.23834195733070374,,0.2860870969538786
43,,,,,,mmlu:high_school_macroeconomics,validation,55.55216931551695,llama2_7b_chat,choice,oe,0.6279069781303406,0.302325576543808,,0.369276296008717
390,,,,,,mmlu:high_school_macroeconomics,test,495.42338889837265,llama2_7b_chat,choice,oe,0.5948718190193176,0.3282051384449005,,0.373196406023843
29,,,,,,mmlu:high_school_mathematics,validation,43.01940921321511,llama2_7b_chat,choice,oe,0.13793103396892548,0.6551724076271057,,0.4397183358669281
270,,,,,,mmlu:high_school_mathematics,test,406.8685401342809,llama2_7b_chat,choice,oe,0.1814814805984497,0.6777777671813965,,0.2937668307739146
26,,,,,,mmlu:high_school_microeconomics,validation,35.03491868823767,llama2_7b_chat,choice,oe,0.7307692766189575,0.23076924681663513,,0.41595988614218576
238,,,,,,mmlu:high_school_microeconomics,test,317.6165806800127,llama2_7b_chat,choice,oe,0.6386554837226868,0.28151261806488037,,0.32991176932605354
17,,,,,,mmlu:high_school_physics,validation,27.50843383744359,llama2_7b_chat,choice,oe,0.3529411852359772,0.47058823704719543,,0.37722961902618407
151,,,,,,mmlu:high_school_physics,test,222.74082912132144,llama2_7b_chat,choice,oe,0.42384105920791626,0.430463582277298,,0.3894946481052198
60,,,,,,mmlu:high_school_psychology,validation,85.20618966966867,llama2_7b_chat,choice,oe,0.6000000238418579,0.3500000238418579,,0.4064268906911215
545,,,,,,mmlu:high_school_psychology,test,755.8602034822106,llama2_7b_chat,choice,oe,0.642201840877533,0.33211010694503784,,0.3474432660000665
23,,,,,,mmlu:high_school_statistics,validation,38.48170059174299,llama2_7b_chat,choice,oe,0.43478262424468994,0.30434784293174744,,0.8096487919489542
216,,,,,,mmlu:high_school_statistics,test,355.4277857430279,llama2_7b_chat,choice,oe,0.4305555522441864,0.42592594027519226,,0.440950165011666
22,,,,,,mmlu:high_school_us_history,validation,91.60042016208172,llama2_7b_chat,choice,oe,0.6818181872367859,0.5,,0.22968455155690512
204,,,,,,mmlu:high_school_us_history,test,852.0957267805934,llama2_7b_chat,choice,oe,0.5147058963775635,0.5686274766921997,,0.22609922582027958
23,,,,,,mmlu:human_aging,validation,29.82728672772646,llama2_7b_chat,choice,oe,0.30434784293174744,0.43478262424468994,,0.8161960144837697
223,,,,,,mmlu:human_aging,test,283.1649925597012,llama2_7b_chat,choice,oe,0.44843050837516785,0.47533634305000305,,0.38311837507145746
12,,,,,,mmlu:human_sexuality,validation,15.19560868665576,llama2_7b_chat,choice,oe,0.4166666865348816,0.4166666865348816,,0.5926867127418518
131,,,,,,mmlu:human_sexuality,test,177.49065037816763,llama2_7b_chat,choice,oe,0.6259542107582092,0.3664122223854065,,0.20543191400734157
13,,,,,,mmlu:international_law,validation,162.75568943098187,llama2_7b_chat,choice,oe,0.5384615659713745,0.46153849363327026,,0.43453504145145416
121,,,,,,mmlu:international_law,test,165.86134680360556,llama2_7b_chat,choice,oe,0.6859503984451294,0.44628098607063293,,0.2243045147727518
11,,,,,,mmlu:jurisprudence,validation,15.324706744402647,llama2_7b_chat,choice,oe,0.6363636255264282,0.27272728085517883,,0.561942438284556
108,,,,,,mmlu:jurisprudence,test,140.97549252957106,llama2_7b_chat,choice,oe,0.6296296119689941,0.3055555522441864,,0.48654967325705073
18,,,,,,mmlu:logical_fallacies,validation,26.97610865905881,llama2_7b_chat,choice,oe,0.3888888955116272,0.3333333432674408,,0.7855209350585938
163,,,,,,mmlu:logical_fallacies,test,221.5180698260665,llama2_7b_chat,choice,oe,0.5705521106719971,0.38650307059288025,,0.2249772720866733
11,,,,,,mmlu:machine_learning,validation,17.561157997697592,llama2_7b_chat,choice,oe,0.5454545617103577,0.5454545617103577,,0.31050407886505127
112,,,,,,mmlu:machine_learning,test,170.97154369950294,llama2_7b_chat,choice,oe,0.392857164144516,0.4732142984867096,,0.5279406607151031
11,,,,,,mmlu:management,validation,14.676368176937103,llama2_7b_chat,choice,oe,0.5454545617103577,0.1818181872367859,,0.7944749395052592
103,,,,,,mmlu:management,test,149.02846667915583,llama2_7b_chat,choice,oe,0.4563106894493103,0.4660194218158722,,0.33690924140123224
25,,,,,,mmlu:marketing,validation,32.954147934913635,llama2_7b_chat,choice,oe,0.3999999761581421,0.3199999928474426,,0.8310735651424955
234,,,,,,mmlu:marketing,test,307.84317426383495,llama2_7b_chat,choice,oe,0.576923131942749,0.34188035130500793,,0.4487265994993307
11,,,,,,mmlu:medical_genetics,validation,14.636524107307196,llama2_7b_chat,choice,oe,0.7272727489471436,0.4545454680919647,,0.3224321206410726
100,,,,,,mmlu:medical_genetics,test,124.00311177223921,llama2_7b_chat,choice,oe,0.5699999928474426,0.3499999940395355,,0.4543549418449402
38,,,,,,mmlu:moral_disputes,validation,53.546546801924706,llama2_7b_chat,choice,oe,0.8157894611358643,0.2368421107530594,,0.2701458215713501
346,,,,,,mmlu:moral_disputes,test,474.88511050119996,llama2_7b_chat,choice,oe,0.7658959627151489,0.2398843914270401,,0.28107507475491234
33,,,,,,mmlu:nutrition,validation,46.53718750551343,llama2_7b_chat,choice,oe,0.6060606241226196,0.3030303120613098,,0.4717215630743239
306,,,,,,mmlu:nutrition,test,433.68609731271863,llama2_7b_chat,choice,oe,0.5490196347236633,0.42810457944869995,,0.2765093337405812
34,,,,,,mmlu:philosophy,validation,45.37559322267771,llama2_7b_chat,choice,oe,0.5882353186607361,0.23529411852359772,,0.5534549554189045
311,,,,,,mmlu:philosophy,test,397.2656910903752,llama2_7b_chat,choice,oe,0.6173633337020874,0.3118970990180969,,0.3545388463066846
35,,,,,,mmlu:prehistory,validation,47.40470866113901,llama2_7b_chat,choice,oe,0.5142857432365417,0.2857142984867096,,0.7014621429973178
324,,,,,,mmlu:prehistory,test,429.6328545436263,llama2_7b_chat,choice,oe,0.5802469253540039,0.34876543283462524,,0.431280114032604
69,,,,,,mmlu:professional_psychology,validation,100.20526715740561,llama2_7b_chat,choice,oe,0.5072463750839233,0.49275362491607666,,0.22519645094871524
612,,,,,,mmlu:professional_psychology,test,875.8577130883932,llama2_7b_chat,choice,oe,0.48856210708618164,0.4526143968105316,,0.3000762179875986
12,,,,,,mmlu:public_relations,validation,15.924020130187273,llama2_7b_chat,choice,oe,0.25,0.6666666865348816,,0.3451804399490357
110,,,,,,mmlu:public_relations,test,146.89438338205218,llama2_7b_chat,choice,oe,0.3181818127632141,0.6454545259475708,,0.41023748616377514
27,,,,,,mmlu:security_studies,validation,40.64307354390621,llama2_7b_chat,choice,oe,0.6296296119689941,0.48148149251937866,,0.2876410569463458
245,,,,,,mmlu:security_studies,test,367.1972036883235,llama2_7b_chat,choice,oe,0.6653060913085938,0.4734693765640259,,0.17507567481389116
22,,,,,,mmlu:sociology,validation,30.230191830545664,llama2_7b_chat,choice,oe,0.8181818723678589,0.09090909361839294,,0.6032206018765767
201,,,,,,mmlu:sociology,test,259.6442296542227,llama2_7b_chat,choice,oe,0.6616915464401245,0.2636815905570984,,0.5219849733745351
11,,,,,,mmlu:us_foreign_policy,validation,15.240826196968555,llama2_7b_chat,choice,oe,0.4545454680919647,0.4545454680919647,,0.3304446538289388
100,,,,,,mmlu:us_foreign_policy,test,127.82948550954461,llama2_7b_chat,choice,oe,0.550000011920929,0.44999998807907104,,0.3548749995231628
18,,,,,,mmlu:virology,validation,23.480435252189636,llama2_7b_chat,choice,oe,0.2222222238779068,0.5,,0.543914247642864
166,,,,,,mmlu:virology,test,337.70650631561875,llama2_7b_chat,choice,oe,0.4518072009086609,0.46385541558265686,,0.48205957660135235
19,,,,,,mmlu:world_religions,validation,24.336567103862762,llama2_7b_chat,choice,oe,0.6842105388641357,0.31578946113586426,,0.5267180800437927
171,,,,,,mmlu:world_religions,test,211.7350855767727,llama2_7b_chat,choice,oe,0.4912280738353729,0.5087719559669495,,0.23141624483951306
11,,,,,,mmlu:abstract_algebra,validation,7.866029966622591,llama2_7b_chat,oe,oe,0.3636363744735718,0.3636363744735718,0.9285714285714286,0.421921811320565
100,,,,,,mmlu:abstract_algebra,test,45.39871210232377,llama2_7b_chat,oe,oe,0.2800000011920929,0.5799999833106995,0.4851190476190476,0.12496620297431946
14,,,,,,mmlu:anatomy,validation,8.941375974565744,llama2_7b_chat,oe,oe,0.2142857313156128,0.5,0.3636363636363636,0.27584583844457355
135,,,,,,mmlu:anatomy,test,77.44427971169353,llama2_7b_chat,oe,oe,0.4000000059604645,0.6074073910713196,0.3933470507544582,0.19245823489295114
16,,,,,,mmlu:astronomy,validation,16.4664173014462,llama2_7b_chat,oe,oe,0.375,0.5,0.55,0.25378382205963135
152,,,,,,mmlu:astronomy,test,135.7819960154593,llama2_7b_chat,oe,oe,0.44078949093818665,0.5789473652839661,0.5154521510096577,0.11869045739111149
11,,,,,,mmlu:business_ethics,validation,8.37769453972578,llama2_7b_chat,oe,oe,0.3636363744735718,0.4545454680919647,0.6785714285714286,0.42114774747328326
100,,,,,,mmlu:business_ethics,test,67.38060178235173,llama2_7b_chat,oe,oe,0.29999998211860657,0.35999998450279236,0.5442857142857143,0.38701502859592435
29,,,,,,mmlu:clinical_knowledge,validation,19.290024496614933,llama2_7b_chat,oe,oe,0.10344827175140381,0.8275861740112305,0.37179487179487175,0.0907209371698314
265,,,,,,mmlu:clinical_knowledge,test,175.31359734758735,llama2_7b_chat,oe,oe,0.24150943756103516,0.7207547426223755,0.40625,0.11446369976367587
16,,,,,,mmlu:college_biology,validation,10.226805362850428,llama2_7b_chat,oe,oe,0.375,0.75,0.08333333333333333,0.11907791346311569
144,,,,,,mmlu:college_biology,test,87.04063979163766,llama2_7b_chat,oe,oe,0.3402777910232544,0.6388888955116272,0.4576799140708915,0.12755642500188616
8,,,,,,mmlu:college_chemistry,validation,4.01385984569788,llama2_7b_chat,oe,oe,0.0,0.875,,0.21383316814899447
100,,,,,,mmlu:college_chemistry,test,67.3754082582891,llama2_7b_chat,oe,oe,0.09999999403953552,0.8299999833106995,0.31,0.05464035868644715
11,,,,,,mmlu:college_computer_science,validation,8.597026616334915,llama2_7b_chat,oe,oe,0.1818181872367859,0.6363636255264282,0.4444444444444444,0.3827673684466969
100,,,,,,mmlu:college_computer_science,test,74.26674786955118,llama2_7b_chat,oe,oe,0.17999999225139618,0.7199999690055847,0.4407181571815718,0.11434253096580502
11,,,,,,mmlu:college_mathematics,validation,8.141646694391966,llama2_7b_chat,oe,oe,0.0,1.0,,0.11521525274623524
100,,,,,,mmlu:college_mathematics,test,88.37680652365088,llama2_7b_chat,oe,oe,0.22999998927116394,0.7599999904632568,0.4364765669113495,0.1319970047473908
22,,,,,,mmlu:college_medicine,validation,15.11402279138565,llama2_7b_chat,oe,oe,0.3636363744735718,0.5909091234207153,0.4017857142857143,0.22283096205104483
173,,,,,,mmlu:college_medicine,test,112.3126991391182,llama2_7b_chat,oe,oe,0.3179190754890442,0.676300585269928,0.40747303543913715,0.11938476493592895
11,,,,,,mmlu:college_physics,validation,8.74735440313816,llama2_7b_chat,oe,oe,0.09090909361839294,0.8181818723678589,0.30000000000000004,0.22249110178513962
102,,,,,,mmlu:college_physics,test,67.5857135169208,llama2_7b_chat,oe,oe,0.09803921729326248,0.8627451062202454,0.33260869565217394,0.0827804675289229
11,,,,,,mmlu:computer_security,validation,10.52055149525404,llama2_7b_chat,oe,oe,0.6363636255264282,0.6363636255264282,0.75,0.3200741464441473
100,,,,,,mmlu:computer_security,test,77.2351844124496,llama2_7b_chat,oe,oe,0.5299999713897705,0.5099999904632568,0.5052187876354877,0.22791527092456823
26,,,,,,mmlu:conceptual_physics,validation,28.371529579162598,llama2_7b_chat,oe,oe,0.3461538553237915,0.5769230723381042,0.607843137254902,0.18559390535721412
235,,,,,,mmlu:conceptual_physics,test,219.22991003468633,llama2_7b_chat,oe,oe,0.3787233829498291,0.6680850982666016,0.3762505771894721,0.10291763594809997
12,,,,,,mmlu:econometrics,validation,10.406555265188217,llama2_7b_chat,oe,oe,0.25,0.4166666865348816,0.6296296296296295,0.2817612489064535
114,,,,,,mmlu:econometrics,test,110.01714222878218,llama2_7b_chat,oe,oe,0.12280701845884323,0.5701754689216614,0.5342857142857144,0.17463480537397819
16,,,,,,mmlu:electrical_engineering,validation,8.157105583697557,llama2_7b_chat,oe,oe,0.1875,0.6875,0.3333333333333333,0.2027066834270954
145,,,,,,mmlu:electrical_engineering,test,84.8885630145669,llama2_7b_chat,oe,oe,0.22068965435028076,0.7172414064407349,0.40376106194690264,0.13227105880605763
41,,,,,,mmlu:elementary_mathematics,validation,21.839824218302965,llama2_7b_chat,oe,oe,0.39024388790130615,0.5609756112098694,0.36,0.25925939984437896
378,,,,,,mmlu:elementary_mathematics,test,398.71866792440414,llama2_7b_chat,oe,oe,0.29894179105758667,0.6693121194839478,0.4039572549674403,0.14293386286528648
14,,,,,,mmlu:formal_logic,validation,13.1988006234169,llama2_7b_chat,oe,oe,0.3571428656578064,0.5714285969734192,0.4555555555555556,0.19186111858912877
126,,,,,,mmlu:formal_logic,test,101.9787154942751,llama2_7b_chat,oe,oe,0.2539682686328888,0.7698413133621216,0.28873005319148937,0.0708419576523796
10,,,,,,mmlu:global_facts,validation,8.222170185297728,llama2_7b_chat,oe,oe,0.10000000149011612,0.699999988079071,0.4444444444444444,0.2121438503265381
100,,,,,,mmlu:global_facts,test,86.4417793340981,llama2_7b_chat,oe,oe,0.09999999403953552,0.7400000095367432,0.6061111111111112,0.05397179186344145
32,,,,,,mmlu:high_school_biology,validation,23.719948574900627,llama2_7b_chat,oe,oe,0.3125,0.59375,0.3090909090909091,0.22077901102602482
310,,,,,,mmlu:high_school_biology,test,249.83685706555843,llama2_7b_chat,oe,oe,0.3677419424057007,0.5774193406105042,0.41377998567848184,0.16210814637522544
22,,,,,,mmlu:high_school_chemistry,validation,16.090750828385353,llama2_7b_chat,oe,oe,0.04545454680919647,0.7727273106575012,0.6666666666666667,0.1594912030480125
203,,,,,,mmlu:high_school_chemistry,test,138.8466571830213,llama2_7b_chat,oe,oe,0.17733989655971527,0.7142857313156128,0.3954590818363274,0.04588772275764955
9,,,,,,mmlu:high_school_computer_science,validation,10.091492008417845,llama2_7b_chat,oe,oe,0.4444444477558136,0.5555555820465088,0.2,0.2783245046933492
100,,,,,,mmlu:high_school_computer_science,test,101.36739833652973,llama2_7b_chat,oe,oe,0.429999977350235,0.5799999833106995,0.43268053855569155,0.19673413515090943
22,,,,,,mmlu:high_school_geography,validation,18.327594865113497,llama2_7b_chat,oe,oe,0.5,0.5,0.38842975206611574,0.2687094563787633
198,,,,,,mmlu:high_school_geography,test,162.51678056269884,llama2_7b_chat,oe,oe,0.3787878751754761,0.5757575631141663,0.4141463414634146,0.14218041722220603
21,,,,,,mmlu:high_school_government_and_politics,validation,23.67214698344469,llama2_7b_chat,oe,oe,0.523809552192688,0.4761904776096344,0.4818181818181818,0.3911308305604117
193,,,,,,mmlu:high_school_government_and_politics,test,182.803964946419,llama2_7b_chat,oe,oe,0.5077720284461975,0.5958548784255981,0.4180451127819549,0.17405383203931424
43,,,,,,mmlu:high_school_macroeconomics,validation,41.537911105901,llama2_7b_chat,oe,oe,0.3488371968269348,0.6511628031730652,0.5035714285714286,0.15687726264776186
390,,,,,,mmlu:high_school_macroeconomics,test,363.0501179434359,llama2_7b_chat,oe,oe,0.2794871926307678,0.6820513010025024,0.43937118417186327,0.09339822561312947
29,,,,,,mmlu:high_school_mathematics,validation,11.251568984240294,llama2_7b_chat,oe,oe,0.03448275849223137,0.8965517282485962,0.1428571428571429,0.14301959605052555
270,,,,,,mmlu:high_school_mathematics,test,112.8445727005601,llama2_7b_chat,oe,oe,0.0555555559694767,0.8888888955116272,0.5522875816993463,0.09948811310308954
26,,,,,,mmlu:high_school_microeconomics,validation,20.372094735503197,llama2_7b_chat,oe,oe,0.38461539149284363,0.5,0.5562499999999999,0.2648294980709369
238,,,,,,mmlu:high_school_microeconomics,test,183.40253948420286,llama2_7b_chat,oe,oe,0.3445378243923187,0.6344538331031799,0.4922607879924953,0.0925898727248697
17,,,,,,mmlu:high_school_physics,validation,12.047130793333054,llama2_7b_chat,oe,oe,0.0,0.8235294222831726,,0.15407781390582814
151,,,,,,mmlu:high_school_physics,test,99.47189895063639,llama2_7b_chat,oe,oe,0.17880794405937195,0.7748344540596008,0.42054958183990443,0.07221024557454696
60,,,,,,mmlu:high_school_psychology,validation,39.38763404637575,llama2_7b_chat,oe,oe,0.4833333492279053,0.5333333611488342,0.48387096774193544,0.24173061450322472
545,,,,,,mmlu:high_school_psychology,test,409.6679339557886,llama2_7b_chat,oe,oe,0.5009174346923828,0.48990824818611145,0.4520981469510882,0.23738484590425407
23,,,,,,mmlu:high_school_statistics,validation,14.575610812753439,llama2_7b_chat,oe,oe,0.17391304671764374,0.782608687877655,0.2236842105263158,0.21898082805716473
216,,,,,,mmlu:high_school_statistics,test,176.44658547639847,llama2_7b_chat,oe,oe,0.1805555522441864,0.8240740895271301,0.3364479211936839,0.055262522564993984
22,,,,,,mmlu:high_school_us_history,validation,35.46815614029765,llama2_7b_chat,oe,oe,0.7727273106575012,0.4545454680919647,0.5529411764705883,0.2180260121822357
204,,,,,,mmlu:high_school_us_history,test,303.7923828661442,llama2_7b_chat,oe,oe,0.6323529481887817,0.5196078419685364,0.40299741602067185,0.14130975043072425
23,,,,,,mmlu:human_aging,validation,15.319626230746508,llama2_7b_chat,oe,oe,0.3478260934352875,0.6086956858634949,0.5,0.1637215121932652
223,,,,,,mmlu:human_aging,test,186.88587633520365,llama2_7b_chat,oe,oe,0.3363228738307953,0.6412556171417236,0.5246396396396397,0.08568327255847744
12,,,,,,mmlu:human_sexuality,validation,11.56634296476841,llama2_7b_chat,oe,oe,0.1666666716337204,0.75,0.4,0.1629181702931722
131,,,,,,mmlu:human_sexuality,test,116.54479514434934,llama2_7b_chat,oe,oe,0.38167938590049744,0.5648854970932007,0.49358024691358027,0.16514967962075736
13,,,,,,mmlu:international_law,validation,8.489302456378937,llama2_7b_chat,oe,oe,0.46153849363327026,0.46153849363327026,0.6904761904761906,0.3035084146719712
121,,,,,,mmlu:international_law,test,94.69470858201385,llama2_7b_chat,oe,oe,0.6033057570457458,0.6280991435050964,0.615154109589041,0.14230794847504172
11,,,,,,mmlu:jurisprudence,validation,10.17678502947092,llama2_7b_chat,oe,oe,0.4545454680919647,0.7272727489471436,0.5333333333333334,0.17557074265046554
108,,,,,,mmlu:jurisprudence,test,92.65067986026406,llama2_7b_chat,oe,oe,0.5092592835426331,0.5092592835426331,0.48216123499142366,0.2197092186521601
18,,,,,,mmlu:logical_fallacies,validation,14.292155284434557,llama2_7b_chat,oe,oe,0.5,0.5555555820465088,0.48148148148148145,0.15746439165539214
163,,,,,,mmlu:logical_fallacies,test,119.70531671121716,llama2_7b_chat,oe,oe,0.453987717628479,0.5889570713043213,0.4404038870331005,0.1342625259621743
11,,,,,,mmlu:machine_learning,validation,11.438289508223534,llama2_7b_chat,oe,oe,0.4545454680919647,0.5454545617103577,0.30000000000000004,0.2680792971090837
112,,,,,,mmlu:machine_learning,test,82.74706103280187,llama2_7b_chat,oe,oe,0.2142857313156128,0.7767857313156128,0.4623579545454545,0.08026007350002018
11,,,,,,mmlu:management,validation,11.712660737335682,llama2_7b_chat,oe,oe,0.3636363744735718,0.4545454680919647,0.4285714285714286,0.308347534049641
103,,,,,,mmlu:management,test,90.4905167967081,llama2_7b_chat,oe,oe,0.34951457381248474,0.5339806079864502,0.48507462686567165,0.17594083015201162
25,,,,,,mmlu:marketing,validation,22.119691748172045,llama2_7b_chat,oe,oe,0.2800000011920929,0.5199999809265137,0.6825396825396826,0.26870450496673587
234,,,,,,mmlu:marketing,test,184.74886069446802,llama2_7b_chat,oe,oe,0.3888888955116272,0.49145302176475525,0.5247060631676017,0.171309934467332
11,,,,,,mmlu:medical_genetics,validation,11.182566601783037,llama2_7b_chat,oe,oe,0.8181818723678589,0.4545454680919647,0.2777777777777778,0.38742317394776776
100,,,,,,mmlu:medical_genetics,test,95.46810729056597,llama2_7b_chat,oe,oe,0.3999999761581421,0.5999999642372131,0.47187499999999993,0.20236094772815705
38,,,,,,mmlu:moral_disputes,validation,31.171102344989777,llama2_7b_chat,oe,oe,0.34210526943206787,0.6315789222717285,0.35384615384615387,0.1401348176755403
346,,,,,,mmlu:moral_disputes,test,302.50241762399673,llama2_7b_chat,oe,oe,0.4219653010368347,0.6069363951683044,0.45328767123287667,0.08641343395834027
33,,,,,,mmlu:nutrition,validation,24.647073339670897,llama2_7b_chat,oe,oe,0.3030303120613098,0.5454545617103577,0.5043478260869565,0.21812028595895477
306,,,,,,mmlu:nutrition,test,236.03768288716674,llama2_7b_chat,oe,oe,0.4346405267715454,0.5555555820465088,0.5013907601373375,0.1671361529749203
34,,,,,,mmlu:philosophy,validation,28.05927623808384,llama2_7b_chat,oe,oe,0.3529411852359772,0.6176470518112183,0.43560606060606066,0.1618551384000217
311,,,,,,mmlu:philosophy,test,281.72614278271794,llama2_7b_chat,oe,oe,0.31511253118515015,0.6495176553726196,0.4460093896713615,0.07427494338087716
35,,,,,,mmlu:prehistory,validation,35.42031558603048,llama2_7b_chat,oe,oe,0.3142857253551483,0.6571428775787354,0.34090909090909094,0.1552312867982047
324,,,,,,mmlu:prehistory,test,313.49640576168895,llama2_7b_chat,oe,oe,0.3611111044883728,0.6358024477958679,0.3895701721788678,0.17468011655189372
69,,,,,,mmlu:professional_psychology,validation,58.428184039890766,llama2_7b_chat,oe,oe,0.36231884360313416,0.6811594367027283,0.37,0.13993242080660834
612,,,,,,mmlu:professional_psychology,test,494.6056409291923,llama2_7b_chat,oe,oe,0.3235294222831726,0.6388888955116272,0.41700824671839165,0.1262541245790868
12,,,,,,mmlu:public_relations,validation,8.46007452905178,llama2_7b_chat,oe,oe,0.3333333432674408,0.75,0.15625,0.35223649938901264
110,,,,,,mmlu:public_relations,test,56.755925089120865,llama2_7b_chat,oe,oe,0.3181818127632141,0.663636326789856,0.46628571428571425,0.04540723778984765
27,,,,,,mmlu:security_studies,validation,25.671470746397972,llama2_7b_chat,oe,oe,0.7037037014961243,0.7407407760620117,0.46710526315789475,0.08901053887826425
245,,,,,,mmlu:security_studies,test,227.63829912245274,llama2_7b_chat,oe,oe,0.6979591250419617,0.6979591250419617,0.5802117907381064,0.07884773405230773
22,,,,,,mmlu:sociology,validation,18.755506448447704,llama2_7b_chat,oe,oe,0.40909093618392944,0.5454545617103577,0.5128205128205128,0.2754882601174441
201,,,,,,mmlu:sociology,test,189.10575625300407,llama2_7b_chat,oe,oe,0.42786067724227905,0.5970149040222168,0.4368048533872599,0.1327109289406544
11,,,,,,mmlu:us_foreign_policy,validation,191.75980190560222,llama2_7b_chat,oe,oe,0.6363636255264282,0.5454545617103577,0.4464285714285714,0.1797311631116
100,,,,,,mmlu:us_foreign_policy,test,61.58851546421647,llama2_7b_chat,oe,oe,0.5899999737739563,0.5099999904632568,0.5725506407606449,0.1601883935928345
18,,,,,,mmlu:virology,validation,14.060685895383358,llama2_7b_chat,oe,oe,0.2777777910232544,0.6111111044883728,0.7846153846153846,0.18792446785502964
166,,,,,,mmlu:virology,test,152.22229055687785,llama2_7b_chat,oe,oe,0.3253012001514435,0.6566264629364014,0.48115079365079366,0.14317853551313103
19,,,,,,mmlu:world_religions,validation,8.999431692063808,llama2_7b_chat,oe,oe,0.6315789222717285,0.5263158082962036,0.6369047619047619,0.16939092309851397
171,,,,,,mmlu:world_religions,test,95.01420198008418,llama2_7b_chat,oe,oe,0.5263158082962036,0.5263158082962036,0.5310013717421126,0.16798042972185462
11,,,,,,mmlu:abstract_algebra,validation,14.257258484140038,mistral_7b_instruct,oe,oe,0.27272728085517883,0.4545454680919647,0.41666666666666663,0.32036343487826263
100,,,,,,mmlu:abstract_algebra,test,89.43813870474696,mistral_7b_instruct,oe,oe,0.2800000011920929,0.5600000023841858,0.3898809523809524,0.12136417150497439
14,,,,,,mmlu:anatomy,validation,14.251772712916136,mistral_7b_instruct,oe,oe,0.5714285969734192,0.5,0.3125,0.2882571348122188
135,,,,,,mmlu:anatomy,test,120.97513425722718,mistral_7b_instruct,oe,oe,0.555555522441864,0.5629629492759705,0.512888888888889,0.1670847592530427
16,,,,,,mmlu:astronomy,validation,14.742012776434422,mistral_7b_instruct,oe,oe,0.75,0.375,0.5208333333333334,0.39402220770716667
152,,,,,,mmlu:astronomy,test,135.1009039003402,mistral_7b_instruct,oe,oe,0.7039473652839661,0.4934210479259491,0.4257528556593977,0.2200828022078464
11,,,,,,mmlu:business_ethics,validation,11.941595366224647,mistral_7b_instruct,oe,oe,0.5454545617103577,0.6363636255264282,0.3333333333333333,0.2506011995402249
100,,,,,,mmlu:business_ethics,test,93.60253574326634,mistral_7b_instruct,oe,oe,0.3999999761581421,0.47999998927116394,0.6208333333333332,0.2515889173746109
29,,,,,,mmlu:clinical_knowledge,validation,28.340336007997394,mistral_7b_instruct,oe,oe,0.41379308700561523,0.41379308700561523,0.5196078431372548,0.25090530823016993
265,,,,,,mmlu:clinical_knowledge,test,241.72490269877017,mistral_7b_instruct,oe,oe,0.43018868565559387,0.6000000238418579,0.5061287324270942,0.13799770058326
16,,,,,,mmlu:college_biology,validation,14.331199124455452,mistral_7b_instruct,oe,oe,0.3125,0.625,0.32727272727272727,0.28702670335769653
144,,,,,,mmlu:college_biology,test,138.72294559516013,mistral_7b_instruct,oe,oe,0.4930555522441864,0.6180555820465088,0.4693227860312561,0.1362156296769778
8,,,,,,mmlu:college_chemistry,validation,7.5558932069689035,mistral_7b_instruct,oe,oe,0.125,0.5,0.4285714285714286,0.2209095135331154
100,,,,,,mmlu:college_chemistry,test,94.56767856888473,mistral_7b_instruct,oe,oe,0.25,0.5399999618530273,0.5168,0.21416318058967593
11,,,,,,mmlu:college_computer_science,validation,12.38362063281238,mistral_7b_instruct,oe,oe,0.27272728085517883,0.4545454680919647,0.5833333333333333,0.3455791473388672
100,,,,,,mmlu:college_computer_science,test,119.79691268131137,mistral_7b_instruct,oe,oe,0.28999999165534973,0.699999988079071,0.6694997571636717,0.14350699484348295
11,,,,,,mmlu:college_mathematics,validation,11.759307274594903,mistral_7b_instruct,oe,oe,0.27272728085517883,0.5454545617103577,0.625,0.213620126247406
100,,,,,,mmlu:college_mathematics,test,100.72829911485314,mistral_7b_instruct,oe,oe,0.14999999105930328,0.6599999666213989,0.47647058823529415,0.10178901493549347
22,,,,,,mmlu:college_medicine,validation,22.8716580606997,mistral_7b_instruct,oe,oe,0.5,0.5909091234207153,0.47107438016528924,0.18566944111477243
173,,,,,,mmlu:college_medicine,test,170.83058544062078,mistral_7b_instruct,oe,oe,0.4161849617958069,0.6127167344093323,0.5250962596259626,0.09404833985201883
11,,,,,,mmlu:college_physics,validation,11.637936504557729,mistral_7b_instruct,oe,oe,0.1818181872367859,0.7272727489471436,0.16666666666666669,0.023082624782215434
102,,,,,,mmlu:college_physics,test,107.65700837038457,mistral_7b_instruct,oe,oe,0.1764705926179886,0.7156863212585449,0.611441798941799,0.13035323164042306
11,,,,,,mmlu:computer_security,validation,11.593201966956258,mistral_7b_instruct,oe,oe,0.7272727489471436,0.4545454680919647,0.04166666666666667,0.33935084668072785
100,,,,,,mmlu:computer_security,test,98.11825593747199,mistral_7b_instruct,oe,oe,0.6800000071525574,0.5600000023841858,0.4898897058823529,0.20501139044761657
26,,,,,,mmlu:conceptual_physics,validation,26.249033488333225,mistral_7b_instruct,oe,oe,0.5,0.42307692766189575,0.3668639053254438,0.25223448414068955
235,,,,,,mmlu:conceptual_physics,test,218.39092756435275,mistral_7b_instruct,oe,oe,0.44255316257476807,0.612765908241272,0.49541250733998826,0.08941004859640243
12,,,,,,mmlu:econometrics,validation,11.841151574626565,mistral_7b_instruct,oe,oe,0.25,0.4166666865348816,0.6296296296296295,0.3443910231192907
114,,,,,,mmlu:econometrics,test,113.49966361932456,mistral_7b_instruct,oe,oe,0.22807016968727112,0.5438596606254578,0.5137674825174825,0.16314302045002316
16,,,,,,mmlu:electrical_engineering,validation,15.456200141459703,mistral_7b_instruct,oe,oe,0.3125,0.625,0.4,0.22262756153941154
145,,,,,,mmlu:electrical_engineering,test,142.2704299930483,mistral_7b_instruct,oe,oe,0.4482758641242981,0.6000000238418579,0.5457692307692308,0.15767081071590558
41,,,,,,mmlu:elementary_mathematics,validation,41.605499751865864,mistral_7b_instruct,oe,oe,0.3658536374568939,0.6585365533828735,0.40897435897435896,0.24831050779761338
378,,,,,,mmlu:elementary_mathematics,test,368.5140648316592,mistral_7b_instruct,oe,oe,0.436507910490036,0.5899470448493958,0.48967136150234736,0.1588618293325737
14,,,,,,mmlu:formal_logic,validation,15.46585814282298,mistral_7b_instruct,oe,oe,0.2857142984867096,0.5714285969734192,0.7999999999999999,0.3807277892317092
126,,,,,,mmlu:formal_logic,test,123.51163486205041,mistral_7b_instruct,oe,oe,0.3571428656578064,0.5555555820465088,0.48491083676268865,0.17884692738926602
10,,,,,,mmlu:global_facts,validation,11.546527909114957,mistral_7b_instruct,oe,oe,0.5,0.6000000238418579,0.4,0.28132962584495547
100,,,,,,mmlu:global_facts,test,96.47435765527189,mistral_7b_instruct,oe,oe,0.22999998927116394,0.44999998807907104,0.5660643704121965,0.31600489974021917
32,,,,,,mmlu:high_school_biology,validation,32.76145604811609,mistral_7b_instruct,oe,oe,0.40625,0.625,0.7206477732793523,0.2773705441504717
310,,,,,,mmlu:high_school_biology,test,300.89926446415484,mistral_7b_instruct,oe,oe,0.5774193406105042,0.6451612710952759,0.5723058552603523,0.09676161543015513
22,,,,,,mmlu:high_school_chemistry,validation,22.913144756108522,mistral_7b_instruct,oe,oe,0.22727273404598236,0.6363636255264282,0.6941176470588235,0.2748917883092707
203,,,,,,mmlu:high_school_chemistry,test,195.44987526349723,mistral_7b_instruct,oe,oe,0.29556649923324585,0.5812807679176331,0.5167249417249418,0.18933150216276423
9,,,,,,mmlu:high_school_computer_science,validation,11.420990550890565,mistral_7b_instruct,oe,oe,0.5555555820465088,0.5555555820465088,0.5,0.3205674754248725
100,,,,,,mmlu:high_school_computer_science,test,275.3854314610362,mistral_7b_instruct,oe,oe,0.5799999833106995,0.550000011920929,0.4505336617405583,0.1443068099021911
22,,,,,,mmlu:high_school_geography,validation,22.26556340418756,mistral_7b_instruct,oe,oe,0.40909093618392944,0.6363636255264282,0.3162393162393162,0.14156235348094598
198,,,,,,mmlu:high_school_geography,test,185.97372475080192,mistral_7b_instruct,oe,oe,0.4545454680919647,0.5404040217399597,0.5291666666666667,0.16443059691275008
21,,,,,,mmlu:high_school_government_and_politics,validation,22.1877511870116,mistral_7b_instruct,oe,oe,0.6190476417541504,0.523809552192688,0.6730769230769231,0.21589228085109172
193,,,,,,mmlu:high_school_government_and_politics,test,179.18461305834353,mistral_7b_instruct,oe,oe,0.6424870491027832,0.6321243643760681,0.5396213183730715,0.12993759349220158
43,,,,,,mmlu:high_school_macroeconomics,validation,40.43536159209907,mistral_7b_instruct,oe,oe,0.4651162624359131,0.5116279125213623,0.6304347826086956,0.2382110482038453
390,,,,,,mmlu:high_school_macroeconomics,test,361.7446002699435,mistral_7b_instruct,oe,oe,0.48461538553237915,0.5641025900840759,0.5218879149227408,0.149821033844581
29,,,,,,mmlu:high_school_mathematics,validation,30.366236487403512,mistral_7b_instruct,oe,oe,0.17241379618644714,0.7931034564971924,0.375,0.04789562266448447
270,,,,,,mmlu:high_school_mathematics,test,263.6641625389457,mistral_7b_instruct,oe,oe,0.15925925970077515,0.7407407164573669,0.46906054707509476,0.0634072639324047
26,,,,,,mmlu:high_school_microeconomics,validation,26.92906976491213,mistral_7b_instruct,oe,oe,0.3076923191547394,0.46153849363327026,0.6319444444444444,0.240994373193154
238,,,,,,mmlu:high_school_microeconomics,test,221.65920709259808,mistral_7b_instruct,oe,oe,0.4621849060058594,0.5840336680412292,0.5395596590909091,0.15778820980496766
17,,,,,,mmlu:high_school_physics,validation,19.106617664918303,mistral_7b_instruct,oe,oe,0.1764705926179886,0.529411792755127,0.380952380952381,0.22138379601871264
151,,,,,,mmlu:high_school_physics,test,147.5140928030014,mistral_7b_instruct,oe,oe,0.3509933650493622,0.6225165724754333,0.4811320754716981,0.09696037011430753
60,,,,,,mmlu:high_school_psychology,validation,58.56745903193951,mistral_7b_instruct,oe,oe,0.6666666865348816,0.5666667222976685,0.46187500000000004,0.10759335756301883
545,,,,,,mmlu:high_school_psychology,test,511.9679211284965,mistral_7b_instruct,oe,oe,0.5853211283683777,0.5651376247406006,0.48216217715759985,0.14957882953346321
23,,,,,,mmlu:high_school_statistics,validation,23.727646440267563,mistral_7b_instruct,oe,oe,0.30434784293174744,0.782608687877655,0.6696428571428572,0.19976216036340466
216,,,,,,mmlu:high_school_statistics,test,222.3284465149045,mistral_7b_instruct,oe,oe,0.4027777910232544,0.6435185074806213,0.4632005702575069,0.1524676876487555
22,,,,,,mmlu:high_school_us_history,validation,42.580260729417205,mistral_7b_instruct,oe,oe,0.6818181872367859,0.6818181872367859,0.4666666666666667,0.1279145262458108
204,,,,,,mmlu:high_school_us_history,test,356.42784864269197,mistral_7b_instruct,oe,oe,0.7205882668495178,0.686274528503418,0.5433822651867766,0.07899253946893356
23,,,,,,mmlu:human_aging,validation,22.179743852466345,mistral_7b_instruct,oe,oe,0.3913043439388275,0.6086956858634949,0.48412698412698413,0.28269804819770483
223,,,,,,mmlu:human_aging,test,205.9871114604175,mistral_7b_instruct,oe,oe,0.4663677215576172,0.5650224685668945,0.4483678086619263,0.17439524341591806
12,,,,,,mmlu:human_sexuality,validation,11.103949399664998,mistral_7b_instruct,oe,oe,0.5833333730697632,0.6666666865348816,0.5142857142857142,0.22957110901673636
131,,,,,,mmlu:human_sexuality,test,120.96548662893474,mistral_7b_instruct,oe,oe,0.580152690410614,0.6030534505844116,0.46650717703349287,0.12986316207711024
13,,,,,,mmlu:international_law,validation,14.010671030730009,mistral_7b_instruct,oe,oe,0.7692307829856873,0.692307710647583,0.5333333333333333,0.2432587972054115
121,,,,,,mmlu:international_law,test,111.23358247987926,mistral_7b_instruct,oe,oe,0.8347107172012329,0.719008207321167,0.46287128712871284,0.09440687027844513
11,,,,,,mmlu:jurisprudence,validation,11.305022932589054,mistral_7b_instruct,oe,oe,0.7272727489471436,0.4545454680919647,0.45833333333333337,0.356459146196192
108,,,,,,mmlu:jurisprudence,test,102.07361684925854,mistral_7b_instruct,oe,oe,0.7407407760620117,0.6574074029922485,0.41875000000000007,0.13423741194936964
18,,,,,,mmlu:logical_fallacies,validation,18.682792766019702,mistral_7b_instruct,oe,oe,0.7222222089767456,0.5,0.4769230769230769,0.23466346330112878
163,,,,,,mmlu:logical_fallacies,test,155.46151013858616,mistral_7b_instruct,oe,oe,0.5950919985771179,0.546012282371521,0.4532177444548579,0.16442532005485583
11,,,,,,mmlu:machine_learning,validation,11.866056352853775,mistral_7b_instruct,oe,oe,0.5454545617103577,0.3636363744735718,0.7,0.3761194348335266
112,,,,,,mmlu:machine_learning,test,111.02588924765587,mistral_7b_instruct,oe,oe,0.5089285969734192,0.5089285969734192,0.392822966507177,0.23007181446467126
11,,,,,,mmlu:management,validation,10.09026356600225,mistral_7b_instruct,oe,oe,0.6363636255264282,0.4545454680919647,0.6428571428571428,0.2932514060627331
103,,,,,,mmlu:management,test,96.54193125851452,mistral_7b_instruct,oe,oe,0.48543688654899597,0.6213592290878296,0.5350943396226415,0.16053834470730383
25,,,,,,mmlu:marketing,validation,25.935327833518386,mistral_7b_instruct,oe,oe,0.3199999928474426,0.3999999761581421,0.5073529411764706,0.27564075231552126
234,,,,,,mmlu:marketing,test,221.91163162700832,mistral_7b_instruct,oe,oe,0.47435900568962097,0.5427350401878357,0.4645865377572695,0.11423521418856761
11,,,,,,mmlu:medical_genetics,validation,11.132501512765884,mistral_7b_instruct,oe,oe,0.6363636255264282,0.6363636255264282,0.3571428571428571,0.3208007433197715
100,,,,,,mmlu:medical_genetics,test,91.643649764359,mistral_7b_instruct,oe,oe,0.5699999928474426,0.5899999737739563,0.4916360669114647,0.11517651140689851
38,,,,,,mmlu:moral_disputes,validation,37.344537138938904,mistral_7b_instruct,oe,oe,0.5263158082962036,0.44736841320991516,0.4652777777777778,0.29080343717022944
346,,,,,,mmlu:moral_disputes,test,339.8986536618322,mistral_7b_instruct,oe,oe,0.589595377445221,0.6040462255477905,0.5322769953051644,0.10297342480262581
33,,,,,,mmlu:nutrition,validation,33.5589299723506,mistral_7b_instruct,oe,oe,0.6060606241226196,0.6060606241226196,0.41346153846153844,0.17732868772564514
306,,,,,,mmlu:nutrition,test,296.10623897612095,mistral_7b_instruct,oe,oe,0.5816993713378906,0.6078431606292725,0.518675386235955,0.19216177802459866
34,,,,,,mmlu:philosophy,validation,30.57446662336588,mistral_7b_instruct,oe,oe,0.4117647111415863,0.5588235259056091,0.5642857142857143,0.1945084491196801
311,,,,,,mmlu:philosophy,test,524.199276547879,mistral_7b_instruct,oe,oe,0.4244372844696045,0.5723472833633423,0.5202090739800237,0.12481827617074898
35,,,,,,mmlu:prehistory,validation,39.4020714443177,mistral_7b_instruct,oe,oe,0.5142857432365417,0.48571428656578064,0.33660130718954245,0.21999240773064754
324,,,,,,mmlu:prehistory,test,435.19935350865126,mistral_7b_instruct,oe,oe,0.5617284178733826,0.5185185074806213,0.5268340814115462,0.16828161496439098
69,,,,,,mmlu:professional_psychology,validation,73.3795881792903,mistral_7b_instruct,oe,oe,0.5362318754196167,0.5072463750839233,0.4028716216216216,0.18625167055406427
612,,,,,,mmlu:professional_psychology,test,596.8812335114926,mistral_7b_instruct,oe,oe,0.4215686321258545,0.5653594732284546,0.4503186177900407,0.12253440653576572
12,,,,,,mmlu:public_relations,validation,11.43916254863143,mistral_7b_instruct,oe,oe,0.4166666865348816,0.4166666865348816,0.45714285714285713,0.258364995320638
110,,,,,,mmlu:public_relations,test,102.88117883913219,mistral_7b_instruct,oe,oe,0.38181817531585693,0.5545454621315002,0.5255602240896359,0.16289913654327395
27,,,,,,mmlu:security_studies,validation,26.81021356768906,mistral_7b_instruct,oe,oe,0.7037037014961243,0.5185185074806213,0.48684210526315785,0.26626449161105686
245,,,,,,mmlu:security_studies,test,240.94570218771696,mistral_7b_instruct,oe,oe,0.7673469185829163,0.5959183573722839,0.5191302724897351,0.16937435670774809
22,,,,,,mmlu:sociology,validation,19.967612579464912,mistral_7b_instruct,oe,oe,0.6818181872367859,0.5454545617103577,0.49523809523809526,0.2362846379930323
201,,,,,,mmlu:sociology,test,172.4891706239432,mistral_7b_instruct,oe,oe,0.5621890425682068,0.5174129009246826,0.4924074818986323,0.16502914974345495
11,,,,,,mmlu:us_foreign_policy,validation,11.22665299847722,mistral_7b_instruct,oe,oe,0.8181818723678589,0.3636363744735718,0.3333333333333333,0.4675899635661732
100,,,,,,mmlu:us_foreign_policy,test,90.91354469768703,mistral_7b_instruct,oe,oe,0.8199999928474426,0.6100000143051147,0.551829268292683,0.18078487217426298
18,,,,,,mmlu:virology,validation,18.528729321435094,mistral_7b_instruct,oe,oe,0.7222222089767456,0.6111111044883728,0.7846153846153846,0.1688825719886356
166,,,,,,mmlu:virology,test,153.35884239338338,mistral_7b_instruct,oe,oe,0.668674647808075,0.626505970954895,0.5762489762489763,0.14199908741985456
19,,,,,,mmlu:world_religions,validation,18.02538745291531,mistral_7b_instruct,oe,oe,0.6315789222717285,0.31578946113586426,0.35714285714285715,0.41667213251716206
171,,,,,,mmlu:world_religions,test,155.7244352735579,mistral_7b_instruct,oe,oe,0.6959064602851868,0.5497075915336609,0.5119586296056884,0.18349821909129274
11,,,,,,mmlu:abstract_algebra,validation,20.22817974537611,mistral_7b_instruct,choice,oe,0.27272728085517883,0.8181818723678589,0.375,0.20627532763914627
100,,,,,,mmlu:abstract_algebra,test,140.59102104231715,mistral_7b_instruct,choice,oe,0.29999998211860657,0.6699999570846558,0.5657142857142857,0.1881920886039734
14,,,,,,mmlu:anatomy,validation,19.959275368601084,mistral_7b_instruct,choice,oe,0.4285714626312256,0.785714328289032,0.22916666666666666,0.2528119555541447
135,,,,,,mmlu:anatomy,test,175.7874863334,mistral_7b_instruct,choice,oe,0.555555522441864,0.5999999642372131,0.494,0.31046739198543405
16,,,,,,mmlu:astronomy,validation,21.907598450779915,mistral_7b_instruct,choice,oe,0.5625,0.5625,0.4761904761904762,0.3133287876844406
152,,,,,,mmlu:astronomy,test,210.41998867690563,mistral_7b_instruct,choice,oe,0.6907894611358643,0.41447368264198303,0.38135764944275585,0.42426136332122905
11,,,,,,mmlu:business_ethics,validation,17.29978894069791,mistral_7b_instruct,choice,oe,0.5454545617103577,0.4545454680919647,0.43333333333333335,0.378180747682398
100,,,,,,mmlu:business_ethics,test,148.70093712955713,mistral_7b_instruct,choice,oe,0.429999977350235,0.5,0.5185638514891882,0.2815604531764984
29,,,,,,mmlu:clinical_knowledge,validation,41.39482919871807,mistral_7b_instruct,choice,oe,0.4482758641242981,0.5862069129943848,0.2980769230769231,0.34303278553074806
265,,,,,,mmlu:clinical_knowledge,test,355.8070544973016,mistral_7b_instruct,choice,oe,0.4377358555793762,0.5773584842681885,0.47436935894468873,0.26390293386747254
16,,,,,,mmlu:college_biology,validation,22.701909765601158,mistral_7b_instruct,choice,oe,0.3125,0.5625,0.2727272727272727,0.36281275004148483
144,,,,,,mmlu:college_biology,test,208.3944904692471,mistral_7b_instruct,choice,oe,0.4930555522441864,0.5277777910232544,0.4993247154157824,0.2556758291191525
8,,,,,,mmlu:college_chemistry,validation,12.015053901821375,mistral_7b_instruct,choice,oe,0.0,0.625,,0.1904243528842926
100,,,,,,mmlu:college_chemistry,test,149.02192874252796,mistral_7b_instruct,choice,oe,0.26999998092651367,0.5600000023841858,0.5644342973110096,0.25716622710227965
11,,,,,,mmlu:college_computer_science,validation,22.167514692991972,mistral_7b_instruct,choice,oe,0.1818181872367859,0.6363636255264282,0.8333333333333334,0.25266603448174213
100,,,,,,mmlu:college_computer_science,test,189.05100491642952,mistral_7b_instruct,choice,oe,0.28999999165534973,0.6299999952316284,0.4997571636716852,0.2259321463108063
11,,,,,,mmlu:college_mathematics,validation,19.21616706624627,mistral_7b_instruct,choice,oe,0.0,0.7272727489471436,,0.14492544260892
100,,,,,,mmlu:college_mathematics,test,163.09138983115554,mistral_7b_instruct,choice,oe,0.14999999105930328,0.699999988079071,0.5050980392156863,0.17139441370964048
22,,,,,,mmlu:college_medicine,validation,33.930224772542715,mistral_7b_instruct,choice,oe,0.5454545617103577,0.5,0.5833333333333334,0.3549641885540702
173,,,,,,mmlu:college_medicine,test,269.94374864920974,mistral_7b_instruct,choice,oe,0.4566473960876465,0.5549132823944092,0.43078373283059523,0.2779694668130378
11,,,,,,mmlu:college_physics,validation,18.013856425881386,mistral_7b_instruct,choice,oe,0.3636363744735718,0.5454545617103577,0.7142857142857142,0.5123916430906816
102,,,,,,mmlu:college_physics,test,155.7703435458243,mistral_7b_instruct,choice,oe,0.19607843458652496,0.6078431606292725,0.5704268292682927,0.2638486372489556
11,,,,,,mmlu:computer_security,validation,16.514924757182598,mistral_7b_instruct,choice,oe,0.7272727489471436,0.4545454680919647,0.375,0.37225842475891113
100,,,,,,mmlu:computer_security,test,134.9703454785049,mistral_7b_instruct,choice,oe,0.6399999856948853,0.3499999940395355,0.5108506944444444,0.4264638477563858
26,,,,,,mmlu:conceptual_physics,validation,35.83029302209616,mistral_7b_instruct,choice,oe,0.42307692766189575,0.42307692766189575,0.34545454545454546,0.3758570139224713
235,,,,,,mmlu:conceptual_physics,test,306.22626945748925,mistral_7b_instruct,choice,oe,0.4553191363811493,0.5574467778205872,0.45283294392523366,0.317969019362267
12,,,,,,mmlu:econometrics,validation,19.41738086938858,mistral_7b_instruct,choice,oe,0.5833333730697632,0.75,0.45714285714285713,0.25181108713150024
114,,,,,,mmlu:econometrics,test,184.01750902086496,mistral_7b_instruct,choice,oe,0.24561403691768646,0.5964912176132202,0.3639950166112957,0.21384489327146294
16,,,,,,mmlu:electrical_engineering,validation,22.514640733599663,mistral_7b_instruct,choice,oe,0.3125,0.5,0.5272727272727272,0.44458412751555443
145,,,,,,mmlu:electrical_engineering,test,208.40066577121615,mistral_7b_instruct,choice,oe,0.4413793087005615,0.5034482479095459,0.5244984567901234,0.33679710667708823
41,,,,,,mmlu:elementary_mathematics,validation,62.48411963880062,mistral_7b_instruct,choice,oe,0.4146341383457184,0.6341463327407837,0.463235294117647,0.24858918713360298
378,,,,,,mmlu:elementary_mathematics,test,550.3917978592217,mistral_7b_instruct,choice,oe,0.44708994030952454,0.5608465671539307,0.5059030038787123,0.30072351675184944
14,,,,,,mmlu:formal_logic,validation,23.35794121399522,mistral_7b_instruct,choice,oe,0.4285714626312256,0.6428571939468384,0.4375,0.38512347425733295
126,,,,,,mmlu:formal_logic,test,319.27700432762504,mistral_7b_instruct,choice,oe,0.3492063581943512,0.5952381491661072,0.5753880266075387,0.22543411500870236
10,,,,,,mmlu:global_facts,validation,15.981614671647549,mistral_7b_instruct,choice,oe,0.5,0.4000000059604645,0.6399999999999999,0.48315864205360415
100,,,,,,mmlu:global_facts,test,137.80761424824595,mistral_7b_instruct,choice,oe,0.22999998927116394,0.7699999809265137,0.5590062111801243,0.1807257306575775
32,,,,,,mmlu:high_school_biology,validation,46.839837815612555,mistral_7b_instruct,choice,oe,0.40625,0.53125,0.5546558704453441,0.3611037153750658
310,,,,,,mmlu:high_school_biology,test,444.683487739414,mistral_7b_instruct,choice,oe,0.5935483574867249,0.5032258033752441,0.5219332298136645,0.2937572590766415
22,,,,,,mmlu:high_school_chemistry,validation,34.60470476746559,mistral_7b_instruct,choice,oe,0.1818181872367859,0.5,0.6388888888888888,0.28672057661143213
203,,,,,,mmlu:high_school_chemistry,test,301.6014426611364,mistral_7b_instruct,choice,oe,0.29064038395881653,0.5960590839385986,0.4434439736346516,0.26358895583693037
9,,,,,,mmlu:high_school_computer_science,validation,19.14506085589528,mistral_7b_instruct,choice,oe,0.5555555820465088,0.2222222238779068,0.85,0.681420816315545
100,,,,,,mmlu:high_school_computer_science,test,172.77825055643916,mistral_7b_instruct,choice,oe,0.5399999618530273,0.41999998688697815,0.5205314009661836,0.42724483847618105
22,,,,,,mmlu:high_school_geography,validation,32.93162231892347,mistral_7b_instruct,choice,oe,0.4545454680919647,0.4545454680919647,0.5833333333333333,0.414502276615663
198,,,,,,mmlu:high_school_geography,test,285.91454784199595,mistral_7b_instruct,choice,oe,0.4747474789619446,0.5454545617103577,0.4386252045826514,0.28793303954480876
21,,,,,,mmlu:high_school_government_and_politics,validation,31.167747728526592,mistral_7b_instruct,choice,oe,0.761904776096344,0.4285714328289032,0.37499999999999994,0.4964410094987778
193,,,,,,mmlu:high_school_government_and_politics,test,267.786515198648,mistral_7b_instruct,choice,oe,0.6165803074836731,0.43523314595222473,0.46025437201907793,0.43755684769833025
43,,,,,,mmlu:high_school_macroeconomics,validation,62.690370466560125,mistral_7b_instruct,choice,oe,0.4651162624359131,0.5116279125213623,0.4391304347826087,0.3511626235274381
390,,,,,,mmlu:high_school_macroeconomics,test,514.9883075654507,mistral_7b_instruct,choice,oe,0.4948718249797821,0.5205128192901611,0.4711738249914521,0.3362969477971395
29,,,,,,mmlu:high_school_mathematics,validation,47.58455540239811,mistral_7b_instruct,choice,oe,0.24137930572032928,0.6206896305084229,0.5844155844155843,0.23397383402133815
270,,,,,,mmlu:high_school_mathematics,test,418.34532595798373,mistral_7b_instruct,choice,oe,0.14074073731899261,0.7185184955596924,0.5401542649727767,0.1078210139716113
26,,,,,,mmlu:high_school_microeconomics,validation,35.896401077508926,mistral_7b_instruct,choice,oe,0.3076923191547394,0.5,0.5833333333333334,0.25254692939611584
238,,,,,,mmlu:high_school_microeconomics,test,315.58165871724486,mistral_7b_instruct,choice,oe,0.4327731430530548,0.6008403897285461,0.5021574973031284,0.23010048771104893
17,,,,,,mmlu:high_school_physics,validation,28.619694601744413,mistral_7b_instruct,choice,oe,0.23529411852359772,0.6470588445663452,0.6346153846153846,0.23818407689823823
151,,,,,,mmlu:high_school_physics,test,230.89060289785266,mistral_7b_instruct,choice,oe,0.33112582564353943,0.6026490330696106,0.45792079207920794,0.20697958500969488
60,,,,,,mmlu:high_school_psychology,validation,88.20182111486793,mistral_7b_instruct,choice,oe,0.6333333849906921,0.38333335518836975,0.43301435406698563,0.42551097869873045
545,,,,,,mmlu:high_school_psychology,test,824.1599381379783,mistral_7b_instruct,choice,oe,0.6018348932266235,0.4458715617656708,0.46831094751039676,0.3706192470471793
23,,,,,,mmlu:high_school_statistics,validation,39.30277908965945,mistral_7b_instruct,choice,oe,0.3478260934352875,0.782608687877655,0.26666666666666666,0.11109144791312839
216,,,,,,mmlu:high_school_statistics,test,370.2709535807371,mistral_7b_instruct,choice,oe,0.35185185074806213,0.6805555820465088,0.42749060150375934,0.16164229506695713
22,,,,,,mmlu:high_school_us_history,validation,86.28270174562931,mistral_7b_instruct,choice,oe,0.7727273106575012,0.40909093618392944,0.7411764705882353,0.4403041113506664
204,,,,,,mmlu:high_school_us_history,test,776.5868345014751,mistral_7b_instruct,choice,oe,0.7107843160629272,0.4019607901573181,0.5046171829339567,0.3740747883623722
23,,,,,,mmlu:human_aging,validation,30.91189657524228,mistral_7b_instruct,choice,oe,0.47826087474823,0.43478262424468994,0.5568181818181819,0.4241615119187728
223,,,,,,mmlu:human_aging,test,296.7933606095612,mistral_7b_instruct,choice,oe,0.43946191668510437,0.5022422075271606,0.4683673469387755,0.2651355977550216
12,,,,,,mmlu:human_sexuality,validation,15.7829521112144,mistral_7b_instruct,choice,oe,0.4166666865348816,0.6666666865348816,0.3285714285714286,0.29568425814310706
131,,,,,,mmlu:human_sexuality,test,174.40851962938905,mistral_7b_instruct,choice,oe,0.5343511700630188,0.5038167834281921,0.3559718969555036,0.3229012584868278
13,,,,,,mmlu:international_law,validation,19.814228516072035,mistral_7b_instruct,choice,oe,0.692307710647583,0.46153849363327026,0.25,0.4018836571620062
121,,,,,,mmlu:international_law,test,168.39732591807842,mistral_7b_instruct,choice,oe,0.8016528487205505,0.46280989050865173,0.497852233676976,0.3741352494097938
11,,,,,,mmlu:jurisprudence,validation,16.093005169183016,mistral_7b_instruct,choice,oe,0.7272727489471436,0.1818181872367859,0.625,0.6876961426301436
108,,,,,,mmlu:jurisprudence,test,149.5642027296126,mistral_7b_instruct,choice,oe,0.6851851940155029,0.3888888955116272,0.5457074721780604,0.44370095321425684
18,,,,,,mmlu:logical_fallacies,validation,26.405041601508856,mistral_7b_instruct,choice,oe,0.6666666865348816,0.3888888955116272,0.4583333333333333,0.42427794469727415
163,,,,,,mmlu:logical_fallacies,test,239.20807195827365,mistral_7b_instruct,choice,oe,0.5950919985771179,0.38650307059288025,0.49101843174008125,0.419217208411796
11,,,,,,mmlu:machine_learning,validation,18.407895803451538,mistral_7b_instruct,choice,oe,0.4545454680919647,0.5454545617103577,0.3666666666666667,0.31393251093951136
112,,,,,,mmlu:machine_learning,test,174.05548864603043,mistral_7b_instruct,choice,oe,0.4375000298023224,0.598214328289032,0.3655652737285391,0.23364780736821042
11,,,,,,mmlu:management,validation,13.762908361852169,mistral_7b_instruct,choice,oe,0.8181818723678589,0.1818181872367859,0.8333333333333333,0.6283960721709512
103,,,,,,mmlu:management,test,133.69487550109625,mistral_7b_instruct,choice,oe,0.48543688654899597,0.48543688654899597,0.4630188679245283,0.2721718138861425
25,,,,,,mmlu:marketing,validation,37.71188488230109,mistral_7b_instruct,choice,oe,0.3199999928474426,0.5999999642372131,0.661764705882353,0.3095582532882691
234,,,,,,mmlu:marketing,test,318.31020460650325,mistral_7b_instruct,choice,oe,0.46581199765205383,0.5512821078300476,0.446788990825688,0.23659679828545988
11,,,,,,mmlu:medical_genetics,validation,15.447940368205309,mistral_7b_instruct,choice,oe,0.7272727489471436,0.4545454680919647,0.125,0.38263352350755175
100,,,,,,mmlu:medical_genetics,test,128.19477055221796,mistral_7b_instruct,choice,oe,0.5600000023841858,0.4599999785423279,0.5097402597402597,0.3960628539323806
38,,,,,,mmlu:moral_disputes,validation,54.599522832781076,mistral_7b_instruct,choice,oe,0.5526315569877625,0.44736841320991516,0.5238095238095238,0.45188943649593155
346,,,,,,mmlu:moral_disputes,test,597.3717258237302,mistral_7b_instruct,choice,oe,0.5635837912559509,0.46531790494918823,0.4689420954321617,0.4039563247234146
33,,,,,,mmlu:nutrition,validation,50.09912334755063,mistral_7b_instruct,choice,oe,0.6666666865348816,0.5151515007019043,0.6115702479338843,0.31489186937158753
306,,,,,,mmlu:nutrition,test,441.8457366377115,mistral_7b_instruct,choice,oe,0.5424836874008179,0.5326797366142273,0.4339931153184165,0.2814077526525734
34,,,,,,mmlu:philosophy,validation,43.57603523880243,mistral_7b_instruct,choice,oe,0.4117647111415863,0.529411792755127,0.5107142857142857,0.3604266801301171
311,,,,,,mmlu:philosophy,test,411.817207492888,mistral_7b_instruct,choice,oe,0.46302250027656555,0.5466237664222717,0.4563997005988024,0.3095361519473158
35,,,,,,mmlu:prehistory,validation,49.656585182994604,mistral_7b_instruct,choice,oe,0.4285714328289032,0.5428571701049805,0.48,0.3571688515799386
324,,,,,,mmlu:prehistory,test,443.5453261695802,mistral_7b_instruct,choice,oe,0.5956790447235107,0.43518519401550293,0.5030850769291619,0.446425896183944
69,,,,,,mmlu:professional_psychology,validation,103.43065732717514,mistral_7b_instruct,choice,oe,0.52173912525177,0.5072463750839233,0.38973063973063976,0.3405768698540287
612,,,,,,mmlu:professional_psychology,test,884.3912397734821,mistral_7b_instruct,choice,oe,0.4444444477558136,0.5816993713378906,0.4881271626297578,0.2463733250993529
12,,,,,,mmlu:public_relations,validation,16.160039752721786,mistral_7b_instruct,choice,oe,0.3333333432674408,0.5,0.78125,0.3482894351085027
110,,,,,,mmlu:public_relations,test,149.02937069907784,mistral_7b_instruct,choice,oe,0.33636361360549927,0.5545454621315002,0.4042947056645687,0.22817685875025664
27,,,,,,mmlu:security_studies,validation,42.908269718289375,mistral_7b_instruct,choice,oe,0.7407407760620117,0.5555555820465088,0.6571428571428573,0.22953915154492416
245,,,,,,mmlu:security_studies,test,372.32615887001157,mistral_7b_instruct,choice,oe,0.7755101919174194,0.4693877398967743,0.4439712918660287,0.3449869155883789
22,,,,,,mmlu:sociology,validation,27.89578428119421,mistral_7b_instruct,choice,oe,0.6818181872367859,0.40909093618392944,0.1904761904761905,0.37526756254109467
201,,,,,,mmlu:sociology,test,251.26282893493772,mistral_7b_instruct,choice,oe,0.6019900441169739,0.4825870394706726,0.4833677685950414,0.37290137739323853
11,,,,,,mmlu:us_foreign_policy,validation,16.177138075232506,mistral_7b_instruct,choice,oe,0.8181818723678589,0.27272728085517883,0.6666666666666666,0.6472748843106355
100,,,,,,mmlu:us_foreign_policy,test,132.2552537806332,mistral_7b_instruct,choice,oe,0.7899999618530273,0.4599999785423279,0.4996986136226643,0.3897041183710098
18,,,,,,mmlu:virology,validation,27.086193222552538,mistral_7b_instruct,choice,oe,0.6666666865348816,0.4444444477558136,0.2777777777777778,0.38256197505527073
166,,,,,,mmlu:virology,test,220.13264445215464,mistral_7b_instruct,choice,oe,0.6566264629364014,0.45783132314682007,0.5788668920006439,0.340547100248107
19,,,,,,mmlu:world_religions,validation,25.628899052739143,mistral_7b_instruct,choice,oe,0.7368420958518982,0.6842105388641357,0.6142857142857143,0.17931953856819555
171,,,,,,mmlu:world_religions,test,221.54345018044114,mistral_7b_instruct,choice,oe,0.6783626079559326,0.4736842215061188,0.5998432601880878,0.31063763021725654
11,0.10440169952132486,0.27272728085517883,0.1818181872367859,0.41666666666666663,0.49273400956934144,mmlu:abstract_algebra,validation,3.84461204521358,llama2_7b,oe,choice,,,,
100,0.08465734511613844,0.32999998331069946,0.32999998331069946,0.34803256445047487,0.34413276910781865,mmlu:abstract_algebra,test,11.899626788217574,llama2_7b,oe,choice,,,,
14,0.316505851490157,0.6428571939468384,0.6428571939468384,0.5555555555555556,0.2186956150191171,mmlu:anatomy,validation,1.836643252056092,llama2_7b,oe,choice,,,,
135,0.0471060276031494,0.4814814627170563,0.4814814627170563,0.6298901098901101,0.2676364037725661,mmlu:anatomy,test,16.740639318712056,llama2_7b,oe,choice,,,,
16,0.21303562633693218,0.4375,0.75,0.7222222222222222,0.23312877863645554,mmlu:astronomy,validation,3.133467920124531,llama2_7b,oe,choice,,,,
152,0.09957414159649294,0.42763158679008484,0.4868420958518982,0.6096374889478338,0.1363217732624004,mmlu:astronomy,test,28.57457960769534,llama2_7b,oe,choice,,,,
11,0.18482445044951004,0.5454545617103577,0.4545454680919647,0.3333333333333333,0.20124243064360187,mmlu:business_ethics,validation,2.1462965812534094,llama2_7b,oe,choice,,,,
100,0.10293846011161806,0.5,0.4899999797344208,0.6332,0.19604938328266142,mmlu:business_ethics,test,18.77899672696367,llama2_7b,oe,choice,,,,
29,0.1997113207290913,0.41379308700561523,0.41379308700561523,0.6274509803921569,0.3109901979051788,mmlu:clinical_knowledge,validation,4.094197829719633,llama2_7b,oe,choice,,,,
265,0.04839907445997561,0.4867924451828003,0.5056604146957397,0.5528385772913816,0.23041781007118942,mmlu:clinical_knowledge,test,36.3116777157411,llama2_7b,oe,choice,,,,
16,0.1442484837025404,0.3125,0.375,0.4909090909090909,0.3240104466676712,mmlu:college_biology,validation,2.6634282511658967,llama2_7b,oe,choice,,,,
144,0.05530282855033875,0.4444444477558136,0.4375,0.527734375,0.26733173429965973,mmlu:college_biology,test,23.635875029023737,llama2_7b,oe,choice,,,,
8,0.2846439443528652,0.5,0.5,0.3125,0.38064298033714294,mmlu:college_chemistry,validation,1.5592824001796544,llama2_7b,oe,choice,,,,
100,0.04396307885646821,0.3400000035762787,0.3499999940395355,0.5463458110516933,0.2805834949016571,mmlu:college_chemistry,test,17.68682618299499,llama2_7b,oe,choice,,,,
11,0.27867451310157776,0.6363636255264282,0.6363636255264282,0.42857142857142855,0.04596329819072374,mmlu:college_computer_science,validation,2.885908578056842,llama2_7b,oe,choice,,,,
100,0.12171100914478301,0.3499999940395355,0.4399999976158142,0.5221978021978022,0.17137935757637027,mmlu:college_computer_science,test,26.51613691309467,llama2_7b,oe,choice,,,,
11,0.03904929215257818,0.27272728085517883,0.6363636255264282,0.6666666666666666,0.05801235545765269,mmlu:college_mathematics,validation,2.0832783742807806,llama2_7b,oe,choice,,,,
100,0.06566793262958528,0.35999998450279236,0.5299999713897705,0.5082465277777777,0.05079181313514709,mmlu:college_mathematics,test,17.93606242723763,llama2_7b,oe,choice,,,,
22,0.23144665631380953,0.4545454680919647,0.4545454680919647,0.47500000000000003,0.2997996048493819,mmlu:college_medicine,validation,3.8899409188888967,llama2_7b,oe,choice,,,,
173,0.09870713173998572,0.3815028667449951,0.398843914270401,0.6469130557915604,0.33418115025999917,mmlu:college_medicine,test,35.45234860572964,llama2_7b,oe,choice,,,,
11,0.21092458475719797,0.5454545617103577,0.4545454680919647,0.3333333333333333,0.197800874710083,mmlu:college_physics,validation,1.879516534972936,llama2_7b,oe,choice,,,,
102,0.20560371379057563,0.2352941334247589,0.3333333432674408,0.6808226495726496,0.30405027609245455,mmlu:college_physics,test,16.317681956104934,llama2_7b,oe,choice,,,,
11,0.2262939594008706,0.5454545617103577,0.6363636255264282,0.9333333333333333,0.16117517514662308,mmlu:computer_security,validation,1.733824112918228,llama2_7b,oe,choice,,,,
100,0.08229195713996887,0.5699999928474426,0.550000011920929,0.649734802121583,0.16626500606536868,mmlu:computer_security,test,13.283933391794562,llama2_7b,oe,choice,,,,
26,0.1780651154426428,0.38461539149284363,0.5384615659713745,0.71875,0.16523046676929182,mmlu:conceptual_physics,validation,2.9441753341816366,llama2_7b,oe,choice,,,,
235,0.0895193411948833,0.4382978677749634,0.4893616735935211,0.6026772580170638,0.1582482086851242,mmlu:conceptual_physics,test,25.320647682994604,llama2_7b,oe,choice,,,,
12,0.24002027014891306,0.25,0.25,0.33333333333333337,0.3930479238430659,mmlu:econometrics,validation,2.402777633164078,llama2_7b,oe,choice,,,,
114,0.13919230406744434,0.28947368264198303,0.2982456088066101,0.47381219603441826,0.3582418106104198,mmlu:econometrics,test,22.1757069719024,llama2_7b,oe,choice,,,,
16,0.20740997791290283,0.5625,0.625,0.6031746031746033,0.15094878524541858,mmlu:electrical_engineering,validation,2.3018934158608317,llama2_7b,oe,choice,,,,
145,0.07344877617112522,0.41379308700561523,0.475862056016922,0.6112745098039215,0.20705500676714142,mmlu:electrical_engineering,test,19.897873423062265,llama2_7b,oe,choice,,,,
41,0.11478738377733928,0.2682926654815674,0.4878048598766327,0.6636363636363637,0.10733231684056727,mmlu:elementary_mathematics,validation,7.273211857769638,llama2_7b,oe,choice,,,,
378,0.08419816109238477,0.23280422389507294,0.5158730149269104,0.5473746081504702,0.053133631351763626,mmlu:elementary_mathematics,test,64.91763574676588,llama2_7b,oe,choice,,,,
14,0.1309523582458496,0.2142857313156128,0.2142857313156128,0.303030303030303,0.49885980997766766,mmlu:formal_logic,validation,2.7991571757011116,llama2_7b,oe,choice,,,,
126,0.0734056854058826,0.3968254327774048,0.3968254327774048,0.5211842105263158,0.3275118403964572,mmlu:formal_logic,test,24.613029399886727,llama2_7b,oe,choice,,,,
10,0.31112129986286163,0.0,0.0,,0.6505331993103027,mmlu:global_facts,validation,1.4940394051373005,llama2_7b,oe,choice,,,,
100,0.09453950107097625,0.29999998211860657,0.28999999165534973,0.439047619047619,0.3683828055858612,mmlu:global_facts,test,13.77986524021253,llama2_7b,oe,choice,,,,
32,0.15929202921688557,0.34375,0.375,0.6688311688311688,0.3523493707180023,mmlu:high_school_biology,validation,5.595088351052254,llama2_7b,oe,choice,,,,
310,0.06557648556847727,0.4838709533214569,0.4741935431957245,0.5048333333333334,0.24560962415510612,mmlu:high_school_biology,test,53.462258770130575,llama2_7b,oe,choice,,,,
22,0.14563547616655179,0.3636363744735718,0.4545454680919647,0.7857142857142857,0.22460758144205267,mmlu:high_school_chemistry,validation,3.8876221808604896,llama2_7b,oe,choice,,,,
203,0.07429527751917911,0.37438422441482544,0.4433497488498688,0.6050041442188148,0.21252781475706053,mmlu:high_school_chemistry,test,33.737179996911436,llama2_7b,oe,choice,,,,
9,0.2763041125403509,0.6666666865348816,0.6666666865348816,0.5,0.20127554072274106,mmlu:high_school_computer_science,validation,2.7984313759952784,llama2_7b,oe,choice,,,,
100,0.0944753623008728,0.3799999952316284,0.3999999761581421,0.5660016977928692,0.30877226114273065,mmlu:high_school_computer_science,test,29.736823588144034,llama2_7b,oe,choice,,,,
22,0.14493492787534543,0.7272727489471436,0.6818181872367859,0.23958333333333331,0.2559375979683616,mmlu:high_school_geography,validation,2.919935590121895,llama2_7b,oe,choice,,,,
198,0.1304760573789327,0.5,0.5,0.5946332006938068,0.1884501591475323,mmlu:high_school_geography,test,25.644694871734828,llama2_7b,oe,choice,,,,
21,0.11912707345826284,0.5714285969734192,0.5714285969734192,0.8333333333333334,0.2546045978864034,mmlu:high_school_government_and_politics,validation,3.277833986096084,llama2_7b,oe,choice,,,,
193,0.08869219598374835,0.6891191601753235,0.6891191601753235,0.6026942355889724,0.068909473987441,mmlu:high_school_government_and_politics,test,29.739652237389237,llama2_7b,oe,choice,,,,
43,0.1393191038176071,0.3255814015865326,0.3255814015865326,0.4433497536945813,0.39424672514893283,mmlu:high_school_macroeconomics,validation,5.775023692287505,llama2_7b,oe,choice,,,,
390,0.039585466644702826,0.4435897469520569,0.45897436141967773,0.5770490929916625,0.2553519689119779,mmlu:high_school_macroeconomics,test,51.52644792292267,llama2_7b,oe,choice,,,,
29,0.1322748599381282,0.4482758641242981,0.517241358757019,0.7692307692307692,0.06258526958268262,mmlu:high_school_mathematics,validation,4.958079454023391,llama2_7b,oe,choice,,,,
270,0.03766621925212718,0.277777761220932,0.4333333373069763,0.5292307692307693,0.13153769020681028,mmlu:high_school_mathematics,test,44.70444744406268,llama2_7b,oe,choice,,,,
26,0.20842720568180087,0.3461538553237915,0.38461539149284363,0.5816993464052287,0.32110424912892854,mmlu:high_school_microeconomics,validation,3.496124272700399,llama2_7b,oe,choice,,,,
238,0.07028368027771217,0.4495798647403717,0.4453781843185425,0.5547192694585148,0.2415816653676394,mmlu:high_school_microeconomics,test,31.763223415706307,llama2_7b,oe,choice,,,,
17,0.10082907361142777,0.29411765933036804,0.1764705926179886,0.4,0.42365437395432415,mmlu:high_school_physics,validation,3.1686008451506495,llama2_7b,oe,choice,,,,
151,0.097967157103368,0.29139071702957153,0.3509933650493622,0.5011682242990655,0.264929997210471,mmlu:high_school_physics,test,26.908921365160495,llama2_7b,oe,choice,,,,
60,0.1589977249503136,0.7000000476837158,0.7000000476837158,0.5912698412698413,0.082291446129481,mmlu:high_school_psychology,validation,10.227266734000295,llama2_7b,oe,choice,,,,
545,0.07737777763550435,0.6366972327232361,0.6348623633384705,0.6348936046342386,0.11895913005968849,mmlu:high_school_psychology,test,92.60664691589773,llama2_7b,oe,choice,,,,
23,0.13274553677310116,0.43478262424468994,0.43478262424468994,0.523076923076923,0.28963011244068976,mmlu:high_school_statistics,validation,5.847358371131122,llama2_7b,oe,choice,,,,
216,0.10100761635435954,0.2638888955116272,0.2777777910232544,0.41873551804038395,0.4279604987413795,mmlu:high_school_statistics,test,57.14093745406717,llama2_7b,oe,choice,,,,
22,0.28292583470994775,0.6818181872367859,0.7272727489471436,0.4571428571428572,0.13281853090633047,mmlu:high_school_us_history,validation,20.898821564391255,llama2_7b,oe,choice,,,,
204,0.11426834499134737,0.593137264251709,0.6029412150382996,0.6000697002887583,0.10884870939395005,mmlu:high_school_us_history,test,192.70607423502952,llama2_7b,oe,choice,,,,
23,0.28406256307726324,0.6521739363670349,0.6521739363670349,0.5583333333333333,0.12836367410162225,mmlu:human_aging,validation,2.691759704146534,llama2_7b,oe,choice,,,,
223,0.07760624233382703,0.5426009297370911,0.5381166338920593,0.5346378220709772,0.20657943235919085,mmlu:human_aging,test,24.932627264410257,llama2_7b,oe,choice,,,,
12,0.25977308054765064,0.5833333730697632,0.5833333730697632,0.6571428571428571,0.1561743219693502,mmlu:human_sexuality,validation,1.5246693938970566,llama2_7b,oe,choice,,,,
131,0.08252456943497402,0.5496183037757874,0.5648854970932007,0.49234934086629,0.17707445876288963,mmlu:human_sexuality,test,16.343210159800947,llama2_7b,oe,choice,,,,
13,0.20696626488979047,0.8461538553237915,0.8461538553237915,0.09090909090909091,0.2910934136464046,mmlu:international_law,validation,2.883302138186991,llama2_7b,oe,choice,,,,
121,0.06712943980516481,0.6280991435050964,0.6280991435050964,0.4720760233918128,0.12709586925743038,mmlu:international_law,test,24.452653552871197,llama2_7b,oe,choice,,,,
11,0.2205446470867504,0.5454545617103577,0.5454545617103577,0.8333333333333333,0.22051165862516925,mmlu:jurisprudence,validation,1.5966191180050373,llama2_7b,oe,choice,,,,
108,0.11856746701178728,0.5092592835426331,0.5092592835426331,0.6102915951972555,0.20248880264935668,mmlu:jurisprudence,test,14.517637632787228,llama2_7b,oe,choice,,,,
18,0.170874469810062,0.7222222089767456,0.7222222089767456,0.8,0.046452571948369346,mmlu:logical_fallacies,validation,2.655095883179456,llama2_7b,oe,choice,,,,
163,0.10552868137330366,0.5521472096443176,0.5521472096443176,0.6198630136986301,0.1491658168336365,mmlu:logical_fallacies,test,23.901208089198917,llama2_7b,oe,choice,,,,
11,0.16178627176718277,0.1818181872367859,0.1818181872367859,0.25,0.5145283666524021,mmlu:machine_learning,validation,2.312947606202215,llama2_7b,oe,choice,,,,
112,0.06483048679573196,0.4017857313156128,0.455357164144516,0.5280265339966833,0.2782404667564801,mmlu:machine_learning,test,22.736489065922797,llama2_7b,oe,choice,,,,
11,0.31467008048837836,0.27272728085517883,0.27272728085517883,0.875,0.4376068819652904,mmlu:management,validation,1.1860323431901634,llama2_7b,oe,choice,,,,
103,0.10779039836624293,0.6019417643547058,0.6116504669189453,0.5828088119590873,0.11195617104039612,mmlu:management,test,10.556991235818714,llama2_7b,oe,choice,,,,
25,0.21100118041038513,0.7999999523162842,0.7999999523162842,0.78,0.07988636970520022,mmlu:marketing,validation,3.5383726796135306,llama2_7b,oe,choice,,,,
234,0.08511733282835057,0.6837607026100159,0.6794872283935547,0.6278293918918919,0.0855884118976756,mmlu:marketing,test,31.531545526813716,llama2_7b,oe,choice,,,,
11,0.2489505030892112,0.8181818723678589,0.8181818723678589,0.4444444444444444,0.18603629957545886,mmlu:medical_genetics,validation,1.4834404271095991,llama2_7b,oe,choice,,,,
100,0.08966358572244644,0.4699999988079071,0.4699999988079071,0.6043757527097551,0.3206177544593811,mmlu:medical_genetics,test,12.280069798696786,llama2_7b,oe,choice,,,,
38,0.21275872776382848,0.34210526943206787,0.3684210479259491,0.5876923076923076,0.351738840341568,mmlu:moral_disputes,validation,6.205457645934075,llama2_7b,oe,choice,,,,
346,0.08811942276927087,0.48554912209510803,0.4942196309566498,0.6196328250401284,0.24638220030448343,mmlu:moral_disputes,test,54.90097854472697,llama2_7b,oe,choice,,,,
33,0.13644179250254776,0.6363636255264282,0.6363636255264282,0.5238095238095238,0.12885101997491089,mmlu:nutrition,validation,6.457546140998602,llama2_7b,oe,choice,,,,
306,0.0441471742453918,0.5032680034637451,0.516339898109436,0.5096975393028025,0.22947596646601856,mmlu:nutrition,test,59.443722317926586,llama2_7b,oe,choice,,,,
34,0.25040046783054576,0.38235294818878174,0.4117647111415863,0.6135531135531136,0.33010029266862306,mmlu:philosophy,validation,4.146132024936378,llama2_7b,oe,choice,,,,
311,0.06003534678860875,0.5787781476974487,0.581993579864502,0.5850720949957592,0.15801458400928703,mmlu:philosophy,test,36.538330105133355,llama2_7b,oe,choice,,,,
35,0.18100049325398032,0.4000000059604645,0.4000000059604645,0.5918367346938775,0.2821674908910479,mmlu:prehistory,validation,6.322700195014477,llama2_7b,oe,choice,,,,
324,0.0783309977915552,0.5154321193695068,0.5185185074806213,0.6325756131050001,0.1754109232146063,mmlu:prehistory,test,56.872023556847125,llama2_7b,oe,choice,,,,
69,0.11339120933975,0.42028987407684326,0.42028987407684326,0.6702586206896552,0.3568691179372262,mmlu:professional_psychology,validation,13.226804138161242,llama2_7b,oe,choice,,,,
612,0.03712628182827258,0.43627452850341797,0.43790850043296814,0.5161374368995277,0.3413430353979659,mmlu:professional_psychology,test,112.57465150393546,llama2_7b,oe,choice,,,,
12,0.18629899869362515,0.4166666865348816,0.4166666865348816,0.48571428571428577,0.3486435463031133,mmlu:public_relations,validation,1.874143173918128,llama2_7b,oe,choice,,,,
110,0.10156022689559242,0.5363636016845703,0.5272727012634277,0.38168826852775006,0.16263359297405588,mmlu:public_relations,test,15.544441057834774,llama2_7b,oe,choice,,,,
27,0.08400083250469632,0.4444444477558136,0.4444444477558136,0.6611111111111111,0.27094186897631045,mmlu:security_studies,validation,11.618658987805247,llama2_7b,oe,choice,,,,
245,0.06508886680311085,0.4734693765640259,0.48979589343070984,0.5369219460037423,0.2384443472842781,mmlu:security_studies,test,106.90929674590006,llama2_7b,oe,choice,,,,
22,0.1622227254238996,0.6363636255264282,0.6818181872367859,0.7589285714285714,0.13311491771177814,mmlu:sociology,validation,3.2158922129310668,llama2_7b,oe,choice,,,,
201,0.08522436764109788,0.6368159055709839,0.6616915464401245,0.6366117294520548,0.10458117426924447,mmlu:sociology,test,29.334291896782815,llama2_7b,oe,choice,,,,
11,0.22170420126481488,0.4545454680919647,0.4545454680919647,0.75,0.2889730767770247,mmlu:us_foreign_policy,validation,1.6445404249243438,llama2_7b,oe,choice,,,,
100,0.06871068000793457,0.6499999761581421,0.6499999761581421,0.49252747252747253,0.098275865316391,mmlu:us_foreign_policy,test,13.723368030972779,llama2_7b,oe,choice,,,,
18,0.2937471899721358,0.3888888955116272,0.3333333432674408,0.5974025974025975,0.3828088210688697,mmlu:virology,validation,2.696813871152699,llama2_7b,oe,choice,,,,
166,0.14781458370656855,0.40963852405548096,0.4277108311653137,0.5368397358943579,0.26586107029972306,mmlu:virology,test,20.620261000003666,llama2_7b,oe,choice,,,,
19,0.26303477193179886,0.7894737124443054,0.7894737124443054,0.9,0.21858265525416323,mmlu:world_religions,validation,1.886031806934625,llama2_7b,oe,choice,,,,
171,0.13904649681515163,0.7017543911933899,0.7134503126144409,0.7242647058823529,0.07038999858655426,mmlu:world_religions,test,16.29195433994755,llama2_7b,oe,choice,,,,
11,,,,,,mmlu:abstract_algebra,validation,13.096994349965826,llama2_7b,oe,oe,0.1818181872367859,0.4545454680919647,0.7777777777777778,0.5098655115474354
100,,,,,,mmlu:abstract_algebra,test,89.55234637111425,llama2_7b,oe,oe,0.22999998927116394,0.5299999713897705,0.4548277809147374,0.34537247598171233
14,,,,,,mmlu:anatomy,validation,13.891350505873561,llama2_7b,oe,oe,0.2857142984867096,0.2857142984867096,0.825,0.5243195380483355
135,,,,,,mmlu:anatomy,test,118.38980223215185,llama2_7b,oe,oe,0.4296296238899231,0.5037037134170532,0.6166592028660993,0.21726378025832005
16,,,,,,mmlu:astronomy,validation,15.743543955963105,llama2_7b,oe,oe,0.5,0.4375,0.390625,0.33702730387449265
152,,,,,,mmlu:astronomy,test,140.2013490269892,llama2_7b,oe,oe,0.5065789222717285,0.6118420958518982,0.4829437229437229,0.10880334400816966
11,,,,,,mmlu:business_ethics,validation,10.92260162695311,llama2_7b,oe,oe,0.5454545617103577,0.7272727489471436,0.8,0.23518327149477875
100,,,,,,mmlu:business_ethics,test,95.34870257996954,llama2_7b,oe,oe,0.3100000023841858,0.5999999642372131,0.610331930808789,0.10680277049541473
29,,,,,,mmlu:clinical_knowledge,validation,27.864301678026095,llama2_7b,oe,oe,0.3103448152542114,0.37931033968925476,0.5555555555555556,0.30964059870818567
265,,,,,,mmlu:clinical_knowledge,test,267.6311780209653,llama2_7b,oe,oe,0.3358490467071533,0.4528301954269409,0.6604954034729317,0.25354284835311597
16,,,,,,mmlu:college_biology,validation,14.534849342890084,llama2_7b,oe,oe,0.25,0.375,0.6249999999999999,0.30908937752246857
144,,,,,,mmlu:college_biology,test,130.37962103192694,llama2_7b,oe,oe,0.3125,0.5416666865348816,0.5892255892255892,0.20331581681966782
8,,,,,,mmlu:college_chemistry,validation,8.293613543035462,llama2_7b,oe,oe,0.125,0.375,0.7142857142857143,0.2844347283244133
100,,,,,,mmlu:college_chemistry,test,93.22608607006259,llama2_7b,oe,oe,0.12999999523162842,0.6299999952316284,0.5534924845269673,0.08764234602451326
11,,,,,,mmlu:college_computer_science,validation,11.833558914950117,llama2_7b,oe,oe,0.0,0.7272727489471436,,0.27022474462335766
100,,,,,,mmlu:college_computer_science,test,102.28506053984165,llama2_7b,oe,oe,0.14999999105930328,0.5799999833106995,0.5015686274509804,0.16160715401172637
11,,,,,,mmlu:college_mathematics,validation,11.092245436972007,llama2_7b,oe,oe,0.0,0.9090909361839294,,0.1390531984242526
100,,,,,,mmlu:college_mathematics,test,94.87761467695236,llama2_7b,oe,oe,0.1599999964237213,0.8199999928474426,0.3623511904761905,0.05983470380306245
22,,,,,,mmlu:college_medicine,validation,26.630932457977906,llama2_7b,oe,oe,0.3636363744735718,0.40909093618392944,0.5,0.3038050342689861
173,,,,,,mmlu:college_medicine,test,165.55553136696108,llama2_7b,oe,oe,0.3179190754890442,0.48554912209510803,0.5523882896764253,0.23660393360722273
11,,,,,,mmlu:college_physics,validation,10.950705759227276,llama2_7b,oe,oe,0.27272728085517883,0.8181818723678589,0.5416666666666666,0.14549317143180154
102,,,,,,mmlu:college_physics,test,96.33939795498736,llama2_7b,oe,oe,0.18627451360225677,0.7352941632270813,0.3417882054533925,0.1092921997986588
11,,,,,,mmlu:computer_security,validation,11.00388447707519,llama2_7b,oe,oe,0.5454545617103577,0.6363636255264282,0.3,0.11174012314189566
100,,,,,,mmlu:computer_security,test,92.35799823980778,llama2_7b,oe,oe,0.4699999988079071,0.47999998927116394,0.4787234042553191,0.24452362418174742
26,,,,,,mmlu:conceptual_physics,validation,24.290505832992494,llama2_7b,oe,oe,0.42307692766189575,0.6153846383094788,0.35151515151515156,0.25834031517689043
235,,,,,,mmlu:conceptual_physics,test,204.92160210502334,llama2_7b,oe,oe,0.40425530076026917,0.5234042406082153,0.48413533834586464,0.16901676883088781
12,,,,,,mmlu:econometrics,validation,11.386716322042048,llama2_7b,oe,oe,0.0,0.5,,0.15846793353557587
114,,,,,,mmlu:econometrics,test,108.51243569585495,llama2_7b,oe,oe,0.19298246502876282,0.5701754689216614,0.5382905138339922,0.16566118493414764
16,,,,,,mmlu:electrical_engineering,validation,14.50877457880415,llama2_7b,oe,oe,0.1875,0.75,0.33333333333333337,0.084562499076128
145,,,,,,mmlu:electrical_engineering,test,133.7905071619898,llama2_7b,oe,oe,0.20689654350280762,0.5103448033332825,0.5715942028985508,0.23789095056468046
41,,,,,,mmlu:elementary_mathematics,validation,46.1334098209627,llama2_7b,oe,oe,0.19512194395065308,0.8292682766914368,0.30681818181818177,0.12260321291481573
378,,,,,,mmlu:elementary_mathematics,test,346.88969602505676,llama2_7b,oe,oe,0.317460298538208,0.6719576716423035,0.46745801033591733,0.16366433498089908
14,,,,,,mmlu:formal_logic,validation,14.610332653857768,llama2_7b,oe,oe,0.4285714626312256,0.3571428656578064,0.41666666666666663,0.5605337747505732
126,,,,,,mmlu:formal_logic,test,118.0120243539568,llama2_7b,oe,oe,0.2857142984867096,0.3492063581943512,0.37484567901234567,0.3977879924433572
10,,,,,,mmlu:global_facts,validation,10.7440480790101,llama2_7b,oe,oe,0.20000000298023224,0.6000000238418579,0.625,0.17901642322540284
100,,,,,,mmlu:global_facts,test,90.1814633011818,llama2_7b,oe,oe,0.17000000178813934,0.3700000047683716,0.4663359319631467,0.26779122531414035
32,,,,,,mmlu:high_school_biology,validation,28.779312524944544,llama2_7b,oe,oe,0.28125,0.5,0.3888888888888889,0.19585351459681988
310,,,,,,mmlu:high_school_biology,test,295.82829462504014,llama2_7b,oe,oe,0.43870967626571655,0.5645161271095276,0.5281862745098039,0.146171562710116
22,,,,,,mmlu:high_school_chemistry,validation,21.86648280895315,llama2_7b,oe,oe,0.1818181872367859,0.6363636255264282,0.4305555555555556,0.23358202251521026
203,,,,,,mmlu:high_school_chemistry,test,187.5276854019612,llama2_7b,oe,oe,0.14778324961662292,0.5911329984664917,0.6346820809248555,0.11965716648571598
9,,,,,,mmlu:high_school_computer_science,validation,11.286528539843857,llama2_7b,oe,oe,0.3333333432674408,0.7777777910232544,0.5555555555555556,0.2032317519187927
100,,,,,,mmlu:high_school_computer_science,test,97.56622292194515,llama2_7b,oe,oe,0.3499999940395355,0.5199999809265137,0.5503296703296703,0.15872418403625488
22,,,,,,mmlu:high_school_geography,validation,21.11438178201206,llama2_7b,oe,oe,0.5454545617103577,0.5454545617103577,0.5999999999999999,0.23353633826429196
198,,,,,,mmlu:high_school_geography,test,292.28039247286506,llama2_7b,oe,oe,0.3585858643054962,0.5707070827484131,0.5463014306310302,0.1033874692940953
21,,,,,,mmlu:high_school_government_and_politics,validation,21.229792793048546,llama2_7b,oe,oe,0.380952388048172,0.380952388048172,0.6634615384615385,0.2507436559313819
193,,,,,,mmlu:high_school_government_and_politics,test,175.92456791806035,llama2_7b,oe,oe,0.4559585452079773,0.5077720284461975,0.5520021645021645,0.1678282096595962
43,,,,,,mmlu:high_school_macroeconomics,validation,40.7185466599185,llama2_7b,oe,oe,0.39534884691238403,0.44186046719551086,0.5520361990950226,0.2982868039330771
390,,,,,,mmlu:high_school_macroeconomics,test,347.5787161809858,llama2_7b,oe,oe,0.3692307770252228,0.5256410241127014,0.5316593270099368,0.1931954606985435
29,,,,,,mmlu:high_school_mathematics,validation,29.40669520618394,llama2_7b,oe,oe,0.06896551698446274,0.8275861740112305,0.6481481481481481,0.14477211236953733
270,,,,,,mmlu:high_school_mathematics,test,471.8567434421275,llama2_7b,oe,oe,0.07037036865949631,0.8592592477798462,0.42482700775843996,0.027816979973404463
26,,,,,,mmlu:high_school_microeconomics,validation,24.496351375011727,llama2_7b,oe,oe,0.46153849363327026,0.6153846383094788,0.6369047619047619,0.17146182289490333
238,,,,,,mmlu:high_school_microeconomics,test,210.90553300315514,llama2_7b,oe,oe,0.33193278312683105,0.5504202246665955,0.5189873417721519,0.12393858653156695
17,,,,,,mmlu:high_school_physics,validation,18.930615153862163,llama2_7b,oe,oe,0.23529411852359772,0.529411792755127,0.1923076923076923,0.30646860248902263
151,,,,,,mmlu:high_school_physics,test,141.53177051595412,llama2_7b,oe,oe,0.18543046712875366,0.5695364475250244,0.48301393728222997,0.22967622295910164
60,,,,,,mmlu:high_school_psychology,validation,53.78567405301146,llama2_7b,oe,oe,0.45000001788139343,0.5166667103767395,0.45454545454545453,0.1623528947432836
545,,,,,,mmlu:high_school_psychology,test,490.9464857969433,llama2_7b,oe,oe,0.5064220428466797,0.5761467814445496,0.5822558051829104,0.13416047654020677
23,,,,,,mmlu:high_school_statistics,validation,23.17701012082398,llama2_7b,oe,oe,0.21739131212234497,0.8695652484893799,0.30000000000000004,0.16491777482240097
216,,,,,,mmlu:high_school_statistics,test,214.12680098810233,llama2_7b,oe,oe,0.27314814925193787,0.6666666865348816,0.37487854906617724,0.08751286511067992
22,,,,,,mmlu:high_school_us_history,validation,43.45889726211317,llama2_7b,oe,oe,0.5,0.6818181872367859,0.5041322314049587,0.11166224154559047
204,,,,,,mmlu:high_school_us_history,test,391.04269272997044,llama2_7b,oe,oe,0.6225490570068359,0.5147058963775635,0.467941507311586,0.1362205363956152
23,,,,,,mmlu:human_aging,validation,21.059993585804477,llama2_7b,oe,oe,0.3478260934352875,0.30434784293174744,0.44166666666666665,0.3752620194269263
223,,,,,,mmlu:human_aging,test,198.65037455107085,llama2_7b,oe,oe,0.3273542821407318,0.5201793909072876,0.5907762557077626,0.15528467471289523
12,,,,,,mmlu:human_sexuality,validation,10.560896357055753,llama2_7b,oe,oe,0.4166666865348816,0.5,0.6,0.2336344470580419
131,,,,,,mmlu:human_sexuality,test,119.34967798902653,llama2_7b,oe,oe,0.45038166642189026,0.6412214040756226,0.5796845574387948,0.11511024036480275
13,,,,,,mmlu:international_law,validation,14.00385879795067,llama2_7b,oe,oe,0.23076924681663513,0.5384615659713745,0.39999999999999997,0.3027985921272865
121,,,,,,mmlu:international_law,test,110.53469315799884,llama2_7b,oe,oe,0.4958677589893341,0.45454543828964233,0.5331967213114754,0.24070657678872104
11,,,,,,mmlu:jurisprudence,validation,10.727894515031949,llama2_7b,oe,oe,0.1818181872367859,0.1818181872367859,0.5,0.4828804677182978
108,,,,,,mmlu:jurisprudence,test,94.74333060486242,llama2_7b,oe,oe,0.37962964177131653,0.43518519401550293,0.5777211503458318,0.27504978908432853
18,,,,,,mmlu:logical_fallacies,validation,17.564273874042556,llama2_7b,oe,oe,0.4444444477558136,0.4444444477558136,0.47500000000000003,0.2563339736726549
163,,,,,,mmlu:logical_fallacies,test,147.9422084740363,llama2_7b,oe,oe,0.4417177736759186,0.47852760553359985,0.5399114774114774,0.24575090225488855
11,,,,,,mmlu:machine_learning,validation,10.783823242876679,llama2_7b,oe,oe,0.4545454680919647,0.6363636255264282,0.23333333333333334,0.17714069106362082
112,,,,,,mmlu:machine_learning,test,105.86602102895267,llama2_7b,oe,oe,0.2232142984867096,0.3750000298023224,0.4068965517241379,0.3868520430156163
11,,,,,,mmlu:management,validation,10.622587257996202,llama2_7b,oe,oe,0.5454545617103577,0.7272727489471436,0.7,0.15739104422655972
103,,,,,,mmlu:management,test,102.99727944703773,llama2_7b,oe,oe,0.40776699781417847,0.5145630836486816,0.6385636221701796,0.18128164011297876
25,,,,,,mmlu:marketing,validation,27.42811095993966,llama2_7b,oe,oe,0.2800000011920929,0.2800000011920929,0.6150793650793651,0.45416999340057385
234,,,,,,mmlu:marketing,test,213.75316815800034,llama2_7b,oe,oe,0.46581199765205383,0.5,0.6266422018348625,0.24202208462943373
11,,,,,,mmlu:medical_genetics,validation,10.208371614106,llama2_7b,oe,oe,0.7272727489471436,0.6363636255264282,0.5416666666666666,0.16989483616568823
100,,,,,,mmlu:medical_genetics,test,86.91163310804404,llama2_7b,oe,oe,0.47999998927116394,0.5699999928474426,0.5432692307692307,0.1288609141111374
38,,,,,,mmlu:moral_disputes,validation,35.46772885811515,llama2_7b,oe,oe,0.3684210479259491,0.42105263471603394,0.5714285714285714,0.34367715371282476
346,,,,,,mmlu:moral_disputes,test,421.9437893589493,llama2_7b,oe,oe,0.40751445293426514,0.4624277353286743,0.6295450614080609,0.22967551243787554
33,,,,,,mmlu:nutrition,validation,32.32433221885003,llama2_7b,oe,oe,0.39393940567970276,0.575757622718811,0.7730769230769231,0.18265125968239526
306,,,,,,mmlu:nutrition,test,288.2923368960619,llama2_7b,oe,oe,0.38235294818878174,0.4901960790157318,0.6327725772170216,0.2277577256455141
34,,,,,,mmlu:philosophy,validation,31.46668929583393,llama2_7b,oe,oe,0.29411765933036804,0.2647058963775635,0.5416666666666667,0.46000173337319317
311,,,,,,mmlu:philosophy,test,348.3477524712216,llama2_7b,oe,oe,0.31511253118515015,0.35691317915916443,0.5445051259940596,0.3591001365345774
35,,,,,,mmlu:prehistory,validation,32.8110853319522,llama2_7b,oe,oe,0.3142857253551483,0.5714285969734192,0.6742424242424242,0.1782791989190238
324,,,,,,mmlu:prehistory,test,295.2854656018317,llama2_7b,oe,oe,0.43518519401550293,0.5339506268501282,0.5735573382939968,0.10691474028575568
69,,,,,,mmlu:professional_psychology,validation,87.44077478302643,llama2_7b,oe,oe,0.3913043439388275,0.4637681245803833,0.5136684303350969,0.2349873763927515
612,,,,,,mmlu:professional_psychology,test,597.8771973531693,llama2_7b,oe,oe,0.31699347496032715,0.45588237047195435,0.5775723869185616,0.24080384634678664
12,,,,,,mmlu:public_relations,validation,10.95471048494801,llama2_7b,oe,oe,0.4166666865348816,0.6666666865348816,0.48571428571428577,0.1253942102193832
110,,,,,,mmlu:public_relations,test,103.38011089805514,llama2_7b,oe,oe,0.34545454382896423,0.49090906977653503,0.5626827485380117,0.2075552365996621
27,,,,,,mmlu:security_studies,validation,26.39489354705438,llama2_7b,oe,oe,0.40740740299224854,0.40740740299224854,0.5625,0.36636440621482
245,,,,,,mmlu:security_studies,test,397.58993980498053,llama2_7b,oe,oe,0.5102040767669678,0.5387755036354065,0.5563333333333333,0.21841203339245852
22,,,,,,mmlu:sociology,validation,22.04274948919192,llama2_7b,oe,oe,0.3181818127632141,0.7272727489471436,0.7142857142857143,0.23885971036824313
201,,,,,,mmlu:sociology,test,188.0447388268076,llama2_7b,oe,oe,0.3681592047214508,0.5124378204345703,0.617365396892956,0.15892322265093597
11,,,,,,mmlu:us_foreign_policy,validation,10.848489650059491,llama2_7b,oe,oe,0.5454545617103577,0.7272727489471436,0.8666666666666667,0.1672725244001909
100,,,,,,mmlu:us_foreign_policy,test,92.64381769811735,llama2_7b,oe,oe,0.5999999642372131,0.5699999928474426,0.5395833333333333,0.1643095219135284
18,,,,,,mmlu:virology,validation,17.76733417995274,llama2_7b,oe,oe,0.3888888955116272,0.7222222089767456,0.6363636363636364,0.2898466818862491
166,,,,,,mmlu:virology,test,150.75653196079656,llama2_7b,oe,oe,0.34337347745895386,0.5783132314682007,0.5389505874778691,0.13327911029379047
19,,,,,,mmlu:world_religions,validation,17.247558068018407,llama2_7b,oe,oe,0.7368420958518982,0.5789473652839661,0.2857142857142857,0.17586318756404679
171,,,,,,mmlu:world_religions,test,195.94095606100745,llama2_7b,oe,oe,0.6198830604553223,0.5789473652839661,0.5288098693759071,0.08545955161602176
11,0.1691572151400826,0.4545454680919647,0.4545454680919647,0.3,0.36189002882350574,mmlu:abstract_algebra,validation,4.774683127179742,mistral_7b,choice,choice,,,,
100,0.07374642238020897,0.3400000035762787,0.4399999976158142,0.49732620320855614,0.3007604306936264,mmlu:abstract_algebra,test,10.83338924497366,mistral_7b,choice,choice,,,,
14,0.1835568653685706,0.6428571939468384,0.6428571939468384,0.4666666666666667,0.18637053455625263,mmlu:anatomy,validation,1.6609914284199476,mistral_7b,choice,choice,,,,
135,0.05984317020133691,0.5925925970077515,0.614814817905426,0.5895454545454546,0.20730881558524236,mmlu:anatomy,test,15.08069071546197,mistral_7b,choice,choice,,,,
16,0.1783251389861107,0.6875,0.6875,0.6272727272727272,0.2326948381960392,mmlu:astronomy,validation,2.9354945346713066,mistral_7b,choice,choice,,,,
152,0.10955119034961648,0.6578947305679321,0.6644737124443054,0.6201923076923077,0.070373609662056,mmlu:astronomy,test,26.09888900257647,mistral_7b,choice,choice,,,,
11,0.31949520111083984,0.5454545617103577,0.5454545617103577,0.8166666666666667,0.30022240768779407,mmlu:business_ethics,validation,2.009846618399024,mistral_7b,choice,choice,,,,
100,0.10927680701017381,0.5899999737739563,0.6100000143051147,0.7579578338156263,0.14060590326786046,mmlu:business_ethics,test,16.702963137999177,mistral_7b,choice,choice,,,,
29,0.22172138711501813,0.6206896305084229,0.6206896305084229,0.5202020202020202,0.21791727789517107,mmlu:clinical_knowledge,validation,3.76567211560905,mistral_7b,choice,choice,,,,
265,0.10839791275420278,0.6792452931404114,0.6716980934143066,0.6115686274509804,0.1524913007358335,mmlu:clinical_knowledge,test,33.1463124435395,mistral_7b,choice,choice,,,,
16,0.22501541674137115,0.625,0.625,0.5416666666666667,0.17031804472208023,mmlu:college_biology,validation,2.4835374299436808,mistral_7b,choice,choice,,,,
144,0.03408770201106867,0.7291666865348816,0.7361111044883728,0.5901098901098901,0.09106030273768635,mmlu:college_biology,test,21.480185570195317,mistral_7b,choice,choice,,,,
8,0.3212546817958355,0.25,0.375,0.5,0.556164376437664,mmlu:college_chemistry,validation,1.6702571418136358,mistral_7b,choice,choice,,,,
100,0.07026322543621061,0.47999998927116394,0.5799999833106995,0.4176682692307692,0.16119016289711002,mmlu:college_chemistry,test,16.811493603512645,mistral_7b,choice,choice,,,,
11,0.09282466227358038,0.4545454680919647,0.5454545617103577,0.7,0.3202857971191406,mmlu:college_computer_science,validation,2.8766074553132057,mistral_7b,choice,choice,,,,
100,0.16932701468467715,0.5299999713897705,0.5299999713897705,0.6272581292653552,0.17079252839088438,mmlu:college_computer_science,test,25.367181373760104,mistral_7b,choice,choice,,,,
11,0.051033290949734786,0.27272728085517883,0.5454545617103577,0.7916666666666666,0.27466199614784936,mmlu:college_mathematics,validation,2.087343730032444,mistral_7b,choice,choice,,,,
100,0.06600264132022857,0.35999998450279236,0.44999998807907104,0.6085069444444444,0.17785908460617064,mmlu:college_mathematics,test,16.95963209681213,mistral_7b,choice,choice,,,,
22,0.23622213033112613,0.5454545617103577,0.5454545617103577,0.5791666666666666,0.19627729058265683,mmlu:college_medicine,validation,3.544885288923979,mistral_7b,choice,choice,,,,
173,0.03520325050188628,0.6300578117370605,0.589595377445221,0.4773509174311926,0.1121659885252142,mmlu:college_medicine,test,37.52474388293922,mistral_7b,choice,choice,,,,
11,0.27628340233456006,0.3636363744735718,0.6363636255264282,1.0,0.3782675428823991,mmlu:college_physics,validation,1.7913411818444729,mistral_7b,choice,choice,,,,
102,0.12169014063535953,0.4313725531101227,0.5,0.6108934169278997,0.16136324522542017,mmlu:college_physics,test,14.445480903610587,mistral_7b,choice,choice,,,,
11,0.37010120803659613,0.8181818723678589,0.8181818723678589,0.5555555555555556,0.24254739826375787,mmlu:computer_security,validation,1.7224733754992485,mistral_7b,choice,choice,,,,
100,0.06847967416048052,0.7799999713897705,0.7400000095367432,0.5174825174825175,0.1016157132387161,mmlu:computer_security,test,12.308787982910872,mistral_7b,choice,choice,,,,
26,0.2383161359108411,0.42307692766189575,0.5384615659713745,0.8939393939393939,0.1742307795928075,mmlu:conceptual_physics,validation,2.589634971693158,mistral_7b,choice,choice,,,,
235,0.05404688944207862,0.5957446694374084,0.5999999642372131,0.586390977443609,0.11737967729568481,mmlu:conceptual_physics,test,21.75584322400391,mistral_7b,choice,choice,,,,
12,0.23043375213940936,0.6666666865348816,0.6666666865348816,0.59375,0.2556956559419632,mmlu:econometrics,validation,2.4929291997104883,mistral_7b,choice,choice,,,,
114,0.09663674026204828,0.5,0.4912280738353729,0.5161588180978762,0.31840461440253676,mmlu:econometrics,test,20.981066923588514,mistral_7b,choice,choice,,,,
16,0.2605411633849144,0.625,0.625,0.7666666666666666,0.1896369904279709,mmlu:electrical_engineering,validation,2.255068276077509,mistral_7b,choice,choice,,,,
145,0.05320434755292433,0.5793103575706482,0.5586206912994385,0.5831381733021077,0.23745484763178337,mmlu:electrical_engineering,test,18.364578548818827,mistral_7b,choice,choice,,,,
41,0.049774552990750565,0.4146341383457184,0.4878048598766327,0.48774509803921573,0.3004616702475199,mmlu:elementary_mathematics,validation,6.790368843823671,mistral_7b,choice,choice,,,,
378,0.07989112654375653,0.4047618806362152,0.4179894030094147,0.5417429193899781,0.2525477781497612,mmlu:elementary_mathematics,test,59.55281925946474,mistral_7b,choice,choice,,,,
14,0.30376316606998444,0.2857142984867096,0.4285714626312256,0.5625,0.3311396028314318,mmlu:formal_logic,validation,2.842442937195301,mistral_7b,choice,choice,,,,
126,0.06206903973269083,0.4206349551677704,0.444444477558136,0.6496510726285862,0.2725519079064566,mmlu:formal_logic,test,24.13858837634325,mistral_7b,choice,choice,,,,
10,0.18225549161434174,0.6000000238418579,0.6000000238418579,0.5208333333333333,0.2953503608703613,mmlu:global_facts,validation,1.4831105377525091,mistral_7b,choice,choice,,,,
100,0.06240843772888184,0.3100000023841858,0.3999999761581421,0.4939223936418887,0.29958007752895355,mmlu:global_facts,test,12.530358204618096,mistral_7b,choice,choice,,,,
32,0.11162619106471536,0.6875,0.6875,0.5659090909090909,0.14978738129138947,mmlu:high_school_biology,validation,5.120758695527911,mistral_7b,choice,choice,,,,
310,0.04330246621562587,0.7645161151885986,0.7709677219390869,0.5714409571701058,0.08025078292815915,mmlu:high_school_biology,test,48.78931640088558,mistral_7b,choice,choice,,,,
22,0.30696401270953094,0.3636363744735718,0.5454545617103577,0.6607142857142858,0.16360049356113782,mmlu:high_school_chemistry,validation,3.6788289099931717,mistral_7b,choice,choice,,,,
203,0.03920718601771762,0.517241358757019,0.5566502213478088,0.6228862973760934,0.08106162659640383,mmlu:high_school_chemistry,test,31.045855531468987,mistral_7b,choice,choice,,,,
9,0.30275444189707434,0.6666666865348816,0.7777777910232544,0.6666666666666666,0.07566540108786687,mmlu:high_school_computer_science,validation,2.8117903899401426,mistral_7b,choice,choice,,,,
100,0.1372287786006927,0.7199999690055847,0.6699999570846558,0.7408234126984127,0.07905998885631561,mmlu:high_school_computer_science,test,28.972023198381066,mistral_7b,choice,choice,,,,
22,0.14793096347288653,0.8181818723678589,0.8181818723678589,0.4722222222222222,0.1700648313218897,mmlu:high_school_geography,validation,2.6231478732079268,mistral_7b,choice,choice,,,,
198,0.037832208354063694,0.7979797720909119,0.7676767706871033,0.49422468354430377,0.06770143244001602,mmlu:high_school_geography,test,22.631773486733437,mistral_7b,choice,choice,,,,
21,0.16884195236932664,0.8571428656578064,0.8095238208770752,0.5,0.08704302424476262,mmlu:high_school_government_and_politics,validation,2.9517202749848366,mistral_7b,choice,choice,,,,
193,0.06942348035506017,0.8860103487968445,0.8704662919044495,0.5729665071770335,0.07516414235910598,mmlu:high_school_government_and_politics,test,25.770477443933487,mistral_7b,choice,choice,,,,
43,0.06279944264611534,0.6511628031730652,0.604651153087616,0.49642857142857144,0.1885420610738355,mmlu:high_school_macroeconomics,validation,5.073761615902185,mistral_7b,choice,choice,,,,
390,0.08860078706191137,0.6589744091033936,0.6461538672447205,0.6359234662531816,0.1346188954817943,mmlu:high_school_macroeconomics,test,45.03279947116971,mistral_7b,choice,choice,,,,
29,0.09213767791616503,0.20689654350280762,0.5517241358757019,0.41666666666666663,0.09354033963433629,mmlu:high_school_mathematics,validation,4.563051458448172,mistral_7b,choice,choice,,,,
270,0.060439260028026735,0.3037036955356598,0.5370370149612427,0.5469966268811624,0.07312640923040883,mmlu:high_school_mathematics,test,40.684496611356735,mistral_7b,choice,choice,,,,
26,0.1719460109105477,0.7692307829856873,0.7692307829856873,0.6208333333333333,0.10311524913861202,mmlu:high_school_microeconomics,validation,3.180626632645726,mistral_7b,choice,choice,,,,
238,0.054085744654431035,0.6638655662536621,0.6512605547904968,0.5417721518987342,0.125189289826305,mmlu:high_school_microeconomics,test,28.601586742326617,mistral_7b,choice,choice,,,,
17,0.20823682406369376,0.23529411852359772,0.29411765933036804,0.375,0.39064111429102283,mmlu:high_school_physics,validation,3.076137373223901,mistral_7b,choice,choice,,,,
151,0.07560721710817704,0.38410595059394836,0.430463582277298,0.5439377085650723,0.2471971946046842,mmlu:high_school_physics,test,25.247134815901518,mistral_7b,choice,choice,,,,
60,0.07522060424089431,0.8833333849906921,0.8500000238418579,0.5606469002695418,0.06413541634877523,mmlu:high_school_psychology,validation,8.851629773154855,mistral_7b,choice,choice,,,,
545,0.03199428839421052,0.8165137767791748,0.8110091686248779,0.5747977528089888,0.04764671697529085,mmlu:high_school_psychology,test,81.02610965818167,mistral_7b,choice,choice,,,,
23,0.10689268682314002,0.47826087474823,0.5652173757553101,0.8333333333333334,0.19279189990914386,mmlu:high_school_statistics,validation,5.893725519999862,mistral_7b,choice,choice,,,,
216,0.09523931835536603,0.5833333134651184,0.6018518805503845,0.5820105820105821,0.16417051437828276,mmlu:high_school_statistics,test,54.95546276308596,mistral_7b,choice,choice,,,,
22,0.17360202019864862,0.7727273106575012,0.4545454680919647,0.2647058823529411,0.24106132442300968,mmlu:high_school_us_history,validation,21.047944692894816,mistral_7b,choice,choice,,,,
204,0.04227642948720971,0.779411792755127,0.6764706373214722,0.47037037037037044,0.07136058427539527,mmlu:high_school_us_history,test,187.12703883834183,mistral_7b,choice,choice,,,,
23,0.1808033831741499,0.739130437374115,0.739130437374115,0.6274509803921569,0.13215090658353723,mmlu:human_aging,validation,2.3508205469697714,mistral_7b,choice,choice,,,,
223,0.08314872736888082,0.6995515823364258,0.6995515823364258,0.6059127439724454,0.10193119214789212,mmlu:human_aging,test,21.33404402807355,mistral_7b,choice,choice,,,,
12,0.13673166185617447,0.5833333730697632,0.5,0.5571428571428572,0.2636905064185461,mmlu:human_sexuality,validation,1.475249271839857,mistral_7b,choice,choice,,,,
131,0.10904413757433419,0.8015267252922058,0.7709923982620239,0.5521978021978022,0.05224548223364442,mmlu:human_sexuality,test,14.714492950588465,mistral_7b,choice,choice,,,,
13,0.1028058070402879,0.9230769872665405,0.9230769872665405,0.3333333333333333,0.17453907544796282,mmlu:international_law,validation,2.6183505710214376,mistral_7b,choice,choice,,,,
121,0.04676493534371872,0.7933883666992188,0.8016528487205505,0.5410416666666666,0.10406087548279563,mmlu:international_law,test,22.419684687629342,mistral_7b,choice,choice,,,,
11,0.2665528492494063,0.6363636255264282,0.6363636255264282,0.3571428571428571,0.24069555781104346,mmlu:jurisprudence,validation,1.5340539831668139,mistral_7b,choice,choice,,,,
108,0.11025176721590538,0.8148148059844971,0.7777777910232544,0.6446022727272727,0.0803541016799432,mmlu:jurisprudence,test,13.26057393476367,mistral_7b,choice,choice,,,,
18,0.2051447348462211,0.7222222089767456,0.7222222089767456,0.4538461538461539,0.287627637386322,mmlu:logical_fallacies,validation,2.461423924192786,mistral_7b,choice,choice,,,,
163,0.09089494062347649,0.7975459694862366,0.7975459694862366,0.6298368298368298,0.05313874168630026,mmlu:logical_fallacies,test,21.13742172718048,mistral_7b,choice,choice,,,,
11,0.19851565631953155,0.27272728085517883,0.3636363744735718,0.35416666666666663,0.3788028955459595,mmlu:machine_learning,validation,2.2875126376748085,mistral_7b,choice,choice,,,,
112,0.13035781096134869,0.3750000298023224,0.6428571939468384,0.6370748299319727,0.12041021351303373,mmlu:machine_learning,test,21.80235432460904,mistral_7b,choice,choice,,,,
11,0.16422389854084363,0.9090909361839294,0.8181818723678589,0.3,0.10331737453287299,mmlu:management,validation,1.1376991048455238,mistral_7b,choice,choice,,,,
103,0.04608036650037302,0.7961165308952332,0.7864077687263489,0.6646341463414634,0.04925043779669456,mmlu:management,test,9.084560563787818,mistral_7b,choice,choice,,,,
25,0.0804211163520813,0.8799999952316284,0.8399999737739563,0.7575757575757576,0.14354984760284425,mmlu:marketing,validation,3.2328122667968273,mistral_7b,choice,choice,,,,
234,0.048388646326513365,0.8675214052200317,0.8504273891448975,0.632369299221357,0.09937860593836532,mmlu:marketing,test,28.22134805098176,mistral_7b,choice,choice,,,,
11,0.13245385885238647,1.0,1.0,,0.11581515724008734,mmlu:medical_genetics,validation,1.444713430479169,mistral_7b,choice,choice,,,,
100,0.1275368383526802,0.7299999594688416,0.7400000095367432,0.6453576864535768,0.13707499384880065,mmlu:medical_genetics,test,11.003864705562592,mistral_7b,choice,choice,,,,
38,0.15920385875199972,0.6315789222717285,0.6315789222717285,0.7336309523809523,0.2094282366727528,mmlu:moral_disputes,validation,5.526718413457274,mistral_7b,choice,choice,,,,
346,0.05872425678148434,0.7052022814750671,0.7023121118545532,0.5490798778527803,0.14493053927586946,mmlu:moral_disputes,test,48.79488578811288,mistral_7b,choice,choice,,,,
33,0.14384670691056692,0.7575757503509521,0.7878788113594055,0.79,0.06365645473653622,mmlu:nutrition,validation,5.880208600312471,mistral_7b,choice,choice,,,,
306,0.09811726884514678,0.7450980544090271,0.7320261597633362,0.5859480431848852,0.0795474796513327,mmlu:nutrition,test,54.28094092383981,mistral_7b,choice,choice,,,,
34,0.20319585414493785,0.7352941036224365,0.7058823704719543,0.5177777777777779,0.1849233420456157,mmlu:philosophy,validation,3.8656779192388058,mistral_7b,choice,choice,,,,
311,0.03994166697719857,0.7266880869865417,0.7234726548194885,0.5760020822488288,0.1374408077580369,mmlu:philosophy,test,33.20808542706072,mistral_7b,choice,choice,,,,
35,0.18462679471288407,0.5714285969734192,0.5714285969734192,0.5816666666666667,0.23036548580442157,mmlu:prehistory,validation,5.812522996217012,mistral_7b,choice,choice,,,,
324,0.024386772219045665,0.7407407760620117,0.7160493731498718,0.5671875,0.08064850484147483,mmlu:prehistory,test,50.83476986736059,mistral_7b,choice,choice,,,,
69,0.06908084905665852,0.7101449370384216,0.7101449370384216,0.6331632653061225,0.12023670431496442,mmlu:professional_psychology,validation,12.40618341974914,mistral_7b,choice,choice,,,,
612,0.04635619328302495,0.6781045794487,0.6764705777168274,0.5836584918353617,0.13109412195246203,mmlu:professional_psychology,test,103.87540796026587,mistral_7b,choice,choice,,,,
12,0.22901735206445056,0.5,0.5,0.36111111111111116,0.43406233191490173,mmlu:public_relations,validation,1.8113422747701406,mistral_7b,choice,choice,,,,
110,0.0801185502247377,0.6545454263687134,0.6909090876579285,0.6469298245614036,0.10173827734860506,mmlu:public_relations,test,13.85266643948853,mistral_7b,choice,choice,,,,
27,0.1348053150706821,0.7037037014961243,0.7037037014961243,0.5493421052631579,0.09241924683252972,mmlu:security_studies,validation,10.848888706415892,mistral_7b,choice,choice,,,,
245,0.08448417259722338,0.7551019787788391,0.7387754917144775,0.6644594594594594,0.06371203855592376,mmlu:security_studies,test,98.07442571781576,mistral_7b,choice,choice,,,,
22,0.11663733287291093,0.8636363744735718,0.8636363744735718,0.4035087719298246,0.1431922668760473,mmlu:sociology,validation,2.944298719987273,mistral_7b,choice,choice,,,,
201,0.026367466841171007,0.8407959938049316,0.8358208537101746,0.564164201183432,0.08233885593082182,mmlu:sociology,test,25.59774566628039,mistral_7b,choice,choice,,,,
11,0.19001150131225586,0.9090909361839294,0.9090909361839294,0.9,0.19433100657029587,mmlu:us_foreign_policy,validation,1.5766851156949997,mistral_7b,choice,choice,,,,
100,0.08791743367910385,0.8799999952316284,0.8499999642372131,0.6775568181818182,0.038295845389366145,mmlu:us_foreign_policy,test,12.366884022951126,mistral_7b,choice,choice,,,,
18,0.282570931646559,0.6666666865348816,0.6111111044883728,0.6597222222222222,0.16530361771583554,mmlu:virology,validation,2.647335885092616,mistral_7b,choice,choice,,,,
166,0.21802043340292318,0.5301204919815063,0.5963855385780334,0.6095571095571097,0.13790480954101286,mmlu:virology,test,18.216721018776298,mistral_7b,choice,choice,,,,
19,0.2028370546667199,0.8947368264198303,0.8421052694320679,0.7352941176470589,0.13989224873091047,mmlu:world_religions,validation,1.7437080182135105,mistral_7b,choice,choice,,,,
171,0.0540240089795743,0.8187134265899658,0.7660818696022034,0.6091013824884793,0.046970549034096344,mmlu:world_religions,test,14.084186451509595,mistral_7b,choice,choice,,,,
11,0.29379816759716376,0.4545454680919647,0.5454545617103577,0.36666666666666664,0.31219571286981757,mmlu:abstract_algebra,validation,5.198338378220797,llama2_13b_chat,oe,choice,,,,
100,0.16200531616806985,0.28999999165534973,0.6800000071525574,0.4176784847013113,0.17518055379390718,mmlu:abstract_algebra,test,19.170281674712896,llama2_13b_chat,oe,choice,,,,
14,0.20662898250988554,0.5714285969734192,0.5,0.45833333333333337,0.19871469906398226,mmlu:anatomy,validation,2.9398111552000046,llama2_13b_chat,oe,choice,,,,
135,0.19448365834024214,0.5111110806465149,0.555555522441864,0.358695652173913,0.12440892546265213,mmlu:anatomy,test,27.445794876664877,llama2_13b_chat,oe,choice,,,,
16,0.11424661241471767,0.625,0.375,0.35,0.4225494898855686,mmlu:astronomy,validation,5.252742558717728,llama2_13b_chat,oe,choice,,,,
152,0.245416279097921,0.5657894611358643,0.46710526943206787,0.4047744890768147,0.2726804159189526,mmlu:astronomy,test,47.340528037399054,llama2_13b_chat,oe,choice,,,,
11,0.22440953959118237,0.5454545617103577,0.6363636255264282,0.23333333333333328,0.3563687638802962,mmlu:business_ethics,validation,3.519288543611765,llama2_13b_chat,oe,choice,,,,
100,0.24410267770290378,0.5299999713897705,0.550000011920929,0.3133279807306303,0.13973982572555543,mmlu:business_ethics,test,30.94037863984704,llama2_13b_chat,oe,choice,,,,
29,0.3209612348984028,0.517241358757019,0.48275861144065857,0.5619047619047619,0.19303366644629116,mmlu:clinical_knowledge,validation,7.0524671748280525,llama2_13b_chat,oe,choice,,,,
265,0.20924414148870502,0.5660377740859985,0.5471698045730591,0.43399999999999994,0.12986106220281352,mmlu:clinical_knowledge,test,61.09653804078698,llama2_13b_chat,oe,choice,,,,
16,0.20605568774044514,0.5625,0.5,0.14285714285714285,0.27070551738142967,mmlu:college_biology,validation,4.373937211930752,llama2_13b_chat,oe,choice,,,,
144,0.1936526567571693,0.5833333134651184,0.4166666567325592,0.4384920634920635,0.3474814113643434,mmlu:college_biology,test,38.691932272166014,llama2_13b_chat,oe,choice,,,,
8,0.5105344615876675,0.125,0.875,0.4285714285714286,0.23351062834262848,mmlu:college_chemistry,validation,2.599870540201664,llama2_13b_chat,oe,choice,,,,
100,0.2275681433081627,0.3700000047683716,0.6599999666213989,0.38309738309738317,0.07732208967208866,mmlu:college_chemistry,test,29.5001456476748,llama2_13b_chat,oe,choice,,,,
11,0.15991395170038397,0.5454545617103577,0.4545454680919647,0.39999999999999997,0.34834336150776257,mmlu:college_computer_science,validation,4.824839178472757,llama2_13b_chat,oe,choice,,,,
100,0.15642848163843157,0.5399999618530273,0.4699999988079071,0.4514895330112721,0.3540905356407166,mmlu:college_computer_science,test,43.44807990267873,llama2_13b_chat,oe,choice,,,,
11,0.25650960748845886,0.27272728085517883,0.6363636255264282,0.625,0.046377918936989504,mmlu:college_mathematics,validation,3.5301680639386177,llama2_13b_chat,oe,choice,,,,
100,0.2351979598402977,0.3499999940395355,0.6299999952316284,0.4953846153846153,0.053300543427467345,mmlu:college_mathematics,test,29.774616237729788,llama2_13b_chat,oe,choice,,,,
22,0.44382848387414764,0.3636363744735718,0.5909091234207153,0.4375,0.20529299432581122,mmlu:college_medicine,validation,6.453275728970766,llama2_13b_chat,oe,choice,,,,
173,0.2904427091165775,0.4624277353286743,0.5780346393585205,0.3092741935483871,0.18214272246884472,mmlu:college_medicine,test,58.157692931592464,llama2_13b_chat,oe,choice,,,,
11,0.3878866867585615,0.4545454680919647,0.5454545617103577,0.3666666666666667,0.3320143547925082,mmlu:college_physics,validation,2.9438081569969654,llama2_13b_chat,oe,choice,,,,
102,0.370677268096045,0.2450980544090271,0.7450980544090271,0.5329870129870129,0.09413741266026217,mmlu:college_physics,test,26.591864865273237,llama2_13b_chat,oe,choice,,,,
11,0.45247231830250134,0.6363636255264282,0.4545454680919647,0.6428571428571428,0.3051239089532332,mmlu:computer_security,validation,2.8052608482539654,llama2_13b_chat,oe,choice,,,,
100,0.2238504680991173,0.6499999761581421,0.4099999964237213,0.3967032967032967,0.3071894013881684,mmlu:computer_security,test,22.06017879769206,llama2_13b_chat,oe,choice,,,,
26,0.31387063173147345,0.46153849363327026,0.5384615659713745,0.375,0.28307138268764204,mmlu:conceptual_physics,validation,4.561331678181887,llama2_13b_chat,oe,choice,,,,
235,0.3247843713202375,0.4127659499645233,0.5957446694374084,0.4541685342895562,0.17817061454691785,mmlu:conceptual_physics,test,39.90816122666001,llama2_13b_chat,oe,choice,,,,
12,0.49937231590350467,0.3333333432674408,0.6666666865348816,0.6875,0.2262109120686849,mmlu:econometrics,validation,4.056535724550486,llama2_13b_chat,oe,choice,,,,
114,0.30435455237564285,0.31578946113586426,0.6754385828971863,0.47008547008547014,0.12555696723753945,mmlu:econometrics,test,36.61005899682641,llama2_13b_chat,oe,choice,,,,
16,0.39805904775857925,0.5,0.5,0.625,0.3362521752715111,mmlu:electrical_engineering,validation,3.960423693060875,llama2_13b_chat,oe,choice,,,,
145,0.2309398133179237,0.4965517222881317,0.5034482479095459,0.36891171993911726,0.2971892221220608,mmlu:electrical_engineering,test,33.57189712673426,llama2_13b_chat,oe,choice,,,,
41,0.25017098609994093,0.4146341383457184,0.5853658318519592,0.47058823529411764,0.24119095976759747,mmlu:elementary_mathematics,validation,12.127666346728802,llama2_13b_chat,oe,choice,,,,
378,0.31418251179198114,0.3253968060016632,0.6825396418571472,0.5035708592380042,0.14817997214024659,mmlu:elementary_mathematics,test,107.80056589841843,llama2_13b_chat,oe,choice,,,,
14,0.5272892628397261,0.0714285746216774,0.8571429252624512,0.7692307692307692,0.19083449670246672,mmlu:formal_logic,validation,4.588090013712645,llama2_13b_chat,oe,choice,,,,
126,0.32209860214165287,0.2857142984867096,0.7222222685813904,0.3722222222222222,0.09472594847754824,mmlu:formal_logic,test,40.71548333391547,llama2_13b_chat,oe,choice,,,,
10,0.47349956631660467,0.20000000298023224,0.800000011920929,0.25,0.2074462294578552,mmlu:global_facts,validation,2.538747686892748,llama2_13b_chat,oe,choice,,,,
100,0.3165890657901764,0.3100000023841858,0.6899999976158142,0.47662459093034126,0.20946682810783385,mmlu:global_facts,test,23.16781732812524,llama2_13b_chat,oe,choice,,,,
32,0.2618219470605254,0.5625,0.4375,0.37698412698412703,0.32229647785425186,mmlu:high_school_biology,validation,9.207829594612122,llama2_13b_chat,oe,choice,,,,
310,0.1704712515877139,0.6774193644523621,0.36451610922813416,0.37078571428571433,0.38115269868604607,mmlu:high_school_biology,test,88.33951053395867,llama2_13b_chat,oe,choice,,,,
22,0.30064125359058386,0.40909093618392944,0.5909091234207153,0.37606837606837606,0.15398595549843527,mmlu:high_school_chemistry,validation,6.434506952762604,llama2_13b_chat,oe,choice,,,,
203,0.2409859713662434,0.41379308700561523,0.5960590839385986,0.46218487394957986,0.21922680574097658,mmlu:high_school_chemistry,test,55.46366535127163,llama2_13b_chat,oe,choice,,,,
9,0.2520365847481621,0.7777777910232544,0.4444444477558136,0.42857142857142855,0.25367173883650035,mmlu:high_school_computer_science,validation,4.582775354385376,llama2_13b_chat,oe,choice,,,,
100,0.1541334843635559,0.5999999642372131,0.4699999988079071,0.42875,0.18929738223552706,mmlu:high_school_computer_science,test,48.992039665579796,llama2_13b_chat,oe,choice,,,,
22,0.15720224651423365,0.7272727489471436,0.27272728085517883,0.23958333333333331,0.4843720387328755,mmlu:high_school_geography,validation,5.017393745481968,llama2_13b_chat,oe,choice,,,,
198,0.18159390278536866,0.7070707082748413,0.3333333432674408,0.3873152709359606,0.4691606862376435,mmlu:high_school_geography,test,42.89780133217573,llama2_13b_chat,oe,choice,,,,
21,0.22747943231037682,0.7142857313156128,0.2857142984867096,0.13333333333333336,0.5891282785506475,mmlu:high_school_government_and_politics,validation,5.555736429989338,llama2_13b_chat,oe,choice,,,,
193,0.1270896543801757,0.7927460670471191,0.21243523061275482,0.2926470588235294,0.6640584808557144,mmlu:high_school_government_and_politics,test,48.28995756432414,llama2_13b_chat,oe,choice,,,,
43,0.2938208836455678,0.4651162624359131,0.5348837375640869,0.29130434782608694,0.1949835877085841,mmlu:high_school_macroeconomics,validation,9.486730828881264,llama2_13b_chat,oe,choice,,,,
390,0.23552503035618708,0.535897433757782,0.482051283121109,0.4858441936080784,0.25669688888085196,mmlu:high_school_macroeconomics,test,86.27934901043773,llama2_13b_chat,oe,choice,,,,
29,0.23744304940618322,0.27586206793785095,0.7241379022598267,0.5059523809523809,0.13588570315262366,mmlu:high_school_mathematics,validation,8.20152760669589,llama2_13b_chat,oe,choice,,,,
270,0.2369200842248069,0.28148147463798523,0.6925925612449646,0.4300732501356484,0.032060634648358385,mmlu:high_school_mathematics,test,73.74104495346546,llama2_13b_chat,oe,choice,,,,
26,0.21208596000304591,0.6153846383094788,0.5384615659713745,0.26874999999999993,0.14550597851093,mmlu:high_school_microeconomics,validation,5.883623611181974,llama2_13b_chat,oe,choice,,,,
238,0.1999973366741373,0.5840336680412292,0.4663865864276886,0.5219460795000364,0.23096290982070083,mmlu:high_school_microeconomics,test,53.05510015413165,llama2_13b_chat,oe,choice,,,,
17,0.5390769944471472,0.29411765933036804,0.7058823704719543,0.2666666666666667,0.15344891478033626,mmlu:high_school_physics,validation,5.305295392870903,llama2_13b_chat,oe,choice,,,,
151,0.3287348271600458,0.33774834871292114,0.6622516512870789,0.5568627450980392,0.1594435004209051,mmlu:high_school_physics,test,44.56566919758916,llama2_13b_chat,oe,choice,,,,
60,0.11621293028195703,0.8000000715255737,0.20000001788139343,0.2517361111111111,0.6194298644860585,mmlu:high_school_psychology,validation,16.814131181687117,llama2_13b_chat,oe,choice,,,,
545,0.1283313002608238,0.752293586730957,0.2568807303905487,0.37221318879855464,0.5742078782221594,mmlu:high_school_psychology,test,152.41672233492136,llama2_13b_chat,oe,choice,,,,
23,0.31580342028452013,0.3478260934352875,0.695652186870575,0.43333333333333335,0.17299759906271228,mmlu:high_school_statistics,validation,9.71171747148037,llama2_13b_chat,oe,choice,,,,
216,0.24046254544346418,0.36574074625968933,0.6342592835426331,0.4749145338630694,0.18136956791083023,mmlu:high_school_statistics,test,93.6129772476852,llama2_13b_chat,oe,choice,,,,
22,0.2284643677147952,0.7272727489471436,0.3181818127632141,0.5104166666666667,0.5439069677482952,mmlu:high_school_us_history,validation,34.65951406955719,llama2_13b_chat,oe,choice,,,,
204,0.14268829118387372,0.75,0.27450981736183167,0.3908753043701141,0.5354650362449533,mmlu:high_school_us_history,test,313.5941172130406,llama2_13b_chat,oe,choice,,,,
23,0.23342548505119656,0.695652186870575,0.3478260934352875,0.30357142857142855,0.4105644355649533,mmlu:human_aging,validation,4.231298577040434,llama2_13b_chat,oe,choice,,,,
223,0.1750242027199322,0.6457399129867554,0.39910316467285156,0.4075246132208158,0.3566072390753058,mmlu:human_aging,test,39.53821391239762,llama2_13b_chat,oe,choice,,,,
12,0.23100995272397995,0.4166666865348816,0.5833333730697632,0.35714285714285715,0.25844353437423706,mmlu:human_sexuality,validation,2.4266943521797657,llama2_13b_chat,oe,choice,,,,
131,0.20160232518465465,0.6106870174407959,0.48091602325439453,0.4540441176470588,0.20647428736431908,mmlu:human_sexuality,test,26.920951146632433,llama2_13b_chat,oe,choice,,,,
13,0.09920215606689457,0.8461538553237915,0.5384615659713745,0.045454545454545456,0.13469212330304658,mmlu:international_law,validation,4.659398775547743,llama2_13b_chat,oe,choice,,,,
121,0.14776173135465825,0.7520660758018494,0.3636363446712494,0.33205128205128204,0.3349824567471654,mmlu:international_law,test,40.03110606595874,llama2_13b_chat,oe,choice,,,,
11,0.2845090708949349,0.4545454680919647,0.5454545617103577,0.06666666666666668,0.3289166038686579,mmlu:jurisprudence,validation,2.53644410520792,llama2_13b_chat,oe,choice,,,,
108,0.07530087784484582,0.7685185074806213,0.25,0.30650602409638555,0.5267622586753633,mmlu:jurisprudence,test,24.160006545484066,llama2_13b_chat,oe,choice,,,,
18,0.2260679933759901,0.7222222089767456,0.4444444477558136,0.38461538461538464,0.32972080177730984,mmlu:logical_fallacies,validation,4.452678423374891,llama2_13b_chat,oe,choice,,,,
163,0.18132933681727922,0.6748465895652771,0.4417177736759186,0.3658662092624357,0.23378210601631116,mmlu:logical_fallacies,test,39.413999043405056,llama2_13b_chat,oe,choice,,,,
11,0.3903419483791698,0.27272728085517883,0.8181818723678589,0.29166666666666663,0.12581410733136264,mmlu:machine_learning,validation,3.7626173235476017,llama2_13b_chat,oe,choice,,,,
112,0.42653715983033186,0.2946428656578064,0.7321428656578064,0.4102416570771001,0.05864179027932032,mmlu:machine_learning,test,37.48653980344534,llama2_13b_chat,oe,choice,,,,
11,0.19820608875968238,0.8181818723678589,0.1818181872367859,0.2222222222222222,0.5276034799489109,mmlu:management,validation,1.9547881931066513,llama2_13b_chat,oe,choice,,,,
103,0.12850591685008078,0.7281553745269775,0.33980584144592285,0.3545238095238095,0.38572722384073194,mmlu:management,test,16.8260360956192,llama2_13b_chat,oe,choice,,,,
25,0.1604520511627197,0.7999999523162842,0.3199999928474426,0.31999999999999995,0.4220872688293458,mmlu:marketing,validation,5.925020322203636,llama2_13b_chat,oe,choice,,,,
234,0.0556038345536615,0.811965823173523,0.25641027092933655,0.27547846889952154,0.4702544423759493,mmlu:marketing,test,53.241408951580524,llama2_13b_chat,oe,choice,,,,
11,0.19195573980158026,0.7272727489471436,0.3636363744735718,0.5,0.31663800911469897,mmlu:medical_genetics,validation,2.4507708325982094,llama2_13b_chat,oe,choice,,,,
100,0.2222991907596588,0.5699999928474426,0.5099999904632568,0.4434924520603835,0.15204430699348448,mmlu:medical_genetics,test,20.130778662860394,llama2_13b_chat,oe,choice,,,,
38,0.274641951448039,0.4736842215061188,0.5263158082962036,0.25277777777777777,0.2496017719569959,mmlu:moral_disputes,validation,9.805226135998964,llama2_13b_chat,oe,choice,,,,
346,0.2104136041134079,0.6011560559272766,0.4017340838909149,0.4153950668896321,0.39403786686803566,mmlu:moral_disputes,test,89.43510970845819,llama2_13b_chat,oe,choice,,,,
33,0.12391907067009898,0.7272727489471436,0.3333333432674408,0.39583333333333337,0.41207418116656214,mmlu:nutrition,validation,10.593436297029257,llama2_13b_chat,oe,choice,,,,
306,0.20404470599944294,0.5947712659835815,0.44117647409439087,0.36888514711095355,0.31549357627731534,mmlu:nutrition,test,98.46625041216612,llama2_13b_chat,oe,choice,,,,
34,0.3614660878391827,0.5588235259056091,0.5882353186607361,0.36140350877192984,0.17652074905002818,mmlu:philosophy,validation,6.661809805780649,llama2_13b_chat,oe,choice,,,,
311,0.2685818516939783,0.6141479015350342,0.469453364610672,0.3780759162303665,0.1854926433977207,mmlu:philosophy,test,59.447767812758684,llama2_13b_chat,oe,choice,,,,
35,0.24310854503086635,0.6285714507102966,0.37142857909202576,0.5104895104895105,0.38591395616531377,mmlu:prehistory,validation,10.410162340849638,llama2_13b_chat,oe,choice,,,,
324,0.2470247510958601,0.5956790447235107,0.42901235818862915,0.3168729976664162,0.3437725364426036,mmlu:prehistory,test,94.11062097921968,llama2_13b_chat,oe,choice,,,,
69,0.20283278304597607,0.6086956858634949,0.4057971239089966,0.4986772486772487,0.3641571048377216,mmlu:professional_psychology,validation,21.733646746724844,llama2_13b_chat,oe,choice,,,,
612,0.23851665124004962,0.5522875785827637,0.46405228972435,0.40802487798557424,0.3065885119383631,mmlu:professional_psychology,test,185.95844100788236,llama2_13b_chat,oe,choice,,,,
12,0.4481361309687297,0.5,0.5,0.2777777777777778,0.30470193425814307,mmlu:public_relations,validation,3.1036848053336143,llama2_13b_chat,oe,choice,,,,
110,0.16180461211638014,0.6363636255264282,0.37272727489471436,0.34535714285714286,0.45423684716224666,mmlu:public_relations,test,25.705262944102287,llama2_13b_chat,oe,choice,,,,
27,0.34522028322573056,0.5555555820465088,0.48148149251937866,0.46111111111111114,0.21446183434239138,mmlu:security_studies,validation,18.73841066285968,llama2_13b_chat,oe,choice,,,,
245,0.22966081475724975,0.6408162713050842,0.5265305638313293,0.3440938042848871,0.15160523190790295,mmlu:security_studies,test,175.17720142379403,llama2_13b_chat,oe,choice,,,,
22,0.11438660730015147,0.8181818723678589,0.1818181872367859,0.3888888888888889,0.634815048087727,mmlu:sociology,validation,5.308673087507486,llama2_13b_chat,oe,choice,,,,
201,0.1654659453316114,0.7661691308021545,0.24378108978271484,0.364741641337386,0.5692778662662601,mmlu:sociology,test,48.170089691877365,llama2_13b_chat,oe,choice,,,,
11,0.09280334277586508,0.9090909361839294,0.09090909361839294,0.0,0.6974653655832463,mmlu:us_foreign_policy,validation,2.7017882019281387,llama2_13b_chat,oe,choice,,,,
100,0.12127714633941647,0.7899999618530273,0.20999999344348907,0.4478601567209163,0.5860199165344238,mmlu:us_foreign_policy,test,22.968333061784506,llama2_13b_chat,oe,choice,,,,
18,0.4539293646812439,0.4444444477558136,0.6111111044883728,0.38125,0.1468449996577369,mmlu:virology,validation,4.374044623225927,llama2_13b_chat,oe,choice,,,,
166,0.32515772369252627,0.48192769289016724,0.5240963697433472,0.4334302325581395,0.19873069065162935,mmlu:virology,test,33.48633174225688,llama2_13b_chat,oe,choice,,,,
19,0.18241700686906515,0.7894737124443054,0.21052631735801697,0.2833333333333333,0.5634682053013852,mmlu:world_religions,validation,3.117334108799696,llama2_13b_chat,oe,choice,,,,
171,0.08028784359407706,0.7836257219314575,0.23976609110832214,0.2739007664380798,0.540800146192138,mmlu:world_religions,test,26.931416980922222,llama2_13b_chat,oe,choice,,,,
11,0.7672683298587799,0.09090909361839294,0.7272727489471436,1.0,0.2516044324094599,mmlu:abstract_algebra,validation,3.960143458098173,mistral_7b_instruct,choice,choice,,,,
100,0.39101023793220524,0.3199999928474426,0.5299999713897705,0.4646139705882353,0.15738885104656222,mmlu:abstract_algebra,test,10.961478140205145,mistral_7b_instruct,choice,choice,,,,
14,0.40706101059913635,0.5714285969734192,0.4285714626312256,0.5833333333333334,0.4299791625567845,mmlu:anatomy,validation,1.7408477291464806,mistral_7b_instruct,choice,choice,,,,
135,0.2980206537025946,0.5925925970077515,0.614814817905426,0.5846590909090909,0.2538377620555736,mmlu:anatomy,test,15.283279173076153,mistral_7b_instruct,choice,choice,,,,
16,0.3419100232422352,0.5625,0.5,0.6349206349206349,0.2244230955839157,mmlu:astronomy,validation,2.9884478598833084,mistral_7b_instruct,choice,choice,,,,
152,0.2365347754798437,0.6513158082962036,0.6315789222717285,0.6471316943015057,0.11190959066152574,mmlu:astronomy,test,26.27082497999072,mistral_7b_instruct,choice,choice,,,,
11,0.21197160265662457,0.7272727489471436,0.6363636255264282,0.625,0.2314452637325634,mmlu:business_ethics,validation,2.0200708135962486,mistral_7b_instruct,choice,choice,,,,
100,0.30458214223384855,0.5600000023841858,0.6699999570846558,0.6994724025974026,0.13423118591308594,mmlu:business_ethics,test,16.73324279487133,mistral_7b_instruct,choice,choice,,,,
29,0.28883933404396317,0.6206896305084229,0.6896551847457886,0.7676767676767676,0.13206446376340145,mmlu:clinical_knowledge,validation,3.8334852010011673,mistral_7b_instruct,choice,choice,,,,
265,0.2140062397381045,0.6905660629272461,0.698113203048706,0.6386778621884579,0.07771215168934952,mmlu:clinical_knowledge,test,33.45775172486901,mistral_7b_instruct,choice,choice,,,,
16,0.29021563567221165,0.6875,0.6875,0.7454545454545455,0.11940080672502516,mmlu:college_biology,validation,2.5217899307608604,mistral_7b_instruct,choice,choice,,,,
144,0.2212118407090505,0.7291666865348816,0.6736111044883728,0.6423687423687423,0.1339536789390776,mmlu:college_biology,test,21.76576468348503,mistral_7b_instruct,choice,choice,,,,
8,0.411501407623291,0.5,0.75,0.6875,0.22426582127809525,mmlu:college_chemistry,validation,1.7346821166574955,mistral_7b_instruct,choice,choice,,,,
100,0.3503990235924721,0.4599999785423279,0.6599999666213989,0.6114010437575271,0.10721108853816988,mmlu:college_chemistry,test,16.938480969518423,mistral_7b_instruct,choice,choice,,,,
11,0.31782128323208203,0.5454545617103577,0.7272727489471436,0.39999999999999997,0.4383254863999107,mmlu:college_computer_science,validation,2.9320943914353848,mistral_7b_instruct,choice,choice,,,,
100,0.2193018850684166,0.5199999809265137,0.6299999952316284,0.4697516025641026,0.11873768329620361,mmlu:college_computer_science,test,25.49281843751669,mistral_7b_instruct,choice,choice,,,,
11,0.41145863316275855,0.5454545617103577,0.6363636255264282,0.19999999999999996,0.13451006737622348,mmlu:college_mathematics,validation,2.131516121327877,mistral_7b_instruct,choice,choice,,,,
100,0.36507476270198824,0.3100000023841858,0.7099999785423279,0.4546517064048621,0.07125938653945922,mmlu:college_mathematics,test,17.113737143576145,mistral_7b_instruct,choice,choice,,,,
22,0.29418525099754333,0.6363636255264282,0.6818181872367859,0.41964285714285715,0.11507836255160245,mmlu:college_medicine,validation,3.569988302886486,mistral_7b_instruct,choice,choice,,,,
173,0.3489016642460244,0.5722543001174927,0.6589595079421997,0.5754845754845754,0.09739969128129111,mmlu:college_medicine,test,37.8809662014246,mistral_7b_instruct,choice,choice,,,,
11,0.49320362914692273,0.4545454680919647,0.6363636255264282,0.3333333333333333,0.20898452130230993,mmlu:college_physics,validation,1.7857221439480782,mistral_7b_instruct,choice,choice,,,,
102,0.4078320749834472,0.4117647111415863,0.6666666865348816,0.5025793650793651,0.11424661442345267,mmlu:college_physics,test,14.618509501218796,mistral_7b_instruct,choice,choice,,,,
11,0.32218621535734693,0.6363636255264282,0.4545454680919647,0.4642857142857143,0.2983736450021917,mmlu:computer_security,validation,1.7817952930927277,mistral_7b_instruct,choice,choice,,,,
100,0.19834299713373182,0.7199999690055847,0.6100000143051147,0.5314980158730158,0.1357001221179962,mmlu:computer_security,test,12.400302175432444,mistral_7b_instruct,choice,choice,,,,
26,0.32636356812257034,0.5,0.7307692766189575,0.7869822485207101,0.036223290058282676,mmlu:conceptual_physics,validation,2.6408273950219154,mistral_7b_instruct,choice,choice,,,,
235,0.3299011430841811,0.5106382966041565,0.6255319118499756,0.5357608695652173,0.08796654178741127,mmlu:conceptual_physics,test,22.023205291479826,mistral_7b_instruct,choice,choice,,,,
12,0.23288339376449588,0.6666666865348816,0.8333333730697632,0.6875,0.2177057812611262,mmlu:econometrics,validation,2.499850932508707,mistral_7b_instruct,choice,choice,,,,
114,0.4431572051947577,0.4035087823867798,0.6052631735801697,0.5406010230179028,0.13674135009447735,mmlu:econometrics,test,21.226266846060753,mistral_7b_instruct,choice,choice,,,,
16,0.15209423378109932,0.6875,0.5625,0.5454545454545454,0.21399084478616714,mmlu:electrical_engineering,validation,2.2751850448548794,mistral_7b_instruct,choice,choice,,,,
145,0.27955022063748597,0.565517246723175,0.5793103575706482,0.5461672473867596,0.21409598588943482,mmlu:electrical_engineering,test,18.57333103567362,mistral_7b_instruct,choice,choice,,,,
41,0.5656240008226255,0.2926829159259796,0.5853658318519592,0.4942528735632184,0.14038190754448496,mmlu:elementary_mathematics,validation,6.911024276167154,mistral_7b_instruct,choice,choice,,,,
378,0.41615077727055416,0.3888888657093048,0.6111111044883728,0.5102040816326531,0.09837579774478125,mmlu:elementary_mathematics,test,60.14283852651715,mistral_7b_instruct,choice,choice,,,,
14,0.5280403409685408,0.3571428656578064,0.3571428656578064,0.7111111111111111,0.3229353555611202,mmlu:formal_logic,validation,2.9069313295185566,mistral_7b_instruct,choice,choice,,,,
126,0.443770761291186,0.3730158805847168,0.4682539999485016,0.5297603016428764,0.20156125227610266,mmlu:formal_logic,test,24.304830510169268,mistral_7b_instruct,choice,choice,,,,
10,0.6455999225378037,0.20000000298023224,0.699999988079071,0.875,0.3793914794921875,mmlu:global_facts,validation,1.53199652582407,mistral_7b_instruct,choice,choice,,,,
100,0.4822067002952099,0.35999998450279236,0.4399999976158142,0.45431145431145437,0.24157851219177248,mmlu:global_facts,test,12.689103107899427,mistral_7b_instruct,choice,choice,,,,
32,0.23250380996614692,0.6875,0.75,0.7727272727272727,0.12068723887205125,mmlu:high_school_biology,validation,5.2236901596188545,mistral_7b_instruct,choice,choice,,,,
310,0.19379353061799082,0.7290322184562683,0.7354838848114014,0.6349030762747576,0.09413976900039181,mmlu:high_school_biology,test,49.22937874495983,mistral_7b_instruct,choice,choice,,,,
22,0.3552863326939669,0.5454545617103577,0.5454545617103577,0.4583333333333333,0.2707976319573142,mmlu:high_school_chemistry,validation,3.7264606282114983,mistral_7b_instruct,choice,choice,,,,
203,0.3310383346867679,0.5024630427360535,0.6108373999595642,0.640846437584935,0.1742802274050971,mmlu:high_school_chemistry,test,31.410768274217844,mistral_7b_instruct,choice,choice,,,,
9,0.3025580942630768,0.6666666865348816,0.5555555820465088,0.5,0.30874304638968575,mmlu:high_school_computer_science,validation,2.7454351261258125,mistral_7b_instruct,choice,choice,,,,
100,0.24929694920778278,0.6299999952316284,0.6200000047683716,0.516087516087516,0.10199147284030911,mmlu:high_school_computer_science,test,29.010339502245188,mistral_7b_instruct,choice,choice,,,,
22,0.10552806204015558,0.8636363744735718,0.6818181872367859,0.4385964912280702,0.16017340530048715,mmlu:high_school_geography,validation,2.652404259890318,mistral_7b_instruct,choice,choice,,,,
198,0.1666101745583794,0.7575757503509521,0.7979797720909119,0.6386111111111112,0.0556424055436645,mmlu:high_school_geography,test,22.853866659104824,mistral_7b_instruct,choice,choice,,,,
21,0.15795220931371057,0.761904776096344,0.8095238208770752,0.55,0.06606692075729372,mmlu:high_school_government_and_politics,validation,2.9977770932018757,mistral_7b_instruct,choice,choice,,,,
193,0.13090339611849022,0.8290154933929443,0.7668393850326538,0.5732007575757576,0.06378474136708313,mmlu:high_school_government_and_politics,test,25.965550541877747,mistral_7b_instruct,choice,choice,,,,
43,0.23478324122207112,0.6744186282157898,0.7441860437393188,0.6822660098522169,0.1453856063443561,mmlu:high_school_macroeconomics,validation,5.1380145363509655,mistral_7b_instruct,choice,choice,,,,
390,0.31224886988982176,0.5794872045516968,0.6512820720672607,0.5057333261385711,0.09262481973721429,mmlu:high_school_macroeconomics,test,45.531766064465046,mistral_7b_instruct,choice,choice,,,,
29,0.3456694185733795,0.3448275923728943,0.5517241358757019,0.4447368421052632,0.27742541452934005,mmlu:high_school_mathematics,validation,4.655618503689766,mistral_7b_instruct,choice,choice,,,,
270,0.339378222712764,0.32592591643333435,0.6037036776542664,0.4491133866133867,0.11131915781233047,mmlu:high_school_mathematics,test,41.07493505254388,mistral_7b_instruct,choice,choice,,,,
26,0.297431109043268,0.6538462042808533,0.7307692766189575,0.5620915032679739,0.10103182380016035,mmlu:high_school_microeconomics,validation,3.224981125444174,mistral_7b_instruct,choice,choice,,,,
238,0.24980106499014784,0.6596639156341553,0.680672287940979,0.5630651883305812,0.07836315010776038,mmlu:high_school_microeconomics,test,28.956473719328642,mistral_7b_instruct,choice,choice,,,,
17,0.5791807507767397,0.1764705926179886,0.47058823704719543,0.9761904761904763,0.3019944254089804,mmlu:high_school_physics,validation,3.1315270252525806,mistral_7b_instruct,choice,choice,,,,
151,0.47759866556584446,0.3245033025741577,0.4701986610889435,0.5622248899559824,0.2682252810490842,mmlu:high_school_physics,test,25.40667723119259,mistral_7b_instruct,choice,choice,,,,
60,0.14693470696608227,0.8666667342185974,0.8833333849906921,0.7379807692307692,0.07163939674695333,mmlu:high_school_psychology,validation,8.91745175421238,mistral_7b_instruct,choice,choice,,,,
545,0.15354312926257424,0.7963302731513977,0.8275229334831238,0.676823406478579,0.024743574256197047,mmlu:high_school_psychology,test,81.50379292294383,mistral_7b_instruct,choice,choice,,,,
23,0.2837708385094353,0.52173912525177,0.52173912525177,0.5303030303030303,0.1792811129404151,mmlu:high_school_statistics,validation,5.952262576669455,mistral_7b_instruct,choice,choice,,,,
216,0.3684417888246201,0.45370370149612427,0.625,0.5798599100657212,0.10339613286433398,mmlu:high_school_statistics,test,55.23291005194187,mistral_7b_instruct,choice,choice,,,,
22,0.20858199758963158,0.7727273106575012,0.6818181872367859,0.7294117647058823,0.17328170212832367,mmlu:high_school_us_history,validation,21.154842007905245,mistral_7b_instruct,choice,choice,,,,
204,0.17567587600034823,0.7647058963775635,0.7696078419685364,0.6549813034188033,0.05181882398969985,mmlu:high_school_us_history,test,187.9604019895196,mistral_7b_instruct,choice,choice,,,,
23,0.28377026060353155,0.739130437374115,0.6521739363670349,0.4607843137254902,0.1899149625197701,mmlu:human_aging,validation,2.390688817948103,mistral_7b_instruct,choice,choice,,,,
223,0.2798985352430643,0.6412556171417236,0.6278027296066284,0.6086101398601399,0.10811507835516478,mmlu:human_aging,test,21.585710924118757,mistral_7b_instruct,choice,choice,,,,
12,0.39886192232370377,0.5,0.6666666865348816,0.5833333333333334,0.1605549057324727,mmlu:human_sexuality,validation,1.500822078436613,mistral_7b_instruct,choice,choice,,,,
131,0.19018031349618933,0.6870229244232178,0.7633587718009949,0.5069105691056911,0.09281515392638343,mmlu:human_sexuality,test,14.870389524847269,mistral_7b_instruct,choice,choice,,,,
13,0.04525377200200008,1.0,0.7692307829856873,,0.11123974048174343,mmlu:international_law,validation,2.6509483605623245,mistral_7b_instruct,choice,choice,,,,
121,0.2001115286892111,0.7520660758018494,0.7355371713638306,0.6329670329670329,0.07291305065155029,mmlu:international_law,test,22.54779313132167,mistral_7b_instruct,choice,choice,,,,
11,0.40400578758933325,0.5454545617103577,0.7272727489471436,0.6,0.3210460164330222,mmlu:jurisprudence,validation,1.559875201433897,mistral_7b_instruct,choice,choice,,,,
108,0.12610692006570323,0.7777777910232544,0.7685185074806213,0.6691468253968254,0.05443738897641498,mmlu:jurisprudence,test,13.460459966212511,mistral_7b_instruct,choice,choice,,,,
18,0.22719257407718238,0.7222222089767456,0.6666666865348816,0.47692307692307695,0.23696849743525186,mmlu:logical_fallacies,validation,2.4951931685209274,mistral_7b_instruct,choice,choice,,,,
163,0.21776216454301145,0.699386477470398,0.7668711543083191,0.4652703186537773,0.0650265940859274,mmlu:logical_fallacies,test,21.32672467082739,mistral_7b_instruct,choice,choice,,,,
11,0.44795854525132617,0.3636363744735718,0.5454545617103577,0.4642857142857143,0.20597730983387338,mmlu:machine_learning,validation,2.3104470036923885,mistral_7b_instruct,choice,choice,,,,
112,0.4235134688871247,0.4375000298023224,0.5,0.4920634920634921,0.18184621791754452,mmlu:machine_learning,test,21.918089777231216,mistral_7b_instruct,choice,choice,,,,
11,0.08112492886456579,0.9090909361839294,0.7272727489471436,0.8,0.08505215428092264,mmlu:management,validation,1.1427287459373474,mistral_7b_instruct,choice,choice,,,,
103,0.2112188009382451,0.737864077091217,0.6310679912567139,0.6006335282651073,0.09505157563292865,mmlu:management,test,9.196760583668947,mistral_7b_instruct,choice,choice,,,,
25,0.13537898302078247,0.8399999737739563,0.9199999570846558,0.6904761904761905,0.1859518837928772,mmlu:marketing,validation,3.3394143730401993,mistral_7b_instruct,choice,choice,,,,
234,0.09140556732304073,0.8675214052200317,0.7820513248443604,0.6457174638487208,0.04388955260953334,mmlu:marketing,test,28.51266834884882,mistral_7b_instruct,choice,choice,,,,
11,0.05355577577244151,0.9090909361839294,0.9090909361839294,1.0,0.19229773499748923,mmlu:medical_genetics,validation,1.4964385107159615,mistral_7b_instruct,choice,choice,,,,
100,0.26982351928949355,0.6499999761581421,0.7099999785423279,0.5389010989010989,0.04203611791133881,mmlu:medical_genetics,test,11.111119959503412,mistral_7b_instruct,choice,choice,,,,
38,0.38890403195431356,0.5,0.6842105388641357,0.6357340720221607,0.160992830991745,mmlu:moral_disputes,validation,5.591180510818958,mistral_7b_instruct,choice,choice,,,,
346,0.21252157956878573,0.6994219422340393,0.6387283205986023,0.5610100127145582,0.05331795339639474,mmlu:moral_disputes,test,49.4333057962358,mistral_7b_instruct,choice,choice,,,,
33,0.218837017362768,0.7272727489471436,0.7575757503509521,0.42592592592592593,0.23733140663667157,mmlu:nutrition,validation,6.014237858355045,mistral_7b_instruct,choice,choice,,,,
306,0.21866727245399373,0.6764705777168274,0.6699346303939819,0.6088420436246523,0.05526579380814549,mmlu:nutrition,test,54.62788932770491,mistral_7b_instruct,choice,choice,,,,
34,0.24476109883364505,0.7058823704719543,0.7352941036224365,0.6083333333333333,0.12629040900398703,mmlu:philosophy,validation,3.8913281820714474,mistral_7b_instruct,choice,choice,,,,
311,0.23200910181477905,0.6881029009819031,0.6945337653160095,0.5919404566913962,0.036421370467955676,mmlu:philosophy,test,33.623536974191666,mistral_7b_instruct,choice,choice,,,,
35,0.2817061432770321,0.6285714507102966,0.6571428775787354,0.6276223776223775,0.14076263734272548,mmlu:prehistory,validation,5.847480971366167,mistral_7b_instruct,choice,choice,,,,
324,0.21169170001406726,0.7037037014961243,0.6635802388191223,0.5967881944444444,0.1125802958821073,mmlu:prehistory,test,51.39862719923258,mistral_7b_instruct,choice,choice,,,,
69,0.2250513468963512,0.695652186870575,0.6376811861991882,0.5163690476190477,0.12152722866638847,mmlu:professional_psychology,validation,12.472627952694893,mistral_7b_instruct,choice,choice,,,,
612,0.2639094320387622,0.6372548937797546,0.6062091588973999,0.5654719885199802,0.1247293542023578,mmlu:professional_psychology,test,104.57722126320004,mistral_7b_instruct,choice,choice,,,,
12,0.26613214115301764,0.5833333730697632,0.5,0.6,0.2717058857282003,mmlu:public_relations,validation,1.8299426846206188,mistral_7b_instruct,choice,choice,,,,
110,0.2205008919943463,0.699999988079071,0.6727272272109985,0.6084218811491539,0.09212141578847712,mmlu:public_relations,test,14.014965023845434,mistral_7b_instruct,choice,choice,,,,
27,0.29304870852717646,0.6296296119689941,0.7037037014961243,0.588235294117647,0.20790744931609545,mmlu:security_studies,validation,10.854338865727186,mistral_7b_instruct,choice,choice,,,,
245,0.21320708041288416,0.7061223983764648,0.669387698173523,0.5788375080282595,0.057027381780196194,mmlu:security_studies,test,98.43281199783087,mistral_7b_instruct,choice,choice,,,,
22,0.09626402367245067,0.9090909361839294,0.8636363744735718,0.9,0.18854735927148303,mmlu:sociology,validation,2.9926666989922523,mistral_7b_instruct,choice,choice,,,,
201,0.15200453670463754,0.815920352935791,0.7512437701225281,0.47750494396835863,0.08132965558796972,mmlu:sociology,test,25.983618464320898,mistral_7b_instruct,choice,choice,,,,
11,0.09955185651779172,0.9090909361839294,0.7272727489471436,0.6,0.28862253102389246,mmlu:us_foreign_policy,validation,1.6229936853051186,mistral_7b_instruct,choice,choice,,,,
100,0.14251588940620424,0.8399999737739563,0.7899999618530273,0.5770089285714286,0.10658837258815763,mmlu:us_foreign_policy,test,12.452590633183718,mistral_7b_instruct,choice,choice,,,,
18,0.30144514143466944,0.6111111044883728,0.6666666865348816,0.37662337662337664,0.09926279717021519,mmlu:virology,validation,2.6835842803120613,mistral_7b_instruct,choice,choice,,,,
166,0.4208652215549745,0.48795178532600403,0.5301204919815063,0.5446428571428571,0.1875575105827975,mmlu:virology,test,18.47327408567071,mistral_7b_instruct,choice,choice,,,,
19,0.16152709095101603,0.8421052694320679,0.6842105388641357,0.27083333333333337,0.26958919826306793,mmlu:world_religions,validation,1.787957213819027,mistral_7b_instruct,choice,choice,,,,
171,0.1347603517317633,0.8245614171028137,0.7894737124443054,0.6566193853427896,0.0336832494763603,mmlu:world_religions,test,14.299878541380167,mistral_7b_instruct,choice,choice,,,,
11,,,,,,mmlu:abstract_algebra,validation,15.734950074926019,llama2_13b_chat,oe,oe,0.09090909361839294,0.9090909361839294,0.7,0.11040774258700281
100,,,,,,mmlu:abstract_algebra,test,99.59779604896903,llama2_13b_chat,oe,oe,0.28999999165534973,0.6699999570846558,0.48227294803302573,0.08296753585338594
14,,,,,,mmlu:anatomy,validation,5.38210191950202,llama2_13b_chat,oe,oe,0.3571428656578064,0.5,0.6222222222222223,0.3181387484073639
135,,,,,,mmlu:anatomy,test,44.607210429385304,llama2_13b_chat,oe,oe,0.45185184478759766,0.6666666269302368,0.5528356225077536,0.03518798262984665
16,,,,,,mmlu:astronomy,validation,8.473740469664335,llama2_13b_chat,oe,oe,0.4375,0.5625,0.3492063492063492,0.2113053873181343
152,,,,,,mmlu:astronomy,test,77.93288137763739,llama2_13b_chat,oe,oe,0.5,0.6447368264198303,0.43386426592797783,0.10961959393400895
11,,,,,,mmlu:business_ethics,validation,5.905531892552972,llama2_13b_chat,oe,oe,0.27272728085517883,0.5454545617103577,0.25,0.20747855576601892
100,,,,,,mmlu:business_ethics,test,57.041265711188316,llama2_13b_chat,oe,oe,0.3499999940395355,0.5,0.5681318681318681,0.1432581627368927
29,,,,,,mmlu:clinical_knowledge,validation,13.43517036177218,llama2_13b_chat,oe,oe,0.17241379618644714,0.7931034564971924,0.2666666666666667,0.16576619394894304
265,,,,,,mmlu:clinical_knowledge,test,120.20359163917601,llama2_13b_chat,oe,oe,0.28679245710372925,0.6754717230796814,0.45829852408799776,0.06836827970900626
16,,,,,,mmlu:college_biology,validation,7.780209064483643,llama2_13b_chat,oe,oe,0.125,0.4375,0.3214285714285714,0.23887096345424652
144,,,,,,mmlu:college_biology,test,84.9741564579308,llama2_13b_chat,oe,oe,0.3402777910232544,0.5833333134651184,0.39785177228786256,0.11851563346054819
8,,,,,,mmlu:college_chemistry,validation,4.146339016035199,llama2_13b_chat,oe,oe,0.125,0.5,0.0,0.18306849896907806
100,,,,,,mmlu:college_chemistry,test,54.32817963883281,llama2_13b_chat,oe,oe,0.12999999523162842,0.6299999952316284,0.40804597701149425,0.08250370621681213
11,,,,,,mmlu:college_computer_science,validation,10.923845613375306,llama2_13b_chat,oe,oe,0.3636363744735718,0.5454545617103577,0.35714285714285715,0.3230418183586814
100,,,,,,mmlu:college_computer_science,test,80.31811309419572,llama2_13b_chat,oe,oe,0.22999998927116394,0.5999999642372131,0.45313382269904007,0.13163573563098907
11,,,,,,mmlu:college_mathematics,validation,9.179711986333132,llama2_13b_chat,oe,oe,0.09090909361839294,0.7272727489471436,0.4,0.23878859389912
100,,,,,,mmlu:college_mathematics,test,83.94910943321884,llama2_13b_chat,oe,oe,0.14999999105930328,0.699999988079071,0.367843137254902,0.06491809368133543
22,,,,,,mmlu:college_medicine,validation,12.239762358367443,llama2_13b_chat,oe,oe,0.4545454680919647,0.5454545617103577,0.4458333333333333,0.2665307007052682
173,,,,,,mmlu:college_medicine,test,103.23970467969775,llama2_13b_chat,oe,oe,0.39306357502937317,0.6647398471832275,0.4121848739495798,0.03221702024426766
11,,,,,,mmlu:college_physics,validation,6.160923585295677,llama2_13b_chat,oe,oe,0.27272728085517883,0.6363636255264282,0.5,0.2236417857083407
102,,,,,,mmlu:college_physics,test,58.339025212451816,llama2_13b_chat,oe,oe,0.11764706671237946,0.7254902124404907,0.5430555555555556,0.09856798309905856
11,,,,,,mmlu:computer_security,validation,5.17326619848609,llama2_13b_chat,oe,oe,0.4545454680919647,0.7272727489471436,0.3666666666666667,0.308747643774206
100,,,,,,mmlu:computer_security,test,62.51025377586484,llama2_13b_chat,oe,oe,0.5,0.550000011920929,0.61,0.12054500460624695
26,,,,,,mmlu:conceptual_physics,validation,9.434331076219678,llama2_13b_chat,oe,oe,0.26923078298568726,0.6538462042808533,0.368421052631579,0.10911217790383557
235,,,,,,mmlu:conceptual_physics,test,72.37465877644718,llama2_13b_chat,oe,oe,0.44680848717689514,0.5659574270248413,0.43054945054945054,0.17631685936704597
12,,,,,,mmlu:econometrics,validation,8.571384919807315,llama2_13b_chat,oe,oe,0.1666666716337204,0.6666666865348816,0.7,0.14913245538870498
114,,,,,,mmlu:econometrics,test,124.13529044575989,llama2_13b_chat,oe,oe,0.15789473056793213,0.5526315569877625,0.43258101851851855,0.11829065858272084
16,,,,,,mmlu:electrical_engineering,validation,19.62624548561871,llama2_13b_chat,oe,oe,0.25,0.75,0.25,0.11284647881984708
145,,,,,,mmlu:electrical_engineering,test,120.92334317602217,llama2_13b_chat,oe,oe,0.1862068921327591,0.7724137902259827,0.31418706842435656,0.03925637006759646
41,,,,,,mmlu:elementary_mathematics,validation,23.501282073557377,llama2_13b_chat,oe,oe,0.2195121943950653,0.6829267740249634,0.578125,0.10896354913711549
378,,,,,,mmlu:elementary_mathematics,test,193.94336616434157,llama2_13b_chat,oe,oe,0.30423280596733093,0.6666666269302368,0.46948255910067793,0.08244336881334818
14,,,,,,mmlu:formal_logic,validation,12.405370743945241,llama2_13b_chat,oe,oe,0.5714285969734192,0.7142857313156128,0.5208333333333334,0.2573765942028591
126,,,,,,mmlu:formal_logic,test,93.53629437834024,llama2_13b_chat,oe,oe,0.3730158805847168,0.6984127163887024,0.46754645838944253,0.10575676295492381
10,,,,,,mmlu:global_facts,validation,4.474692165851593,llama2_13b_chat,oe,oe,0.20000000298023224,0.800000011920929,0.53125,0.07525740265846251
100,,,,,,mmlu:global_facts,test,43.340764256194234,llama2_13b_chat,oe,oe,0.12999999523162842,0.7899999618530273,0.3687002652519894,0.048578917384147643
32,,,,,,mmlu:high_school_biology,validation,16.734762761741877,llama2_13b_chat,oe,oe,0.21875,0.5625,0.6171428571428571,0.20622744038701057
310,,,,,,mmlu:high_school_biology,test,155.78783080913126,llama2_13b_chat,oe,oe,0.448387086391449,0.5419355034828186,0.4735369599057596,0.1538555879746714
22,,,,,,mmlu:high_school_chemistry,validation,11.90080432780087,llama2_13b_chat,oe,oe,0.1818181872367859,0.6818181872367859,0.13888888888888892,0.16787124763835562
203,,,,,,mmlu:high_school_chemistry,test,109.29109579697251,llama2_13b_chat,oe,oe,0.19704432785511017,0.6995073556900024,0.40590490797546014,0.08650471982110312
9,,,,,,mmlu:high_school_computer_science,validation,9.356354063376784,llama2_13b_chat,oe,oe,0.5555555820465088,0.6666666865348816,0.6,0.20491023858388263
100,,,,,,mmlu:high_school_computer_science,test,122.02403860911727,llama2_13b_chat,oe,oe,0.47999998927116394,0.550000011920929,0.4875801282051282,0.1357382583618164
22,,,,,,mmlu:high_school_geography,validation,15.005465710535645,llama2_13b_chat,oe,oe,0.5,0.40909093618392944,0.3223140495867769,0.28589938987385144
198,,,,,,mmlu:high_school_geography,test,131.4147176295519,llama2_13b_chat,oe,oe,0.3484848439693451,0.5959596037864685,0.3863049095607235,0.10371118513020604
21,,,,,,mmlu:high_school_government_and_politics,validation,10.160974394530058,llama2_13b_chat,oe,oe,0.380952388048172,0.6190476417541504,0.6538461538461537,0.15349536282675608
193,,,,,,mmlu:high_school_government_and_politics,test,80.58748472481966,llama2_13b_chat,oe,oe,0.46113988757133484,0.590673565864563,0.5041594641313742,0.05992839033739554
43,,,,,,mmlu:high_school_macroeconomics,validation,26.053615123033524,llama2_13b_chat,oe,oe,0.39534884691238403,0.7674418687820435,0.23755656108597284,0.10210759833801622
390,,,,,,mmlu:high_school_macroeconomics,test,239.16185684874654,llama2_13b_chat,oe,oe,0.30000001192092896,0.656410276889801,0.41287060517829755,0.0444024234245985
29,,,,,,mmlu:high_school_mathematics,validation,13.348251041024923,llama2_13b_chat,oe,oe,0.06896551698446274,0.7931034564971924,0.5185185185185186,0.03559235252183059
270,,,,,,mmlu:high_school_mathematics,test,144.51447829976678,llama2_13b_chat,oe,oe,0.1111111119389534,0.7925925850868225,0.5013888888888889,0.04222266651965955
26,,,,,,mmlu:high_school_microeconomics,validation,19.271292028948665,llama2_13b_chat,oe,oe,0.26923078298568726,0.692307710647583,0.3157894736842105,0.17083210670031035
238,,,,,,mmlu:high_school_microeconomics,test,149.6289289481938,llama2_13b_chat,oe,oe,0.3445378243923187,0.6512605547904968,0.401031894934334,0.05329870326178417
17,,,,,,mmlu:high_school_physics,validation,11.293502699583769,llama2_13b_chat,oe,oe,0.29411765933036804,0.5882353186607361,0.15,0.22900671117446003
151,,,,,,mmlu:high_school_physics,test,91.9576341509819,llama2_13b_chat,oe,oe,0.18543046712875366,0.6688741445541382,0.42726480836236935,0.09451511522002568
60,,,,,,mmlu:high_school_psychology,validation,129.06575669907033,llama2_13b_chat,oe,oe,0.550000011920929,0.5833333730697632,0.3518518518518519,0.1286461522181829
545,,,,,,mmlu:high_school_psychology,test,272.07646386511624,llama2_13b_chat,oe,oe,0.515596330165863,0.5688073635101318,0.3915938746899601,0.11770148233536187
23,,,,,,mmlu:high_school_statistics,validation,29.68154671229422,llama2_13b_chat,oe,oe,0.1304347813129425,0.6086956858634949,0.4333333333333333,0.20689925680989807
216,,,,,,mmlu:high_school_statistics,test,397.6225338242948,llama2_13b_chat,oe,oe,0.25925925374031067,0.5833333134651184,0.46517857142857144,0.10546058030040177
22,,,,,,mmlu:high_school_us_history,validation,42.583884213119745,llama2_13b_chat,oe,oe,0.7272727489471436,0.40909093618392944,0.71875,0.2739777537909421
204,,,,,,mmlu:high_school_us_history,test,405.37098633125424,llama2_13b_chat,oe,oe,0.6715686321258545,0.6274510025978088,0.40140538184987473,0.10405166330290776
23,,,,,,mmlu:human_aging,validation,20.749107072129846,llama2_13b_chat,oe,oe,0.3913043439388275,0.739130437374115,0.30952380952380953,0.1294464728106623
223,,,,,,mmlu:human_aging,test,155.09474016539752,llama2_13b_chat,oe,oe,0.3811659514904022,0.6591928601264954,0.45852514919011084,0.05199862355074007
12,,,,,,mmlu:human_sexuality,validation,10.230235859751701,llama2_13b_chat,oe,oe,0.25,0.5,0.40740740740740744,0.1874045431613922
131,,,,,,mmlu:human_sexuality,test,75.39058518968523,llama2_13b_chat,oe,oe,0.5114504098892212,0.5648854970932007,0.4141791044776119,0.11924142100428808
13,,,,,,mmlu:international_law,validation,13.151155576109886,llama2_13b_chat,oe,oe,0.1538461595773697,0.46153849363327026,0.5909090909090908,0.35202897511995757
121,,,,,,mmlu:international_law,test,86.22361983172596,llama2_13b_chat,oe,oe,0.44628098607063293,0.42975205183029175,0.5262576008844666,0.2847041556657839
11,,,,,,mmlu:jurisprudence,validation,7.8372834995388985,llama2_13b_chat,oe,oe,0.27272728085517883,0.7272727489471436,0.41666666666666663,0.1665521264076233
108,,,,,,mmlu:jurisprudence,test,51.12872336804867,llama2_13b_chat,oe,oe,0.4166666567325592,0.5833333134651184,0.4649029982363315,0.07658894967149805
18,,,,,,mmlu:logical_fallacies,validation,7.184707138687372,llama2_13b_chat,oe,oe,0.4444444477558136,0.6666666865348816,0.5625,0.1685424678855472
163,,,,,,mmlu:logical_fallacies,test,87.2670633457601,llama2_13b_chat,oe,oe,0.4969325065612793,0.5950919985771179,0.5443390545016562,0.04814932243955647
11,,,,,,mmlu:machine_learning,validation,6.3845378663390875,llama2_13b_chat,oe,oe,0.4545454680919647,0.3636363744735718,0.43333333333333335,0.32116590846668597
112,,,,,,mmlu:machine_learning,test,59.75966498814523,llama2_13b_chat,oe,oe,0.3125,0.5446428656578064,0.42059369202226343,0.12099352000015125
11,,,,,,mmlu:management,validation,3.831467632204294,llama2_13b_chat,oe,oe,0.4545454680919647,0.3636363744735718,0.49999999999999994,0.3356254805218089
103,,,,,,mmlu:management,test,43.188493467867374,llama2_13b_chat,oe,oe,0.35922330617904663,0.5436893105506897,0.37899262899262903,0.11974570241946618
25,,,,,,mmlu:marketing,validation,17.19724084250629,llama2_13b_chat,oe,oe,0.1599999964237213,0.7599999904632568,0.5714285714285714,0.1321842813491822
234,,,,,,mmlu:marketing,test,143.04126836173236,llama2_13b_chat,oe,oe,0.43589746952056885,0.6623932123184204,0.35880867498514557,0.05863207425826633
11,,,,,,mmlu:medical_genetics,validation,6.8721951600164175,llama2_13b_chat,oe,oe,0.7272727489471436,0.5454545617103577,0.20833333333333334,0.364495418288491
100,,,,,,mmlu:medical_genetics,test,60.82808820717037,llama2_13b_chat,oe,oe,0.4599999785423279,0.5699999928474426,0.48691626409017713,0.08916797876358032
38,,,,,,mmlu:moral_disputes,validation,23.44307365640998,llama2_13b_chat,oe,oe,0.6052631735801697,0.42105263471603394,0.6333333333333333,0.2262598683959559
346,,,,,,mmlu:moral_disputes,test,359.70660759322345,llama2_13b_chat,oe,oe,0.41040462255477905,0.5924855470657349,0.46984603700635186,0.057062094094436314
33,,,,,,mmlu:nutrition,validation,22.133489198982716,llama2_13b_chat,oe,oe,0.24242424964904785,0.4848484992980957,0.275,0.1748486504410252
306,,,,,,mmlu:nutrition,test,223.86691544018686,llama2_13b_chat,oe,oe,0.36274510622024536,0.5032680034637451,0.5336567336567337,0.16378756461579816
34,,,,,,mmlu:philosophy,validation,10.482734609395266,llama2_13b_chat,oe,oe,0.2647058963775635,0.7941176295280457,0.32666666666666666,0.11271701840793384
311,,,,,,mmlu:philosophy,test,159.91155049949884,llama2_13b_chat,oe,oe,0.260450154542923,0.7427652478218079,0.41650563607085345,0.07301182858046994
35,,,,,,mmlu:prehistory,validation,15.54947473295033,llama2_13b_chat,oe,oe,0.3142857253551483,0.6000000238418579,0.47159090909090906,0.13393209832055233
324,,,,,,mmlu:prehistory,test,136.5660849045962,llama2_13b_chat,oe,oe,0.395061731338501,0.5833333134651184,0.49860491071428564,0.07541376757033078
69,,,,,,mmlu:professional_psychology,validation,81.2423918005079,llama2_13b_chat,oe,oe,0.36231884360313416,0.6666666865348816,0.4159090909090909,0.085323547107586
612,,,,,,mmlu:professional_psychology,test,692.5682015623897,llama2_13b_chat,oe,oe,0.3382352888584137,0.6797385811805725,0.38569809745333095,0.026831043604152664
12,,,,,,mmlu:public_relations,validation,4.2687384840101,llama2_13b_chat,oe,oe,0.25,0.6666666865348816,0.25925925925925924,0.157217671473821
110,,,,,,mmlu:public_relations,test,68.44107041321695,llama2_13b_chat,oe,oe,0.29999998211860657,0.6272727251052856,0.5100354191263281,0.06985717199065468
27,,,,,,mmlu:security_studies,validation,21.65698905289173,llama2_13b_chat,oe,oe,0.6666666865348816,0.7037037014961243,0.46296296296296297,0.18122431525477659
245,,,,,,mmlu:security_studies,test,207.37270092964172,llama2_13b_chat,oe,oe,0.6040816307067871,0.6734693646430969,0.5388687656728894,0.03663647977673276
22,,,,,,mmlu:sociology,validation,9.364689292386174,llama2_13b_chat,oe,oe,0.3636363744735718,0.7272727489471436,0.48214285714285715,0.09394366361878136
201,,,,,,mmlu:sociology,test,88.11789049208164,llama2_13b_chat,oe,oe,0.4029850661754608,0.5920397639274597,0.39886831275720164,0.06924849511379036
11,,,,,,mmlu:us_foreign_policy,validation,144.74915279075503,llama2_13b_chat,oe,oe,0.7272727489471436,0.27272728085517883,0.7083333333333334,0.4263050881299106
100,,,,,,mmlu:us_foreign_policy,test,49.77014376409352,llama2_13b_chat,oe,oe,0.5999999642372131,0.4899999797344208,0.39125,0.2116413849592209
18,,,,,,mmlu:virology,validation,11.501713635399938,llama2_13b_chat,oe,oe,0.3333333432674408,0.6111111044883728,0.7083333333333334,0.36491183108753633
166,,,,,,mmlu:virology,test,213.82320043072104,llama2_13b_chat,oe,oe,0.2469879388809204,0.6144577860832214,0.43912195121951225,0.0625584498945489
19,,,,,,mmlu:world_religions,validation,7.420903358608484,llama2_13b_chat,oe,oe,0.6315789222717285,0.7894737124443054,0.7976190476190477,0.1814651269661753
171,,,,,,mmlu:world_religions,test,61.75727198459208,llama2_13b_chat,oe,oe,0.5906432867050171,0.6549707651138306,0.6094059405940594,0.07227094689307853
11,0.06920236890966242,0.1818181872367859,0.8181818723678589,0.16666666666666669,0.1840913566676053,mmlu:abstract_algebra,validation,5.2283427231013775,llama2_13b,choice,choice,,,,
100,0.04222254246473312,0.3100000023841858,0.7099999785423279,0.3641888733052829,0.04260705947875978,mmlu:abstract_algebra,test,19.08429771848023,llama2_13b,choice,choice,,,,
14,0.14716745274407525,0.4285714626312256,0.5714285969734192,0.5833333333333334,0.08493549908910482,mmlu:anatomy,validation,2.9191154930740595,llama2_13b,choice,choice,,,,
135,0.09001349961316145,0.5111110806465149,0.6592592597007751,0.6480017566974089,0.06627952831762808,mmlu:anatomy,test,27.487673422321677,llama2_13b,choice,choice,,,,
16,0.2289632372558117,0.5625,0.625,0.6349206349206349,0.08864101395010951,mmlu:astronomy,validation,5.078526405617595,llama2_13b,choice,choice,,,,
152,0.1163935759349873,0.5131579041481018,0.5855263471603394,0.636001386001386,0.09198673696894394,mmlu:astronomy,test,47.09032176434994,llama2_13b,choice,choice,,,,
11,0.25074630975723267,0.3636363744735718,0.4545454680919647,0.75,0.30635926940224384,mmlu:business_ethics,validation,3.491342132911086,llama2_13b,choice,choice,,,,
100,0.08249628603458406,0.5299999713897705,0.5799999833106995,0.802488960256925,0.12944854080677032,mmlu:business_ethics,test,30.88478073850274,llama2_13b,choice,choice,,,,
29,0.13683780308427484,0.5862069129943848,0.517241358757019,0.5686274509803921,0.15327005550779144,mmlu:clinical_knowledge,validation,6.793275272473693,llama2_13b,choice,choice,,,,
265,0.03372989926698072,0.5886792540550232,0.6603773832321167,0.6327040696306752,0.02816479138608249,mmlu:clinical_knowledge,test,60.76364607550204,llama2_13b,choice,choice,,,,
16,0.1720481961965561,0.5625,0.5,0.746031746031746,0.20667041465640068,mmlu:college_biology,validation,4.24649553745985,llama2_13b,choice,choice,,,,
144,0.06489325004319352,0.5486111044883728,0.6041666865348816,0.6122687439143134,0.06703893509176043,mmlu:college_biology,test,38.43396545574069,llama2_13b,choice,choice,,,,
8,0.40915826708078384,0.625,0.5,0.8,0.43436145782470703,mmlu:college_chemistry,validation,2.5308595318347216,llama2_13b,choice,choice,,,,
100,0.12028073847293855,0.44999998807907104,0.5600000023841858,0.43272727272727274,0.11785585224628449,mmlu:college_chemistry,test,29.23016293719411,llama2_13b,choice,choice,,,,
11,0.23285808075558057,0.6363636255264282,0.3636363744735718,0.6785714285714286,0.3092958331108093,mmlu:college_computer_science,validation,4.690921980887651,llama2_13b,choice,choice,,,,
100,0.1002258676290512,0.4399999976158142,0.5600000023841858,0.5773133116883117,0.13949597716331485,mmlu:college_computer_science,test,43.12960767187178,llama2_13b,choice,choice,,,,
11,0.12380083853548224,0.1818181872367859,0.8181818723678589,0.36111111111111116,0.11966239864175969,mmlu:college_mathematics,validation,3.394137119874358,llama2_13b,choice,choice,,,,
100,0.06589578837156294,0.29999998211860657,0.6899999976158142,0.5911904761904762,0.15174574851989744,mmlu:college_mathematics,test,29.592699017375708,llama2_13b,choice,choice,,,,
22,0.12571292438290338,0.5454545617103577,0.5,0.5708333333333333,0.14854488318616693,mmlu:college_medicine,validation,6.322145717218518,llama2_13b,choice,choice,,,,
173,0.058592356009290414,0.5549132823944092,0.6184970736503601,0.5830627705627706,0.053457005864622965,mmlu:college_medicine,test,57.908399257808924,llama2_13b,choice,choice,,,,
11,0.1288730718872764,0.5454545617103577,0.5454545617103577,0.6666666666666666,0.16717360236428006,mmlu:college_physics,validation,2.9371839482337236,llama2_13b,choice,choice,,,,
102,0.15867351404592106,0.2549019753932953,0.6764706373214722,0.5774291497975709,0.044116568915984256,mmlu:college_physics,test,26.35865286923945,llama2_13b,choice,choice,,,,
11,0.3201443932273171,0.8181818723678589,0.8181818723678589,0.6666666666666667,0.12491555647416548,mmlu:computer_security,validation,2.7851399797946215,llama2_13b,choice,choice,,,,
100,0.07781153231859207,0.7099999785423279,0.7199999690055847,0.7297231665857212,0.05832123637199402,mmlu:computer_security,test,22.033062979578972,llama2_13b,choice,choice,,,,
26,0.15561166520302114,0.42307692766189575,0.5384615659713745,0.7303030303030302,0.19284185996422404,mmlu:conceptual_physics,validation,4.546041306108236,llama2_13b,choice,choice,,,,
235,0.12013903146094464,0.3914893567562103,0.4765957295894623,0.5891608391608392,0.15274255630817823,mmlu:conceptual_physics,test,39.62507836148143,llama2_13b,choice,choice,,,,
12,0.17015917847553888,0.25,0.5833333730697632,0.33333333333333337,0.45400530099868774,mmlu:econometrics,validation,3.926949320361018,llama2_13b,choice,choice,,,,
114,0.1632876720344811,0.24561403691768646,0.4736842215061188,0.5664451827242525,0.1282197163816084,mmlu:econometrics,test,36.4159219302237,llama2_13b,choice,choice,,,,
16,0.13311614841222763,0.375,0.75,0.7166666666666667,0.21593191474676132,mmlu:electrical_engineering,validation,3.815509667620063,llama2_13b,choice,choice,,,,
145,0.0973424523041166,0.4413793087005615,0.6413792967796326,0.4256365740740741,0.10253339101528301,mmlu:electrical_engineering,test,33.359210109338164,llama2_13b,choice,choice,,,,
41,0.09600169629585452,0.4146341383457184,0.5121951103210449,0.5367647058823529,0.14654637546074098,mmlu:elementary_mathematics,validation,11.968664383515716,llama2_13b,choice,choice,,,,
378,0.06784735217926996,0.31216931343078613,0.6190475821495056,0.5824315514993481,0.0821045971421338,mmlu:elementary_mathematics,test,107.15997567214072,llama2_13b,choice,choice,,,,
14,0.12916469999722072,0.2857142984867096,0.5714285969734192,0.6749999999999999,0.06463531936917984,mmlu:formal_logic,validation,4.550271412357688,llama2_13b,choice,choice,,,,
126,0.02843788242529311,0.3492063581943512,0.626984179019928,0.5738636363636364,0.04436390409393917,mmlu:formal_logic,test,40.584274446591735,llama2_13b,choice,choice,,,,
10,0.14060280919075013,0.5,0.6000000238418579,0.52,0.24573931694030765,mmlu:global_facts,validation,2.4388855509459972,llama2_13b,choice,choice,,,,
100,0.08612264096736909,0.3499999940395355,0.6899999976158142,0.38417582417582413,0.04279566287994381,mmlu:global_facts,test,23.00644274428487,llama2_13b,choice,choice,,,,
32,0.1209655273705721,0.53125,0.5,0.6392156862745098,0.19863301888108253,mmlu:high_school_biology,validation,9.173324555158615,llama2_13b,choice,choice,,,,
310,0.060094018520847454,0.6645160913467407,0.6580644845962524,0.6882935026138909,0.07089272660593837,mmlu:high_school_biology,test,88.01124802231789,llama2_13b,choice,choice,,,,
22,0.10005006465044892,0.3636363744735718,0.5454545617103577,0.6830357142857143,0.1149221360683441,mmlu:high_school_chemistry,validation,6.375737067312002,llama2_13b,choice,choice,,,,
203,0.05729783227291012,0.4729064106941223,0.5763546824455261,0.48491043613707163,0.06142405659107154,mmlu:high_school_chemistry,test,55.148043897002935,llama2_13b,choice,choice,,,,
9,0.17603182130389744,0.6666666865348816,0.6666666865348816,0.7222222222222223,0.12826128138436213,mmlu:high_school_computer_science,validation,4.491478938609362,llama2_13b,choice,choice,,,,
100,0.09345588743686677,0.5399999618530273,0.6899999976158142,0.7731481481481481,0.06289392590522766,mmlu:high_school_computer_science,test,48.78159082867205,llama2_13b,choice,choice,,,,
22,0.14594153247096323,0.7272727489471436,0.6818181872367859,0.734375,0.0762371529232372,mmlu:high_school_geography,validation,4.80956500582397,llama2_13b,choice,choice,,,,
198,0.06559802004785248,0.7222222089767456,0.6818181872367859,0.5080101716465353,0.05078023792517307,mmlu:high_school_geography,test,42.57360432110727,llama2_13b,choice,choice,,,,
21,0.1844906466347831,0.7142857313156128,0.7142857313156128,0.7055555555555555,0.07158325399671281,mmlu:high_school_government_and_politics,validation,5.306473953649402,llama2_13b,choice,choice,,,,
193,0.04912939513285542,0.8238341808319092,0.8134714961051941,0.6739733629300776,0.10744393798353759,mmlu:high_school_government_and_politics,test,47.970309130847454,llama2_13b,choice,choice,,,,
43,0.16379689199979913,0.5116279125213623,0.5116279125213623,0.7694805194805195,0.24774698878443516,mmlu:high_school_macroeconomics,validation,9.467603243887424,llama2_13b,choice,choice,,,,
390,0.07977168086247566,0.5333333611488342,0.5461538434028625,0.6294114539306847,0.1832810070270147,mmlu:high_school_macroeconomics,test,85.60541680268943,llama2_13b,choice,choice,,,,
29,0.11061135551025127,0.24137930572032928,0.7241379022598267,0.42857142857142855,0.04666987369800436,mmlu:high_school_mathematics,validation,8.121947275474668,llama2_13b,choice,choice,,,,
270,0.09013029590800958,0.23333333432674408,0.7111110687255859,0.4871558929529944,0.046551804630844656,mmlu:high_school_mathematics,test,73.46537087857723,llama2_13b,choice,choice,,,,
26,0.23534159706189087,0.692307710647583,0.6538462042808533,0.5,0.19871058143102205,mmlu:high_school_microeconomics,validation,5.718422267585993,llama2_13b,choice,choice,,,,
238,0.070158546086119,0.5756303071975708,0.542016863822937,0.5676808556768086,0.13501532939301825,mmlu:high_school_microeconomics,test,52.66093488223851,llama2_13b,choice,choice,,,,
17,0.214115626671735,0.23529411852359772,0.5882353186607361,0.4423076923076923,0.27111967872170845,mmlu:high_school_physics,validation,5.194157347083092,llama2_13b,choice,choice,,,,
151,0.032332958172488685,0.3907284736633301,0.5960264801979065,0.5404384672070744,0.12991045247640046,mmlu:high_school_physics,test,44.33111729286611,llama2_13b,choice,choice,,,,
60,0.11067090133825937,0.8000000715255737,0.8166667222976685,0.8124999999999999,0.11605280240376792,mmlu:high_school_psychology,validation,16.70951028354466,llama2_13b,choice,choice,,,,
545,0.05436075614133011,0.7614678740501404,0.7651376128196716,0.6811955514365152,0.054496141639324494,mmlu:high_school_psychology,test,151.77915325574577,llama2_13b,choice,choice,,,,
23,0.1703792395799056,0.43478262424468994,0.43478262424468994,0.7769230769230769,0.24983015526895938,mmlu:high_school_statistics,validation,9.506883416324854,llama2_13b,choice,choice,,,,
216,0.04346492265661556,0.4490740895271301,0.4583333432674408,0.5349562505414537,0.17452756481038204,mmlu:high_school_statistics,test,93.29060370661318,llama2_13b,choice,choice,,,,
22,0.17520021985877646,0.7727273106575012,0.7727273106575012,0.5647058823529412,0.14868137240409857,mmlu:high_school_us_history,validation,34.36810664460063,llama2_13b,choice,choice,,,,
204,0.09055403050254372,0.7598039507865906,0.7598039507865906,0.6552337063857802,0.07421535136652925,mmlu:high_school_us_history,test,312.2378600537777,llama2_13b,choice,choice,,,,
23,0.29493607386298804,0.5652173757553101,0.6086956858634949,0.7538461538461538,0.1946361894192903,mmlu:human_aging,validation,4.229251880198717,llama2_13b,choice,choice,,,,
223,0.07797254281193688,0.5964125990867615,0.6233184337615967,0.7443191311612364,0.09983280661929349,mmlu:human_aging,test,39.28487805835903,llama2_13b,choice,choice,,,,
12,0.15332866211732227,0.5,0.5833333730697632,0.4722222222222222,0.2649167726437251,mmlu:human_sexuality,validation,2.397690048441291,llama2_13b,choice,choice,,,,
131,0.09053917058551583,0.6106870174407959,0.7175572514533997,0.6705882352941176,0.09723604953926028,mmlu:human_sexuality,test,26.839352130889893,llama2_13b,choice,choice,,,,
13,0.18429349935971776,0.7692307829856873,0.7692307829856873,0.9666666666666668,0.1655709055753855,mmlu:international_law,validation,4.672882756218314,llama2_13b,choice,choice,,,,
121,0.0732406697982599,0.719008207321167,0.7355371713638306,0.7503380662609871,0.07903945938614777,mmlu:international_law,test,39.95165037922561,llama2_13b,choice,choice,,,,
11,0.22142491828311575,0.4545454680919647,0.4545454680919647,1.0,0.31050748174840753,mmlu:jurisprudence,validation,2.5444233510643244,llama2_13b,choice,choice,,,,
108,0.10479138874345355,0.7037037014961243,0.75,0.7117598684210525,0.07797648895669866,mmlu:jurisprudence,test,23.990022579208016,llama2_13b,choice,choice,,,,
18,0.2224999864896138,0.7777777910232544,0.7222222089767456,0.5714285714285714,0.19371092981762356,mmlu:logical_fallacies,validation,4.403530970215797,llama2_13b,choice,choice,,,,
163,0.06698918635128467,0.6380367875099182,0.7361962795257568,0.6083767926988267,0.09469555528617346,mmlu:logical_fallacies,test,39.08038435690105,llama2_13b,choice,choice,,,,
11,0.19108336080204355,0.4545454680919647,0.3636363744735718,0.6666666666666666,0.33056193048303784,mmlu:machine_learning,validation,3.705460598692298,llama2_13b,choice,choice,,,,
112,0.19081376971943037,0.2142857313156128,0.4285714626312256,0.6524621212121211,0.27566854442868916,mmlu:machine_learning,test,37.37082298099995,llama2_13b,choice,choice,,,,
11,0.23109854893250903,0.7272727489471436,0.9090909361839294,0.75,0.27726764570583,mmlu:management,validation,1.93138144351542,llama2_13b,choice,choice,,,,
103,0.10133581601300287,0.7766990661621094,0.7475728392601013,0.5817934782608696,0.08059514784118503,mmlu:management,test,16.79820884205401,llama2_13b,choice,choice,,,,
25,0.2459735798835755,0.8399999737739563,0.8399999737739563,0.6904761904761905,0.07768117427825928,mmlu:marketing,validation,5.8329766895622015,llama2_13b,choice,choice,,,,
234,0.0601038861478496,0.7820513248443604,0.7777777910232544,0.7076502732240436,0.07663867081332412,mmlu:marketing,test,52.462833335623145,llama2_13b,choice,choice,,,,
11,0.17915785854512994,0.8181818723678589,0.9090909361839294,1.0,0.20379903641614044,mmlu:medical_genetics,validation,2.438972694799304,llama2_13b,choice,choice,,,,
100,0.1411105951666832,0.5799999833106995,0.6399999856948853,0.6832922824302134,0.10200434029102326,mmlu:medical_genetics,test,20.12015377357602,llama2_13b,choice,choice,,,,
38,0.18718513611115908,0.5263158082962036,0.5789473652839661,0.663888888888889,0.10770677892785324,mmlu:moral_disputes,validation,9.716589579358697,llama2_13b,choice,choice,,,,
346,0.055437243484348246,0.6098265647888184,0.6358381509780884,0.5984202211690364,0.016064312933497343,mmlu:moral_disputes,test,87.98747417517006,llama2_13b,choice,choice,,,,
33,0.1813181160074292,0.7575757503509521,0.7878788113594055,0.885,0.09869888334563284,mmlu:nutrition,validation,10.592602409422398,llama2_13b,choice,choice,,,,
306,0.07220801623428569,0.6241829991340637,0.6405228972434998,0.6720919644889597,0.045192839078653874,mmlu:nutrition,test,97.63228613696992,llama2_13b,choice,choice,,,,
34,0.20816840319072502,0.6470588445663452,0.6470588445663452,0.7196969696969697,0.0974408142706927,mmlu:philosophy,validation,6.640491060912609,llama2_13b,choice,choice,,,,
311,0.09089757631446005,0.6495176553726196,0.6655948162078857,0.6463348169679353,0.05723270246836917,mmlu:philosophy,test,58.325564950704575,llama2_13b,choice,choice,,,,
35,0.18569657632282802,0.6285714507102966,0.6000000238418579,0.673076923076923,0.09016545500074115,mmlu:prehistory,validation,10.329927964136004,llama2_13b,choice,choice,,,,
324,0.06019172900252873,0.6419752836227417,0.6759259104728699,0.6907949270557029,0.022390868928697377,mmlu:prehistory,test,93.44312293082476,llama2_13b,choice,choice,,,,
69,0.15859784207482272,0.5652173757553101,0.5652173757553101,0.7085470085470085,0.16051818236060766,mmlu:professional_psychology,validation,21.72110710479319,llama2_13b,choice,choice,,,,
612,0.0725067993199903,0.5555555820465088,0.5686274766921997,0.6671280276816609,0.16066130382173205,mmlu:professional_psychology,test,185.2016757801175,llama2_13b,choice,choice,,,,
12,0.49819476405779517,0.5833333730697632,0.5833333730697632,0.37142857142857144,0.3731871545314789,mmlu:public_relations,validation,3.069483967497945,llama2_13b,choice,choice,,,,
110,0.07987526167522778,0.6363636255264282,0.6363636255264282,0.79375,0.1869470076127486,mmlu:public_relations,test,25.63530980423093,llama2_13b,choice,choice,,,,
27,0.23700715546254758,0.5925925970077515,0.5925925970077515,0.5909090909090909,0.24775193576459528,mmlu:security_studies,validation,18.6494611967355,llama2_13b,choice,choice,,,,
245,0.047171321328805416,0.6326530575752258,0.6326530575752258,0.5753046594982079,0.1908348314616145,mmlu:security_studies,test,174.34630480408669,llama2_13b,choice,choice,,,,
22,0.160487486557527,0.8181818723678589,0.8181818723678589,0.8125,0.1470074328509244,mmlu:sociology,validation,5.302734971046448,llama2_13b,choice,choice,,,,
201,0.06170249207695916,0.7661691308021545,0.7910447716712952,0.6593672285161647,0.0916192537516504,mmlu:sociology,test,47.99368436448276,llama2_13b,choice,choice,,,,
11,0.13227141445333307,0.9090909361839294,0.9090909361839294,0.9,0.18458630821921607,mmlu:us_foreign_policy,validation,2.6471612006425858,llama2_13b,choice,choice,,,,
100,0.06834511309862137,0.8499999642372131,0.8499999642372131,0.5956862745098039,0.0877311098575592,mmlu:us_foreign_policy,test,22.90896152704954,llama2_13b,choice,choice,,,,
18,0.24425924155447218,0.5,0.6111111044883728,0.6234567901234568,0.28968651427163017,mmlu:virology,validation,4.36332899518311,llama2_13b,choice,choice,,,,
166,0.17515957481171712,0.4457831084728241,0.48795178532600403,0.6321974148061104,0.2181417030024241,mmlu:virology,test,33.26132935471833,llama2_13b,choice,choice,,,,
19,0.08429366820736936,0.7894737124443054,0.8421052694320679,0.6333333333333333,0.20564597531368853,mmlu:world_religions,validation,3.08145266585052,llama2_13b,choice,choice,,,,
171,0.04342272372273675,0.7719298601150513,0.7602339386940002,0.6069347319347319,0.10868095201358458,mmlu:world_religions,test,26.847783403471112,llama2_13b,choice,choice,,,,
11,0.40860054980624805,0.1818181872367859,0.5454545617103577,0.5555555555555556,0.005134419961409176,mmlu:abstract_algebra,validation,3.974214006215334,llama2_7b_chat,oe,choice,,,,
100,0.33865155398845675,0.2199999988079071,0.5999999642372131,0.46416083916083917,0.10456767082214359,mmlu:abstract_algebra,test,11.098401140421629,llama2_7b_chat,oe,choice,,,,
14,0.16611006430217198,0.785714328289032,0.6428571939468384,0.5454545454545454,0.19017409852572853,mmlu:anatomy,validation,1.7065327186137438,llama2_7b_chat,oe,choice,,,,
135,0.2326331599994942,0.4444444477558136,0.6370370388031006,0.47722222222222227,0.05304505869194314,mmlu:anatomy,test,15.907623678445816,llama2_7b_chat,oe,choice,,,,
16,0.31718727201223373,0.3125,0.625,0.4727272727272728,0.21084795147180557,mmlu:astronomy,validation,3.0339768044650555,llama2_7b_chat,oe,choice,,,,
152,0.2587384585487215,0.3486842215061188,0.5328947305679321,0.5546026300743282,0.08461078021087147,mmlu:astronomy,test,27.76089207082987,llama2_7b_chat,oe,choice,,,,
11,0.2636793255805969,0.5454545617103577,0.8181818723678589,0.43333333333333335,0.2374467091126875,mmlu:business_ethics,validation,2.153411414474249,llama2_7b_chat,oe,choice,,,,
100,0.2027903527021408,0.4899999797344208,0.5699999928474426,0.5578231292517006,0.0554600840806961,mmlu:business_ethics,test,18.168719332665205,llama2_7b_chat,oe,choice,,,,
29,0.30299188453575665,0.48275861144065857,0.5862069129943848,0.6666666666666667,0.06983082664423974,mmlu:clinical_knowledge,validation,3.908860106021166,llama2_7b_chat,oe,choice,,,,
265,0.2012587421345261,0.5056604146957397,0.5320754647254944,0.5127036572860886,0.09986657039174496,mmlu:clinical_knowledge,test,34.68364004790783,llama2_7b_chat,oe,choice,,,,
16,0.3297007419168949,0.25,0.625,0.5625,0.20783422142267227,mmlu:college_biology,validation,2.54879155382514,llama2_7b_chat,oe,choice,,,,
144,0.16690380829903814,0.4791666567325592,0.5625,0.5265700483091788,0.10833036278684935,mmlu:college_biology,test,22.797175407409668,llama2_7b_chat,oe,choice,,,,
8,0.30733129382133484,0.25,0.625,0.5833333333333333,0.14616382122039792,mmlu:college_chemistry,validation,1.6591093353927135,llama2_7b_chat,oe,choice,,,,
100,0.3795311897993088,0.17000000178813934,0.6399999856948853,0.6371367824238129,0.042970377206802364,mmlu:college_chemistry,test,17.40874121338129,llama2_7b_chat,oe,choice,,,,
11,0.37904362515969703,0.1818181872367859,0.4545454680919647,0.6111111111111112,0.2312782515179027,mmlu:college_computer_science,validation,2.911227960139513,llama2_7b_chat,oe,choice,,,,
100,0.3648486855626107,0.1899999976158142,0.25,0.5159194282001299,0.3929947382211685,mmlu:college_computer_science,test,26.129834573715925,llama2_7b_chat,oe,choice,,,,
11,0.22788689082319086,0.4545454680919647,0.6363636255264282,0.4666666666666667,0.2442125461318276,mmlu:college_mathematics,validation,2.131106775254011,llama2_7b_chat,oe,choice,,,,
100,0.18770410388708117,0.25,0.5,0.5205333333333334,0.1411510419845581,mmlu:college_mathematics,test,17.429659789428115,llama2_7b_chat,oe,choice,,,,
22,0.3398749489675869,0.3181818127632141,0.8636363744735718,0.419047619047619,0.20204461975531143,mmlu:college_medicine,validation,3.8399247489869595,llama2_7b_chat,oe,choice,,,,
173,0.3578732292776163,0.32947975397109985,0.6358381509780884,0.5848457350272233,0.10602680417154567,mmlu:college_medicine,test,40.283986788243055,llama2_7b_chat,oe,choice,,,,
11,0.2627552070400932,0.4545454680919647,0.7272727489471436,0.3333333333333333,0.11287179860201746,mmlu:college_physics,validation,1.8208032362163067,llama2_7b_chat,oe,choice,,,,
102,0.33012838369491054,0.2352941334247589,0.6274510025978088,0.6180555555555556,0.13796914383476852,mmlu:college_physics,test,15.223825059831142,llama2_7b_chat,oe,choice,,,,
11,0.37034989757971326,0.27272728085517883,0.5454545617103577,0.5416666666666666,0.13281140544197775,mmlu:computer_security,validation,1.7785413041710854,llama2_7b_chat,oe,choice,,,,
100,0.28003013134002686,0.4899999797344208,0.5099999904632568,0.5270108043217288,0.11682403504848479,mmlu:computer_security,test,12.910878276452422,llama2_7b_chat,oe,choice,,,,
26,0.3869931823932208,0.3461538553237915,0.7307692766189575,0.37254901960784315,0.14643980218813968,mmlu:conceptual_physics,validation,2.7209530994296074,llama2_7b_chat,oe,choice,,,,
235,0.31803804483819514,0.4170212745666504,0.5574467778205872,0.5052137643378519,0.12494373093260093,mmlu:conceptual_physics,test,22.893441358581185,llama2_7b_chat,oe,choice,,,,
12,0.5138435711463293,0.0833333358168602,0.25,0.0,0.3846641182899475,mmlu:econometrics,validation,2.418404320254922,llama2_7b_chat,oe,choice,,,,
114,0.26663590131098763,0.3245614171028137,0.5438596606254578,0.5335205335205336,0.18481003453857023,mmlu:econometrics,test,21.670069601386786,llama2_7b_chat,oe,choice,,,,
16,0.3721194565296173,0.1875,0.5625,0.6153846153846153,0.07281528785824776,mmlu:electrical_engineering,validation,2.228295098990202,llama2_7b_chat,oe,choice,,,,
145,0.29587967991828923,0.29655173420906067,0.4965517222881317,0.624829001367989,0.12701460451915347,mmlu:electrical_engineering,test,18.946658911183476,llama2_7b_chat,oe,choice,,,,
41,0.26353369907635016,0.19512194395065308,0.4390243887901306,0.6704545454545455,0.20883901235533925,mmlu:elementary_mathematics,validation,7.028885617852211,llama2_7b_chat,oe,choice,,,,
378,0.32520310919751566,0.15608465671539307,0.48677247762680054,0.5612347909250306,0.13929413361524148,mmlu:elementary_mathematics,test,61.911817429587245,llama2_7b_chat,oe,choice,,,,
14,0.3947497137955257,0.2142857313156128,0.4285714626312256,0.4242424242424242,0.22956514358520508,mmlu:formal_logic,validation,2.7473331671208143,llama2_7b_chat,oe,choice,,,,
126,0.34293854993487166,0.1666666716337204,0.341269850730896,0.48117913832199544,0.2901832518123445,mmlu:formal_logic,test,24.12924680300057,llama2_7b_chat,oe,choice,,,,
10,0.39951248168945314,0.5,0.5,0.52,0.414712929725647,mmlu:global_facts,validation,1.4830014016479254,llama2_7b_chat,oe,choice,,,,
100,0.19522883623838427,0.3700000047683716,0.5199999809265137,0.4444444444444445,0.10725109815597536,mmlu:global_facts,test,13.265046836808324,llama2_7b_chat,oe,choice,,,,
32,0.26464015059173107,0.34375,0.5625,0.5887445887445888,0.10672567598521711,mmlu:high_school_biology,validation,5.3430694453418255,llama2_7b_chat,oe,choice,,,,
310,0.19769324294982418,0.45483869314193726,0.6096774339675903,0.5447983549456544,0.03181774539332237,mmlu:high_school_biology,test,50.95085862278938,llama2_7b_chat,oe,choice,,,,
22,0.288499116897583,0.3181818127632141,0.5,0.7142857142857143,0.20561692389574918,mmlu:high_school_chemistry,validation,3.73295870795846,llama2_7b_chat,oe,choice,,,,
203,0.32531837201470815,0.2807881832122803,0.45812806487083435,0.6485219899062725,0.17603724314074212,mmlu:high_school_chemistry,test,32.304537016898394,llama2_7b_chat,oe,choice,,,,
9,0.3720434374279446,0.3333333432674408,0.5555555820465088,0.8333333333333333,0.29493377606074017,mmlu:high_school_computer_science,validation,2.779360031709075,llama2_7b_chat,oe,choice,,,,
100,0.3044472533464432,0.3199999928474426,0.4699999988079071,0.5983455882352942,0.14944067597389224,mmlu:high_school_computer_science,test,29.82078856229782,llama2_7b_chat,oe,choice,,,,
22,0.11895058371803977,0.6818181872367859,0.5454545617103577,0.8476190476190477,0.1724851483648474,mmlu:high_school_geography,validation,2.7651862632483244,llama2_7b_chat,oe,choice,,,,
198,0.21035245632884475,0.5252525210380554,0.5505050420761108,0.6153334697217676,0.06829968245342527,mmlu:high_school_geography,test,24.350783564150333,llama2_7b_chat,oe,choice,,,,
21,0.49150010801496963,0.3333333432674408,0.6666666865348816,0.2857142857142857,0.044685119674319304,mmlu:high_school_government_and_politics,validation,3.191906338557601,llama2_7b_chat,oe,choice,,,,
193,0.11383651482626563,0.6994818449020386,0.6113989353179932,0.48473818646232436,0.06687280273190432,mmlu:high_school_government_and_politics,test,28.242628894746304,llama2_7b_chat,oe,choice,,,,
43,0.25150079574695855,0.44186046719551086,0.4651162624359131,0.4824561403508772,0.19235242522040077,mmlu:high_school_macroeconomics,validation,5.524168435484171,llama2_7b_chat,oe,choice,,,,
390,0.24026215068804913,0.41025641560554504,0.6051282286643982,0.5585461956521739,0.028046821936582905,mmlu:high_school_macroeconomics,test,49.19661990739405,llama2_7b_chat,oe,choice,,,,
29,0.2573509483501829,0.20689654350280762,0.37931033968925476,0.24637681159420294,0.2167710209714955,mmlu:high_school_mathematics,validation,4.705982103943825,llama2_7b_chat,oe,choice,,,,
270,0.2809365680924169,0.20000000298023224,0.40740740299224854,0.5195044581618655,0.20440727693063238,mmlu:high_school_mathematics,test,42.0504211243242,llama2_7b_chat,oe,choice,,,,
26,0.3872666691358273,0.3461538553237915,0.46153849363327026,0.4575163398692811,0.2084040871033302,mmlu:high_school_microeconomics,validation,3.3470571134239435,llama2_7b_chat,oe,choice,,,,
238,0.2912635302343288,0.3571428656578064,0.5588235855102539,0.6153018069973087,0.06636623124114609,mmlu:high_school_microeconomics,test,30.47583471611142,llama2_7b_chat,oe,choice,,,,
17,0.30807772454093485,0.1764705926179886,0.4117647111415863,0.6190476190476191,0.23763253758935365,mmlu:high_school_physics,validation,3.1729356348514557,llama2_7b_chat,oe,choice,,,,
151,0.2579703638885195,0.2450331151485443,0.42384105920791626,0.560692271218587,0.1900382882711903,mmlu:high_school_physics,test,26.231312457472086,llama2_7b_chat,oe,choice,,,,
60,0.1757079487045606,0.6666666865348816,0.6500000357627869,0.52875,0.13654082119464872,mmlu:high_school_psychology,validation,9.706836327910423,llama2_7b_chat,oe,choice,,,,
545,0.13719539418133028,0.5853211283683777,0.6183486580848694,0.5790842511165979,0.04054269615663299,mmlu:high_school_psychology,test,88.93643733114004,llama2_7b_chat,oe,choice,,,,
23,0.25403486645740014,0.260869562625885,0.695652186870575,0.39215686274509803,0.0558552042297695,mmlu:high_school_statistics,validation,5.862922389060259,llama2_7b_chat,oe,choice,,,,
216,0.30122099596041224,0.25,0.6388888955116272,0.5354938271604938,0.048749548969445444,mmlu:high_school_statistics,test,56.11567802168429,llama2_7b_chat,oe,choice,,,,
22,0.28984237665479834,0.40909093618392944,0.6363636255264282,0.3162393162393162,0.13806072419339957,mmlu:high_school_us_history,validation,21.72521075233817,llama2_7b_chat,oe,choice,,,,
204,0.15090080686644014,0.529411792755127,0.5833333730697632,0.45775462962962965,0.0878105689497555,mmlu:high_school_us_history,test,192.41251107677817,llama2_7b_chat,oe,choice,,,,
23,0.2563094224618829,0.695652186870575,0.3913043439388275,0.35714285714285715,0.29602975171545276,mmlu:human_aging,validation,2.452693423256278,llama2_7b_chat,oe,choice,,,,
223,0.12175258673359995,0.5695067644119263,0.452914834022522,0.4524278215223097,0.2512456566228995,mmlu:human_aging,test,22.56031772866845,llama2_7b_chat,oe,choice,,,,
12,0.2739627212285995,0.4166666865348816,0.6666666865348816,0.2571428571428572,0.1506176292896271,mmlu:human_sexuality,validation,1.5204388182610273,llama2_7b_chat,oe,choice,,,,
131,0.18593752816433218,0.5038167834281921,0.580152690410614,0.4502331002331002,0.1277584219706878,mmlu:human_sexuality,test,15.600306274369359,llama2_7b_chat,oe,choice,,,,
13,0.13006082406410804,0.9230769872665405,0.692307710647583,0.5,0.17618703842163086,mmlu:international_law,validation,2.7727050371468067,llama2_7b_chat,oe,choice,,,,
121,0.17942237927893964,0.6280991435050964,0.6446280479431152,0.6089181286549707,0.0349916244341322,mmlu:international_law,test,23.71690267138183,llama2_7b_chat,oe,choice,,,,
11,0.2877437797459689,0.3636363744735718,0.8181818723678589,0.14285714285714285,0.1826417554508556,mmlu:jurisprudence,validation,1.5575965717434883,llama2_7b_chat,oe,choice,,,,
108,0.1411077680963057,0.5462962985038757,0.472222238779068,0.4259771705292287,0.16417700217829811,mmlu:jurisprudence,test,13.960483837872744,llama2_7b_chat,oe,choice,,,,
18,0.30899602837032747,0.6111111044883728,0.6666666865348816,0.5714285714285714,0.1306105156739553,mmlu:logical_fallacies,validation,2.615444131195545,llama2_7b_chat,oe,choice,,,,
163,0.24012123807076294,0.460122674703598,0.6257668733596802,0.6247727272727274,0.044421872843993994,mmlu:logical_fallacies,test,22.92276382818818,llama2_7b_chat,oe,choice,,,,
11,0.4008538722991944,0.09090909361839294,0.6363636255264282,0.5,0.26481320641257544,mmlu:machine_learning,validation,2.324588183313608,llama2_7b_chat,oe,choice,,,,
112,0.39928808914763586,0.1875000149011612,0.4285714626312256,0.5405546834118262,0.22876110672950745,mmlu:machine_learning,test,22.25546428002417,llama2_7b_chat,oe,choice,,,,
11,0.20957784219221637,0.7272727489471436,0.6363636255264282,0.2916666666666667,0.1668708486990495,mmlu:management,validation,1.1406714897602797,llama2_7b_chat,oe,choice,,,,
103,0.13900363300610513,0.6504854559898376,0.5436893105506897,0.4548092868988391,0.1378488413338522,mmlu:management,test,9.530747367069125,llama2_7b_chat,oe,choice,,,,
25,0.2425061905384064,0.7199999690055847,0.6399999856948853,0.3888888888888889,0.20194047451019287,mmlu:marketing,validation,3.4083045832812786,llama2_7b_chat,oe,choice,,,,
234,0.07061166704719901,0.7264957427978516,0.5811966061592102,0.5315257352941176,0.05322469860060604,mmlu:marketing,test,30.038867818191648,llama2_7b_chat,oe,choice,,,,
11,0.25215952775695105,0.7272727489471436,0.8181818723678589,0.5416666666666667,0.31296784769405017,mmlu:medical_genetics,validation,1.4724860917776823,llama2_7b_chat,oe,choice,,,,
100,0.2430890989303589,0.4399999976158142,0.5799999833106995,0.6101866883116882,0.11969738066196445,mmlu:medical_genetics,test,11.60611616820097,llama2_7b_chat,oe,choice,,,,
38,0.28020251424689047,0.4736842215061188,0.6052631735801697,0.37777777777777777,0.13213000799480237,mmlu:moral_disputes,validation,5.692475605756044,llama2_7b_chat,oe,choice,,,,
346,0.29246990391284744,0.4566473960876465,0.5404624342918396,0.4774946135200646,0.10782696315318864,mmlu:moral_disputes,test,51.442240841686726,llama2_7b_chat,oe,choice,,,,
33,0.2738685996243448,0.42424243688583374,0.6666666865348816,0.6616541353383459,0.07630433097030179,mmlu:nutrition,validation,6.276554048061371,llama2_7b_chat,oe,choice,,,,
306,0.2845178060477076,0.3464052379131317,0.584967315196991,0.5560141509433963,0.021286316167295365,mmlu:nutrition,test,57.5602522790432,llama2_7b_chat,oe,choice,,,,
34,0.3599341485430212,0.529411792755127,0.47058823704719543,0.375,0.23326647106338952,mmlu:philosophy,validation,3.9647752083837986,llama2_7b_chat,oe,choice,,,,
311,0.22359934727095332,0.5755627155303955,0.5273311734199524,0.42470797359065515,0.13526713637293727,mmlu:philosophy,test,34.53749513439834,llama2_7b_chat,oe,choice,,,,
35,0.33360244716916765,0.37142857909202576,0.5428571701049805,0.7867132867132867,0.17352881431579592,mmlu:prehistory,validation,6.586449924856424,llama2_7b_chat,oe,choice,,,,
324,0.2215912996986766,0.48765432834625244,0.5586419701576233,0.5552272380661888,0.06152461561155908,mmlu:prehistory,test,54.629484659060836,llama2_7b_chat,oe,choice,,,,
69,0.3111147733702176,0.37681159377098083,0.6376811861991882,0.4141323792486583,0.08783121644586755,mmlu:professional_psychology,validation,13.01443318463862,llama2_7b_chat,oe,choice,,,,
612,0.2945669362065839,0.3741829991340637,0.6127451062202454,0.4535498876942547,0.033779630571409,mmlu:professional_psychology,test,109.45141275040805,llama2_7b_chat,oe,choice,,,,
12,0.37314925591150916,0.5,0.4166666865348816,0.3888888888888889,0.25275109211603797,mmlu:public_relations,validation,1.8830669820308685,llama2_7b_chat,oe,choice,,,,
110,0.18714106326753444,0.5454545021057129,0.5545454621315002,0.553,0.06484392231160946,mmlu:public_relations,test,15.00705485790968,llama2_7b_chat,oe,choice,,,,
27,0.2797603011131287,0.48148149251937866,0.5555555820465088,0.5384615384615385,0.12859549345793547,mmlu:security_studies,validation,11.770874440670013,llama2_7b_chat,oe,choice,,,,
245,0.3246809972792256,0.3551020324230194,0.5428571105003357,0.5647461079586789,0.0821446939390533,mmlu:security_studies,test,106.5268478076905,llama2_7b_chat,oe,choice,,,,
22,0.17001411454244092,0.7727273106575012,0.3181818127632141,0.7058823529411764,0.3405432538552718,mmlu:sociology,validation,3.0956108402460814,llama2_7b_chat,oe,choice,,,,
201,0.1533688143711185,0.676616907119751,0.5522388219833374,0.6373868778280544,0.10324965217220251,mmlu:sociology,test,28.088155515491962,llama2_7b_chat,oe,choice,,,,
11,0.14814346757802097,0.7272727489471436,0.6363636255264282,0.5833333333333334,0.276151564988223,mmlu:us_foreign_policy,validation,1.6194038689136505,llama2_7b_chat,oe,choice,,,,
100,0.15613329023122788,0.699999988079071,0.5299999713897705,0.48309523809523813,0.13945346772670747,mmlu:us_foreign_policy,test,13.116577303037047,llama2_7b_chat,oe,choice,,,,
18,0.28152537180317777,0.4444444477558136,0.5555555820465088,0.4125,0.1874687241183387,mmlu:virology,validation,2.754456039518118,llama2_7b_chat,oe,choice,,,,
166,0.3160623094762664,0.41566264629364014,0.5060240626335144,0.4871507545196474,0.13545309635530034,mmlu:virology,test,19.520353496074677,llama2_7b_chat,oe,choice,,,,
19,0.08325813945971036,0.7894737124443054,0.4736842215061188,0.5833333333333333,0.23160773515701294,mmlu:world_religions,validation,1.7933202665299177,llama2_7b_chat,oe,choice,,,,
171,0.09975372141564798,0.6608186960220337,0.39181286096572876,0.5362374122673176,0.2258822367205258,mmlu:world_religions,test,14.692780438810587,llama2_7b_chat,oe,choice,,,,
