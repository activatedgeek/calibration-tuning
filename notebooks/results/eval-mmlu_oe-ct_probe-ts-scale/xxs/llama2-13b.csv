N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.5454545617103577,0.85,0.363671875,mmlu_offline:llama2-13b:abstract_algebra,validation,1.9611342640127987
100,0.23000000417232513,0.5400000214576721,0.6487859966120836,0.2969958112411893,mmlu_offline:llama2-13b:abstract_algebra,test,5.159133560024202
14,0.2142857164144516,0.2857142984867096,0.6212121212121211,0.5652901657990047,mmlu_offline:llama2-13b:anatomy,validation,0.6708711448591202
135,0.45185184478759766,0.4444444477558136,0.48427115640230395,0.38446179407614245,mmlu_offline:llama2-13b:anatomy,test,5.396132418885827
16,0.25,0.4375,0.39583333333333337,0.32275390625,mmlu_offline:llama2-13b:astronomy,validation,1.1219869288615882
152,0.5131579041481018,0.5723684430122375,0.5515419265419266,0.1624177686477963,mmlu_offline:llama2-13b:astronomy,test,8.575649722944945
11,0.4545454680919647,0.5454545617103577,0.7333333333333333,0.26846589825370093,mmlu_offline:llama2-13b:business_ethics,validation,0.943032587878406
100,0.3199999928474426,0.3499999940395355,0.5232077205882353,0.3696874892711639,mmlu_offline:llama2-13b:business_ethics,test,7.406602795934305
29,0.24137930572032928,0.27586206793785095,0.672077922077922,0.5732758517923027,mmlu_offline:llama2-13b:clinical_knowledge,validation,1.5080108428373933
265,0.3207547068595886,0.4000000059604645,0.6018954248366013,0.46326652990197237,mmlu_offline:llama2-13b:clinical_knowledge,test,12.41632175585255
16,0.25,0.375,0.7083333333333334,0.4694824106991291,mmlu_offline:llama2-13b:college_biology,validation,1.1024931599386036
144,0.3958333432674408,0.4861111044883728,0.5587820125025207,0.2808431035114659,mmlu_offline:llama2-13b:college_biology,test,8.779739127960056
8,0.125,0.25,1.0,0.5078125,mmlu_offline:llama2-13b:college_chemistry,validation,0.6584413959644735
100,0.15000000596046448,0.5899999737739563,0.703529411764706,0.19808593213558198,mmlu_offline:llama2-13b:college_chemistry,test,7.21996414498426
11,0.1818181872367859,0.6363636255264282,0.6666666666666667,0.3650568236004223,mmlu_offline:llama2-13b:college_computer_science,validation,1.5438832098152488
100,0.2199999988079071,0.47999998927116394,0.5201048951048951,0.31340752165726943,mmlu_offline:llama2-13b:college_computer_science,test,12.95265751099214
11,0.1818181872367859,0.8181818127632141,0.9444444444444444,0.18185762564341226,mmlu_offline:llama2-13b:college_mathematics,validation,1.1814606711268425
100,0.10000000149011612,0.7300000190734863,0.5722222222222222,0.16663489472575307,mmlu_offline:llama2-13b:college_mathematics,test,8.926087894942611
22,0.5,0.40909090638160706,0.5743801652892562,0.3984374918720938,mmlu_offline:llama2-13b:college_medicine,validation,1.5909905668813735
173,0.3583815097808838,0.47398844361305237,0.5877651845393781,0.3179190689428693,mmlu_offline:llama2-13b:college_medicine,test,16.82173066609539
11,0.3636363744735718,0.5454545617103577,0.5714285714285714,0.33167613094503234,mmlu_offline:llama2-13b:college_physics,validation,1.1045507108792663
102,0.21568627655506134,0.7549019455909729,0.6227272727272728,0.08061426644231759,mmlu_offline:llama2-13b:college_physics,test,7.9254164199810475
11,0.3636363744735718,0.3636363744735718,0.3571428571428572,0.5784801136363636,mmlu_offline:llama2-13b:computer_security,validation,0.9790817580651492
100,0.46000000834465027,0.3799999952316284,0.32407407407407407,0.34078124642372126,mmlu_offline:llama2-13b:computer_security,test,5.2934121349826455
26,0.3461538553237915,0.42307692766189575,0.41830065359477125,0.31715744733810425,mmlu_offline:llama2-13b:conceptual_physics,validation,1.2187792418990284
235,0.44255319237709045,0.5148935914039612,0.5662800939518496,0.2153091808582874,mmlu_offline:llama2-13b:conceptual_physics,test,9.395880684955046
12,0.0833333358168602,0.8333333134651184,0.8181818181818181,0.19628906249999997,mmlu_offline:llama2-13b:econometrics,validation,1.2805182170122862
114,0.19298245012760162,0.640350878238678,0.6274703557312252,0.14771156184441223,mmlu_offline:llama2-13b:econometrics,test,10.33989120903425
16,0.375,0.4375,0.4916666666666667,0.2717285118997097,mmlu_offline:llama2-13b:electrical_engineering,validation,1.1022743878420442
145,0.2344827651977539,0.6206896305084229,0.550476947535771,0.1406521275639534,mmlu_offline:llama2-13b:electrical_engineering,test,9.113681307062507
41,0.2926829159259796,0.7317073345184326,0.3764367816091954,0.25524010163981736,mmlu_offline:llama2-13b:elementary_mathematics,validation,3.0264810260850936
378,0.4021163880825043,0.5820105671882629,0.48911271541686074,0.3263293959761179,mmlu_offline:llama2-13b:elementary_mathematics,test,24.559274956816807
14,0.3571428656578064,0.2142857164144516,0.2333333333333334,0.4207589200564793,mmlu_offline:llama2-13b:formal_logic,validation,1.1873662031721324
126,0.190476194024086,0.4285714328289032,0.667483660130719,0.27824280990494626,mmlu_offline:llama2-13b:formal_logic,test,9.497818684903905
10,0.30000001192092896,0.4000000059604645,0.7380952380952381,0.32851561307907107,mmlu_offline:llama2-13b:global_facts,validation,0.7104892691131681
100,0.23999999463558197,0.3100000023841858,0.5800438596491229,0.4126171958446503,mmlu_offline:llama2-13b:global_facts,test,5.402608323842287
32,0.34375,0.28125,0.3203463203463204,0.47314452566206455,mmlu_offline:llama2-13b:high_school_biology,validation,2.065088666975498
310,0.47096773982048035,0.4935483932495117,0.5282951887738054,0.24275453821305307,mmlu_offline:llama2-13b:high_school_biology,test,18.963463472900912
22,0.04545454680919647,0.3636363744735718,0.5714285714285714,0.3689630790190265,mmlu_offline:llama2-13b:high_school_chemistry,validation,1.7238593930378556
203,0.19704432785511017,0.39901477098464966,0.5033742331288343,0.322640860902852,mmlu_offline:llama2-13b:high_school_chemistry,test,14.361162841087207
9,0.2222222238779068,0.5555555820465088,0.4642857142857143,0.21310764551162717,mmlu_offline:llama2-13b:high_school_computer_science,validation,1.1971829237882048
100,0.41999998688697815,0.5299999713897705,0.5519293924466339,0.22238281190395356,mmlu_offline:llama2-13b:high_school_computer_science,test,11.487902775872499
18,0.7222222089767456,0.4444444477558136,0.3615384615384616,0.2960069444444444,mmlu_offline:llama2-13b:high_school_european_history,validation,9.345069671981037
165,0.6000000238418579,0.4727272689342499,0.4461279461279461,0.18252841270331183,mmlu_offline:llama2-13b:high_school_european_history,test,86.4084360320121
22,0.40909090638160706,0.3181818127632141,0.23076923076923075,0.5465198809450323,mmlu_offline:llama2-13b:high_school_geography,validation,1.1271186829544604
198,0.3787878751754761,0.39898988604545593,0.5696476964769648,0.4044744333233497,mmlu_offline:llama2-13b:high_school_geography,test,8.529532703803852
21,0.4761904776096344,0.4285714328289032,0.32727272727272727,0.3216145861716498,mmlu_offline:llama2-13b:high_school_government_and_politics,validation,1.2540834890678525
193,0.5544041395187378,0.49740931391716003,0.46886546402955875,0.20328691555428383,mmlu_offline:llama2-13b:high_school_government_and_politics,test,9.78084513405338
43,0.41860464215278625,0.41860464215278625,0.3666666666666667,0.3561046511627907,mmlu_offline:llama2-13b:high_school_macroeconomics,validation,2.0288803309667856
390,0.34358975291252136,0.4923076927661896,0.5280725279850746,0.2599659522374471,mmlu_offline:llama2-13b:high_school_macroeconomics,test,17.815472844988108
29,0.13793103396892548,0.8620689511299133,0.58,0.09519675042894149,mmlu_offline:llama2-13b:high_school_mathematics,validation,2.4388365109916776
270,0.10000000149011612,0.8185185194015503,0.5708733424782808,0.07026467712558046,mmlu_offline:llama2-13b:high_school_mathematics,test,21.293378959875554
26,0.38461539149284363,0.42307692766189575,0.525,0.33248197803130514,mmlu_offline:llama2-13b:high_school_microeconomics,validation,1.2712898349855095
238,0.3781512677669525,0.4453781545162201,0.48284534534534534,0.2863707980688881,mmlu_offline:llama2-13b:high_school_microeconomics,test,10.556329036829993
17,0.11764705926179886,0.7647058963775635,0.7166666666666667,0.20059742647058823,mmlu_offline:llama2-13b:high_school_physics,validation,1.4679840500466526
151,0.20529800653457642,0.7417218685150146,0.5979838709677419,0.07046771838965007,mmlu_offline:llama2-13b:high_school_physics,test,11.364263356896117
60,0.6000000238418579,0.550000011920929,0.5515046296296297,0.17057290971279146,mmlu_offline:llama2-13b:high_school_psychology,validation,3.9261142790783197
545,0.5357798337936401,0.5724770426750183,0.5750175970545239,0.12965882699423972,mmlu_offline:llama2-13b:high_school_psychology,test,34.28187192394398
23,0.043478261679410934,0.8695651888847351,0.36363636363636365,0.14612926949154245,mmlu_offline:llama2-13b:high_school_statistics,validation,2.501320973969996
216,0.25925925374031067,0.6203703880310059,0.5469308035714286,0.12686100377226778,mmlu_offline:llama2-13b:high_school_statistics,test,22.259149346034974
22,0.5909090638160706,0.5454545617103577,0.5256410256410257,0.23899148269133133,mmlu_offline:llama2-13b:high_school_us_history,validation,8.883715040050447
204,0.6225489974021912,0.6323529481887817,0.6209223847019123,0.13997396183948893,mmlu_offline:llama2-13b:high_school_us_history,test,81.79769468912855
26,0.6153846383094788,0.7307692170143127,0.6875,0.1379206799543821,mmlu_offline:llama2-13b:high_school_world_history,validation,7.479617862962186
237,0.5274261832237244,0.552742600440979,0.5639642857142858,0.10815532650122661,mmlu_offline:llama2-13b:high_school_world_history,test,62.13754205801524
23,0.3478260934352875,0.3913043439388275,0.375,0.3468070600343787,mmlu_offline:llama2-13b:human_aging,validation,1.068484626011923
223,0.3497757911682129,0.4304932653903961,0.5435455349248454,0.25839055733830407,mmlu_offline:llama2-13b:human_aging,test,9.187036651885137
12,0.25,0.5,0.7777777777777778,0.35188801586627955,mmlu_offline:llama2-13b:human_sexuality,validation,0.770515421172604
131,0.442748099565506,0.47328245639801025,0.5638875767595655,0.244155527981183,mmlu_offline:llama2-13b:human_sexuality,test,6.849272927036509
13,0.3076923191547394,0.5384615659713745,0.6111111111111112,0.1820913369839008,mmlu_offline:llama2-13b:international_law,validation,0.936110750073567
121,0.5206611752510071,0.39669421315193176,0.3665845648604269,0.2223334100620806,mmlu_offline:llama2-13b:international_law,test,7.574738507857546
11,0.3636363744735718,0.4545454680919647,0.4642857142857143,0.4190340909090909,mmlu_offline:llama2-13b:jurisprudence,validation,0.7313226070255041
108,0.39814814925193787,0.37037035822868347,0.4329159212880143,0.44480611107967516,mmlu_offline:llama2-13b:jurisprudence,test,5.565279070055112
18,0.5555555820465088,0.4444444477558136,0.4375,0.25325521164470255,mmlu_offline:llama2-13b:logical_fallacies,validation,1.147598161129281
163,0.4601227045059204,0.5092024803161621,0.5104545454545455,0.20118385772763586,mmlu_offline:llama2-13b:logical_fallacies,test,9.045703719137236
11,0.4545454680919647,0.7272727489471436,0.9,0.23615057360042224,mmlu_offline:llama2-13b:machine_learning,validation,1.0426528491079807
112,0.2232142835855484,0.3928571343421936,0.47057471264367823,0.4086565316787788,mmlu_offline:llama2-13b:machine_learning,test,9.380431677913293
11,0.8181818127632141,0.9090909361839294,0.5,0.35404829003594135,mmlu_offline:llama2-13b:management,validation,0.6001530620269477
103,0.43689319491386414,0.48543688654899597,0.49808429118773945,0.2413531512890047,mmlu_offline:llama2-13b:management,test,3.8998458380810916
25,0.36000001430511475,0.36000001430511475,0.6527777777777778,0.5489062690734864,mmlu_offline:llama2-13b:marketing,validation,1.5151817000005394
234,0.5170940160751343,0.5213675498962402,0.5218313464492066,0.39314568806917244,mmlu_offline:llama2-13b:marketing,test,11.685216075042263
11,0.7272727489471436,0.6363636255264282,0.6666666666666667,0.1832386309450323,mmlu_offline:llama2-13b:medical_genetics,validation,0.6068951168563217
100,0.4699999988079071,0.46000000834465027,0.48875953432356484,0.2542578160762787,mmlu_offline:llama2-13b:medical_genetics,test,4.116252816980705
86,0.604651153087616,0.6395348906517029,0.6521493212669683,0.19926417289778242,mmlu_offline:llama2-13b:miscellaneous,validation,3.5387766850180924
783,0.6168582439422607,0.6143039464950562,0.5641959972394754,0.17368593085010087,mmlu_offline:llama2-13b:miscellaneous,test,32.194061495829374
38,0.3947368562221527,0.42105263471603394,0.6666666666666667,0.39319489504161637,mmlu_offline:llama2-13b:moral_disputes,validation,2.229573623975739
346,0.424855500459671,0.44797688722610474,0.521331145523536,0.37215498554913296,mmlu_offline:llama2-13b:moral_disputes,test,18.56376525806263
100,0.47999998927116394,0.47999998927116394,0.4268830128205128,0.30949219226837155,mmlu_offline:llama2-13b:moral_scenarios,validation,10.007063113851473
895,0.44134077429771423,0.44134077429771423,0.4911620253164557,0.34921000956157067,mmlu_offline:llama2-13b:moral_scenarios,test,87.69434890919365
33,0.3030303120613098,0.4545454680919647,0.6608695652173913,0.32729639790274884,mmlu_offline:llama2-13b:nutrition,validation,2.3061918870080262
306,0.36274510622024536,0.516339898109436,0.5977823977823978,0.23414520890105003,mmlu_offline:llama2-13b:nutrition,test,19.798579124966636
34,0.3235294222831726,0.44117647409439087,0.45059288537549413,0.28584557771682745,mmlu_offline:llama2-13b:philosophy,validation,1.7321697399020195
311,0.34405145049095154,0.4115755558013916,0.44014568444200103,0.35295668503095873,mmlu_offline:llama2-13b:philosophy,test,13.828240445815027
35,0.3142857253551483,0.37142857909202576,0.6022727272727273,0.41227678912026544,mmlu_offline:llama2-13b:prehistory,validation,2.1212016311474144
324,0.48148149251937866,0.48148149251937866,0.5944368131868132,0.34174863902139074,mmlu_offline:llama2-13b:prehistory,test,16.91097047715448
31,0.09677419066429138,0.4193548262119293,0.40476190476190477,0.30367943163841005,mmlu_offline:llama2-13b:professional_accounting,validation,3.5091907859314233
282,0.14539006352424622,0.4716311991214752,0.4558749114462099,0.31633699003686294,mmlu_offline:llama2-13b:professional_accounting,test,31.14991466794163
170,0.364705890417099,0.3764705955982208,0.5130675029868579,0.3240579023080713,mmlu_offline:llama2-13b:professional_law,validation,42.27373063284904
1534,0.29400262236595154,0.3116036653518677,0.4987920554098515,0.3818168576024813,mmlu_offline:llama2-13b:professional_law,test,388.75135200098157
31,0.35483869910240173,0.4516128897666931,0.5795454545454546,0.1780494066976732,mmlu_offline:llama2-13b:professional_medicine,validation,6.130742205074057
272,0.3345588147640228,0.5404411554336548,0.5862121304110254,0.17603975753573808,mmlu_offline:llama2-13b:professional_medicine,test,54.11969392304309
69,0.3913043439388275,0.5652173757553101,0.5088183421516754,0.15913724121840106,mmlu_offline:llama2-13b:professional_psychology,validation,4.958944056881592
612,0.3006536066532135,0.6192810535430908,0.5571096607070296,0.11164725537783182,mmlu_offline:llama2-13b:professional_psychology,test,39.504545537987724
12,0.25,0.25,0.25925925925925924,0.6246744841337204,mmlu_offline:llama2-13b:public_relations,validation,0.8202541850041598
110,0.30909091234207153,0.4000000059604645,0.6097136222910217,0.3670454464175485,mmlu_offline:llama2-13b:public_relations,test,5.878000057069585
27,0.48148149251937866,0.48148149251937866,0.5521978021978022,0.29846643739276457,mmlu_offline:llama2-13b:security_studies,validation,2.253317865077406
245,0.5265306234359741,0.5469387769699097,0.5341820368885325,0.21648598009226278,mmlu_offline:llama2-13b:security_studies,test,19.535032316111028
22,0.5909090638160706,0.3636363744735718,0.37606837606837606,0.23686080087314954,mmlu_offline:llama2-13b:sociology,validation,1.1531633140984923
201,0.4129353165626526,0.5472636818885803,0.5327241168062078,0.09295321845296604,mmlu_offline:llama2-13b:sociology,test,9.455508501967415
11,0.6363636255264282,0.5454545617103577,0.7142857142857142,0.15660512447357178,mmlu_offline:llama2-13b:us_foreign_policy,validation,0.7112317560240626
100,0.5699999928474426,0.5400000214576721,0.5593635250917993,0.21027342796325685,mmlu_offline:llama2-13b:us_foreign_policy,test,4.906289403093979
18,0.3333333432674408,0.5,0.5277777777777778,0.318576388888889,mmlu_offline:llama2-13b:virology,validation,1.2348418268375099
166,0.33734938502311707,0.5120481848716736,0.503896103896104,0.20830195639506882,mmlu_offline:llama2-13b:virology,test,7.760022846981883
19,0.6315789222717285,0.6315789222717285,0.4166666666666667,0.21936677945287605,mmlu_offline:llama2-13b:world_religions,validation,0.863427413860336
171,0.6432748436927795,0.6432748436927795,0.570715350223547,0.10658807712688782,mmlu_offline:llama2-13b:world_religions,test,6.2021263430360705
