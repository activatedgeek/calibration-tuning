N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.9090909361839294,0.5,0.40518465909090906,mmlu_offline:llama2-13b:abstract_algebra,validation,2.4665040066465735
100,0.23000000417232513,0.699999988079071,0.4720496894409938,0.26906249701976775,mmlu_offline:llama2-13b:abstract_algebra,test,5.182781462091953
14,0.2142857164144516,0.5714285969734192,0.6969696969696969,0.47656249999999994,mmlu_offline:llama2-13b:anatomy,validation,0.6765279569663107
135,0.45185184478759766,0.5925925970077515,0.7066902968542312,0.25892024609579967,mmlu_offline:llama2-13b:anatomy,test,5.38526679482311
16,0.25,0.625,0.4791666666666667,0.2675781399011612,mmlu_offline:llama2-13b:astronomy,validation,1.1216669348068535
152,0.5131579041481018,0.5,0.4941961191961192,0.07591489192686582,mmlu_offline:llama2-13b:astronomy,test,8.569897496607155
11,0.4545454680919647,0.5454545617103577,0.5666666666666667,0.052201704545454544,mmlu_offline:llama2-13b:business_ethics,validation,0.9558259970508516
100,0.3199999928474426,0.5199999809265137,0.5622702205882353,0.1630859422683716,mmlu_offline:llama2-13b:business_ethics,test,7.4334073420614
29,0.24137930572032928,0.6896551847457886,0.45454545454545453,0.22912177546270965,mmlu_offline:llama2-13b:clinical_knowledge,validation,1.5251895640976727
265,0.3207547068595886,0.6415094137191772,0.5677450980392157,0.22597287196033405,mmlu_offline:llama2-13b:clinical_knowledge,test,12.452823840081692
16,0.25,0.3125,0.34375,0.6372767899717604,mmlu_offline:llama2-13b:college_biology,validation,1.1073058699257672
144,0.3958333432674408,0.4583333432674408,0.564327485380117,0.35560727964901756,mmlu_offline:llama2-13b:college_biology,test,8.790958909317851
8,0.125,0.25,0.1428571428571429,0.630859375,mmlu_offline:llama2-13b:college_chemistry,validation,0.6626667808741331
100,0.15000000596046448,0.18000000715255737,0.6611764705882353,0.6042968726158142,mmlu_offline:llama2-13b:college_chemistry,test,7.223321984056383
11,0.1818181872367859,0.9090909361839294,1.0,0.38991478356448084,mmlu_offline:llama2-13b:college_computer_science,validation,1.5441243560053408
100,0.2199999988079071,0.6100000143051147,0.5352564102564104,0.20906249344348904,mmlu_offline:llama2-13b:college_computer_science,test,12.947463573887944
11,0.1818181872367859,0.8181818127632141,0.6666666666666666,0.4339488744735718,mmlu_offline:llama2-13b:college_mathematics,validation,1.1891898987814784
100,0.10000000149011612,0.7799999713897705,0.5299999999999999,0.3665234476327896,mmlu_offline:llama2-13b:college_mathematics,test,8.923491864930838
22,0.5,0.40909090638160706,0.4752066115702479,0.31054687500000006,mmlu_offline:llama2-13b:college_medicine,validation,1.5944769061170518
173,0.3583815097808838,0.45086705684661865,0.5822435338564371,0.345420877368464,mmlu_offline:llama2-13b:college_medicine,test,16.770958357024938
11,0.3636363744735718,0.3636363744735718,0.7857142857142857,0.4151278409090909,mmlu_offline:llama2-13b:college_physics,validation,1.1202028500847518
102,0.21568627655506134,0.3235294222831726,0.602840909090909,0.4431678915725035,mmlu_offline:llama2-13b:college_physics,test,7.937002860940993
11,0.3636363744735718,0.6363636255264282,0.5,0.13245738636363635,mmlu_offline:llama2-13b:computer_security,validation,0.9553072461858392
100,0.46000000834465027,0.6600000262260437,0.6461352657004832,0.15218751907348635,mmlu_offline:llama2-13b:computer_security,test,5.296509635169059
26,0.3461538553237915,0.5,0.5784313725490196,0.2765925320295188,mmlu_offline:llama2-13b:conceptual_physics,validation,1.2353362222202122
235,0.44255319237709045,0.5106382966041565,0.5513065179095713,0.2524434774479968,mmlu_offline:llama2-13b:conceptual_physics,test,9.413984237238765
12,0.0833333358168602,0.8333333134651184,0.9090909090909091,0.42187501986821496,mmlu_offline:llama2-13b:econometrics,validation,1.2847569580189884
114,0.19298245012760162,0.6315789222717285,0.47356719367588934,0.2313596365744607,mmlu_offline:llama2-13b:econometrics,test,10.365005327854306
16,0.375,0.8125,0.9000000000000001,0.2080078311264515,mmlu_offline:llama2-13b:electrical_engineering,validation,1.101820426993072
145,0.2344827651977539,0.4482758641242981,0.48065712771595126,0.31346984156246843,mmlu_offline:llama2-13b:electrical_engineering,test,9.093187500722706
41,0.2926829159259796,0.6341463327407837,0.4698275862068965,0.18044968494554842,mmlu_offline:llama2-13b:elementary_mathematics,validation,3.0432833400554955
378,0.4021163880825043,0.6164020895957947,0.563780857009781,0.11351894969662661,mmlu_offline:llama2-13b:elementary_mathematics,test,24.591209539677948
14,0.3571428656578064,0.7857142686843872,0.7,0.27092632651329046,mmlu_offline:llama2-13b:formal_logic,validation,1.1958451899699867
126,0.190476194024086,0.7698412537574768,0.4922385620915033,0.2954179043807681,mmlu_offline:llama2-13b:formal_logic,test,9.508618239779025
10,0.30000001192092896,0.800000011920929,0.6666666666666666,0.29218750000000004,mmlu_offline:llama2-13b:global_facts,validation,0.727388883009553
100,0.23999999463558197,0.699999988079071,0.5068530701754386,0.1969531065225601,mmlu_offline:llama2-13b:global_facts,test,5.407389346044511
32,0.34375,0.4375,0.40692640692640697,0.3955393087479375,mmlu_offline:llama2-13b:high_school_biology,validation,2.0873171370476484
310,0.47096773982048035,0.45483872294425964,0.44952806548613433,0.3059601747220562,mmlu_offline:llama2-13b:high_school_biology,test,19.013517423998564
22,0.04545454680919647,0.04545454680919647,0.023809523809523836,0.7237215990369971,mmlu_offline:llama2-13b:high_school_chemistry,validation,1.730593339074403
203,0.19704432785511017,0.23152709007263184,0.5360429447852761,0.5477794044710733,mmlu_offline:llama2-13b:high_school_chemistry,test,14.410706048831344
9,0.2222222238779068,0.6666666865348816,0.5357142857142857,0.43489583333333326,mmlu_offline:llama2-13b:high_school_computer_science,validation,1.2245810818858445
100,0.41999998688697815,0.550000011920929,0.48542692939244675,0.09300780355930334,mmlu_offline:llama2-13b:high_school_computer_science,test,11.50534678902477
18,0.7222222089767456,0.3333333432674408,0.4769230769230769,0.2170138888888889,mmlu_offline:llama2-13b:high_school_european_history,validation,9.333834385033697
165,0.6000000238418579,0.4545454680919647,0.5207376798285889,0.08984374566511673,mmlu_offline:llama2-13b:high_school_european_history,test,86.03859119489789
22,0.40909090638160706,0.5909090638160706,0.576923076923077,0.12038353627378294,mmlu_offline:llama2-13b:high_school_geography,validation,1.1271993112750351
198,0.3787878751754761,0.5454545617103577,0.5375609756097561,0.05348407379304519,mmlu_offline:llama2-13b:high_school_geography,test,8.553940584883094
21,0.4761904776096344,0.5714285969734192,0.55,0.1344865929512751,mmlu_offline:llama2-13b:high_school_government_and_politics,validation,1.260254496242851
193,0.5544041395187378,0.4818652868270874,0.5062486415996522,0.05458627834221244,mmlu_offline:llama2-13b:high_school_government_and_politics,test,9.814154047053307
43,0.41860464215278625,0.5813953280448914,0.5277777777777778,0.12627179262249968,mmlu_offline:llama2-13b:high_school_macroeconomics,validation,2.039525017142296
390,0.34358975291252136,0.6025640964508057,0.5121851679104478,0.14328926282051282,mmlu_offline:llama2-13b:high_school_macroeconomics,test,17.868960950989276
29,0.13793103396892548,0.8620689511299133,0.61,0.35304420569847367,mmlu_offline:llama2-13b:high_school_mathematics,validation,2.447597191669047
270,0.10000000149011612,0.8370370268821716,0.566986739826246,0.34628183400189433,mmlu_offline:llama2-13b:high_school_mathematics,test,21.370065941940993
26,0.38461539149284363,0.5769230723381042,0.5812499999999999,0.13146035946332493,mmlu_offline:llama2-13b:high_school_microeconomics,validation,1.2762201465666294
238,0.3781512677669525,0.605042040348053,0.5644894894894895,0.14702600290795337,mmlu_offline:llama2-13b:high_school_microeconomics,test,10.585918095894158
17,0.11764705926179886,0.3529411852359772,0.2,0.3694852941176471,mmlu_offline:llama2-13b:high_school_physics,validation,1.4790241797454655
151,0.20529800653457642,0.430463582277298,0.5311827956989247,0.33148799510981075,mmlu_offline:llama2-13b:high_school_physics,test,11.393464816268533
60,0.6000000238418579,0.4333333373069763,0.4594907407407407,0.19817707339922586,mmlu_offline:llama2-13b:high_school_psychology,validation,3.9223866420798004
545,0.5357798337936401,0.5596330165863037,0.5716200119118524,0.08635322260200429,mmlu_offline:llama2-13b:high_school_psychology,test,34.382471850607544
23,0.043478261679410934,0.9130434989929199,1.0,0.4780910326086957,mmlu_offline:llama2-13b:high_school_statistics,validation,2.5040031312964857
216,0.25925925374031067,0.7083333134651184,0.5016741071428571,0.21466289846985423,mmlu_offline:llama2-13b:high_school_statistics,test,22.247233727946877
22,0.5909090638160706,0.27272728085517883,0.33333333333333337,0.24769174239852215,mmlu_offline:llama2-13b:high_school_us_history,validation,8.860855943057686
204,0.6225489974021912,0.4362744987010956,0.5269966254218222,0.0956648436247134,mmlu_offline:llama2-13b:high_school_us_history,test,81.55292503302917
26,0.6153846383094788,0.5,0.575,0.11748798535420346,mmlu_offline:llama2-13b:high_school_world_history,validation,7.47685164026916
237,0.5274261832237244,0.5738396644592285,0.5802857142857143,0.054160086162985656,mmlu_offline:llama2-13b:high_school_world_history,test,61.92218895955011
23,0.3478260934352875,0.47826087474823,0.39999999999999997,0.1949728442275006,mmlu_offline:llama2-13b:human_aging,validation,1.0746670756489038
223,0.3497757911682129,0.6278026700019836,0.6713085764809903,0.19123107996756716,mmlu_offline:llama2-13b:human_aging,test,9.223076868802309
12,0.25,0.6666666865348816,0.5925925925925926,0.22460938493410743,mmlu_offline:llama2-13b:human_sexuality,validation,0.7654032278805971
131,0.442748099565506,0.6259542107582092,0.6198630136986303,0.1318284782744546,mmlu_offline:llama2-13b:human_sexuality,test,6.8698011501692235
13,0.3076923191547394,0.6153846383094788,0.5138888888888888,0.18930289378532997,mmlu_offline:llama2-13b:international_law,validation,0.9383658007718623
121,0.5206611752510071,0.4793388545513153,0.4889162561576355,0.04519625734691778,mmlu_offline:llama2-13b:international_law,test,7.575921777635813
11,0.3636363744735718,0.5454545617103577,0.5,0.19460227272727273,mmlu_offline:llama2-13b:jurisprudence,validation,0.7312312428839505
108,0.39814814925193787,0.5370370149612427,0.46422182468694095,0.08875868165934528,mmlu_offline:llama2-13b:jurisprudence,test,5.584724770858884
18,0.5555555820465088,0.6666666865348816,0.7000000000000001,0.11219617062144807,mmlu_offline:llama2-13b:logical_fallacies,validation,1.139028251171112
163,0.4601227045059204,0.5889570713043213,0.5764393939393939,0.07045628797788564,mmlu_offline:llama2-13b:logical_fallacies,test,9.060908108018339
11,0.4545454680919647,0.5454545617103577,0.5,0.041548295454545414,mmlu_offline:llama2-13b:machine_learning,validation,1.042774320114404
112,0.2232142835855484,0.7053571343421936,0.49517241379310356,0.28662108044539175,mmlu_offline:llama2-13b:machine_learning,test,9.407882133033127
11,0.8181818127632141,0.6363636255264282,0.7777777777777778,0.23579545996405862,mmlu_offline:llama2-13b:management,validation,0.6161657758057117
103,0.43689319491386414,0.5922330021858215,0.5881226053639846,0.10732708162474401,mmlu_offline:llama2-13b:management,test,3.82866494031623
25,0.36000001430511475,0.5199999809265137,0.4444444444444445,0.19343749999999996,mmlu_offline:llama2-13b:marketing,validation,1.5191982630640268
234,0.5170940160751343,0.49145299196243286,0.5046807576976523,0.035506798925562806,mmlu_offline:llama2-13b:marketing,test,11.695107474923134
11,0.7272727489471436,0.7272727489471436,0.8541666666666667,0.18643465909090912,mmlu_offline:llama2-13b:medical_genetics,validation,0.6271176668815315
100,0.4699999988079071,0.5400000214576721,0.7073464472099558,0.21953125,mmlu_offline:llama2-13b:medical_genetics,test,4.1152316983789206
86,0.604651153087616,0.569767415523529,0.5989819004524888,0.034020694189293446,mmlu_offline:llama2-13b:miscellaneous,validation,3.5693425936624408
783,0.6168582439422607,0.5530012845993042,0.5961421670117323,0.037790347942142796,mmlu_offline:llama2-13b:miscellaneous,test,32.22047156887129
38,0.3947368562221527,0.6052631735801697,0.5,0.10135690789473684,mmlu_offline:llama2-13b:moral_disputes,validation,2.215137765277177
346,0.424855500459671,0.6011560559272766,0.5331760845041535,0.09774656033929377,mmlu_offline:llama2-13b:moral_disputes,test,18.55320397624746
100,0.47999998927116394,0.5199999809265137,0.5,0.016093750000000018,mmlu_offline:llama2-13b:moral_scenarios,validation,9.955619310960174
895,0.44134077429771423,0.5586591958999634,0.5,0.05475296787709494,mmlu_offline:llama2-13b:moral_scenarios,test,87.6911297487095
33,0.3030303120613098,0.39393940567970276,0.6043478260869565,0.30965909452149365,mmlu_offline:llama2-13b:nutrition,validation,2.3062977651134133
306,0.36274510622024536,0.5228758454322815,0.6045045045045045,0.27400287358384384,mmlu_offline:llama2-13b:nutrition,test,19.854732827283442
34,0.3235294222831726,0.6764705777168274,0.5731225296442688,0.22644762431873994,mmlu_offline:llama2-13b:philosophy,validation,1.7316991770640016
311,0.34405145049095154,0.7041800618171692,0.6014293567894448,0.19489802789074814,mmlu_offline:llama2-13b:philosophy,test,13.866928348783404
35,0.3142857253551483,0.5142857432365417,0.43939393939393945,0.18348213774817326,mmlu_offline:llama2-13b:prehistory,validation,2.150403239298612
324,0.48148149251937866,0.5586419701576233,0.5575015262515262,0.05642359124289618,mmlu_offline:llama2-13b:prehistory,test,16.939911044202745
31,0.09677419066429138,0.5806451439857483,0.3214285714285714,0.3019153437306804,mmlu_offline:llama2-13b:professional_accounting,validation,3.5277296351268888
282,0.14539006352424622,0.6631205677986145,0.5583442971359175,0.29201296415734806,mmlu_offline:llama2-13b:professional_accounting,test,31.157244055066258
170,0.364705890417099,0.6352941393852234,0.5,0.1313878676470588,mmlu_offline:llama2-13b:professional_law,validation,42.03973899409175
1534,0.29400262236595154,0.7059974074363708,0.5006479906148847,0.2018950661981898,mmlu_offline:llama2-13b:professional_law,test,387.5097677106969
31,0.35483869910240173,0.5161290168762207,0.6318181818181818,0.25078124205271407,mmlu_offline:llama2-13b:professional_medicine,validation,6.1209544078446925
272,0.3345588147640228,0.4485294222831726,0.524376176309878,0.3128015778082259,mmlu_offline:llama2-13b:professional_medicine,test,53.957476150244474
69,0.3913043439388275,0.4637681245803833,0.4241622574955909,0.08559782435928567,mmlu_offline:llama2-13b:professional_psychology,validation,4.963729186914861
612,0.3006536066532135,0.648692786693573,0.5750838073953678,0.21331825423863976,mmlu_offline:llama2-13b:professional_psychology,test,39.45516183739528
12,0.25,0.5833333134651184,0.3888888888888889,0.28352864583333326,mmlu_offline:llama2-13b:public_relations,validation,0.8147551552392542
110,0.30909091234207153,0.6000000238418579,0.5541795665634675,0.15106533657420765,mmlu_offline:llama2-13b:public_relations,test,5.871717733796686
27,0.48148149251937866,0.5185185074806213,0.5,0.01461226851851849,mmlu_offline:llama2-13b:security_studies,validation,2.2524274848401546
245,0.5265306234359741,0.4693877696990967,0.49525527933707564,0.03593749902686291,mmlu_offline:llama2-13b:security_studies,test,19.511327812913805
22,0.5909090638160706,0.4545454680919647,0.5213675213675213,0.09446023810993542,mmlu_offline:llama2-13b:sociology,validation,1.1528472378849983
201,0.4129353165626526,0.6318408250808716,0.6121605064325097,0.12993626155663482,mmlu_offline:llama2-13b:sociology,test,9.444598203059286
11,0.6363636255264282,0.5454545617103577,0.6428571428571428,0.033025557344610046,mmlu_offline:llama2-13b:us_foreign_policy,validation,0.7251310627907515
100,0.5699999928474426,0.44999998807907104,0.5006119951040392,0.07746095418930056,mmlu_offline:llama2-13b:us_foreign_policy,test,4.925596299115568
18,0.3333333432674408,0.6111111044883728,0.5833333333333333,0.2743055456214481,mmlu_offline:llama2-13b:virology,validation,1.2659764299169183
166,0.33734938502311707,0.46385541558265686,0.48798701298701297,0.2386812743652298,mmlu_offline:llama2-13b:virology,test,7.749675797298551
19,0.6315789222717285,0.6842105388641357,0.5119047619047619,0.27919406326193563,mmlu_offline:llama2-13b:world_religions,validation,0.8668990638107061
171,0.6432748436927795,0.5906432867050171,0.5507451564828614,0.08182565963756269,mmlu_offline:llama2-13b:world_religions,test,6.2139405673369765
