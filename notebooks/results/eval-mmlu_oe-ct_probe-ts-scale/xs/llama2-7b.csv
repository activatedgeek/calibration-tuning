N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.8181818127632141,0.5,0.29083806818181823,mmlu_offline:llama2-7b:abstract_algebra,validation,6.73583019617945
100,0.2199999988079071,0.7799999713897705,0.5,0.25265625,mmlu_offline:llama2-7b:abstract_algebra,test,4.903070039115846
14,0.2857142984867096,0.7142857313156128,0.5,0.1869419642857143,mmlu_offline:llama2-7b:anatomy,validation,0.9285740102641284
135,0.4148148000240326,0.585185170173645,0.5,0.05784143518518514,mmlu_offline:llama2-7b:anatomy,test,5.600157347973436
16,0.4375,0.5625,0.5,0.03515625,mmlu_offline:llama2-7b:astronomy,validation,1.0360601441934705
152,0.5065789222717285,0.4934210479259491,0.5066666666666666,0.037571957236842105,mmlu_offline:llama2-7b:astronomy,test,7.0926151890307665
11,0.6363636255264282,0.3636363744735718,0.5,0.16370738636363635,mmlu_offline:llama2-7b:business_ethics,validation,1.1657216120511293
100,0.30000001192092896,0.699999988079071,0.5,0.17265624999999996,mmlu_offline:llama2-7b:business_ethics,test,6.128349935170263
29,0.24137930572032928,0.7586206793785095,0.5,0.23127693965517238,mmlu_offline:llama2-7b:clinical_knowledge,validation,1.6064871409907937
265,0.35849055647850037,0.6415094137191772,0.49473684210526314,0.11858785377358488,mmlu_offline:llama2-7b:clinical_knowledge,test,12.151509038172662
16,0.3125,0.6875,0.5,0.16015625,mmlu_offline:llama2-7b:college_biology,validation,0.9832503371872008
144,0.2986111044883728,0.7013888955116272,0.5,0.17404513888888884,mmlu_offline:llama2-7b:college_biology,test,7.056829591747373
8,0.125,0.875,0.5,0.34765625,mmlu_offline:llama2-7b:college_chemistry,validation,0.6868774760514498
100,0.14000000059604645,0.8600000143051147,0.5,0.33265625,mmlu_offline:llama2-7b:college_chemistry,test,5.466765652410686
11,0.0,1.0,,0.47265625,mmlu_offline:llama2-7b:college_computer_science,validation,1.5252289022319019
100,0.17000000178813934,0.8299999833106995,0.5060240963855422,0.30082031249999996,mmlu_offline:llama2-7b:college_computer_science,test,9.307339949999005
11,0.0,1.0,,0.47265625,mmlu_offline:llama2-7b:college_mathematics,validation,1.1231498871929944
100,0.1599999964237213,0.8399999737739563,0.5,0.31265624999999997,mmlu_offline:llama2-7b:college_mathematics,test,6.817932827863842
22,0.3636363744735718,0.6363636255264282,0.5,0.10901988636363635,mmlu_offline:llama2-7b:college_medicine,validation,1.5453587928786874
173,0.36994218826293945,0.6300578117370605,0.5,0.10271405346820806,mmlu_offline:llama2-7b:college_medicine,test,12.7296445351094
11,0.27272728085517883,0.7272727489471436,0.5,0.1999289772727273,mmlu_offline:llama2-7b:college_physics,validation,1.0257503460161388
102,0.14705882966518402,0.8529411554336548,0.5,0.3255974264705882,mmlu_offline:llama2-7b:college_physics,test,6.141813287977129
11,0.7272727489471436,0.27272728085517883,0.5,0.2546164772727273,mmlu_offline:llama2-7b:computer_security,validation,0.9497164073400199
100,0.4300000071525574,0.5600000023841858,0.49122807017543857,0.04429687499999998,mmlu_offline:llama2-7b:computer_security,test,4.82924257684499
26,0.3076923191547394,0.692307710647583,0.5,0.1649639423076923,mmlu_offline:llama2-7b:conceptual_physics,validation,1.8086851728148758
235,0.4127659499645233,0.5872340202331543,0.5,0.05989029255319145,mmlu_offline:llama2-7b:conceptual_physics,test,11.178524385206401
12,0.0833333358168602,0.9166666865348816,0.5,0.38932291666666663,mmlu_offline:llama2-7b:econometrics,validation,1.1047156560234725
114,0.14912280440330505,0.8508771657943726,0.5051546391752577,0.32089501096491224,mmlu_offline:llama2-7b:econometrics,test,8.207320316694677
16,0.125,0.875,0.5357142857142857,0.3393229166666667,mmlu_offline:llama2-7b:electrical_engineering,validation,1.0523094041272998
145,0.1862068921327591,0.8137931227684021,0.5127118644067796,0.2838362266277445,mmlu_offline:llama2-7b:electrical_engineering,test,8.197968655265868
41,0.26829269528388977,0.7317073345184326,0.5,0.20436356707317072,mmlu_offline:llama2-7b:elementary_mathematics,validation,2.7669474640861154
378,0.32275131344795227,0.6772486567497253,0.5,0.1499049272486772,mmlu_offline:llama2-7b:elementary_mathematics,test,21.95977244200185
14,0.5,0.5,0.5,0.02734375,mmlu_offline:llama2-7b:formal_logic,validation,1.3061103112995625
126,0.30158731341362,0.6984127163887024,0.5056818181818181,0.1704179067460317,mmlu_offline:llama2-7b:formal_logic,test,8.459871225059032
10,0.30000001192092896,0.699999988079071,0.5,0.17265624999999996,mmlu_offline:llama2-7b:global_facts,validation,1.235987565945834
100,0.17000000178813934,0.8299999833106995,0.5,0.30265624999999996,mmlu_offline:llama2-7b:global_facts,test,5.762454533018172
32,0.15625,0.84375,0.5,0.31640625,mmlu_offline:llama2-7b:high_school_biology,validation,2.28854559129104
310,0.41290321946144104,0.5870967507362366,0.5027472527472527,0.05922379032258068,mmlu_offline:llama2-7b:high_school_biology,test,15.756047462113202
22,0.13636364042758942,0.8636363744735718,0.5,0.33629261363636365,mmlu_offline:llama2-7b:high_school_chemistry,validation,1.484892725944519
203,0.16748768091201782,0.8325123190879822,0.5,0.30516856527093594,mmlu_offline:llama2-7b:high_school_chemistry,test,11.460758260916919
9,0.2222222238779068,0.7777777910232544,0.5,0.2504340277777778,mmlu_offline:llama2-7b:high_school_computer_science,validation,1.2490778998471797
100,0.3700000047683716,0.6299999952316284,0.4864864864864865,0.10901988636363635,mmlu_offline:llama2-7b:high_school_computer_science,test,8.350904596969485
18,0.7222222089767456,0.2777777910232544,0.5,0.2495659722222222,mmlu_offline:llama2-7b:high_school_european_history,validation,6.3718914412893355
165,0.6727272868156433,0.3333333432674408,0.5136803470136803,0.19902936617533362,mmlu_offline:llama2-7b:high_school_european_history,test,58.3134221569635
22,0.4545454680919647,0.5454545617103577,0.5,0.018110795454545414,mmlu_offline:llama2-7b:high_school_geography,validation,1.1864972868934274
198,0.3636363744735718,0.6363636255264282,0.5,0.10901988636363635,mmlu_offline:llama2-7b:high_school_geography,test,8.732242677360773
21,0.4285714328289032,0.5714285969734192,0.5,0.0440848214285714,mmlu_offline:llama2-7b:high_school_government_and_politics,validation,1.3214831538498402
193,0.48704662919044495,0.5129533410072327,0.5,0.014390382124352286,mmlu_offline:llama2-7b:high_school_government_and_politics,test,8.931294474750757
43,0.41860464215278625,0.5813953280448914,0.5,0.054051598837209336,mmlu_offline:llama2-7b:high_school_macroeconomics,validation,2.3138003828935325
390,0.34358975291252136,0.656410276889801,0.5,0.1290665064102564,mmlu_offline:llama2-7b:high_school_macroeconomics,test,17.66395094199106
29,0.03448275849223137,0.9655172228813171,0.5,0.4381734913793104,mmlu_offline:llama2-7b:high_school_mathematics,validation,1.9463060819543898
270,0.08148147910833359,0.9185185432434082,0.5,0.3911747685185185,mmlu_offline:llama2-7b:high_school_mathematics,test,15.77532167499885
26,0.3076923191547394,0.692307710647583,0.5,0.1649639423076923,mmlu_offline:llama2-7b:high_school_microeconomics,validation,1.5434816870838404
238,0.32773110270500183,0.6722689270973206,0.5,0.14492515756302526,mmlu_offline:llama2-7b:high_school_microeconomics,test,10.855745720211416
17,0.23529411852359772,0.7647058963775635,0.5,0.23736213235294112,mmlu_offline:llama2-7b:high_school_physics,validation,1.3396735228598118
151,0.17880794405937195,0.8211920261383057,0.5,0.2938483029801324,mmlu_offline:llama2-7b:high_school_physics,test,8.571290580090135
60,0.5,0.5,0.5,0.02734375,mmlu_offline:llama2-7b:high_school_psychology,validation,3.317866946104914
545,0.5064220428466797,0.4935779869556427,0.49814126394052044,0.03375146323387773,mmlu_offline:llama2-7b:high_school_psychology,test,28.013020570855588
23,0.1304347813129425,0.8695651888847351,0.5,0.3422214673913043,mmlu_offline:llama2-7b:high_school_statistics,validation,1.9971778839826584
216,0.24074074625968933,0.7592592835426331,0.5,0.2319155092592593,mmlu_offline:llama2-7b:high_school_statistics,test,16.012725876178592
22,0.5909090638160706,0.40909090638160706,0.5,0.11825284090909088,mmlu_offline:llama2-7b:high_school_us_history,validation,6.1746890489012
204,0.5980392098426819,0.406862735748291,0.49815073970411833,0.12038527984245151,mmlu_offline:llama2-7b:high_school_us_history,test,55.660234364215285
26,0.5384615659713745,0.4615384638309479,0.5357142857142857,0.06490382781395543,mmlu_offline:llama2-7b:high_school_world_history,validation,5.261751860380173
237,0.4345991611480713,0.5611814260482788,0.49029126213592233,0.04348405878594579,mmlu_offline:llama2-7b:high_school_world_history,test,43.16414428083226
23,0.21739129722118378,0.782608687877655,0.5,0.25526494565217395,mmlu_offline:llama2-7b:human_aging,validation,1.4017931460402906
223,0.340807169675827,0.6591928005218506,0.5034013605442177,0.13039517937219736,mmlu_offline:llama2-7b:human_aging,test,10.045840727165341
12,0.4166666567325592,0.5833333134651184,0.5,0.05598958333333337,mmlu_offline:llama2-7b:human_sexuality,validation,0.9097535740584135
131,0.47328245639801025,0.5267175436019897,0.5,0.0006261927480916141,mmlu_offline:llama2-7b:human_sexuality,test,5.9130822527222335
13,0.23076923191547394,0.7692307829856873,0.5,0.24188701923076927,mmlu_offline:llama2-7b:international_law,validation,0.9664792218245566
121,0.4876033067703247,0.5123966932296753,0.5,0.014947055785124008,mmlu_offline:llama2-7b:international_law,test,6.614949803799391
11,0.4545454680919647,0.5454545617103577,0.5,0.018110795454545414,mmlu_offline:llama2-7b:jurisprudence,validation,0.9765186067670584
108,0.37037035822868347,0.6296296119689941,0.5,0.10228587962962965,mmlu_offline:llama2-7b:jurisprudence,test,5.077376374043524
18,0.4444444477558136,0.5555555820465088,0.5,0.02821180555555558,mmlu_offline:llama2-7b:logical_fallacies,validation,1.1475395797751844
163,0.42944785952568054,0.5705521702766418,0.5,0.04320839723926384,mmlu_offline:llama2-7b:logical_fallacies,test,7.732102711219341
11,0.27272728085517883,0.7272727489471436,0.5,0.1999289772727273,mmlu_offline:llama2-7b:machine_learning,validation,0.9662944078445435
112,0.2857142984867096,0.7142857313156128,0.5,0.1869419642857143,mmlu_offline:llama2-7b:machine_learning,test,7.118075480684638
11,0.4545454680919647,0.5454545617103577,0.5,0.018110795454545414,mmlu_offline:llama2-7b:management,validation,0.9301586980000138
103,0.4563106894493103,0.5339806079864502,0.49107142857142855,0.006826434899302347,mmlu_offline:llama2-7b:management,test,4.675744746811688
25,0.2800000011920929,0.7200000286102295,0.5,0.19265624999999997,mmlu_offline:llama2-7b:marketing,validation,1.7637872910127044
234,0.4572649598121643,0.5427350401878357,0.5,0.015391292735042694,mmlu_offline:llama2-7b:marketing,test,10.844018775969744
11,0.7272727489471436,0.27272728085517883,0.5,0.2546164772727273,mmlu_offline:llama2-7b:medical_genetics,validation,0.9138607024215162
100,0.4699999988079071,0.5299999713897705,0.5,0.0026562500000000266,mmlu_offline:llama2-7b:medical_genetics,test,4.346811012364924
86,0.5465116500854492,0.45348837971687317,0.48936170212765956,0.07785247093023258,mmlu_offline:llama2-7b:miscellaneous,validation,4.046786077786237
783,0.5874840617179871,0.4125159680843353,0.5061919504643964,0.11787595785440612,mmlu_offline:llama2-7b:miscellaneous,test,31.625443419907242
38,0.42105263471603394,0.5789473652839661,0.5,0.051603618421052655,mmlu_offline:llama2-7b:moral_disputes,validation,2.2442840188741684
346,0.41040462255477905,0.589595377445221,0.5,0.06225162572254339,mmlu_offline:llama2-7b:moral_disputes,test,16.746359798591584
100,0.3499999940395355,0.6499999761581421,0.5,0.12265625000000002,mmlu_offline:llama2-7b:moral_scenarios,validation,7.265149703714997
895,0.3173184394836426,0.6826815605163574,0.5,0.15533781424581006,mmlu_offline:llama2-7b:moral_scenarios,test,61.583592873066664
33,0.3636363744735718,0.6363636255264282,0.5,0.10901988636363635,mmlu_offline:llama2-7b:nutrition,validation,2.0574414008297026
306,0.38235294818878174,0.6176470518112183,0.5,0.09030330882352944,mmlu_offline:llama2-7b:nutrition,test,16.2409247062169
34,0.29411765933036804,0.7058823704719543,0.5,0.17853860294117652,mmlu_offline:llama2-7b:philosophy,validation,2.039930858183652
311,0.3247588276863098,0.672025740146637,0.4976190476190476,0.14459405662162506,mmlu_offline:llama2-7b:philosophy,test,14.129589828196913
35,0.3142857253551483,0.6857143044471741,0.5,0.15837053571428572,mmlu_offline:llama2-7b:prehistory,validation,2.226622223854065
324,0.4166666567325592,0.5833333134651184,0.5,0.05598958333333337,mmlu_offline:llama2-7b:prehistory,test,15.278918941970915
31,0.12903225421905518,0.8709677457809448,0.5,0.3436239919354839,mmlu_offline:llama2-7b:professional_accounting,validation,2.741980721708387
282,0.152482271194458,0.847517728805542,0.50418410041841,0.3188996010638298,mmlu_offline:llama2-7b:professional_accounting,test,22.355077563785017
170,0.3117647171020508,0.6882352828979492,0.5,0.16089154411764706,mmlu_offline:llama2-7b:professional_law,validation,29.321980606764555
1534,0.2777053415775299,0.7222946286201477,0.5,0.1949509044980443,mmlu_offline:llama2-7b:professional_law,test,267.8057071119547
31,0.4193548262119293,0.5806451439857483,0.5,0.05330141129032262,mmlu_offline:llama2-7b:professional_medicine,validation,4.395026236772537
272,0.27941176295280457,0.720588207244873,0.5,0.19324448529411764,mmlu_offline:llama2-7b:professional_medicine,test,38.37865041522309
69,0.3913043439388275,0.6086956262588501,0.5,0.08135190217391308,mmlu_offline:llama2-7b:professional_psychology,validation,4.137372221332043
612,0.30882352590560913,0.6911764740943909,0.4988179669030733,0.16387742407181682,mmlu_offline:llama2-7b:professional_psychology,test,32.75628799991682
12,0.4166666567325592,0.5833333134651184,0.5,0.05598958333333337,mmlu_offline:llama2-7b:public_relations,validation,0.9905657740309834
110,0.3181818127632141,0.6818181872367859,0.5133333333333333,0.14921874999999998,mmlu_offline:llama2-7b:public_relations,test,5.5091381832025945
27,0.5925925970077515,0.40740740299224854,0.5,0.11993634259259262,mmlu_offline:llama2-7b:security_studies,validation,1.9759672046639025
245,0.5306122303009033,0.4653061330318451,0.49130434782608695,0.0620057390660656,mmlu_offline:llama2-7b:security_studies,test,15.230877093039453
22,0.3181818127632141,0.6818181872367859,0.5,0.15447443181818177,mmlu_offline:llama2-7b:sociology,validation,1.3655188786797225
201,0.3781094551086426,0.6218905448913574,0.506578947368421,0.09458565949207509,mmlu_offline:llama2-7b:sociology,test,9.30084670567885
11,0.6363636255264282,0.3636363744735718,0.5,0.16370738636363635,mmlu_offline:llama2-7b:us_foreign_policy,validation,1.1262936280108988
100,0.5799999833106995,0.41999998688697815,0.5,0.10734375000000002,mmlu_offline:llama2-7b:us_foreign_policy,test,4.906003922689706
18,0.5,0.4444444477558136,0.3950617283950617,0.08311632606718278,mmlu_offline:llama2-7b:virology,validation,1.4001154587604105
166,0.3313252925872803,0.6686747074127197,0.5045045045045045,0.13883659638554213,mmlu_offline:llama2-7b:virology,test,7.571845559868962
19,0.7368420958518982,0.2631579041481018,0.5,0.2641858552631579,mmlu_offline:llama2-7b:world_religions,validation,1.2275570901110768
171,0.5847952961921692,0.4152046740055084,0.5,0.11213907163742692,mmlu_offline:llama2-7b:world_religions,test,6.854468259960413
