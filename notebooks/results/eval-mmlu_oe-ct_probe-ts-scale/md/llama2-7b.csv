N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.4545454680919647,0.3888888888888889,0.1054687337441878,mmlu_offline:llama2-7b:abstract_algebra,validation,2.120064032264054
100,0.2199999988079071,0.5,0.5678904428904429,0.0546875,mmlu_offline:llama2-7b:abstract_algebra,test,3.264589063823223
14,0.2857142984867096,0.2857142984867096,0.7375,0.3671874872275761,mmlu_offline:llama2-7b:anatomy,validation,0.5188341261819005
135,0.4148148000240326,0.46666666865348816,0.5935804701627486,0.12042821998949402,mmlu_offline:llama2-7b:anatomy,test,3.5984815838746727
16,0.4375,0.5,0.6507936507936508,0.048583984375,mmlu_offline:llama2-7b:astronomy,validation,0.7838930860161781
152,0.5065789222717285,0.5986841917037964,0.6868398268398268,0.051706403493881205,mmlu_offline:llama2-7b:astronomy,test,5.459812175948173
11,0.6363636255264282,0.5454545617103577,0.5,0.10511363636363635,mmlu_offline:llama2-7b:business_ethics,validation,0.702757403254509
100,0.30000001192092896,0.4099999964237213,0.6871428571428572,0.17027344942092892,mmlu_offline:llama2-7b:business_ethics,test,4.705646981019527
29,0.24137930572032928,0.27586206793785095,0.5844155844155844,0.29404635470488977,mmlu_offline:llama2-7b:clinical_knowledge,validation,1.02510931994766
265,0.35849055647850037,0.4377358555793762,0.6811764705882354,0.14338150541737396,mmlu_offline:llama2-7b:clinical_knowledge,test,7.961286311969161
16,0.3125,0.6875,0.6363636363636364,0.13525390252470967,mmlu_offline:llama2-7b:college_biology,validation,0.7485914723947644
144,0.2986111044883728,0.5416666865348816,0.5933686391895003,0.006564665999677441,mmlu_offline:llama2-7b:college_biology,test,5.589949501212686
8,0.125,0.625,0.7142857142857143,0.08642578125,mmlu_offline:llama2-7b:college_chemistry,validation,0.5023172940127552
100,0.14000000059604645,0.6000000238418579,0.6943521594684385,0.06921874999999995,mmlu_offline:llama2-7b:college_chemistry,test,4.642712113913149
11,0.0,0.5454545617103577,,0.01278410716490308,mmlu_offline:llama2-7b:college_computer_science,validation,1.0224020099267364
100,0.17000000178813934,0.5199999809265137,0.5262225372076542,0.013828139305114728,mmlu_offline:llama2-7b:college_computer_science,test,8.078212298918515
11,0.0,0.8181818127632141,,0.26775569265539,mmlu_offline:llama2-7b:college_mathematics,validation,0.7859237599186599
100,0.1599999964237213,0.8199999928474426,0.6372767857142858,0.2843750190734863,mmlu_offline:llama2-7b:college_mathematics,test,5.646460998803377
22,0.3636363744735718,0.40909090638160706,0.5044642857142857,0.15802557360042224,mmlu_offline:llama2-7b:college_medicine,validation,1.0592798152938485
173,0.36994218826293945,0.4566473960876465,0.6007740825688074,0.11127165528391139,mmlu_offline:llama2-7b:college_medicine,test,10.261976024135947
11,0.27272728085517883,0.8181818127632141,0.9166666666666666,0.28480113094503234,mmlu_offline:llama2-7b:college_physics,validation,0.7621981441043317
102,0.14705882966518402,0.8725489974021912,0.761302681992337,0.3327205999224794,mmlu_offline:llama2-7b:college_physics,test,5.205108870752156
11,0.7272727489471436,0.8181818127632141,0.7083333333333335,0.2521306872367859,mmlu_offline:llama2-7b:computer_security,validation,0.6455721422098577
100,0.4300000071525574,0.5400000214576721,0.5911872705018361,0.013828109502792398,mmlu_offline:llama2-7b:computer_security,test,3.351614967919886
26,0.3076923191547394,0.5,0.5520833333333334,0.11598559067799499,mmlu_offline:llama2-7b:conceptual_physics,validation,0.9598097917623818
235,0.4127659499645233,0.4893617033958435,0.5717167189601076,0.07067817474933383,mmlu_offline:llama2-7b:conceptual_physics,test,6.330249867867678
12,0.0833333358168602,0.8333333134651184,0.8636363636363635,0.3004557092984518,mmlu_offline:llama2-7b:econometrics,validation,0.8499471768736839
114,0.14912280440330505,0.6491228342056274,0.5348696179502729,0.11509731673357781,mmlu_offline:llama2-7b:econometrics,test,6.513012814335525
16,0.125,0.625,0.9107142857142857,0.08056640625,mmlu_offline:llama2-7b:electrical_engineering,validation,0.7459437167271972
145,0.1862068921327591,0.5034482479095459,0.5243251726302574,0.05177799915445264,mmlu_offline:llama2-7b:electrical_engineering,test,5.79634042782709
41,0.26829269528388977,0.707317054271698,0.6106060606060606,0.17044587833125413,mmlu_offline:llama2-7b:elementary_mathematics,validation,1.875739592127502
378,0.32275131344795227,0.6613756418228149,0.5285284323770492,0.1240802602793174,mmlu_offline:llama2-7b:elementary_mathematics,test,15.749606800731272
14,0.5,0.2857142984867096,0.3877551020408163,0.26395090988704134,mmlu_offline:llama2-7b:formal_logic,validation,0.8324555060826242
126,0.30158731341362,0.3095238208770752,0.4110346889952153,0.2328248837637523,mmlu_offline:llama2-7b:formal_logic,test,6.143850501161069
10,0.30000001192092896,0.4000000059604645,1.0,0.22187501788139347,mmlu_offline:llama2-7b:global_facts,validation,0.5425494648516178
100,0.17000000178813934,0.23000000417232513,0.6839121190644932,0.3245312577486038,mmlu_offline:llama2-7b:global_facts,test,3.505959700793028
32,0.15625,0.40625,0.6370370370370371,0.1486816368997097,mmlu_offline:llama2-7b:high_school_biology,validation,1.372289280872792
310,0.41290321946144104,0.5322580933570862,0.6161572802197803,0.04417844722347874,mmlu_offline:llama2-7b:high_school_biology,test,12.011722814757377
22,0.13636364042758942,0.4545454680919647,0.5526315789473684,0.08291900970719081,mmlu_offline:llama2-7b:high_school_chemistry,validation,1.1014718422666192
203,0.16748768091201782,0.6157635450363159,0.6991820396797772,0.07825972352709087,mmlu_offline:llama2-7b:high_school_chemistry,test,9.041647059842944
9,0.2222222238779068,0.5555555820465088,0.7142857142857143,0.1566840277777778,mmlu_offline:llama2-7b:high_school_computer_science,validation,0.8136474429629743
100,0.3700000047683716,0.47999998927116394,0.5476190476190477,0.051491495936807956,mmlu_offline:llama2-7b:high_school_computer_science,test,7.141023817937821
18,0.7222222089767456,0.6111111044883728,0.5153846153846153,0.08311629957622957,mmlu_offline:llama2-7b:high_school_european_history,validation,5.728317170869559
165,0.6727272868156433,0.6606060862541199,0.6769269269269269,0.12348486040577747,mmlu_offline:llama2-7b:high_school_european_history,test,52.033046655822545
22,0.4545454680919647,0.4545454680919647,0.5791666666666666,0.13512073863636362,mmlu_offline:llama2-7b:high_school_geography,validation,0.826123827137053
198,0.3636363744735718,0.39898988604545593,0.6419753086419753,0.18073311026650246,mmlu_offline:llama2-7b:high_school_geography,test,5.803488180041313
21,0.4285714328289032,0.380952388048172,0.3564814814814815,0.16871277207419985,mmlu_offline:llama2-7b:high_school_government_and_politics,validation,0.8670971458777785
193,0.48704662919044495,0.5336787700653076,0.6113260262196432,0.033638299438002166,mmlu_offline:llama2-7b:high_school_government_and_politics,test,6.2666544071398675
43,0.41860464215278625,0.4883720874786377,0.5566666666666668,0.05368822258572248,mmlu_offline:llama2-7b:high_school_macroeconomics,validation,1.4043271369300783
390,0.34358975291252136,0.49743589758872986,0.6219682835820894,0.045773226634050014,mmlu_offline:llama2-7b:high_school_macroeconomics,test,11.248361418023705
29,0.03448275849223137,0.9655172228813171,0.9642857142857142,0.42780174674658944,mmlu_offline:llama2-7b:high_school_mathematics,validation,1.6873665400780737
270,0.08148147910833359,0.8777777552604675,0.6123533724340178,0.34059604273902044,mmlu_offline:llama2-7b:high_school_mathematics,test,13.377965683117509
26,0.3076923191547394,0.5769230723381042,0.5833333333333334,0.042217557246868376,mmlu_offline:llama2-7b:high_school_microeconomics,validation,0.9263154082000256
238,0.32773110270500183,0.5504201650619507,0.5504407051282052,0.01859572454660884,mmlu_offline:llama2-7b:high_school_microeconomics,test,6.874792592134327
17,0.23529411852359772,0.7647058963775635,0.7115384615384615,0.22771142510806808,mmlu_offline:llama2-7b:high_school_physics,validation,1.0403334526345134
151,0.17880794405937195,0.5894039869308472,0.556899641577061,0.05344577656676437,mmlu_offline:llama2-7b:high_school_physics,test,7.260172886773944
60,0.5,0.44999998807907104,0.5116666666666666,0.12330730756123859,mmlu_offline:llama2-7b:high_school_psychology,validation,2.624753901269287
545,0.5064220428466797,0.5669724941253662,0.6230604493292388,0.02038416446895778,mmlu_offline:llama2-7b:high_school_psychology,test,21.696381016168743
23,0.1304347813129425,0.8260869383811951,0.8416666666666667,0.29313858177350915,mmlu_offline:llama2-7b:high_school_statistics,validation,1.6228023683652282
216,0.24074074625968933,0.6157407164573669,0.5512429643527205,0.08658852621361057,mmlu_offline:llama2-7b:high_school_statistics,test,13.72925746627152
22,0.5909090638160706,0.5,0.5683760683760684,0.03906249729069793,mmlu_offline:llama2-7b:high_school_us_history,validation,5.451549047138542
204,0.5980392098426819,0.563725471496582,0.5846161535385845,0.02196309788554319,mmlu_offline:llama2-7b:high_school_us_history,test,49.56364409485832
26,0.5384615659713745,0.692307710647583,0.7202380952380953,0.1512920696001787,mmlu_offline:llama2-7b:high_school_world_history,validation,4.604651206173003
237,0.4345991611480713,0.5654008388519287,0.5815461527314882,0.03505695143998677,mmlu_offline:llama2-7b:high_school_world_history,test,37.677244532853365
23,0.21739129722118378,0.30434781312942505,0.3888888888888889,0.27122961179069854,mmlu_offline:llama2-7b:human_aging,validation,0.7756942212581635
223,0.340807169675827,0.4260089695453644,0.5731292517006803,0.15048695626280234,mmlu_offline:llama2-7b:human_aging,test,6.080170128960162
12,0.4166666567325592,0.5,0.6428571428571428,0.17643227179845172,mmlu_offline:llama2-7b:human_sexuality,validation,0.5488163847476244
131,0.47328245639801025,0.5343511700630188,0.635343618513324,0.06097923253328745,mmlu_offline:llama2-7b:human_sexuality,test,4.013380517717451
13,0.23076923191547394,0.6153846383094788,0.5333333333333333,0.08533654304651117,mmlu_offline:llama2-7b:international_law,validation,0.6844802382402122
121,0.4876033067703247,0.5041322112083435,0.4971295790049207,0.05052298208898748,mmlu_offline:llama2-7b:international_law,test,4.870875081047416
11,0.4545454680919647,0.4545454680919647,0.6666666666666667,0.09303979440168902,mmlu_offline:llama2-7b:jurisprudence,validation,0.5536608761176467
108,0.37037035822868347,0.37962964177131653,0.5005514705882353,0.1796874823393645,mmlu_offline:llama2-7b:jurisprudence,test,3.519091492984444
18,0.4444444477558136,0.4444444477558136,0.5687500000000001,0.11631944444444443,mmlu_offline:llama2-7b:logical_fallacies,validation,0.8065552529878914
163,0.42944785952568054,0.5030674934387207,0.5774961597542242,0.04953510263946159,mmlu_offline:llama2-7b:logical_fallacies,test,5.69163324823603
11,0.27272728085517883,0.5454545617103577,0.625,0.01349429650740186,mmlu_offline:llama2-7b:machine_learning,validation,0.7301137000322342
112,0.2857142984867096,0.4821428656578064,0.5009765625,0.05950052982994486,mmlu_offline:llama2-7b:machine_learning,test,5.875763853080571
11,0.4545454680919647,0.4545454680919647,0.6333333333333333,0.14062501083720813,mmlu_offline:llama2-7b:management,validation,0.49665210396051407
103,0.4563106894493103,0.5048543810844421,0.6158814589665654,0.07884556170806144,mmlu_offline:llama2-7b:management,test,2.4530633608810604
25,0.2800000011920929,0.3199999928474426,0.5515873015873016,0.2887499928474426,mmlu_offline:llama2-7b:marketing,validation,1.0574871273711324
234,0.4572649598121643,0.4572649598121643,0.6140260504820075,0.14344619176326656,mmlu_offline:llama2-7b:marketing,test,7.399118146859109
11,0.7272727489471436,0.5454545617103577,0.7083333333333333,0.20099431818181818,mmlu_offline:llama2-7b:medical_genetics,validation,0.49270948534831405
100,0.4699999988079071,0.49000000953674316,0.5680449618627057,0.08953125357627871,mmlu_offline:llama2-7b:medical_genetics,test,2.646163246128708
86,0.5465116500854492,0.6627907156944275,0.8011456628477904,0.10147168054137118,mmlu_offline:llama2-7b:miscellaneous,validation,2.337237310130149
783,0.5874840617179871,0.6360152959823608,0.6987380535738322,0.0685115220598486,mmlu_offline:llama2-7b:miscellaneous,test,20.516560482792556
38,0.42105263471603394,0.44736841320991516,0.5426136363636364,0.09560032110465197,mmlu_offline:llama2-7b:moral_disputes,validation,1.5101957763545215
346,0.41040462255477905,0.424855500459671,0.5939139740403203,0.14540053929896718,mmlu_offline:llama2-7b:moral_disputes,test,12.041058314032853
100,0.3499999940395355,0.3499999940395355,0.5971428571428572,0.20144530534744265,mmlu_offline:llama2-7b:moral_scenarios,validation,6.104529215954244
895,0.3173184394836426,0.3173184394836426,0.5673566768861943,0.23451030627309277,mmlu_offline:llama2-7b:moral_scenarios,test,52.81015853397548
33,0.3636363744735718,0.4848484992980957,0.6904761904761906,0.11647729078928631,mmlu_offline:llama2-7b:nutrition,validation,1.543697883374989
306,0.38235294818878174,0.4869281053543091,0.6467688689910912,0.10112849209043714,mmlu_offline:llama2-7b:nutrition,test,12.450652167666703
34,0.29411765933036804,0.3235294222831726,0.65625,0.30204502624623913,mmlu_offline:llama2-7b:philosophy,validation,1.1904278602451086
311,0.3247588276863098,0.35691317915916443,0.5850777934936351,0.20201968341778329,mmlu_offline:llama2-7b:philosophy,test,8.790780456271023
35,0.3142857253551483,0.34285715222358704,0.5890151515151516,0.22611607142857143,mmlu_offline:llama2-7b:prehistory,validation,1.4137943317182362
324,0.4166666567325592,0.4166666567325592,0.5963550852439743,0.15433303772667306,mmlu_offline:llama2-7b:prehistory,test,10.700680721085519
31,0.12903225421905518,0.7096773982048035,0.6111111111111112,0.20929941054313408,mmlu_offline:llama2-7b:professional_accounting,validation,2.2516094390302896
282,0.152482271194458,0.7056737542152405,0.6407511919820958,0.17474238056663083,mmlu_offline:llama2-7b:professional_accounting,test,19.08646970288828
170,0.3117647171020508,0.3764705955982208,0.6357845508788905,0.15278033158358406,mmlu_offline:llama2-7b:professional_law,validation,25.648853679187596
1534,0.2777053415775299,0.36114731431007385,0.589473059778648,0.16596724289181647,mmlu_offline:llama2-7b:professional_law,test,235.63210475584492
31,0.4193548262119293,0.5806451439857483,0.4914529914529915,0.1629284485693901,mmlu_offline:llama2-7b:professional_medicine,validation,3.803100527729839
272,0.27941176295280457,0.49632352590560913,0.5393394199785178,0.051355679245556056,mmlu_offline:llama2-7b:professional_medicine,test,33.00489302026108
69,0.3913043439388275,0.4202898442745209,0.468694885361552,0.13264264231142792,mmlu_offline:llama2-7b:professional_psychology,validation,3.1726852538995445
612,0.30882352590560913,0.4444444477558136,0.5153289053998273,0.11439825701557735,mmlu_offline:llama2-7b:professional_psychology,test,24.78286678576842
12,0.4166666567325592,0.4166666567325592,0.5714285714285715,0.2747396032015482,mmlu_offline:llama2-7b:public_relations,validation,0.5725137894041836
110,0.3181818127632141,0.3909091055393219,0.570857142857143,0.1942826802080328,mmlu_offline:llama2-7b:public_relations,test,3.7226481339894235
27,0.5925925970077515,0.5185185074806213,0.53125,0.11660879408871688,mmlu_offline:llama2-7b:security_studies,validation,1.5284445229917765
245,0.5306122303009033,0.5755102038383484,0.5949498327759197,0.003635222084668234,mmlu_offline:llama2-7b:security_studies,test,12.275664512068033
22,0.3181818127632141,0.6363636255264282,0.7047619047619047,0.09694601189006458,mmlu_offline:llama2-7b:sociology,validation,0.8106830827891827
201,0.3781094551086426,0.5920398235321045,0.5810526315789473,0.05913792083512495,mmlu_offline:llama2-7b:sociology,test,6.1039809309877455
11,0.6363636255264282,0.7272727489471436,0.9285714285714286,0.1629971590909091,mmlu_offline:llama2-7b:us_foreign_policy,validation,0.5591150000691414
100,0.5799999833106995,0.5899999737739563,0.6073481116584565,0.07191407322883606,mmlu_offline:llama2-7b:us_foreign_policy,test,3.1890934691764414
18,0.5,0.6666666865348816,0.5679012345679012,0.150390625,mmlu_offline:llama2-7b:virology,validation,0.8888719379901886
166,0.3313252925872803,0.4337349534034729,0.5053235053235052,0.12998869404735336,mmlu_offline:llama2-7b:virology,test,5.0163815203122795
19,0.7368420958518982,0.8421052694320679,0.6571428571428571,0.26644736842105265,mmlu_offline:llama2-7b:world_religions,validation,0.6829112428240478
171,0.5847952961921692,0.6081871390342712,0.6228169014084508,0.033945552786888426,mmlu_offline:llama2-7b:world_religions,test,4.0751886130310595
