N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.1818181872367859,0.3636363744735718,0.7777777777777778,0.16157669912685046,mmlu:abstract_algebra,validation,2.807241176997195
100,0.30000001192092896,0.33000001311302185,0.5307142857142857,0.21222653448581696,mmlu:abstract_algebra,test,1.5242993509891676
14,0.3571428656578064,0.3571428656578064,0.7666666666666667,0.39508927719933645,mmlu:anatomy,validation,0.3749341239890782
135,0.5185185074806213,0.5111111402511597,0.5924175824175825,0.20153357187906906,mmlu:anatomy,test,1.863208126000245
16,0.5,0.5,0.625,0.2434082068502903,mmlu:astronomy,validation,0.39422262100561056
152,0.6907894611358643,0.6907894611358643,0.6887537993920972,0.04284027610954485,mmlu:astronomy,test,2.123183400995913
11,0.5454545617103577,0.7272727489471436,0.8833333333333333,0.21306816556236963,mmlu:business_ethics,validation,0.4029350930068176
100,0.4300000071525574,0.6800000071525574,0.6958384332925336,0.16468747913837437,mmlu:business_ethics,test,1.585819503001403
29,0.4137931168079376,0.4137931168079376,0.4877450980392157,0.2514816687024873,mmlu:clinical_knowledge,validation,0.617522442000336
265,0.4226415157318115,0.4226415157318115,0.5644549486461251,0.24565151997332305,mmlu:clinical_knowledge,test,3.649963570002001
16,0.375,0.375,0.3833333333333333,0.4423828125,mmlu:college_biology,validation,0.37994523798988666
144,0.4791666567325592,0.4791666567325592,0.6914009661835748,0.20258247107267377,mmlu:college_biology,test,2.024705603995244
8,0.0,0.25,,0.291015625,mmlu:college_chemistry,validation,0.28900718499789946
100,0.25999999046325684,0.550000011920929,0.7120582120582122,0.015429710149764974,mmlu:college_chemistry,test,1.570962163998047
11,0.1818181872367859,0.8181818127632141,0.5,0.17365056818181823,mmlu:college_computer_science,validation,0.37739464901096653
100,0.3100000023841858,0.6899999976158142,0.5,0.04546874999999995,mmlu:college_computer_science,test,1.679939486013609
11,0.09090909361839294,0.09090909361839294,0.0,0.48934659632769495,mmlu:college_mathematics,validation,0.40718917999765836
100,0.14000000059604645,0.20999999344348907,0.43936877076411956,0.3858984339237213,mmlu:college_mathematics,test,1.5821442020096583
22,0.40909090638160706,0.40909090638160706,0.49572649572649574,0.32848011905496766,mmlu:college_medicine,validation,0.47039586599566974
173,0.4624277353286743,0.4624277353286743,0.614516129032258,0.30344560897419226,mmlu:college_medicine,test,2.5114151559973834
11,0.1818181872367859,0.27272728085517883,0.8333333333333334,0.3082386309450323,mmlu:college_physics,validation,0.3672849259892246
102,0.19607843458652496,0.3137255012989044,0.6573170731707317,0.26570160833059575,mmlu:college_physics,test,1.6306270229979418
11,0.8181818127632141,0.5454545617103577,0.8611111111111112,0.115056801926006,mmlu:computer_security,validation,0.32150593999540433
100,0.6800000071525574,0.49000000953674316,0.6328125,0.08468750238418578,mmlu:computer_security,test,1.4193876430072123
26,0.38461539149284363,0.38461539149284363,0.584375,0.22806489926118118,mmlu:conceptual_physics,validation,0.498392948997207
235,0.46382978558540344,0.45957446098327637,0.5596330275229359,0.14454786320950125,mmlu:conceptual_physics,test,3.0901989209960448
12,0.4166666567325592,0.4166666567325592,0.2857142857142857,0.12467445929845172,mmlu:econometrics,validation,0.32279366299917456
114,0.31578946113586426,0.3684210479259491,0.5746082621082621,0.19198878397021377,mmlu:econometrics,test,1.7176904030056903
16,0.3125,0.5625,0.0,0.1916503943502903,mmlu:electrical_engineering,validation,0.32407355299801566
145,0.43448275327682495,0.6206896305084229,0.6377274487030584,0.01775323111435461,mmlu:electrical_engineering,test,2.0230560839991085
41,0.3658536672592163,0.6341463327407837,0.4987179487179487,0.16225228949290954,mmlu:elementary_mathematics,validation,0.7278582449944224
378,0.45502644777297974,0.5449735522270203,0.47314574396026193,0.2467757687366829,mmlu:elementary_mathematics,test,5.115857261000201
14,0.2857142984867096,0.2857142984867096,0.6749999999999999,0.3473772151129586,mmlu:formal_logic,validation,0.3328747060004389
126,0.380952388048172,0.380952388048172,0.4465811965811966,0.2509920795758565,mmlu:formal_logic,test,1.8395722189889057
10,0.5,0.5,0.48000000000000004,0.1828125,mmlu:global_facts,validation,0.3050392550067045
100,0.20999999344348907,0.20999999344348907,0.49728752260397824,0.47925780832767484,mmlu:global_facts,test,1.411636406002799
32,0.40625,0.40625,0.680161943319838,0.3446045033633709,mmlu:high_school_biology,validation,0.5295161940011894
310,0.57419353723526,0.57419353723526,0.5582226762002044,0.20451107851920594,mmlu:high_school_biology,test,4.210924704006175
22,0.22727273404598236,0.22727273404598236,0.6764705882352939,0.45134944265538995,mmlu:high_school_chemistry,validation,0.43266875301196706
203,0.2807881832122803,0.29064038395881653,0.5681927421292958,0.35135082658288513,mmlu:high_school_chemistry,test,2.8644157770031597
9,0.4444444477558136,0.5555555820465088,0.7,0.19487847222222224,mmlu:high_school_computer_science,validation,0.3097318490035832
100,0.5099999904632568,0.49000000953674316,0.5582232893157263,0.09015625953674317,mmlu:high_school_computer_science,test,1.5757336980022956
18,0.8333333134651184,0.8333333134651184,0.5,0.29427083333333337,mmlu:high_school_european_history,validation,0.5388784259994281
165,0.8060606122016907,0.8060606122016907,0.5,0.26699810606060603,mmlu:high_school_european_history,test,3.368410863011377
22,0.3636363744735718,0.3636363744735718,0.7276785714285714,0.3227983090010556,mmlu:high_school_geography,validation,0.423228643994662
198,0.4595959484577179,0.4595959484577179,0.5235185375372291,0.1774976512398383,mmlu:high_school_geography,test,2.7099465649953345
21,0.761904776096344,0.2380952388048172,0.775,0.2946428514662243,mmlu:high_school_government_and_politics,validation,0.4041828049957985
193,0.6269429922103882,0.40414509177207947,0.5743801652892563,0.1314766583047383,mmlu:high_school_government_and_politics,test,2.6998501820053207
43,0.5116279125213623,0.5116279125213623,0.3831168831168831,0.1994912582774495,mmlu:high_school_macroeconomics,validation,0.7166089480015216
390,0.5102564096450806,0.5128205418586731,0.5219158620326765,0.09003403966243449,mmlu:high_school_macroeconomics,test,5.15748230900499
29,0.13793103396892548,0.8620689511299133,0.445,0.09146012931034486,mmlu:high_school_mathematics,validation,0.5634082289907383
270,0.11481481790542603,0.885185182094574,0.5357673100283439,0.11801216204961144,mmlu:high_school_mathematics,test,3.908484312996734
26,0.38461539149284363,0.38461539149284363,0.4125,0.2913161011842581,mmlu:high_school_microeconomics,validation,0.48743986400950234
238,0.45798319578170776,0.45798319578170776,0.5259938837920489,0.22444525736720622,mmlu:high_school_microeconomics,test,3.1545762740133796
17,0.1764705926179886,0.529411792755127,0.4523809523809524,0.0043658333666184435,mmlu:high_school_physics,validation,0.4351643400004832
151,0.38410595059394836,0.503311276435852,0.5421764923989618,0.028895888502234655,mmlu:high_school_physics,test,2.1316328249959042
60,0.6333333253860474,0.36666667461395264,0.527511961722488,0.21009113192558287,mmlu:high_school_psychology,validation,0.9367962289979914
545,0.6091743111610413,0.39266055822372437,0.5715821030601278,0.1694667221209325,mmlu:high_school_psychology,test,7.405304555009934
23,0.30434781312942505,0.695652186870575,0.6071428571428571,0.16762905017189356,mmlu:high_school_statistics,validation,0.4289840700075729
216,0.40740740299224854,0.5462962985038757,0.5617453835227273,0.015606914405469586,mmlu:high_school_statistics,test,3.204329863001476
22,0.8181818127632141,0.8181818127632141,0.5,0.30646306818181823,mmlu:high_school_us_history,validation,0.5256585030001588
204,0.7352941036224365,0.7352941036224365,0.5,0.22357536764705888,mmlu:high_school_us_history,test,3.967733616998885
26,0.692307710647583,0.692307710647583,0.5,0.1727764423076923,mmlu:high_school_world_history,validation,0.6229817749990616
237,0.7257384061813354,0.7257384061813354,0.5,0.2062071466244726,mmlu:high_school_world_history,test,4.078892810997786
23,0.43478259444236755,0.43478259444236755,0.49230769230769234,0.24558423913043478,mmlu:human_aging,validation,0.3909188260004157
223,0.46188339591026306,0.46188339591026306,0.6308252427184465,0.20569998507007894,mmlu:human_aging,test,2.924114196008304
12,0.5,0.5,0.4305555555555556,0.1419270634651184,mmlu:human_sexuality,validation,0.2923516720038606
131,0.6030534505844116,0.5954198241233826,0.5087633885102241,0.04887285532842157,mmlu:human_sexuality,test,1.8626732470002025
13,0.6153846383094788,0.5384615659713745,0.475,0.11057692307692307,mmlu:international_law,validation,0.32790719901095144
121,0.7851239442825317,0.7768595218658447,0.5184210526315789,0.1926975501470329,mmlu:international_law,test,1.812145349002094
11,0.7272727489471436,0.7272727489471436,0.41666666666666663,0.09872159090909091,mmlu:jurisprudence,validation,0.29589851200580597
108,0.7407407164573669,0.7314814925193787,0.4089285714285714,0.09346066856825792,mmlu:jurisprudence,test,1.5457510959968204
18,0.6666666865348816,0.6666666865348816,0.4930555555555556,0.07248263888888888,mmlu:logical_fallacies,validation,0.40780125600576866
163,0.5889570713043213,0.5889570713043213,0.5616449004975125,0.042801011193749385,mmlu:logical_fallacies,test,2.2610182909993455
11,0.4545454680919647,0.5454545617103577,0.31666666666666665,0.008167608217759526,mmlu:machine_learning,validation,0.3429592800093815
112,0.4642857015132904,0.5267857313156128,0.5011217948717949,0.006173270089285698,mmlu:machine_learning,test,1.7015311800059862
11,0.6363636255264282,0.5454545617103577,0.7857142857142857,0.25994317639957776,mmlu:management,validation,0.29391998100618366
103,0.49514561891555786,0.5242718458175659,0.7875188536953243,0.19007887655091518,mmlu:management,test,1.4408508769993205
25,0.36000001430511475,0.6399999856948853,0.3958333333333333,0.12124998807907106,mmlu:marketing,validation,0.5146571890072664
234,0.4444444477558136,0.5811966061592102,0.5572485207100591,0.06037995703199994,mmlu:marketing,test,3.130149625998456
11,0.7272727489471436,0.7272727489471436,0.7291666666666667,0.09446022727272728,mmlu:medical_genetics,validation,0.3388648420077516
100,0.5600000023841858,0.5600000023841858,0.6156655844155844,0.22718747794628144,mmlu:medical_genetics,test,1.3961356049985625
86,0.6744186282157898,0.4883720874786377,0.541564039408867,0.03524709579556487,mmlu:miscellaneous,validation,1.2239063440065365
783,0.6666666865348816,0.5389527678489685,0.5669470501020244,0.015545154135498195,mmlu:miscellaneous,test,9.923945728995022
38,0.6315789222717285,0.6315789222717285,0.48363095238095244,0.07113486528396605,mmlu:moral_disputes,validation,0.64307014500082
346,0.5780346989631653,0.5635837912559509,0.4949143835616438,0.00893020285347297,mmlu:moral_disputes,test,4.624411885990412
100,0.5,0.5,0.4812,0.10992185831069946,mmlu:moral_scenarios,validation,1.564136224988033
895,0.5307262539863586,0.529608964920044,0.5110225563909775,0.08114087894642157,mmlu:moral_scenarios,test,13.323867475992301
33,0.5454545617103577,0.5454545617103577,0.6592592592592592,0.09209280483650442,mmlu:nutrition,validation,0.6206340979988454
306,0.5522875785827637,0.5555555820465088,0.571200276422062,0.06655942458732454,mmlu:nutrition,test,4.341691180001362
34,0.47058823704719543,0.47058823704719543,0.7274305555555555,0.15452665616484249,mmlu:philosophy,validation,0.6233704589976696
311,0.4308681786060333,0.4565916359424591,0.5289231807066364,0.14528487771270357,mmlu:philosophy,test,4.06830029298726
35,0.4571428596973419,0.48571428656578064,0.5723684210526316,0.12957589285714285,mmlu:prehistory,validation,0.6067957339982968
324,0.5555555820465088,0.5555555820465088,0.6070216049382716,0.07294078060874233,mmlu:prehistory,test,4.290306511000381
31,0.25806450843811035,0.6774193644523621,0.4429347826086957,0.1619203590577648,mmlu:professional_accounting,validation,0.5487247769924579
282,0.20921985805034637,0.741134762763977,0.5914722201109676,0.22600840423124058,mmlu:professional_accounting,test,4.244476116989972
170,0.4647058844566345,0.5352941155433655,0.5,0.01185661764705881,mmlu:professional_law,validation,3.033156739998958
1534,0.36245110630989075,0.6375488638877869,0.5,0.1141113917861799,mmlu:professional_law,test,25.26447921800718
31,0.4193548262119293,0.4193548262119293,0.5,0.10017641129032256,mmlu:professional_medicine,validation,0.5935283979924861
272,0.375,0.375,0.5,0.14453125,mmlu:professional_medicine,test,4.297876025011647
69,0.5362318754196167,0.5072463750839233,0.49028716216216217,0.015794811905294193,mmlu:professional_psychology,validation,1.1033133599994471
612,0.4395424723625183,0.46568626165390015,0.5137427249179013,0.05961501851580501,mmlu:professional_psychology,test,8.493425310996827
12,0.4166666567325592,0.5,0.6428571428571428,0.05078125,mmlu:public_relations,validation,0.3378482479893137
110,0.37272727489471436,0.40909090638160706,0.49186991869918706,0.13227983225475656,mmlu:public_relations,test,1.5139094539918005
27,0.6666666865348816,0.6666666865348816,0.7345679012345679,0.0954861044883728,mmlu:security_studies,validation,0.5593779719929444
245,0.7877551317214966,0.7755101919174194,0.614836588282184,0.1990911841392517,mmlu:security_studies,test,3.5836322550021578
22,0.6818181872367859,0.6818181872367859,0.5428571428571428,0.05415483496405864,mmlu:sociology,validation,0.41486593199078925
201,0.5671641826629639,0.5621890425682068,0.5999697519661222,0.06401587422214337,mmlu:sociology,test,2.776855650008656
11,0.9090909361839294,0.9090909361839294,0.8500000000000001,0.2734375,mmlu:us_foreign_policy,validation,0.32082657699356787
100,0.7900000214576721,0.7900000214576721,0.6473779385171791,0.15441404640674591,mmlu:us_foreign_policy,test,1.4296913650032366
18,0.6666666865348816,0.6666666865348816,0.5902777777777778,0.2111545271343655,mmlu:virology,validation,0.4104420170042431
166,0.6867470145225525,0.6867470145225525,0.6916329284750338,0.21656155837587565,mmlu:virology,test,2.24278530900483
19,0.6315789222717285,0.6315789222717285,0.42857142857142855,0.15357730263157895,mmlu:world_religions,validation,0.3988639399904059
171,0.6900584697723389,0.6959064602851868,0.6268787975695556,0.07058661060723648,mmlu:world_religions,test,2.2536191740073264
