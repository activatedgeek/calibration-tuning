N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.09090909361839294,0.09999999999999998,0.5010653463276951,mmlu:abstract_algebra,validation,1.482000022995635
100,0.3499999940395355,0.3499999940395355,0.6239560439560439,0.24730468451976775,mmlu:abstract_algebra,test,1.7463366589945508
14,0.2857142984867096,0.2857142984867096,0.7,0.45424105865614756,mmlu:anatomy,validation,0.3623303060012404
135,0.42222222685813904,0.42222222685813904,0.5907557354925775,0.2708912081188626,mmlu:anatomy,test,2.242359399999259
16,0.5,0.5,0.609375,0.195556640625,mmlu:astronomy,validation,0.375771809995058
152,0.5263158082962036,0.5263158082962036,0.5953993055555555,0.1520096424378847,mmlu:astronomy,test,2.6554476649907883
11,0.5454545617103577,0.5454545617103577,0.55,0.13139205087314954,mmlu:business_ethics,validation,0.41748516699590255
100,0.3199999928474426,0.3199999928474426,0.4568014705882353,0.3504687511920929,mmlu:business_ethics,test,1.8576801180024631
29,0.24137930572032928,0.24137930572032928,0.6071428571428572,0.3799838259302336,mmlu:clinical_knowledge,validation,0.6317863559961552
265,0.2981131970882416,0.2981131970882416,0.5868381652375119,0.33102890410513247,mmlu:clinical_knowledge,test,4.425535955000669
16,0.25,0.25,0.5208333333333334,0.5451660417020321,mmlu:college_biology,validation,0.4075000029988587
144,0.3958333432674408,0.3958333432674408,0.5127041742286752,0.41031902407606446,mmlu:college_biology,test,2.430244914998184
8,0.0,0.0,,0.6528320237994194,mmlu:college_chemistry,validation,0.23230132699245587
100,0.17000000178813934,0.17000000178813934,0.7349397590361446,0.46105469942092897,mmlu:college_chemistry,test,1.76022619100695
11,0.27272728085517883,0.27272728085517883,0.5,0.2936789772727273,mmlu:college_computer_science,validation,0.3978895859909244
100,0.23999999463558197,0.23999999463558197,0.5,0.32640625,mmlu:college_computer_science,test,1.964404073994956
11,0.0,0.0,,0.5845170454545454,mmlu:college_mathematics,validation,0.392635723008425
100,0.09000000357627869,0.09000000357627869,0.5836385836385837,0.4902343916893005,mmlu:college_mathematics,test,1.8593958499986911
22,0.5,0.5,0.5495867768595042,0.24236503785306757,mmlu:college_medicine,validation,0.5050632560014492
173,0.3988439440727234,0.3988439440727234,0.6141304347826088,0.3546333113157681,mmlu:college_medicine,test,2.9524631920066895
11,0.27272728085517883,0.27272728085517883,0.7708333333333334,0.4673295454545454,mmlu:college_physics,validation,0.3899011300090933
102,0.1568627506494522,0.1568627506494522,0.5098110465116279,0.5719592588789324,mmlu:college_physics,test,1.8073522399936337
11,0.5454545617103577,0.5454545617103577,0.5333333333333332,0.17471589825370096,mmlu:computer_security,validation,0.3463534800102934
100,0.550000011920929,0.550000011920929,0.5422222222222222,0.04597657322883611,mmlu:computer_security,test,1.733311218995368
26,0.3461538553237915,0.4615384638309479,0.607843137254902,0.11117788003041196,mmlu:conceptual_physics,validation,0.5971278060023906
235,0.4553191363811493,0.48510637879371643,0.5375292056074765,0.07764294198218814,mmlu:conceptual_physics,test,3.939010543996119
12,0.25,0.25,0.7962962962962963,0.3395182291666667,mmlu:econometrics,validation,0.36148031600168906
114,0.1315789520740509,0.1315789520740509,0.6468013468013467,0.47039475775601575,mmlu:econometrics,test,2.1066530799871543
16,0.25,0.5,0.22916666666666666,0.07128903642296794,mmlu:electrical_engineering,validation,0.3505522540071979
145,0.24827586114406586,0.6965517401695251,0.5462538226299694,0.12174029185854153,mmlu:electrical_engineering,test,2.5602941350080073
41,0.26829269528388977,0.7317073345184326,0.4196969696969697,0.09498856707317074,mmlu:elementary_mathematics,validation,0.879642216998036
378,0.3174603283405304,0.682539701461792,0.5322835917312662,0.04150134735006501,mmlu:elementary_mathematics,test,6.319579186994815
14,0.2142857164144516,0.2142857164144516,0.6818181818181818,0.3816964200564793,mmlu:formal_logic,validation,0.3605014970089542
126,0.261904776096344,0.261904776096344,0.6127403062886934,0.32936506611960276,mmlu:formal_logic,test,2.257529717986472
10,0.20000000298023224,0.20000000298023224,0.96875,0.44335936307907103,mmlu:global_facts,validation,0.335073624009965
100,0.12999999523162842,0.12999999523162842,0.392130857648099,0.513359363079071,mmlu:global_facts,test,1.8116338209947571
32,0.3125,0.3125,0.4363636363636364,0.5482177659869194,mmlu:high_school_biology,validation,0.6389128610026091
310,0.42258065938949585,0.42258065938949585,0.5001492600963794,0.43883569855843824,mmlu:high_school_biology,test,5.18572032598604
22,0.1818181872367859,0.1818181872367859,0.375,0.5172230357473546,mmlu:high_school_chemistry,validation,0.4857049660058692
203,0.1822660118341446,0.1822660118341446,0.4188375122110062,0.5309421223372661,mmlu:high_school_chemistry,test,3.5305236510030227
9,0.6666666865348816,0.7777777910232544,0.6666666666666667,0.22743056880103218,mmlu:high_school_computer_science,validation,0.36500997000257485
100,0.4300000071525574,0.4699999988079071,0.569563443492452,0.08292969942092898,mmlu:high_school_computer_science,test,1.831100912997499
18,0.7777777910232544,0.7777777910232544,0.5,0.00434027777777779,mmlu:high_school_european_history,validation,0.5998606450011721
165,0.7575757503509521,0.7575757503509521,0.5,0.01586174242424243,mmlu:high_school_european_history,test,3.841347500012489
22,0.5,0.5,0.5371900826446281,0.09197444807399405,mmlu:high_school_geography,validation,0.4916806740075117
198,0.39393940567970276,0.39393940567970276,0.5003205128205128,0.19902145200305515,mmlu:high_school_geography,test,3.312383543001488
21,0.523809552192688,0.523809552192688,0.46818181818181814,0.12109377838316415,mmlu:high_school_government_and_politics,validation,0.481382729994948
193,0.6321243643760681,0.6321243643760681,0.5478526899099515,0.00862206572695721,mmlu:high_school_government_and_politics,test,3.390837286002352
43,0.4883720874786377,0.4883720874786377,0.5476190476190477,0.1471656976744186,mmlu:high_school_macroeconomics,validation,0.8900351029878948
390,0.3692307770252228,0.36666667461395264,0.548413504968383,0.2667267674054855,mmlu:high_school_macroeconomics,test,6.282950030989014
29,0.06896551698446274,0.9655172228813171,0.7777777777777778,0.3437499917786696,mmlu:high_school_mathematics,validation,0.6262266349949641
270,0.10000000149011612,0.9037036895751953,0.4441396128638927,0.2770399188553845,mmlu:high_school_mathematics,test,4.670489857002394
26,0.3076923191547394,0.7692307829856873,0.5173611111111112,0.2827523969686948,mmlu:high_school_microeconomics,validation,0.612181160991895
238,0.36554622650146484,0.6428571343421936,0.5490979675725052,0.08398439202989852,mmlu:high_school_microeconomics,test,3.881039645013516
17,0.29411765933036804,0.29411765933036804,0.6666666666666667,0.30491726889329795,mmlu:high_school_physics,validation,0.49474174799979664
151,0.17218543589115143,0.17218543589115143,0.46353846153846157,0.42241827620575756,mmlu:high_school_physics,test,2.6232327329926193
60,0.6000000238418579,0.6000000238418579,0.5590277777777778,0.046744799613952615,mmlu:high_school_psychology,validation,1.142361082995194
545,0.5064220428466797,0.5064220428466797,0.48818086310004855,0.04873850761203593,mmlu:high_school_psychology,test,9.155477422988042
23,0.17391304671764374,0.17391304671764374,0.5526315789473685,0.3970788173053575,mmlu:high_school_statistics,validation,0.5169635140046012
216,0.25925925374031067,0.25462964177131653,0.5484374999999999,0.3178711114106355,mmlu:high_school_statistics,test,3.8156164989923127
22,0.7727272510528564,0.7727272510528564,0.5,0.10866477272727271,mmlu:high_school_us_history,validation,0.6107900669885566
204,0.6764705777168274,0.6764705777168274,0.5,0.012408088235294157,mmlu:high_school_us_history,test,4.378473427001154
26,0.6538461446762085,0.6538461446762085,0.5,0.037560096153846145,mmlu:high_school_world_history,validation,0.7348071159940446
237,0.6033755540847778,0.6033755540847778,0.5,0.0880307225738397,mmlu:high_school_world_history,test,4.627690737004741
23,0.3913043439388275,0.3913043439388275,0.4841269841269841,0.23420516822649087,mmlu:human_aging,validation,0.49810618099581916
223,0.3901345431804657,0.3901345431804657,0.5389198782961461,0.22805142883762652,mmlu:human_aging,test,3.7018660820031073
12,0.3333333432674408,0.3333333432674408,0.65625,0.3277995040019353,mmlu:human_sexuality,validation,0.3477426530007506
131,0.5114504098892212,0.5114504098892212,0.5295009328358209,0.1512702935524569,mmlu:human_sexuality,test,2.282244810005068
13,0.6153846383094788,0.6153846383094788,0.6124999999999999,0.20492790295527535,mmlu:international_law,validation,0.35806885799684096
121,0.6280992031097412,0.6280992031097412,0.48304093567251466,0.05956224222813757,mmlu:international_law,test,2.128473524004221
11,0.1818181872367859,0.1818181872367859,0.25,0.48721588741649274,mmlu:jurisprudence,validation,0.34348425299685914
108,0.3611111044883728,0.3611111044883728,0.40579710144927533,0.3168040856167122,mmlu:jurisprudence,test,1.8834786399966106
18,0.6666666865348816,0.6666666865348816,0.3055555555555555,0.19726563162273836,mmlu:logical_fallacies,validation,0.5334211089939345
163,0.48466256260871887,0.48466256260871887,0.6286919831223629,0.20331671413468438,mmlu:logical_fallacies,test,2.8080144909908995
11,0.27272728085517883,0.27272728085517883,0.5625,0.2585227272727273,mmlu:machine_learning,validation,0.35880989200086333
112,0.2946428656578064,0.3035714328289032,0.44629842731108554,0.23304966517857145,mmlu:machine_learning,test,2.0661296519974712
11,0.6363636255264282,0.6363636255264282,0.4107142857142857,0.2336647781458768,mmlu:management,validation,0.33242102300573606
103,0.42718446254730225,0.41747573018074036,0.45146379044684126,0.185110745499435,mmlu:management,test,1.7403831600095145
25,0.23999999463558197,0.2800000011920929,0.3947368421052632,0.24765625715255735,mmlu:marketing,validation,0.6150621670094552
234,0.44871795177459717,0.45299145579338074,0.43270579549649313,0.07320043724826258,mmlu:marketing,test,3.9798361829889473
11,0.9090909361839294,0.9090909361839294,1.0,0.28125,mmlu:medical_genetics,validation,0.3398839239962399
100,0.44999998807907104,0.44999998807907104,0.6046464646464647,0.2752343559265137,mmlu:medical_genetics,test,1.7255469570081914
86,0.5581395626068115,0.5581395626068115,0.6071820175438596,0.02566316931746726,mmlu:miscellaneous,validation,1.5249246649909765
783,0.618135392665863,0.6206896305084229,0.5973527460681611,0.08585768930452238,mmlu:miscellaneous,test,12.489254200001596
38,0.42105263471603394,0.42105263471603394,0.5241477272727273,0.2798108489889848,mmlu:moral_disputes,validation,0.748829394011409
346,0.43063583970069885,0.43063583970069885,0.49170442544203313,0.27069407908213616,mmlu:moral_disputes,test,5.767098338998039
100,0.4300000071525574,0.4300000071525574,0.41962464300285596,0.1662109249830246,mmlu:moral_scenarios,validation,1.850824486988131
895,0.38100558519363403,0.38100558519363403,0.5152556189588914,0.21630152250801385,mmlu:moral_scenarios,test,15.225571148999734
33,0.3333333432674408,0.3333333432674408,0.7045454545454546,0.36612215909090906,mmlu:nutrition,validation,0.7445243209949695
306,0.4542483687400818,0.4542483687400818,0.5690561323396373,0.24488102493722455,mmlu:nutrition,test,5.159388005005894
34,0.3235294222831726,0.3235294222831726,0.47430830039525695,0.3164062307161443,mmlu:philosophy,validation,0.7060489419964142
311,0.3633440434932709,0.3633440434932709,0.4291141503530883,0.2796297385761592,mmlu:philosophy,test,5.1021985670086
35,0.37142857909202576,0.37142857909202576,0.3688811188811189,0.2585937363760812,mmlu:prehistory,validation,0.7453458770032739
324,0.4413580298423767,0.4413580298423767,0.5563883630181973,0.1887900483461074,mmlu:prehistory,test,5.403371752996463
31,0.16129031777381897,0.16129031777381897,0.5653846153846154,0.4938255798432135,mmlu:professional_accounting,validation,0.6661080749909161
282,0.1879432648420334,0.1879432648420334,0.5912910933509105,0.4719913775193776,mmlu:professional_accounting,test,5.122175251002773
170,0.38235294818878174,0.38235294818878174,0.5,0.14108455882352944,mmlu:professional_law,validation,3.451472606000607
1534,0.34810951352119446,0.34810951352119446,0.5,0.17532798239895697,mmlu:professional_law,test,29.78643362200819
31,0.35483869910240173,0.35483869910240173,0.5,0.2740675403225806,mmlu:professional_medicine,validation,0.7117031870002393
272,0.2904411852359772,0.2904411852359772,0.5,0.33846507352941174,mmlu:professional_medicine,test,4.99003509299655
69,0.37681159377098083,0.37681159377098083,0.580948121645796,0.21444747327030567,mmlu:professional_psychology,validation,1.25852394499816
612,0.3464052379131317,0.3464052379131317,0.551061320754717,0.2440767747903961,mmlu:professional_psychology,test,9.873727818005136
12,0.1666666716337204,0.1666666716337204,0.3,0.464192713300387,mmlu:public_relations,validation,0.37385266899946146
110,0.30909091234207153,0.30909091234207153,0.47232972136222906,0.3054687229069797,mmlu:public_relations,test,1.8314838259975659
27,0.5555555820465088,0.5555555820465088,0.725,0.15364585099396882,mmlu:security_studies,validation,0.656687722002971
245,0.6612244844436646,0.6612244844436646,0.5014874312063067,0.020153051249834963,mmlu:security_studies,test,4.133212405999075
22,0.5909090638160706,0.5909090638160706,0.40598290598290604,0.13760653950951318,mmlu:sociology,validation,0.5188690130016766
201,0.447761207818985,0.447761207818985,0.6162662662662662,0.14649408640553113,mmlu:sociology,test,3.2719073470070725
11,0.7272727489471436,0.7272727489471436,0.2916666666666667,0.08096591450951318,mmlu:us_foreign_policy,validation,0.3554343459982192
100,0.5899999737739563,0.5899999737739563,0.5194295163290616,0.09535154759883878,mmlu:us_foreign_policy,test,1.7410153590026312
18,0.5555555820465088,0.5555555820465088,0.60625,0.219835059510337,mmlu:virology,validation,0.46416062000207603
166,0.34939759969711304,0.34939759969711304,0.4497924648786718,0.44886577201176847,mmlu:virology,test,2.6696541519922903
19,0.6315789222717285,0.6315789222717285,0.5238095238095238,0.0662006767172562,mmlu:world_religions,validation,0.5261318429984385
171,0.6081871390342712,0.6081871390342712,0.47373708381171076,0.03620705025935036,mmlu:world_religions,test,2.7629194379987894
