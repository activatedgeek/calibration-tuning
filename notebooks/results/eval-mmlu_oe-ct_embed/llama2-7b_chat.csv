N,acc,unc_acc,unc_auroc,unc_ece,dataset,split,ts
11,0.09090909361839294,0.8181818127632141,0.45,0.3014915043657477,mmlu:abstract_algebra,validation,3.8561684859450907
100,0.20999999344348907,0.6100000143051147,0.6250753465943338,0.0958984351158142,mmlu:abstract_algebra,test,2.0716218929737806
14,0.2142857164144516,0.4285714328289032,0.7272727272727273,0.1361607313156128,mmlu:anatomy,validation,0.4476899860892445
135,0.385185182094574,0.5111111402511597,0.5421686746987951,0.030121545438413257,mmlu:anatomy,test,2.543431335128844
16,0.5625,0.5625,0.5317460317460317,0.1809081956744194,mmlu:astronomy,validation,0.4554805720690638
152,0.42763158679008484,0.42763158679008484,0.5725906277630415,0.28464229444139877,mmlu:astronomy,test,2.997939908877015
11,0.4545454680919647,0.7272727489471436,0.7666666666666667,0.16654829003594135,mmlu:business_ethics,validation,0.47849447606131434
100,0.33000001311302185,0.4000000059604645,0.5375395748530076,0.16957032740116118,mmlu:business_ethics,test,2.2203058630693704
29,0.17241379618644714,0.17241379618644714,0.36250000000000004,0.40207437194626905,mmlu:clinical_knowledge,validation,0.7451592560391873
265,0.2792452871799469,0.30188679695129395,0.5280529220319796,0.26935434926230956,mmlu:clinical_knowledge,test,4.865348369115964
16,0.375,0.375,0.3416666666666667,0.1909179538488388,mmlu:college_biology,validation,0.4683511189650744
144,0.3402777910232544,0.3611111044883728,0.4822771213748657,0.2097710371017456,mmlu:college_biology,test,2.8395253089256585
8,0.0,0.75,,0.203125,mmlu:college_chemistry,validation,0.538586504990235
100,0.14000000059604645,0.7900000214576721,0.6690199335548171,0.23148439168930054,mmlu:college_chemistry,test,2.1554214619100094
11,0.27272728085517883,0.7272727489471436,0.5,0.06321022727272729,mmlu:college_computer_science,validation,0.432837100001052
100,0.17000000178813934,0.8299999833106995,0.5,0.16593749999999996,mmlu:college_computer_science,test,2.085699924034998
11,0.0,0.9090909361839294,,0.31285509738055145,mmlu:college_mathematics,validation,0.4600177821703255
100,0.2199999988079071,0.7300000190734863,0.5777972027972028,0.14089842140674594,mmlu:college_mathematics,test,2.2360326079651713
22,0.3181818127632141,0.3181818127632141,0.6761904761904762,0.2457386146892201,mmlu:college_medicine,validation,0.5834844689816236
173,0.2947976887226105,0.30635836720466614,0.6648183863709417,0.2635476882058072,mmlu:college_medicine,test,3.5053497939370573
11,0.09090909361839294,0.8181818127632141,0.7999999999999999,0.2691761363636364,mmlu:college_physics,validation,0.489278880180791
102,0.0882352963089943,0.8627451062202454,0.6523297491039426,0.2881433788467856,mmlu:college_physics,test,2.2303003100678325
11,0.6363636255264282,0.6363636255264282,0.5178571428571428,0.11079546538266268,mmlu:computer_security,validation,0.4228699170053005
100,0.5,0.5199999809265137,0.581,0.0864453125,mmlu:computer_security,test,2.05534814693965
26,0.1538461595773697,0.3461538553237915,0.6534090909090909,0.1784855815080496,mmlu:conceptual_physics,validation,0.7357223110739142
235,0.3787234127521515,0.47659575939178467,0.5333230721871632,0.05061502735665502,mmlu:conceptual_physics,test,4.047491310862824
12,0.3333333432674408,0.4166666567325592,0.734375,0.1328125198682149,mmlu:econometrics,validation,0.5012654829770327
114,0.17543859779834747,0.19298245012760162,0.6284574468085107,0.37558253344736603,mmlu:econometrics,test,2.4978642149362713
16,0.1875,0.8125,0.16666666666666663,0.1481933556497097,mmlu:electrical_engineering,validation,0.45708017400465906
145,0.2137930989265442,0.7862069010734558,0.5178268251273345,0.10258620566335216,mmlu:electrical_engineering,test,2.8811137068551034
41,0.3658536672592163,0.6341463327407837,0.7115384615384615,0.23751906360067973,mmlu:elementary_mathematics,validation,1.0651486250571907
378,0.28042328357696533,0.7195767164230347,0.5615288568257492,0.05459450398172654,mmlu:elementary_mathematics,test,7.160776820965111
14,0.4285714328289032,0.4285714328289032,0.5833333333333333,0.12918529340199064,mmlu:formal_logic,validation,0.4078085529617965
126,0.2539682686328888,0.2539682686328888,0.6835106382978723,0.29777406132410444,mmlu:formal_logic,test,2.612819283036515
10,0.20000000298023224,0.20000000298023224,0.3125,0.5285156071186066,mmlu:global_facts,validation,0.5312563260085881
100,0.07999999821186066,0.07000000029802322,0.3267663043478261,0.5742578214406968,mmlu:global_facts,test,1.944357868982479
32,0.3125,0.5,0.5704545454545455,0.03967285156249999,mmlu:high_school_biology,validation,0.7804182500112802
310,0.3838709592819214,0.45483872294425964,0.5396189889568392,0.0802545318680425,mmlu:high_school_biology,test,5.585234286962077
22,0.1818181872367859,0.7272727489471436,0.8333333333333334,0.1880326650359414,mmlu:high_school_chemistry,validation,0.6691248889546841
203,0.1428571492433548,0.6403940916061401,0.5696591359492668,0.10154324182735876,mmlu:high_school_chemistry,test,4.159340595128015
9,0.4444444477558136,0.5555555820465088,0.04999999999999999,0.3832465344005161,mmlu:high_school_computer_science,validation,0.4127070140093565
100,0.4099999964237213,0.5899999737739563,0.4576271186440678,0.05335938453674319,mmlu:high_school_computer_science,test,2.0042459769174457
18,0.8333333134651184,0.8333333134651184,0.5,0.29036458333333337,mmlu:high_school_european_history,validation,0.7418819451704621
165,0.7090908885002136,0.7090908885002136,0.5,0.1661221590909091,mmlu:high_school_european_history,test,4.265176180982962
22,0.4545454680919647,0.5454545617103577,0.575,0.014914794401688969,mmlu:high_school_geography,validation,0.5963866668753326
198,0.3737373650074005,0.46464645862579346,0.5221774193548387,0.06328915947615499,mmlu:high_school_geography,test,3.6422499490436167
21,0.523809552192688,0.7142857313156128,0.7090909090909091,0.1910342403820583,mmlu:high_school_government_and_politics,validation,0.7711298640351743
193,0.5233160853385925,0.5803108811378479,0.6324257425742573,0.05936282842270446,mmlu:high_school_government_and_politics,test,3.7108246949501336
43,0.39534884691238403,0.4883720874786377,0.46945701357466063,0.03588300388912824,mmlu:high_school_macroeconomics,validation,1.0071432180702686
390,0.2897436022758484,0.6102564334869385,0.5768985016453149,0.0832732408474653,mmlu:high_school_macroeconomics,test,7.180880033178255
29,0.0,1.0,,0.18911637108901452,mmlu:high_school_mathematics,validation,0.6820607190020382
270,0.0555555559694767,0.9444444179534912,0.6235294117647059,0.12913775598561317,mmlu:high_school_mathematics,test,5.244347566040233
26,0.26923078298568726,0.38461539149284363,0.7781954887218046,0.14393029304651112,mmlu:high_school_microeconomics,validation,0.9141704279463738
238,0.3403361439704895,0.4285714328289032,0.5510733663599905,0.10364693879079416,mmlu:high_school_microeconomics,test,4.4437048479449
17,0.0,1.0,,0.3832720658358406,mmlu:high_school_physics,validation,0.6614953898824751
151,0.18543046712875366,0.8145695328712463,0.6270325203252033,0.19890833137840627,mmlu:high_school_physics,test,2.9721641109790653
60,0.5666666626930237,0.4333333373069763,0.5656108597285068,0.15358074307441716,mmlu:high_school_psychology,validation,1.3489743950776756
545,0.5009174346923828,0.4990825653076172,0.532967032967033,0.09026661520704217,mmlu:high_school_psychology,test,10.452563353115693
23,0.17391304671764374,0.739130437374115,0.5657894736842106,0.18138584883316702,mmlu:high_school_statistics,validation,0.7069731818046421
216,0.19907407462596893,0.7777777910232544,0.5497378679930098,0.21372252261197128,mmlu:high_school_statistics,test,4.217003274010494
22,0.6363636255264282,0.6363636255264282,0.5,0.09339488636363635,mmlu:high_school_us_history,validation,0.8016452600713819
204,0.5784313678741455,0.5784313678741455,0.5,0.03546262254901966,mmlu:high_school_us_history,test,5.124688723124564
26,0.7307692170143127,0.26923078298568726,0.5,0.2581129807692308,mmlu:high_school_world_history,validation,0.8160657009575516
237,0.552742600440979,0.4472573697566986,0.5,0.0800863660337553,mmlu:high_school_world_history,test,5.276030347915366
23,0.30434781312942505,0.30434781312942505,0.31249999999999994,0.31657607918200287,mmlu:human_aging,validation,0.6590974109712988
223,0.33183857798576355,0.33183857798576355,0.5928260475240342,0.29880186634747974,mmlu:human_aging,test,4.237233905121684
12,0.25,0.3333333432674408,0.8333333333333334,0.23339842756589257,mmlu:human_sexuality,validation,0.4638878048863262
131,0.4198473393917084,0.4580152630805969,0.5489234449760766,0.09759658802556627,mmlu:human_sexuality,test,2.5235766030382365
13,0.4615384638309479,0.4615384638309479,0.4761904761904762,0.15144229852236235,mmlu:international_law,validation,0.46347296610474586
121,0.6115702390670776,0.6198347210884094,0.5286083956296722,0.014236829497597466,mmlu:international_law,test,2.447780067101121
11,0.5454545617103577,0.5454545617103577,0.2666666666666666,0.1207386146892201,mmlu:jurisprudence,validation,0.47257537697441876
108,0.5185185074806213,0.5185185074806213,0.5159684065934066,0.16077111385486742,mmlu:jurisprudence,test,2.1763983729761094
18,0.4444444477558136,0.4444444477558136,0.20625,0.2931857672002581,mmlu:logical_fallacies,validation,0.6705876460764557
163,0.42944785952568054,0.42944785952568054,0.46313364055299533,0.2685486996100724,mmlu:logical_fallacies,test,3.341771050123498
11,0.3636363744735718,0.7272727489471436,0.3214285714285714,0.26491478356448084,mmlu:machine_learning,validation,0.5811117021366954
112,0.1964285671710968,0.8035714030265808,0.6045454545454545,0.20615932238953455,mmlu:machine_learning,test,2.389233004068956
11,0.27272728085517883,0.6363636255264282,0.5416666666666666,0.09481532465327869,mmlu:management,validation,0.4774389979429543
103,0.3689320385456085,0.6116504669189453,0.6050607287449393,0.07167779531293701,mmlu:management,test,2.086203381884843
25,0.20000000298023224,0.4399999976158142,0.515,0.0934374976158142,mmlu:marketing,validation,0.6230141669511795
234,0.39743590354919434,0.45299145579338074,0.4950049569129871,0.07862580026316845,mmlu:marketing,test,4.256661225110292
11,0.7272727489471436,0.6363636255264282,0.625,0.08700286258350717,mmlu:medical_genetics,validation,0.49973946483805776
100,0.4099999964237213,0.47999998927116394,0.5905332782141381,0.054921898245811444,mmlu:medical_genetics,test,1.8622529001440853
86,0.41860464215278625,0.5232558250427246,0.5380555555555555,0.012172948482424673,mmlu:miscellaneous,validation,1.9059799159877002
783,0.4533844292163849,0.5593869686126709,0.5948565223114387,0.02419078357679477,mmlu:miscellaneous,test,14.26362912892364
38,0.4736842215061188,0.4736842215061188,0.7347222222222223,0.1389802788433276,mmlu:moral_disputes,validation,0.9202983588911593
346,0.41040462255477905,0.41040462255477905,0.47110604805302403,0.20129604921864633,mmlu:moral_disputes,test,6.558632947970182
100,0.5099999904632568,0.5099999904632568,0.5348139255702281,0.1869922065734863,mmlu:moral_scenarios,validation,2.0930204899050295
895,0.46145251393318176,0.46145251393318176,0.4688269217244531,0.23573671093200171,mmlu:moral_scenarios,test,17.240276145050302
33,0.3636363744735718,0.3636363744735718,0.5912698412698413,0.2437263329823812,mmlu:nutrition,validation,0.947741508949548
306,0.4084967374801636,0.4117647111415863,0.5321988950276243,0.19143175708702184,mmlu:nutrition,test,5.993304652161896
34,0.3529411852359772,0.3529411852359772,0.553030303030303,0.2514935661764706,mmlu:philosophy,validation,0.7863363120704889
311,0.3376205861568451,0.3536977469921112,0.5060564031437818,0.25048987006834467,mmlu:philosophy,test,5.901702981907874
35,0.2857142984867096,0.6571428775787354,0.44,0.151450879233224,mmlu:prehistory,validation,1.0016395840793848
324,0.34259259700775146,0.6419752836227417,0.584676225521296,0.0827425874677705,mmlu:prehistory,test,6.110426772153005
31,0.06451612710952759,0.8387096524238586,0.5,0.26915321811552967,mmlu:professional_accounting,validation,0.8503645921591669
282,0.1560283750295639,0.7659574747085571,0.600792589763178,0.20492574255517187,mmlu:professional_accounting,test,5.441008958034217
170,0.30588236451148987,0.30588236451148987,0.5,0.2761488970588235,mmlu:professional_law,validation,3.976537083974108
1534,0.3200782239437103,0.3200782239437103,0.5,0.2619530231421121,mmlu:professional_law,test,32.61444449191913
31,0.25806450843811035,0.7419354915618896,0.5,0.20677923387096775,mmlu:professional_medicine,validation,0.8652470798697323
272,0.23529411852359772,0.7647058963775635,0.5,0.22954963235294112,mmlu:professional_medicine,test,5.550030020996928
69,0.37681159377098083,0.5507246255874634,0.4776386404293381,0.01964445131412451,mmlu:professional_psychology,validation,1.6838059430010617
612,0.32189542055130005,0.5784313678741455,0.5254602165005199,0.04907708132968233,mmlu:professional_psychology,test,11.30836941092275
12,0.3333333432674408,0.3333333432674408,0.65625,0.19596354166666669,mmlu:public_relations,validation,0.39148421213030815
110,0.3272727131843567,0.4727272689342499,0.6064189189189189,0.06455967643044212,mmlu:public_relations,test,2.17126428312622
27,0.7407407164573669,0.7777777910232544,0.7607142857142857,0.21180553568734067,mmlu:security_studies,validation,0.7782601758372039
245,0.6816326379776001,0.7020407915115356,0.6323122984799632,0.12504783187593732,mmlu:security_studies,test,5.058725533075631
22,0.5,0.5,0.6735537190082644,0.13068182630972427,mmlu:sociology,validation,0.5860395319759846
201,0.45771142840385437,0.45771142840385437,0.569006781013163,0.14528915775356008,mmlu:sociology,test,3.855299295159057
11,0.5454545617103577,0.5454545617103577,0.65,0.11896307360042224,mmlu:us_foreign_policy,validation,0.4881960100028664
100,0.550000011920929,0.550000011920929,0.4888888888888889,0.0893749988079071,mmlu:us_foreign_policy,test,1.9640537698287517
18,0.2777777910232544,0.2777777910232544,0.7076923076923076,0.479383690489663,mmlu:virology,validation,0.6136545778717846
166,0.34337350726127625,0.34337350726127625,0.533961049412522,0.4188158896314093,mmlu:virology,test,3.207802555989474
19,0.6315789222717285,0.5263158082962036,0.6785714285714286,0.009868424189718117,mmlu:world_religions,validation,0.573342293035239
171,0.5380116701126099,0.5497075915336609,0.5706521739130436,0.03225512393036778,mmlu:world_religions,test,3.1483621830120683
